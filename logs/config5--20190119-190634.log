vocabulary size: 13035
<type 'int'>
<type 'numpy.float64'>
n tunes: 999
n train tunes: 951
n validation tunes: 48
min, max length 39 835
Building the model
  number of parameters: 208545956
  layer output shapes:               #params:   output shape:
    InputLayer                       0          (16, None)
    EmbeddingLayer                   169911225  (16, None, 13035)
    InputLayer                       0          (16, None)
    LSTMLayer                        27747328   (16, None, 512)
    DropoutLayer                     0          (16, None, 512)
    LSTMLayer                        2100224    (16, None, 512)
    DropoutLayer                     0          (16, None, 512)
    LSTMLayer                        2100224    (16, None, 512)
    DropoutLayer                     0          (16, None, 512)
    ReshapeLayer                     0          (None, 512)
    DenseLayer                       6686955    (None, 13035)
Train model
1/5900 (epoch 0.017) train_loss=696.37915039 time/batch=0.97s
2/5900 (epoch 0.034) train_loss=1317.14196777 time/batch=0.49s
3/5900 (epoch 0.051) train_loss=624.87884521 time/batch=0.38s
4/5900 (epoch 0.068) train_loss=702.78039551 time/batch=0.39s
5/5900 (epoch 0.085) train_loss=971.41235352 time/batch=0.63s
6/5900 (epoch 0.102) train_loss=976.19421387 time/batch=0.76s
7/5900 (epoch 0.119) train_loss=602.02819824 time/batch=0.41s
8/5900 (epoch 0.136) train_loss=440.12408447 time/batch=0.27s
9/5900 (epoch 0.153) train_loss=2144.59863281 time/batch=2.65s
10/5900 (epoch 0.169) train_loss=648.96899414 time/batch=0.78s
11/5900 (epoch 0.186) train_loss=631.21368408 time/batch=0.37s
12/5900 (epoch 0.203) train_loss=468.56362915 time/batch=0.28s
13/5900 (epoch 0.220) train_loss=618.11779785 time/batch=0.36s
14/5900 (epoch 0.237) train_loss=465.11758423 time/batch=0.30s
15/5900 (epoch 0.254) train_loss=315.41912842 time/batch=0.19s
16/5900 (epoch 0.271) train_loss=700.83001709 time/batch=0.39s
17/5900 (epoch 0.288) train_loss=377.24365234 time/batch=0.26s
18/5900 (epoch 0.305) train_loss=271.63269043 time/batch=0.17s
19/5900 (epoch 0.322) train_loss=274.56588745 time/batch=0.18s
20/5900 (epoch 0.339) train_loss=748.92974854 time/batch=0.40s
21/5900 (epoch 0.356) train_loss=607.16674805 time/batch=0.38s
22/5900 (epoch 0.373) train_loss=315.98724365 time/batch=0.22s
23/5900 (epoch 0.390) train_loss=662.49926758 time/batch=0.39s
24/5900 (epoch 0.407) train_loss=381.62121582 time/batch=0.26s
25/5900 (epoch 0.424) train_loss=404.05740356 time/batch=0.26s
26/5900 (epoch 0.441) train_loss=254.75393677 time/batch=0.19s
27/5900 (epoch 0.458) train_loss=502.85229492 time/batch=0.28s
28/5900 (epoch 0.475) train_loss=552.05151367 time/batch=0.33s
29/5900 (epoch 0.492) train_loss=516.63562012 time/batch=0.33s
30/5900 (epoch 0.508) train_loss=589.62573242 time/batch=0.38s
31/5900 (epoch 0.525) train_loss=475.97647095 time/batch=0.30s
32/5900 (epoch 0.542) train_loss=257.45144653 time/batch=0.19s
33/5900 (epoch 0.559) train_loss=451.08767700 time/batch=0.28s
34/5900 (epoch 0.576) train_loss=509.79101562 time/batch=0.30s
35/5900 (epoch 0.593) train_loss=292.69830322 time/batch=0.19s
36/5900 (epoch 0.610) train_loss=605.83374023 time/batch=1.75s
37/5900 (epoch 0.627) train_loss=302.47790527 time/batch=0.47s
38/5900 (epoch 0.644) train_loss=411.84347534 time/batch=0.26s
39/5900 (epoch 0.661) train_loss=244.47729492 time/batch=0.19s
40/5900 (epoch 0.678) train_loss=511.33618164 time/batch=0.30s
41/5900 (epoch 0.695) train_loss=707.81146240 time/batch=0.44s
42/5900 (epoch 0.712) train_loss=561.28979492 time/batch=0.47s
43/5900 (epoch 0.729) train_loss=496.76031494 time/batch=0.31s
44/5900 (epoch 0.746) train_loss=333.02459717 time/batch=0.22s
45/5900 (epoch 0.763) train_loss=518.82672119 time/batch=0.31s
46/5900 (epoch 0.780) train_loss=244.12362671 time/batch=0.19s
47/5900 (epoch 0.797) train_loss=393.49765015 time/batch=0.31s
48/5900 (epoch 0.814) train_loss=283.81674194 time/batch=0.20s
49/5900 (epoch 0.831) train_loss=236.68212891 time/batch=0.17s
50/5900 (epoch 0.847) train_loss=228.25424194 time/batch=0.19s
51/5900 (epoch 0.864) train_loss=252.06866455 time/batch=0.17s
52/5900 (epoch 0.881) train_loss=266.37579346 time/batch=0.19s
53/5900 (epoch 0.898) train_loss=259.04776001 time/batch=0.19s
54/5900 (epoch 0.915) train_loss=239.34350586 time/batch=0.17s
55/5900 (epoch 0.932) train_loss=233.16423035 time/batch=0.19s
56/5900 (epoch 0.949) train_loss=227.93544006 time/batch=0.19s
57/5900 (epoch 0.966) train_loss=248.74717712 time/batch=0.17s
58/5900 (epoch 0.983) train_loss=251.27667236 time/batch=0.19s
59/5900 (epoch 1.000) train_loss=255.99656677 time/batch=0.19s
60/5900 (epoch 1.017) train_loss=230.24417114 time/batch=0.17s
61/5900 (epoch 1.034) train_loss=546.32238770 time/batch=0.30s
62/5900 (epoch 1.051) train_loss=2237.47314453 time/batch=2.66s
63/5900 (epoch 1.068) train_loss=540.14147949 time/batch=2.22s
64/5900 (epoch 1.085) train_loss=830.77148438 time/batch=0.78s
65/5900 (epoch 1.102) train_loss=361.85015869 time/batch=0.28s
66/5900 (epoch 1.119) train_loss=622.15576172 time/batch=0.38s
67/5900 (epoch 1.136) train_loss=492.15966797 time/batch=0.33s
68/5900 (epoch 1.153) train_loss=659.06518555 time/batch=0.44s
69/5900 (epoch 1.169) train_loss=647.06347656 time/batch=0.44s
70/5900 (epoch 1.186) train_loss=467.85556030 time/batch=0.34s
71/5900 (epoch 1.203) train_loss=411.18652344 time/batch=0.27s
72/5900 (epoch 1.220) train_loss=411.40838623 time/batch=0.27s
73/5900 (epoch 1.237) train_loss=800.46942139 time/batch=0.55s
74/5900 (epoch 1.254) train_loss=827.58312988 time/batch=0.69s
75/5900 (epoch 1.271) train_loss=490.00030518 time/batch=0.38s
76/5900 (epoch 1.288) train_loss=488.63305664 time/batch=0.33s
77/5900 (epoch 1.305) train_loss=292.34158325 time/batch=0.23s
78/5900 (epoch 1.322) train_loss=501.31222534 time/batch=0.33s
79/5900 (epoch 1.339) train_loss=583.03259277 time/batch=0.40s
80/5900 (epoch 1.356) train_loss=374.83255005 time/batch=0.26s
81/5900 (epoch 1.373) train_loss=553.31909180 time/batch=0.35s
82/5900 (epoch 1.390) train_loss=265.40765381 time/batch=0.21s
83/5900 (epoch 1.407) train_loss=405.48294067 time/batch=0.26s
84/5900 (epoch 1.424) train_loss=378.58111572 time/batch=0.26s
85/5900 (epoch 1.441) train_loss=533.23474121 time/batch=0.35s
86/5900 (epoch 1.458) train_loss=397.62969971 time/batch=0.28s
87/5900 (epoch 1.475) train_loss=242.61178589 time/batch=0.19s
88/5900 (epoch 1.492) train_loss=416.90759277 time/batch=0.28s
89/5900 (epoch 1.508) train_loss=310.74090576 time/batch=0.27s
90/5900 (epoch 1.525) train_loss=622.70190430 time/batch=0.41s
91/5900 (epoch 1.542) train_loss=639.61804199 time/batch=0.66s
92/5900 (epoch 1.559) train_loss=241.54417419 time/batch=0.25s
93/5900 (epoch 1.576) train_loss=250.42047119 time/batch=0.19s
94/5900 (epoch 1.593) train_loss=502.87194824 time/batch=0.31s
95/5900 (epoch 1.610) train_loss=280.55856323 time/batch=0.20s
96/5900 (epoch 1.627) train_loss=531.04455566 time/batch=0.33s
97/5900 (epoch 1.644) train_loss=444.20037842 time/batch=0.33s
98/5900 (epoch 1.661) train_loss=459.96936035 time/batch=0.36s
99/5900 (epoch 1.678) train_loss=626.38769531 time/batch=0.65s
100/5900 (epoch 1.695) train_loss=467.54864502 time/batch=0.34s
101/5900 (epoch 1.712) train_loss=258.16680908 time/batch=0.20s
102/5900 (epoch 1.729) train_loss=410.32266235 time/batch=0.27s
103/5900 (epoch 1.746) train_loss=232.78775024 time/batch=0.19s
104/5900 (epoch 1.763) train_loss=225.06585693 time/batch=0.19s
105/5900 (epoch 1.780) train_loss=244.64453125 time/batch=0.25s
106/5900 (epoch 1.797) train_loss=222.34846497 time/batch=0.20s
107/5900 (epoch 1.814) train_loss=417.21853638 time/batch=0.34s
108/5900 (epoch 1.831) train_loss=271.65429688 time/batch=0.20s
109/5900 (epoch 1.847) train_loss=210.76718140 time/batch=0.19s
110/5900 (epoch 1.864) train_loss=209.08102417 time/batch=0.17s
111/5900 (epoch 1.881) train_loss=239.67373657 time/batch=0.34s
112/5900 (epoch 1.898) train_loss=213.56201172 time/batch=0.20s
113/5900 (epoch 1.915) train_loss=238.24851990 time/batch=0.19s
114/5900 (epoch 1.932) train_loss=200.81027222 time/batch=0.17s
115/5900 (epoch 1.949) train_loss=213.32023621 time/batch=0.19s
116/5900 (epoch 1.966) train_loss=205.08843994 time/batch=0.19s
117/5900 (epoch 1.983) train_loss=287.45867920 time/batch=0.33s
118/5900 (epoch 2.000) train_loss=194.52899170 time/batch=0.20s
119/5900 (epoch 2.017) train_loss=707.54174805 time/batch=0.45s
120/5900 (epoch 2.034) train_loss=1474.26342773 time/batch=2.05s
121/5900 (epoch 2.051) train_loss=557.98559570 time/batch=0.65s
122/5900 (epoch 2.068) train_loss=754.02612305 time/batch=0.48s
123/5900 (epoch 2.085) train_loss=568.50592041 time/batch=0.39s
124/5900 (epoch 2.102) train_loss=1316.43432617 time/batch=2.66s
125/5900 (epoch 2.119) train_loss=250.16928101 time/batch=0.64s
126/5900 (epoch 2.136) train_loss=430.88150024 time/batch=0.28s
127/5900 (epoch 2.153) train_loss=749.52954102 time/batch=0.52s
128/5900 (epoch 2.169) train_loss=474.95285034 time/batch=0.36s
129/5900 (epoch 2.186) train_loss=482.19866943 time/batch=0.34s
130/5900 (epoch 2.203) train_loss=413.17102051 time/batch=0.31s
131/5900 (epoch 2.220) train_loss=577.40734863 time/batch=0.40s
132/5900 (epoch 2.237) train_loss=321.55197144 time/batch=0.26s
133/5900 (epoch 2.254) train_loss=477.52807617 time/batch=1.75s
134/5900 (epoch 2.271) train_loss=577.16253662 time/batch=0.67s
135/5900 (epoch 2.288) train_loss=401.88574219 time/batch=0.31s
136/5900 (epoch 2.305) train_loss=457.12786865 time/batch=0.31s
137/5900 (epoch 2.322) train_loss=254.52462769 time/batch=0.22s
138/5900 (epoch 2.339) train_loss=526.24987793 time/batch=0.34s
139/5900 (epoch 2.356) train_loss=257.22808838 time/batch=0.23s
140/5900 (epoch 2.373) train_loss=335.04449463 time/batch=0.26s
141/5900 (epoch 2.390) train_loss=410.99536133 time/batch=0.30s
142/5900 (epoch 2.407) train_loss=480.02792358 time/batch=0.36s
143/5900 (epoch 2.424) train_loss=389.84927368 time/batch=0.28s
144/5900 (epoch 2.441) train_loss=556.70312500 time/batch=0.38s
145/5900 (epoch 2.458) train_loss=449.88574219 time/batch=0.30s
146/5900 (epoch 2.475) train_loss=539.25927734 time/batch=0.38s
147/5900 (epoch 2.492) train_loss=310.88952637 time/batch=0.27s
148/5900 (epoch 2.508) train_loss=618.13867188 time/batch=0.42s
149/5900 (epoch 2.525) train_loss=566.16882324 time/batch=0.42s
150/5900 (epoch 2.542) train_loss=258.35101318 time/batch=0.28s
151/5900 (epoch 2.559) train_loss=367.73345947 time/batch=0.27s
152/5900 (epoch 2.576) train_loss=413.81707764 time/batch=0.28s
153/5900 (epoch 2.593) train_loss=448.91674805 time/batch=0.31s
154/5900 (epoch 2.610) train_loss=448.07977295 time/batch=0.33s
155/5900 (epoch 2.627) train_loss=465.10729980 time/batch=0.41s
156/5900 (epoch 2.644) train_loss=197.84776306 time/batch=0.20s
157/5900 (epoch 2.661) train_loss=194.74423218 time/batch=0.19s
158/5900 (epoch 2.678) train_loss=234.13453674 time/batch=0.18s
159/5900 (epoch 2.695) train_loss=202.83143616 time/batch=0.19s
160/5900 (epoch 2.712) train_loss=446.49838257 time/batch=0.30s
161/5900 (epoch 2.729) train_loss=191.59460449 time/batch=0.20s
162/5900 (epoch 2.746) train_loss=342.88281250 time/batch=0.25s
163/5900 (epoch 2.763) train_loss=198.70303345 time/batch=0.19s
164/5900 (epoch 2.780) train_loss=216.50112915 time/batch=0.19s
165/5900 (epoch 2.797) train_loss=221.15881348 time/batch=0.25s
166/5900 (epoch 2.814) train_loss=225.66226196 time/batch=0.19s
167/5900 (epoch 2.831) train_loss=204.53393555 time/batch=0.19s
168/5900 (epoch 2.847) train_loss=192.62258911 time/batch=0.19s
169/5900 (epoch 2.864) train_loss=177.54791260 time/batch=0.17s
170/5900 (epoch 2.881) train_loss=176.20457458 time/batch=0.19s
171/5900 (epoch 2.898) train_loss=185.72215271 time/batch=0.17s
172/5900 (epoch 2.915) train_loss=193.44363403 time/batch=0.19s
173/5900 (epoch 2.932) train_loss=186.96688843 time/batch=0.17s
174/5900 (epoch 2.949) train_loss=208.00970459 time/batch=0.19s
175/5900 (epoch 2.966) train_loss=178.72412109 time/batch=0.18s
176/5900 (epoch 2.983) train_loss=193.15838623 time/batch=0.17s
177/5900 (epoch 3.000) train_loss=209.47088623 time/batch=0.19s
178/5900 (epoch 3.017) train_loss=400.49700928 time/batch=0.25s
179/5900 (epoch 3.034) train_loss=877.14355469 time/batch=0.61s
180/5900 (epoch 3.051) train_loss=625.95324707 time/batch=0.45s
181/5900 (epoch 3.068) train_loss=618.30096436 time/batch=0.44s
182/5900 (epoch 3.085) train_loss=302.05657959 time/batch=0.25s
183/5900 (epoch 3.102) train_loss=333.40304565 time/batch=0.25s
184/5900 (epoch 3.119) train_loss=1849.51684570 time/batch=2.64s
185/5900 (epoch 3.136) train_loss=539.13623047 time/batch=0.78s
186/5900 (epoch 3.153) train_loss=411.57000732 time/batch=0.30s
187/5900 (epoch 3.169) train_loss=796.94885254 time/batch=0.63s
188/5900 (epoch 3.186) train_loss=390.46994019 time/batch=0.36s
189/5900 (epoch 3.203) train_loss=516.91546631 time/batch=0.36s
190/5900 (epoch 3.220) train_loss=474.30755615 time/batch=0.36s
191/5900 (epoch 3.237) train_loss=331.87020874 time/batch=0.27s
192/5900 (epoch 3.254) train_loss=649.21850586 time/batch=0.47s
193/5900 (epoch 3.271) train_loss=270.53567505 time/batch=0.24s
194/5900 (epoch 3.288) train_loss=247.70318604 time/batch=0.20s
195/5900 (epoch 3.305) train_loss=460.13497925 time/batch=0.31s
196/5900 (epoch 3.322) train_loss=667.49700928 time/batch=0.48s
197/5900 (epoch 3.339) train_loss=361.75329590 time/batch=0.30s
198/5900 (epoch 3.356) train_loss=390.77734375 time/batch=0.30s
199/5900 (epoch 3.373) train_loss=350.17022705 time/batch=0.27s
200/5900 (epoch 3.390) train_loss=475.96725464 time/batch=0.34s
201/5900 (epoch 3.407) train_loss=217.28117371 time/batch=0.20s
202/5900 (epoch 3.424) train_loss=441.54199219 time/batch=0.30s
203/5900 (epoch 3.441) train_loss=311.53497314 time/batch=0.28s
204/5900 (epoch 3.458) train_loss=461.29687500 time/batch=0.33s
205/5900 (epoch 3.475) train_loss=227.00933838 time/batch=0.22s
206/5900 (epoch 3.492) train_loss=333.44635010 time/batch=0.27s
207/5900 (epoch 3.508) train_loss=259.79388428 time/batch=0.28s
208/5900 (epoch 3.525) train_loss=596.67669678 time/batch=0.39s
209/5900 (epoch 3.542) train_loss=259.36416626 time/batch=0.20s
210/5900 (epoch 3.559) train_loss=410.98071289 time/batch=0.30s
211/5900 (epoch 3.576) train_loss=388.42077637 time/batch=0.30s
212/5900 (epoch 3.593) train_loss=501.13372803 time/batch=0.36s
213/5900 (epoch 3.610) train_loss=430.50781250 time/batch=0.33s
214/5900 (epoch 3.627) train_loss=181.29306030 time/batch=0.19s
215/5900 (epoch 3.644) train_loss=577.45422363 time/batch=0.39s
216/5900 (epoch 3.661) train_loss=329.22354126 time/batch=1.78s
217/5900 (epoch 3.678) train_loss=555.52929688 time/batch=0.64s
218/5900 (epoch 3.695) train_loss=434.61090088 time/batch=0.33s
219/5900 (epoch 3.712) train_loss=338.32232666 time/batch=1.73s
220/5900 (epoch 3.729) train_loss=191.42211914 time/batch=0.45s
221/5900 (epoch 3.746) train_loss=252.63800049 time/batch=0.31s
222/5900 (epoch 3.763) train_loss=179.62399292 time/batch=0.19s
223/5900 (epoch 3.780) train_loss=178.96665955 time/batch=0.19s
224/5900 (epoch 3.797) train_loss=191.24893188 time/batch=0.17s
225/5900 (epoch 3.814) train_loss=448.34814453 time/batch=0.35s
226/5900 (epoch 3.831) train_loss=393.03265381 time/batch=0.40s
227/5900 (epoch 3.847) train_loss=240.13308716 time/batch=0.20s
228/5900 (epoch 3.864) train_loss=200.26609802 time/batch=0.19s
229/5900 (epoch 3.881) train_loss=186.38442993 time/batch=0.17s
230/5900 (epoch 3.898) train_loss=188.37564087 time/batch=0.17s
231/5900 (epoch 3.915) train_loss=180.59121704 time/batch=0.19s
232/5900 (epoch 3.932) train_loss=181.96490479 time/batch=0.17s
233/5900 (epoch 3.949) train_loss=189.40063477 time/batch=0.19s
234/5900 (epoch 3.966) train_loss=185.93991089 time/batch=0.19s
235/5900 (epoch 3.983) train_loss=198.38046265 time/batch=0.19s
236/5900 (epoch 4.000) train_loss=203.80036926 time/batch=0.19s
237/5900 (epoch 4.017) train_loss=906.02844238 time/batch=0.61s
238/5900 (epoch 4.034) train_loss=541.15832520 time/batch=0.42s
239/5900 (epoch 4.051) train_loss=612.07238770 time/batch=0.47s
240/5900 (epoch 4.068) train_loss=451.34045410 time/batch=0.35s
241/5900 (epoch 4.085) train_loss=578.27288818 time/batch=0.41s
242/5900 (epoch 4.102) train_loss=234.54293823 time/batch=0.22s
243/5900 (epoch 4.119) train_loss=1902.62109375 time/batch=2.64s
244/5900 (epoch 4.136) train_loss=455.35412598 time/batch=0.75s
245/5900 (epoch 4.153) train_loss=402.09808350 time/batch=0.30s
246/5900 (epoch 4.169) train_loss=333.74273682 time/batch=0.27s
247/5900 (epoch 4.186) train_loss=305.93603516 time/batch=0.23s
248/5900 (epoch 4.203) train_loss=327.24987793 time/batch=0.24s
249/5900 (epoch 4.220) train_loss=628.66662598 time/batch=0.47s
250/5900 (epoch 4.237) train_loss=368.79275513 time/batch=0.30s
251/5900 (epoch 4.254) train_loss=750.41223145 time/batch=0.64s
252/5900 (epoch 4.271) train_loss=589.54644775 time/batch=0.47s
253/5900 (epoch 4.288) train_loss=388.31024170 time/batch=0.31s
254/5900 (epoch 4.305) train_loss=476.23037720 time/batch=1.78s
255/5900 (epoch 4.322) train_loss=340.97277832 time/batch=0.53s
256/5900 (epoch 4.339) train_loss=383.83828735 time/batch=0.30s
257/5900 (epoch 4.356) train_loss=646.72009277 time/batch=0.47s
258/5900 (epoch 4.373) train_loss=350.35217285 time/batch=0.31s
259/5900 (epoch 4.390) train_loss=377.35742188 time/batch=0.30s
260/5900 (epoch 4.407) train_loss=439.64465332 time/batch=0.34s
261/5900 (epoch 4.424) train_loss=424.24371338 time/batch=0.33s
262/5900 (epoch 4.441) train_loss=190.70788574 time/batch=0.20s
263/5900 (epoch 4.458) train_loss=223.98916626 time/batch=0.19s
264/5900 (epoch 4.475) train_loss=239.91143799 time/batch=0.20s
265/5900 (epoch 4.492) train_loss=183.36441040 time/batch=0.17s
266/5900 (epoch 4.508) train_loss=274.32540894 time/batch=0.23s
267/5900 (epoch 4.525) train_loss=521.22167969 time/batch=0.38s
268/5900 (epoch 4.542) train_loss=409.80084229 time/batch=0.33s
269/5900 (epoch 4.559) train_loss=427.79974365 time/batch=0.33s
270/5900 (epoch 4.576) train_loss=424.47979736 time/batch=0.34s
271/5900 (epoch 4.593) train_loss=538.37438965 time/batch=0.39s
272/5900 (epoch 4.610) train_loss=473.71575928 time/batch=0.35s
273/5900 (epoch 4.627) train_loss=306.10113525 time/batch=0.27s
274/5900 (epoch 4.644) train_loss=483.40515137 time/batch=0.36s
275/5900 (epoch 4.661) train_loss=439.87142944 time/batch=0.35s
276/5900 (epoch 4.678) train_loss=464.64233398 time/batch=0.36s
277/5900 (epoch 4.695) train_loss=241.11761475 time/batch=0.20s
278/5900 (epoch 4.712) train_loss=255.59945679 time/batch=0.25s
279/5900 (epoch 4.729) train_loss=444.79232788 time/batch=0.35s
280/5900 (epoch 4.746) train_loss=190.96530151 time/batch=0.22s
281/5900 (epoch 4.763) train_loss=178.05245972 time/batch=0.17s
282/5900 (epoch 4.780) train_loss=173.60519409 time/batch=0.17s
283/5900 (epoch 4.797) train_loss=196.95584106 time/batch=0.19s
284/5900 (epoch 4.814) train_loss=169.57653809 time/batch=0.17s
285/5900 (epoch 4.831) train_loss=182.93287659 time/batch=0.19s
286/5900 (epoch 4.847) train_loss=180.53863525 time/batch=0.19s
287/5900 (epoch 4.864) train_loss=166.19905090 time/batch=0.17s
288/5900 (epoch 4.881) train_loss=158.46520996 time/batch=0.19s
289/5900 (epoch 4.898) train_loss=153.57363892 time/batch=0.19s
290/5900 (epoch 4.915) train_loss=167.18705750 time/batch=0.17s
291/5900 (epoch 4.932) train_loss=175.15744019 time/batch=0.19s
292/5900 (epoch 4.949) train_loss=173.56886292 time/batch=0.17s
293/5900 (epoch 4.966) train_loss=160.18742371 time/batch=0.19s
294/5900 (epoch 4.983) train_loss=145.36711121 time/batch=0.17s
295/5900 (epoch 5.000) train_loss=143.73126221 time/batch=0.19s
296/5900 (epoch 5.017) train_loss=1392.99853516 time/batch=2.02s
297/5900 (epoch 5.034) train_loss=367.01220703 time/batch=0.57s
298/5900 (epoch 5.051) train_loss=550.18542480 time/batch=0.38s
299/5900 (epoch 5.068) train_loss=583.33831787 time/batch=0.44s
300/5900 (epoch 5.085) train_loss=446.67498779 time/batch=0.35s
301/5900 (epoch 5.102) train_loss=375.39938354 time/batch=0.31s
302/5900 (epoch 5.119) train_loss=229.16323853 time/batch=0.22s
303/5900 (epoch 5.136) train_loss=672.68774414 time/batch=0.50s
304/5900 (epoch 5.153) train_loss=506.77777100 time/batch=0.42s
305/5900 (epoch 5.169) train_loss=503.52801514 time/batch=0.42s
306/5900 (epoch 5.186) train_loss=1300.52148438 time/batch=2.66s
307/5900 (epoch 5.203) train_loss=166.61338806 time/batch=0.62s
308/5900 (epoch 5.220) train_loss=354.97393799 time/batch=0.27s
309/5900 (epoch 5.237) train_loss=295.82385254 time/batch=0.25s
310/5900 (epoch 5.254) train_loss=262.11901855 time/batch=0.24s
311/5900 (epoch 5.271) train_loss=359.42620850 time/batch=0.30s
312/5900 (epoch 5.288) train_loss=374.45159912 time/batch=0.31s
313/5900 (epoch 5.305) train_loss=651.98797607 time/batch=0.53s
314/5900 (epoch 5.322) train_loss=465.83746338 time/batch=0.40s
315/5900 (epoch 5.339) train_loss=330.58325195 time/batch=0.30s
316/5900 (epoch 5.356) train_loss=305.88031006 time/batch=1.77s
317/5900 (epoch 5.373) train_loss=424.95046997 time/batch=0.61s
318/5900 (epoch 5.390) train_loss=325.52899170 time/batch=0.27s
319/5900 (epoch 5.407) train_loss=291.24783325 time/batch=0.27s
320/5900 (epoch 5.424) train_loss=554.17407227 time/batch=0.44s
321/5900 (epoch 5.441) train_loss=432.17608643 time/batch=0.37s
322/5900 (epoch 5.458) train_loss=557.30603027 time/batch=0.44s
323/5900 (epoch 5.475) train_loss=303.39837646 time/batch=0.30s
324/5900 (epoch 5.492) train_loss=429.86965942 time/batch=0.34s
325/5900 (epoch 5.508) train_loss=419.32446289 time/batch=0.36s
326/5900 (epoch 5.525) train_loss=448.87957764 time/batch=0.37s
327/5900 (epoch 5.542) train_loss=138.20068359 time/batch=0.20s
328/5900 (epoch 5.559) train_loss=148.53701782 time/batch=0.19s
329/5900 (epoch 5.576) train_loss=380.07107544 time/batch=0.34s
330/5900 (epoch 5.593) train_loss=379.38391113 time/batch=0.33s
331/5900 (epoch 5.610) train_loss=301.31066895 time/batch=1.73s
332/5900 (epoch 5.627) train_loss=191.57112122 time/batch=0.45s
333/5900 (epoch 5.644) train_loss=203.88215637 time/batch=0.20s
334/5900 (epoch 5.661) train_loss=365.58108521 time/batch=0.28s
335/5900 (epoch 5.678) train_loss=202.09974670 time/batch=0.20s
336/5900 (epoch 5.695) train_loss=416.13085938 time/batch=0.28s
337/5900 (epoch 5.712) train_loss=224.01568604 time/batch=0.27s
338/5900 (epoch 5.729) train_loss=327.17108154 time/batch=0.30s
339/5900 (epoch 5.746) train_loss=162.93473816 time/batch=0.20s
340/5900 (epoch 5.763) train_loss=183.83064270 time/batch=0.26s
341/5900 (epoch 5.780) train_loss=253.79205322 time/batch=0.31s
342/5900 (epoch 5.797) train_loss=141.02676392 time/batch=0.19s
343/5900 (epoch 5.814) train_loss=294.31072998 time/batch=0.31s
344/5900 (epoch 5.831) train_loss=150.79090881 time/batch=0.20s
345/5900 (epoch 5.847) train_loss=140.43774414 time/batch=0.19s
346/5900 (epoch 5.864) train_loss=148.53228760 time/batch=0.19s
347/5900 (epoch 5.881) train_loss=205.04710388 time/batch=0.17s
348/5900 (epoch 5.898) train_loss=153.51123047 time/batch=0.19s
349/5900 (epoch 5.915) train_loss=146.97164917 time/batch=0.17s
350/5900 (epoch 5.932) train_loss=142.43806458 time/batch=0.19s
351/5900 (epoch 5.949) train_loss=134.08412170 time/batch=0.19s
352/5900 (epoch 5.966) train_loss=126.74142456 time/batch=0.17s
353/5900 (epoch 5.983) train_loss=125.03838348 time/batch=0.17s
354/5900 (epoch 6.000) train_loss=122.91754913 time/batch=0.19s
355/5900 (epoch 6.017) train_loss=364.07489014 time/batch=0.30s
356/5900 (epoch 6.034) train_loss=263.17938232 time/batch=0.25s
357/5900 (epoch 6.051) train_loss=229.61187744 time/batch=0.23s
358/5900 (epoch 6.068) train_loss=316.53277588 time/batch=0.28s
359/5900 (epoch 6.085) train_loss=383.57403564 time/batch=0.33s
360/5900 (epoch 6.102) train_loss=551.50500488 time/batch=0.45s
361/5900 (epoch 6.119) train_loss=383.49865723 time/batch=0.34s
362/5900 (epoch 6.136) train_loss=282.51513672 time/batch=0.27s
363/5900 (epoch 6.153) train_loss=331.59432983 time/batch=0.28s
364/5900 (epoch 6.169) train_loss=345.38308716 time/batch=0.31s
365/5900 (epoch 6.186) train_loss=577.69213867 time/batch=0.41s
366/5900 (epoch 6.203) train_loss=456.24404907 time/batch=1.80s
367/5900 (epoch 6.220) train_loss=536.97534180 time/batch=0.64s
368/5900 (epoch 6.237) train_loss=188.69314575 time/batch=0.20s
369/5900 (epoch 6.254) train_loss=218.21939087 time/batch=0.20s
370/5900 (epoch 6.271) train_loss=464.07901001 time/batch=0.35s
371/5900 (epoch 6.288) train_loss=414.59878540 time/batch=0.36s
372/5900 (epoch 6.305) train_loss=547.83605957 time/batch=0.47s
373/5900 (epoch 6.322) train_loss=766.81530762 time/batch=0.63s
374/5900 (epoch 6.339) train_loss=424.15747070 time/batch=0.41s
375/5900 (epoch 6.356) train_loss=623.77697754 time/batch=0.49s
376/5900 (epoch 6.373) train_loss=352.31204224 time/batch=0.35s
377/5900 (epoch 6.390) train_loss=570.76098633 time/batch=0.64s
378/5900 (epoch 6.407) train_loss=150.23388672 time/batch=0.25s
379/5900 (epoch 6.424) train_loss=469.51550293 time/batch=0.39s
380/5900 (epoch 6.441) train_loss=186.35771179 time/batch=0.23s
381/5900 (epoch 6.458) train_loss=1761.99438477 time/batch=2.66s
382/5900 (epoch 6.475) train_loss=335.71453857 time/batch=0.68s
383/5900 (epoch 6.492) train_loss=179.96005249 time/batch=0.19s
384/5900 (epoch 6.508) train_loss=326.02014160 time/batch=0.28s
385/5900 (epoch 6.525) train_loss=283.62695312 time/batch=0.27s
386/5900 (epoch 6.542) train_loss=155.57778931 time/batch=0.20s
387/5900 (epoch 6.559) train_loss=235.81352234 time/batch=0.22s
388/5900 (epoch 6.576) train_loss=362.82659912 time/batch=0.33s
389/5900 (epoch 6.593) train_loss=188.92813110 time/batch=0.28s
390/5900 (epoch 6.610) train_loss=131.86288452 time/batch=0.20s
391/5900 (epoch 6.627) train_loss=397.07763672 time/batch=0.36s
392/5900 (epoch 6.644) train_loss=357.54577637 time/batch=0.34s
393/5900 (epoch 6.661) train_loss=388.98748779 time/batch=0.35s
394/5900 (epoch 6.678) train_loss=466.00781250 time/batch=0.41s
395/5900 (epoch 6.695) train_loss=278.86087036 time/batch=0.29s
396/5900 (epoch 6.712) train_loss=450.82452393 time/batch=0.63s
397/5900 (epoch 6.729) train_loss=155.74794006 time/batch=0.25s
398/5900 (epoch 6.746) train_loss=324.39767456 time/batch=0.29s
399/5900 (epoch 6.763) train_loss=203.26483154 time/batch=0.30s
400/5900 (epoch 6.780) train_loss=124.28298950 time/batch=0.20s
401/5900 (epoch 6.797) train_loss=120.68643188 time/batch=0.17s
402/5900 (epoch 6.814) train_loss=122.50662231 time/batch=0.17s
403/5900 (epoch 6.831) train_loss=116.51364136 time/batch=0.19s
404/5900 (epoch 6.847) train_loss=112.74269104 time/batch=0.17s
405/5900 (epoch 6.864) train_loss=116.58348846 time/batch=0.19s
406/5900 (epoch 6.881) train_loss=169.71784973 time/batch=0.28s
407/5900 (epoch 6.898) train_loss=107.52679443 time/batch=0.19s
408/5900 (epoch 6.915) train_loss=112.55630493 time/batch=0.18s
409/5900 (epoch 6.932) train_loss=125.43644714 time/batch=0.19s
410/5900 (epoch 6.949) train_loss=126.99953461 time/batch=0.18s
411/5900 (epoch 6.966) train_loss=114.16850281 time/batch=0.19s
412/5900 (epoch 6.983) train_loss=109.98107910 time/batch=0.18s
413/5900 (epoch 7.000) train_loss=111.23844147 time/batch=0.18s
414/5900 (epoch 7.017) train_loss=323.15457153 time/batch=0.28s
415/5900 (epoch 7.034) train_loss=207.50869751 time/batch=0.25s
416/5900 (epoch 7.051) train_loss=379.03430176 time/batch=0.33s
417/5900 (epoch 7.068) train_loss=485.71655273 time/batch=0.39s
418/5900 (epoch 7.085) train_loss=490.74154663 time/batch=0.39s
419/5900 (epoch 7.102) train_loss=1189.61755371 time/batch=2.06s
420/5900 (epoch 7.119) train_loss=398.71603394 time/batch=2.09s
421/5900 (epoch 7.136) train_loss=425.50048828 time/batch=0.63s
422/5900 (epoch 7.153) train_loss=676.25915527 time/batch=0.55s
423/5900 (epoch 7.169) train_loss=761.85723877 time/batch=0.91s
424/5900 (epoch 7.186) train_loss=276.40118408 time/batch=0.36s
425/5900 (epoch 7.203) train_loss=378.92950439 time/batch=0.35s
426/5900 (epoch 7.220) train_loss=485.52816772 time/batch=0.44s
427/5900 (epoch 7.237) train_loss=280.30017090 time/batch=0.31s
428/5900 (epoch 7.254) train_loss=230.55773926 time/batch=0.25s
429/5900 (epoch 7.271) train_loss=477.25384521 time/batch=0.41s
430/5900 (epoch 7.288) train_loss=345.99090576 time/batch=0.33s
431/5900 (epoch 7.305) train_loss=302.30328369 time/batch=0.30s
432/5900 (epoch 7.322) train_loss=254.00114441 time/batch=0.27s
433/5900 (epoch 7.339) train_loss=491.26379395 time/batch=0.42s
434/5900 (epoch 7.356) train_loss=420.78894043 time/batch=0.39s
435/5900 (epoch 7.373) train_loss=223.71206665 time/batch=0.25s
436/5900 (epoch 7.390) train_loss=114.79541779 time/batch=0.18s
437/5900 (epoch 7.407) train_loss=300.19067383 time/batch=0.28s
438/5900 (epoch 7.424) train_loss=1024.24926758 time/batch=2.65s
439/5900 (epoch 7.441) train_loss=276.76745605 time/batch=0.72s
440/5900 (epoch 7.458) train_loss=143.53411865 time/batch=0.20s
441/5900 (epoch 7.475) train_loss=247.12918091 time/batch=0.27s
442/5900 (epoch 7.492) train_loss=333.31591797 time/batch=0.34s
443/5900 (epoch 7.508) train_loss=256.69619751 time/batch=0.28s
444/5900 (epoch 7.525) train_loss=449.63757324 time/batch=0.39s
445/5900 (epoch 7.542) train_loss=163.00109863 time/batch=0.23s
446/5900 (epoch 7.559) train_loss=421.73944092 time/batch=0.43s
447/5900 (epoch 7.576) train_loss=336.97268677 time/batch=0.34s
448/5900 (epoch 7.593) train_loss=359.37170410 time/batch=0.34s
449/5900 (epoch 7.610) train_loss=356.78131104 time/batch=0.36s
450/5900 (epoch 7.627) train_loss=201.62478638 time/batch=0.30s
451/5900 (epoch 7.644) train_loss=124.94815063 time/batch=0.19s
452/5900 (epoch 7.661) train_loss=313.77847290 time/batch=0.30s
453/5900 (epoch 7.678) train_loss=109.52329254 time/batch=0.20s
454/5900 (epoch 7.695) train_loss=288.06085205 time/batch=0.28s
455/5900 (epoch 7.712) train_loss=134.98709106 time/batch=0.21s
456/5900 (epoch 7.729) train_loss=123.02510834 time/batch=0.20s
457/5900 (epoch 7.746) train_loss=281.88229370 time/batch=0.29s
458/5900 (epoch 7.763) train_loss=131.64303589 time/batch=0.22s
459/5900 (epoch 7.780) train_loss=117.73400879 time/batch=0.18s
460/5900 (epoch 7.797) train_loss=162.93161011 time/batch=0.18s
461/5900 (epoch 7.814) train_loss=168.66639709 time/batch=0.19s
462/5900 (epoch 7.831) train_loss=113.61081696 time/batch=0.18s
463/5900 (epoch 7.847) train_loss=107.82902527 time/batch=0.17s
464/5900 (epoch 7.864) train_loss=110.41333771 time/batch=0.18s
465/5900 (epoch 7.881) train_loss=103.96701050 time/batch=0.18s
466/5900 (epoch 7.898) train_loss=113.32346344 time/batch=0.19s
467/5900 (epoch 7.915) train_loss=111.75561523 time/batch=0.19s
468/5900 (epoch 7.932) train_loss=109.89873505 time/batch=0.17s
469/5900 (epoch 7.949) train_loss=108.92503357 time/batch=0.19s
470/5900 (epoch 7.966) train_loss=103.80297852 time/batch=0.19s
471/5900 (epoch 7.983) train_loss=103.96555328 time/batch=0.17s
472/5900 (epoch 8.000) train_loss=108.15759277 time/batch=0.18s
473/5900 (epoch 8.017) train_loss=104.23579407 time/batch=0.19s
474/5900 (epoch 8.034) train_loss=349.80557251 time/batch=0.30s
475/5900 (epoch 8.051) train_loss=411.74783325 time/batch=0.37s
476/5900 (epoch 8.068) train_loss=469.12292480 time/batch=0.40s
477/5900 (epoch 8.085) train_loss=373.62890625 time/batch=0.37s
478/5900 (epoch 8.102) train_loss=768.51477051 time/batch=0.58s
479/5900 (epoch 8.119) train_loss=316.47631836 time/batch=0.36s
480/5900 (epoch 8.136) train_loss=249.69290161 time/batch=1.77s
481/5900 (epoch 8.153) train_loss=176.85186768 time/batch=0.48s
482/5900 (epoch 8.169) train_loss=505.83020020 time/batch=0.47s
483/5900 (epoch 8.186) train_loss=496.20141602 time/batch=0.44s
484/5900 (epoch 8.203) train_loss=1136.69702148 time/batch=2.08s
485/5900 (epoch 8.220) train_loss=506.59960938 time/batch=0.78s
486/5900 (epoch 8.237) train_loss=655.15380859 time/batch=0.87s
487/5900 (epoch 8.254) train_loss=295.38751221 time/batch=0.40s
488/5900 (epoch 8.271) train_loss=312.20263672 time/batch=0.32s
489/5900 (epoch 8.288) train_loss=398.88391113 time/batch=0.36s
490/5900 (epoch 8.305) train_loss=386.53698730 time/batch=0.39s
491/5900 (epoch 8.322) train_loss=386.67962646 time/batch=0.39s
492/5900 (epoch 8.339) train_loss=397.50576782 time/batch=0.41s
493/5900 (epoch 8.356) train_loss=430.58795166 time/batch=0.42s
494/5900 (epoch 8.373) train_loss=413.49334717 time/batch=0.22s
495/5900 (epoch 8.390) train_loss=482.68051147 time/batch=0.22s
496/5900 (epoch 8.407) train_loss=440.73297119 time/batch=0.25s
497/5900 (epoch 8.424) train_loss=525.82214355 time/batch=0.31s
498/5900 (epoch 8.441) train_loss=390.01354980 time/batch=0.28s
499/5900 (epoch 8.458) train_loss=440.75570679 time/batch=0.27s
500/5900 (epoch 8.475) train_loss=530.06976318 time/batch=0.33s
501/5900 (epoch 8.492) train_loss=1342.64672852 time/batch=2.67s
502/5900 (epoch 8.508) train_loss=396.35321045 time/batch=0.69s
503/5900 (epoch 8.525) train_loss=278.28973389 time/batch=0.20s
504/5900 (epoch 8.542) train_loss=368.74490356 time/batch=1.72s
505/5900 (epoch 8.559) train_loss=456.50628662 time/batch=0.56s
506/5900 (epoch 8.576) train_loss=232.80461121 time/batch=0.22s
507/5900 (epoch 8.593) train_loss=285.01440430 time/batch=0.25s
508/5900 (epoch 8.610) train_loss=463.45953369 time/batch=0.34s
509/5900 (epoch 8.627) train_loss=357.57049561 time/batch=0.28s
510/5900 (epoch 8.644) train_loss=383.85211182 time/batch=0.29s
511/5900 (epoch 8.661) train_loss=408.05718994 time/batch=0.34s
512/5900 (epoch 8.678) train_loss=320.26593018 time/batch=0.28s
513/5900 (epoch 8.695) train_loss=339.60037231 time/batch=0.30s
514/5900 (epoch 8.712) train_loss=264.70269775 time/batch=0.28s
515/5900 (epoch 8.729) train_loss=168.07473755 time/batch=0.21s
516/5900 (epoch 8.746) train_loss=183.05918884 time/batch=0.19s
517/5900 (epoch 8.763) train_loss=178.46832275 time/batch=0.28s
518/5900 (epoch 8.780) train_loss=126.88047791 time/batch=0.19s
519/5900 (epoch 8.797) train_loss=123.68442535 time/batch=0.17s
520/5900 (epoch 8.814) train_loss=123.79906464 time/batch=0.18s
521/5900 (epoch 8.831) train_loss=122.48216248 time/batch=0.18s
522/5900 (epoch 8.847) train_loss=122.86012268 time/batch=0.19s
523/5900 (epoch 8.864) train_loss=119.47506714 time/batch=0.17s
524/5900 (epoch 8.881) train_loss=134.70765686 time/batch=0.19s
525/5900 (epoch 8.898) train_loss=123.82746887 time/batch=0.17s
526/5900 (epoch 8.915) train_loss=124.63880920 time/batch=0.19s
527/5900 (epoch 8.932) train_loss=118.19268799 time/batch=0.18s
528/5900 (epoch 8.949) train_loss=114.08609009 time/batch=0.19s
529/5900 (epoch 8.966) train_loss=112.79171753 time/batch=0.17s
530/5900 (epoch 8.983) train_loss=119.51575470 time/batch=0.19s
531/5900 (epoch 9.000) train_loss=129.87884521 time/batch=0.18s
532/5900 (epoch 9.017) train_loss=501.38397217 time/batch=0.39s
533/5900 (epoch 9.034) train_loss=250.03077698 time/batch=0.29s
534/5900 (epoch 9.051) train_loss=1564.23889160 time/batch=2.64s
535/5900 (epoch 9.068) train_loss=158.32814026 time/batch=0.64s
536/5900 (epoch 9.085) train_loss=630.14324951 time/batch=0.47s
537/5900 (epoch 9.102) train_loss=564.91583252 time/batch=0.54s
538/5900 (epoch 9.119) train_loss=378.08609009 time/batch=0.38s
539/5900 (epoch 9.136) train_loss=231.84814453 time/batch=1.80s
540/5900 (epoch 9.153) train_loss=355.67449951 time/batch=0.61s
541/5900 (epoch 9.169) train_loss=280.41210938 time/batch=0.28s
542/5900 (epoch 9.186) train_loss=426.04797363 time/batch=0.40s
543/5900 (epoch 9.203) train_loss=313.28289795 time/batch=0.33s
544/5900 (epoch 9.220) train_loss=134.40173340 time/batch=0.21s
545/5900 (epoch 9.237) train_loss=329.71270752 time/batch=0.30s
546/5900 (epoch 9.254) train_loss=315.36614990 time/batch=0.32s
547/5900 (epoch 9.271) train_loss=731.11340332 time/batch=0.64s
548/5900 (epoch 9.288) train_loss=240.50648499 time/batch=0.32s
549/5900 (epoch 9.305) train_loss=264.28137207 time/batch=0.28s
550/5900 (epoch 9.322) train_loss=227.91796875 time/batch=0.25s
551/5900 (epoch 9.339) train_loss=167.72169495 time/batch=0.21s
552/5900 (epoch 9.356) train_loss=132.02151489 time/batch=0.20s
553/5900 (epoch 9.373) train_loss=296.51770020 time/batch=0.27s
554/5900 (epoch 9.390) train_loss=501.96926880 time/batch=0.53s
555/5900 (epoch 9.407) train_loss=398.20684814 time/batch=0.41s
556/5900 (epoch 9.424) train_loss=170.78573608 time/batch=0.24s
557/5900 (epoch 9.441) train_loss=407.69851685 time/batch=0.39s
558/5900 (epoch 9.458) train_loss=351.28234863 time/batch=0.33s
559/5900 (epoch 9.475) train_loss=376.80725098 time/batch=0.27s
560/5900 (epoch 9.492) train_loss=680.30584717 time/batch=0.42s
561/5900 (epoch 9.508) train_loss=195.63995361 time/batch=0.25s
562/5900 (epoch 9.525) train_loss=405.84246826 time/batch=0.35s
563/5900 (epoch 9.542) train_loss=384.90972900 time/batch=0.39s
564/5900 (epoch 9.559) train_loss=267.62832642 time/batch=0.30s
565/5900 (epoch 9.576) train_loss=370.80505371 time/batch=0.34s
566/5900 (epoch 9.593) train_loss=269.65264893 time/batch=0.31s
567/5900 (epoch 9.610) train_loss=345.18209839 time/batch=0.33s
568/5900 (epoch 9.627) train_loss=310.58059692 time/batch=0.33s
569/5900 (epoch 9.644) train_loss=273.57092285 time/batch=0.29s
570/5900 (epoch 9.661) train_loss=252.30865479 time/batch=1.74s
571/5900 (epoch 9.678) train_loss=377.60626221 time/batch=0.70s
572/5900 (epoch 9.695) train_loss=108.53446198 time/batch=0.20s
573/5900 (epoch 9.712) train_loss=102.22290039 time/batch=0.18s
574/5900 (epoch 9.729) train_loss=105.48816681 time/batch=0.18s
575/5900 (epoch 9.746) train_loss=294.13449097 time/batch=0.28s
576/5900 (epoch 9.763) train_loss=184.47738647 time/batch=0.33s
577/5900 (epoch 9.780) train_loss=106.95550537 time/batch=0.21s
578/5900 (epoch 9.797) train_loss=116.92323303 time/batch=0.19s
579/5900 (epoch 9.814) train_loss=110.44692993 time/batch=0.19s
580/5900 (epoch 9.831) train_loss=114.52588654 time/batch=0.17s
581/5900 (epoch 9.847) train_loss=103.10005188 time/batch=0.19s
582/5900 (epoch 9.864) train_loss=118.16627502 time/batch=0.19s
583/5900 (epoch 9.881) train_loss=108.63746643 time/batch=0.17s
584/5900 (epoch 9.898) train_loss=102.65244293 time/batch=0.19s
585/5900 (epoch 9.915) train_loss=101.12265778 time/batch=0.17s
586/5900 (epoch 9.932) train_loss=103.26274872 time/batch=0.19s
587/5900 (epoch 9.949) train_loss=102.77470398 time/batch=0.17s
588/5900 (epoch 9.966) train_loss=108.26716614 time/batch=0.19s
589/5900 (epoch 9.983) train_loss=106.14883423 time/batch=0.18s
590/5900 (epoch 10.000) train_loss=102.93082428 time/batch=0.18s
  saved to metadata/config5--20190119-190634.pkl
591/5900 (epoch 10.017) train_loss=368.28741455 time/batch=8.96s
592/5900 (epoch 10.034) train_loss=1733.47912598 time/batch=2.94s
593/5900 (epoch 10.051) train_loss=516.61657715 time/batch=0.83s
594/5900 (epoch 10.068) train_loss=304.04116821 time/batch=0.33s
595/5900 (epoch 10.085) train_loss=168.95497131 time/batch=0.22s
596/5900 (epoch 10.102) train_loss=229.55767822 time/batch=0.25s
597/5900 (epoch 10.119) train_loss=418.62854004 time/batch=0.39s
598/5900 (epoch 10.136) train_loss=267.77978516 time/batch=0.29s
599/5900 (epoch 10.153) train_loss=509.86196899 time/batch=0.48s
600/5900 (epoch 10.169) train_loss=474.69116211 time/batch=0.45s
601/5900 (epoch 10.186) train_loss=224.41015625 time/batch=0.28s
602/5900 (epoch 10.203) train_loss=605.22296143 time/batch=0.53s
603/5900 (epoch 10.220) train_loss=715.18109131 time/batch=0.67s
604/5900 (epoch 10.237) train_loss=362.11981201 time/batch=0.41s
605/5900 (epoch 10.254) train_loss=330.08590698 time/batch=0.34s
606/5900 (epoch 10.271) train_loss=390.05133057 time/batch=0.37s
607/5900 (epoch 10.288) train_loss=109.52388000 time/batch=0.20s
608/5900 (epoch 10.305) train_loss=98.91330719 time/batch=0.19s
609/5900 (epoch 10.322) train_loss=237.34870911 time/batch=0.25s
610/5900 (epoch 10.339) train_loss=201.74478149 time/batch=0.22s
611/5900 (epoch 10.356) train_loss=347.55877686 time/batch=0.33s
612/5900 (epoch 10.373) train_loss=366.72671509 time/batch=0.37s
613/5900 (epoch 10.390) train_loss=445.93899536 time/batch=0.44s
614/5900 (epoch 10.407) train_loss=402.74114990 time/batch=0.44s
615/5900 (epoch 10.424) train_loss=170.91050720 time/batch=0.29s
616/5900 (epoch 10.441) train_loss=245.40057373 time/batch=0.27s
617/5900 (epoch 10.458) train_loss=264.21624756 time/batch=0.28s
618/5900 (epoch 10.475) train_loss=306.23632812 time/batch=0.31s
619/5900 (epoch 10.492) train_loss=108.16468811 time/batch=0.20s
620/5900 (epoch 10.508) train_loss=100.68517303 time/batch=0.17s
621/5900 (epoch 10.525) train_loss=454.12023926 time/batch=0.47s
622/5900 (epoch 10.542) train_loss=268.48171997 time/batch=0.31s
623/5900 (epoch 10.559) train_loss=348.67413330 time/batch=0.35s
624/5900 (epoch 10.576) train_loss=322.06005859 time/batch=0.32s
625/5900 (epoch 10.593) train_loss=350.06915283 time/batch=0.37s
626/5900 (epoch 10.610) train_loss=272.56994629 time/batch=0.30s
627/5900 (epoch 10.627) train_loss=279.94915771 time/batch=0.30s
628/5900 (epoch 10.644) train_loss=116.71029663 time/batch=0.20s
629/5900 (epoch 10.661) train_loss=359.56787109 time/batch=0.35s
630/5900 (epoch 10.678) train_loss=278.72210693 time/batch=0.31s
631/5900 (epoch 10.695) train_loss=122.03496552 time/batch=0.19s
632/5900 (epoch 10.712) train_loss=310.69116211 time/batch=0.29s
633/5900 (epoch 10.729) train_loss=118.16508484 time/batch=0.21s
634/5900 (epoch 10.746) train_loss=114.62010956 time/batch=0.19s
635/5900 (epoch 10.763) train_loss=162.42002869 time/batch=0.25s
636/5900 (epoch 10.780) train_loss=119.06878662 time/batch=0.20s
637/5900 (epoch 10.797) train_loss=102.98299408 time/batch=0.19s
638/5900 (epoch 10.814) train_loss=113.30929565 time/batch=0.18s
639/5900 (epoch 10.831) train_loss=284.75549316 time/batch=0.31s
640/5900 (epoch 10.847) train_loss=100.73008728 time/batch=0.19s
641/5900 (epoch 10.864) train_loss=136.71163940 time/batch=0.20s
642/5900 (epoch 10.881) train_loss=105.15801239 time/batch=0.18s
643/5900 (epoch 10.898) train_loss=110.40350342 time/batch=0.18s
644/5900 (epoch 10.915) train_loss=107.02297211 time/batch=0.19s
645/5900 (epoch 10.932) train_loss=103.80126953 time/batch=0.18s
646/5900 (epoch 10.949) train_loss=102.98977661 time/batch=0.18s
647/5900 (epoch 10.966) train_loss=101.45080566 time/batch=0.18s
648/5900 (epoch 10.983) train_loss=102.16978455 time/batch=0.18s
649/5900 (epoch 11.000) train_loss=103.02767944 time/batch=0.19s
650/5900 (epoch 11.017) train_loss=1535.76806641 time/batch=2.63s
651/5900 (epoch 11.034) train_loss=446.35015869 time/batch=0.78s
652/5900 (epoch 11.051) train_loss=679.71795654 time/batch=0.58s
653/5900 (epoch 11.068) train_loss=367.16754150 time/batch=0.36s
654/5900 (epoch 11.085) train_loss=480.40740967 time/batch=0.44s
655/5900 (epoch 11.102) train_loss=306.48242188 time/batch=0.33s
656/5900 (epoch 11.119) train_loss=475.37268066 time/batch=0.45s
657/5900 (epoch 11.136) train_loss=227.64215088 time/batch=0.29s
658/5900 (epoch 11.153) train_loss=150.09226990 time/batch=0.21s
659/5900 (epoch 11.169) train_loss=440.30886841 time/batch=0.41s
660/5900 (epoch 11.186) train_loss=391.15209961 time/batch=0.42s
661/5900 (epoch 11.203) train_loss=422.55200195 time/batch=0.41s
662/5900 (epoch 11.220) train_loss=208.85935974 time/batch=0.26s
663/5900 (epoch 11.237) train_loss=104.62571716 time/batch=0.19s
664/5900 (epoch 11.254) train_loss=664.11505127 time/batch=0.60s
665/5900 (epoch 11.271) train_loss=218.44985962 time/batch=1.84s
666/5900 (epoch 11.288) train_loss=337.11431885 time/batch=0.61s
667/5900 (epoch 11.305) train_loss=509.64065552 time/batch=0.47s
668/5900 (epoch 11.322) train_loss=234.87678528 time/batch=1.76s
669/5900 (epoch 11.339) train_loss=115.73292542 time/batch=0.45s
670/5900 (epoch 11.356) train_loss=360.39941406 time/batch=0.34s
671/5900 (epoch 11.373) train_loss=281.57464600 time/batch=0.31s
672/5900 (epoch 11.390) train_loss=316.28204346 time/batch=0.33s
673/5900 (epoch 11.407) train_loss=185.99887085 time/batch=0.23s
674/5900 (epoch 11.424) train_loss=402.73999023 time/batch=0.39s
675/5900 (epoch 11.441) train_loss=283.56207275 time/batch=0.33s
676/5900 (epoch 11.458) train_loss=265.35787964 time/batch=0.28s
677/5900 (epoch 11.475) train_loss=216.71212769 time/batch=0.25s
678/5900 (epoch 11.492) train_loss=109.90243530 time/batch=0.20s
679/5900 (epoch 11.508) train_loss=332.05264282 time/batch=0.31s
680/5900 (epoch 11.525) train_loss=265.33569336 time/batch=0.31s
681/5900 (epoch 11.542) train_loss=380.13055420 time/batch=0.36s
682/5900 (epoch 11.559) train_loss=112.24708557 time/batch=0.22s
683/5900 (epoch 11.576) train_loss=102.95858765 time/batch=0.17s
684/5900 (epoch 11.593) train_loss=96.98357391 time/batch=0.17s
685/5900 (epoch 11.610) train_loss=323.56176758 time/batch=0.30s
686/5900 (epoch 11.627) train_loss=214.91658020 time/batch=0.27s
687/5900 (epoch 11.644) train_loss=357.62768555 time/batch=0.36s
688/5900 (epoch 11.661) train_loss=261.08239746 time/batch=0.30s
689/5900 (epoch 11.678) train_loss=235.41281128 time/batch=0.27s
690/5900 (epoch 11.695) train_loss=250.18586731 time/batch=0.30s
691/5900 (epoch 11.712) train_loss=134.22508240 time/batch=0.20s
692/5900 (epoch 11.729) train_loss=236.34300232 time/batch=0.28s
693/5900 (epoch 11.746) train_loss=103.99651337 time/batch=0.19s
694/5900 (epoch 11.763) train_loss=107.40711975 time/batch=0.19s
695/5900 (epoch 11.780) train_loss=116.95747375 time/batch=0.17s
696/5900 (epoch 11.797) train_loss=331.66528320 time/batch=0.34s
697/5900 (epoch 11.814) train_loss=101.29916382 time/batch=0.21s
698/5900 (epoch 11.831) train_loss=124.74981689 time/batch=0.19s
699/5900 (epoch 11.847) train_loss=107.01319885 time/batch=0.17s
700/5900 (epoch 11.864) train_loss=337.91571045 time/batch=0.34s
701/5900 (epoch 11.881) train_loss=218.26953125 time/batch=0.37s
702/5900 (epoch 11.898) train_loss=118.68919373 time/batch=0.22s
703/5900 (epoch 11.915) train_loss=112.93393707 time/batch=0.19s
704/5900 (epoch 11.932) train_loss=107.53553772 time/batch=0.19s
705/5900 (epoch 11.949) train_loss=98.32088470 time/batch=0.19s
706/5900 (epoch 11.966) train_loss=106.40850067 time/batch=0.17s
707/5900 (epoch 11.983) train_loss=105.43722534 time/batch=0.19s
708/5900 (epoch 12.000) train_loss=103.09682465 time/batch=0.19s
709/5900 (epoch 12.017) train_loss=1126.12182617 time/batch=2.03s
710/5900 (epoch 12.034) train_loss=227.03274536 time/batch=0.56s
711/5900 (epoch 12.051) train_loss=609.63793945 time/batch=0.51s
712/5900 (epoch 12.068) train_loss=402.05389404 time/batch=0.38s
713/5900 (epoch 12.085) train_loss=408.89126587 time/batch=0.38s
714/5900 (epoch 12.102) train_loss=348.60021973 time/batch=0.36s
715/5900 (epoch 12.119) train_loss=872.22485352 time/batch=2.66s
716/5900 (epoch 12.136) train_loss=427.60824585 time/batch=0.83s
717/5900 (epoch 12.153) train_loss=348.78311157 time/batch=0.37s
718/5900 (epoch 12.169) train_loss=188.42681885 time/batch=0.25s
719/5900 (epoch 12.186) train_loss=711.36529541 time/batch=1.38s
720/5900 (epoch 12.203) train_loss=222.74427795 time/batch=0.45s
721/5900 (epoch 12.220) train_loss=444.57244873 time/batch=0.42s
722/5900 (epoch 12.237) train_loss=192.56227112 time/batch=0.28s
723/5900 (epoch 12.254) train_loss=419.09240723 time/batch=0.39s
724/5900 (epoch 12.271) train_loss=351.10870361 time/batch=0.36s
725/5900 (epoch 12.288) train_loss=295.10910034 time/batch=0.33s
726/5900 (epoch 12.305) train_loss=380.55651855 time/batch=0.40s
727/5900 (epoch 12.322) train_loss=306.07125854 time/batch=0.35s
728/5900 (epoch 12.339) train_loss=311.84222412 time/batch=0.32s
729/5900 (epoch 12.356) train_loss=148.14656067 time/batch=0.23s
730/5900 (epoch 12.373) train_loss=101.70399475 time/batch=0.17s
731/5900 (epoch 12.390) train_loss=276.76916504 time/batch=0.28s
732/5900 (epoch 12.407) train_loss=99.06816864 time/batch=0.19s
733/5900 (epoch 12.424) train_loss=355.44772339 time/batch=1.78s
734/5900 (epoch 12.441) train_loss=288.25543213 time/batch=0.56s
735/5900 (epoch 12.458) train_loss=230.71647644 time/batch=0.28s
736/5900 (epoch 12.475) train_loss=249.34487915 time/batch=0.26s
737/5900 (epoch 12.492) train_loss=123.98767090 time/batch=0.20s
738/5900 (epoch 12.508) train_loss=134.30030823 time/batch=0.20s
739/5900 (epoch 12.525) train_loss=340.35891724 time/batch=0.34s
740/5900 (epoch 12.542) train_loss=114.78635406 time/batch=0.22s
741/5900 (epoch 12.559) train_loss=475.35827637 time/batch=0.44s
742/5900 (epoch 12.576) train_loss=320.66796875 time/batch=0.33s
743/5900 (epoch 12.593) train_loss=263.81085205 time/batch=0.28s
744/5900 (epoch 12.610) train_loss=129.50866699 time/batch=0.20s
745/5900 (epoch 12.627) train_loss=269.49926758 time/batch=0.28s
746/5900 (epoch 12.644) train_loss=394.32980347 time/batch=0.41s
747/5900 (epoch 12.661) train_loss=107.73544312 time/batch=0.23s
748/5900 (epoch 12.678) train_loss=351.19183350 time/batch=0.34s
749/5900 (epoch 12.695) train_loss=235.05773926 time/batch=0.30s
750/5900 (epoch 12.712) train_loss=257.50408936 time/batch=0.28s
751/5900 (epoch 12.729) train_loss=232.60839844 time/batch=0.28s
752/5900 (epoch 12.746) train_loss=110.41104126 time/batch=0.20s
753/5900 (epoch 12.763) train_loss=104.48719788 time/batch=0.17s
754/5900 (epoch 12.780) train_loss=295.86016846 time/batch=0.31s
755/5900 (epoch 12.797) train_loss=164.02822876 time/batch=0.33s
756/5900 (epoch 12.814) train_loss=110.56416321 time/batch=0.20s
757/5900 (epoch 12.831) train_loss=116.70014954 time/batch=0.19s
758/5900 (epoch 12.847) train_loss=106.52111053 time/batch=0.17s
759/5900 (epoch 12.864) train_loss=103.61316681 time/batch=0.19s
760/5900 (epoch 12.881) train_loss=98.04586792 time/batch=0.18s
761/5900 (epoch 12.898) train_loss=106.70490265 time/batch=0.19s
762/5900 (epoch 12.915) train_loss=102.80712891 time/batch=0.19s
763/5900 (epoch 12.932) train_loss=102.07827759 time/batch=0.17s
764/5900 (epoch 12.949) train_loss=101.13324738 time/batch=0.19s
765/5900 (epoch 12.966) train_loss=95.96421051 time/batch=0.19s
766/5900 (epoch 12.983) train_loss=99.85608673 time/batch=0.17s
767/5900 (epoch 13.000) train_loss=102.64017487 time/batch=0.19s
768/5900 (epoch 13.017) train_loss=133.59918213 time/batch=0.19s
769/5900 (epoch 13.034) train_loss=551.15527344 time/batch=0.48s
770/5900 (epoch 13.051) train_loss=337.18395996 time/batch=1.81s
771/5900 (epoch 13.068) train_loss=1507.23156738 time/batch=2.92s
772/5900 (epoch 13.085) train_loss=396.43872070 time/batch=0.78s
773/5900 (epoch 13.102) train_loss=456.79254150 time/batch=0.42s
774/5900 (epoch 13.119) train_loss=663.01556396 time/batch=0.59s
775/5900 (epoch 13.136) train_loss=320.23852539 time/batch=0.36s
776/5900 (epoch 13.153) train_loss=437.58203125 time/batch=0.42s
777/5900 (epoch 13.169) train_loss=352.05279541 time/batch=0.36s
778/5900 (epoch 13.186) train_loss=218.21484375 time/batch=0.28s
779/5900 (epoch 13.203) train_loss=259.58160400 time/batch=0.28s
780/5900 (epoch 13.220) train_loss=255.73857117 time/batch=0.28s
781/5900 (epoch 13.237) train_loss=220.87890625 time/batch=0.27s
782/5900 (epoch 13.254) train_loss=381.23382568 time/batch=0.37s
783/5900 (epoch 13.271) train_loss=534.09460449 time/batch=0.61s
784/5900 (epoch 13.288) train_loss=118.92337036 time/batch=0.25s
785/5900 (epoch 13.305) train_loss=178.81881714 time/batch=0.22s
786/5900 (epoch 13.322) train_loss=403.78610229 time/batch=0.38s
787/5900 (epoch 13.339) train_loss=522.54931641 time/batch=0.64s
788/5900 (epoch 13.356) train_loss=407.69503784 time/batch=0.47s
789/5900 (epoch 13.373) train_loss=282.54528809 time/batch=0.33s
790/5900 (epoch 13.390) train_loss=340.16638184 time/batch=0.34s
791/5900 (epoch 13.407) train_loss=350.97753906 time/batch=0.36s
792/5900 (epoch 13.424) train_loss=116.47731018 time/batch=0.20s
793/5900 (epoch 13.441) train_loss=216.44171143 time/batch=0.25s
794/5900 (epoch 13.458) train_loss=367.92364502 time/batch=0.36s
795/5900 (epoch 13.475) train_loss=268.58502197 time/batch=0.31s
796/5900 (epoch 13.492) train_loss=102.29685974 time/batch=0.19s
797/5900 (epoch 13.508) train_loss=264.88433838 time/batch=0.28s
798/5900 (epoch 13.525) train_loss=98.95741272 time/batch=0.20s
799/5900 (epoch 13.542) train_loss=324.04614258 time/batch=0.31s
800/5900 (epoch 13.559) train_loss=357.82568359 time/batch=0.42s
801/5900 (epoch 13.576) train_loss=293.58941650 time/batch=0.34s
802/5900 (epoch 13.593) train_loss=185.65719604 time/batch=0.24s
803/5900 (epoch 13.610) train_loss=300.24380493 time/batch=0.31s
804/5900 (epoch 13.627) train_loss=274.79956055 time/batch=0.33s
805/5900 (epoch 13.644) train_loss=235.50932312 time/batch=0.27s
806/5900 (epoch 13.661) train_loss=306.28146362 time/batch=0.33s
807/5900 (epoch 13.678) train_loss=273.95959473 time/batch=0.33s
808/5900 (epoch 13.695) train_loss=187.81613159 time/batch=0.26s
809/5900 (epoch 13.712) train_loss=110.66469574 time/batch=0.19s
810/5900 (epoch 13.729) train_loss=185.59907532 time/batch=0.25s
811/5900 (epoch 13.746) train_loss=115.89742279 time/batch=0.20s
812/5900 (epoch 13.763) train_loss=102.50901794 time/batch=0.19s
813/5900 (epoch 13.780) train_loss=100.07521057 time/batch=0.17s
814/5900 (epoch 13.797) train_loss=122.30706787 time/batch=0.19s
815/5900 (epoch 13.814) train_loss=119.18365479 time/batch=0.19s
816/5900 (epoch 13.831) train_loss=135.35012817 time/batch=0.26s
817/5900 (epoch 13.847) train_loss=106.07726288 time/batch=0.19s
818/5900 (epoch 13.864) train_loss=104.09418488 time/batch=0.19s
819/5900 (epoch 13.881) train_loss=98.81409454 time/batch=0.17s
820/5900 (epoch 13.898) train_loss=101.46820068 time/batch=0.19s
821/5900 (epoch 13.915) train_loss=99.90421295 time/batch=0.19s
822/5900 (epoch 13.932) train_loss=96.50802612 time/batch=0.17s
823/5900 (epoch 13.949) train_loss=98.53790283 time/batch=0.17s
824/5900 (epoch 13.966) train_loss=97.14457703 time/batch=0.19s
825/5900 (epoch 13.983) train_loss=104.01032257 time/batch=0.17s
826/5900 (epoch 14.000) train_loss=107.28416443 time/batch=0.19s
827/5900 (epoch 14.017) train_loss=312.25665283 time/batch=0.31s
828/5900 (epoch 14.034) train_loss=218.66966248 time/batch=0.26s
829/5900 (epoch 14.051) train_loss=276.71362305 time/batch=0.28s
830/5900 (epoch 14.068) train_loss=439.57690430 time/batch=0.42s
831/5900 (epoch 14.085) train_loss=1384.48388672 time/batch=2.66s
832/5900 (epoch 14.102) train_loss=391.87939453 time/batch=0.80s
833/5900 (epoch 14.119) train_loss=529.56384277 time/batch=0.50s
834/5900 (epoch 14.136) train_loss=360.25555420 time/batch=0.39s
835/5900 (epoch 14.153) train_loss=211.37542725 time/batch=0.27s
836/5900 (epoch 14.169) train_loss=809.53247070 time/batch=1.39s
837/5900 (epoch 14.186) train_loss=206.67533875 time/batch=0.45s
838/5900 (epoch 14.203) train_loss=531.28387451 time/batch=0.50s
839/5900 (epoch 14.220) train_loss=374.56823730 time/batch=0.41s
840/5900 (epoch 14.237) train_loss=230.89440918 time/batch=1.78s
841/5900 (epoch 14.254) train_loss=114.28105164 time/batch=0.46s
842/5900 (epoch 14.271) train_loss=371.26953125 time/batch=0.36s
843/5900 (epoch 14.288) train_loss=299.44409180 time/batch=0.33s
844/5900 (epoch 14.305) train_loss=289.50488281 time/batch=0.33s
845/5900 (epoch 14.322) train_loss=177.23765564 time/batch=0.22s
846/5900 (epoch 14.339) train_loss=462.93911743 time/batch=0.51s
847/5900 (epoch 14.356) train_loss=253.68273926 time/batch=0.31s
848/5900 (epoch 14.373) train_loss=448.55087280 time/batch=0.42s
849/5900 (epoch 14.390) train_loss=250.38507080 time/batch=0.31s
850/5900 (epoch 14.407) train_loss=406.84478760 time/batch=0.39s
851/5900 (epoch 14.424) train_loss=169.73049927 time/batch=0.25s
852/5900 (epoch 14.441) train_loss=305.45025635 time/batch=0.31s
853/5900 (epoch 14.458) train_loss=270.09841919 time/batch=0.30s
854/5900 (epoch 14.475) train_loss=321.78570557 time/batch=0.33s
855/5900 (epoch 14.492) train_loss=263.32800293 time/batch=0.30s
856/5900 (epoch 14.508) train_loss=239.60433960 time/batch=0.28s
857/5900 (epoch 14.525) train_loss=219.22099304 time/batch=1.73s
858/5900 (epoch 14.542) train_loss=281.72747803 time/batch=0.58s
859/5900 (epoch 14.559) train_loss=395.89077759 time/batch=0.39s
860/5900 (epoch 14.576) train_loss=344.01556396 time/batch=0.36s
861/5900 (epoch 14.593) train_loss=320.81570435 time/batch=0.35s
862/5900 (epoch 14.610) train_loss=319.42230225 time/batch=0.34s
863/5900 (epoch 14.627) train_loss=219.60510254 time/batch=0.28s
864/5900 (epoch 14.644) train_loss=299.45013428 time/batch=0.38s
865/5900 (epoch 14.661) train_loss=199.53729248 time/batch=0.28s
866/5900 (epoch 14.678) train_loss=120.29350281 time/batch=0.20s
867/5900 (epoch 14.695) train_loss=125.60116577 time/batch=0.19s
868/5900 (epoch 14.712) train_loss=110.30445862 time/batch=0.19s
869/5900 (epoch 14.729) train_loss=99.96401215 time/batch=0.17s
870/5900 (epoch 14.746) train_loss=97.23963928 time/batch=0.19s
871/5900 (epoch 14.763) train_loss=134.92648315 time/batch=0.19s
872/5900 (epoch 14.780) train_loss=114.76036072 time/batch=0.19s
873/5900 (epoch 14.797) train_loss=105.43314362 time/batch=0.19s
874/5900 (epoch 14.814) train_loss=100.07254028 time/batch=0.17s
875/5900 (epoch 14.831) train_loss=100.35494232 time/batch=0.19s
876/5900 (epoch 14.847) train_loss=101.31973267 time/batch=0.17s
877/5900 (epoch 14.864) train_loss=101.95222473 time/batch=0.19s
878/5900 (epoch 14.881) train_loss=103.99723816 time/batch=0.17s
879/5900 (epoch 14.898) train_loss=116.98486328 time/batch=0.19s
880/5900 (epoch 14.915) train_loss=99.79533386 time/batch=0.19s
881/5900 (epoch 14.932) train_loss=101.19685364 time/batch=0.19s
882/5900 (epoch 14.949) train_loss=94.86235046 time/batch=0.17s
883/5900 (epoch 14.966) train_loss=97.82740021 time/batch=0.17s
884/5900 (epoch 14.983) train_loss=100.41494751 time/batch=0.19s
885/5900 (epoch 15.000) train_loss=101.05982208 time/batch=0.17s
886/5900 (epoch 15.017) train_loss=319.16030884 time/batch=0.31s
887/5900 (epoch 15.034) train_loss=250.80398560 time/batch=0.28s
888/5900 (epoch 15.051) train_loss=134.11759949 time/batch=0.20s
889/5900 (epoch 15.068) train_loss=1457.46862793 time/batch=2.62s
890/5900 (epoch 15.085) train_loss=138.87042236 time/batch=0.64s
891/5900 (epoch 15.102) train_loss=214.20565796 time/batch=0.25s
892/5900 (epoch 15.119) train_loss=722.90441895 time/batch=0.62s
893/5900 (epoch 15.136) train_loss=141.63914490 time/batch=0.27s
894/5900 (epoch 15.153) train_loss=589.59075928 time/batch=0.50s
895/5900 (epoch 15.169) train_loss=363.72772217 time/batch=1.80s
896/5900 (epoch 15.186) train_loss=257.82537842 time/batch=0.56s
897/5900 (epoch 15.203) train_loss=435.60516357 time/batch=0.44s
898/5900 (epoch 15.220) train_loss=141.50250244 time/batch=0.25s
899/5900 (epoch 15.237) train_loss=467.07949829 time/batch=0.44s
900/5900 (epoch 15.254) train_loss=376.11090088 time/batch=0.39s
901/5900 (epoch 15.271) train_loss=320.65835571 time/batch=0.34s
902/5900 (epoch 15.288) train_loss=290.34033203 time/batch=0.31s
903/5900 (epoch 15.305) train_loss=107.16703033 time/batch=0.20s
904/5900 (epoch 15.322) train_loss=440.69525146 time/batch=0.45s
905/5900 (epoch 15.339) train_loss=467.19042969 time/batch=0.50s
906/5900 (epoch 15.356) train_loss=343.84747314 time/batch=0.38s
907/5900 (epoch 15.373) train_loss=378.87463379 time/batch=0.39s
908/5900 (epoch 15.390) train_loss=319.58209229 time/batch=0.36s
909/5900 (epoch 15.407) train_loss=117.78682709 time/batch=0.20s
910/5900 (epoch 15.424) train_loss=263.38040161 time/batch=0.30s
911/5900 (epoch 15.441) train_loss=152.44668579 time/batch=0.22s
912/5900 (epoch 15.458) train_loss=213.23303223 time/batch=0.25s
913/5900 (epoch 15.475) train_loss=222.62724304 time/batch=0.27s
914/5900 (epoch 15.492) train_loss=97.56303406 time/batch=0.19s
915/5900 (epoch 15.508) train_loss=369.53094482 time/batch=0.36s
916/5900 (epoch 15.525) train_loss=168.72927856 time/batch=0.25s
917/5900 (epoch 15.542) train_loss=339.72097778 time/batch=0.34s
918/5900 (epoch 15.559) train_loss=108.25212097 time/batch=0.20s
919/5900 (epoch 15.576) train_loss=98.30265808 time/batch=0.17s
920/5900 (epoch 15.593) train_loss=371.88510132 time/batch=0.35s
921/5900 (epoch 15.610) train_loss=271.73773193 time/batch=0.32s
922/5900 (epoch 15.627) train_loss=100.83145142 time/batch=0.20s
923/5900 (epoch 15.644) train_loss=291.34893799 time/batch=0.30s
924/5900 (epoch 15.661) train_loss=304.90615845 time/batch=0.33s
925/5900 (epoch 15.678) train_loss=301.10095215 time/batch=0.35s
926/5900 (epoch 15.695) train_loss=326.99340820 time/batch=0.37s
927/5900 (epoch 15.712) train_loss=405.27621460 time/batch=0.41s
928/5900 (epoch 15.729) train_loss=238.20364380 time/batch=0.28s
929/5900 (epoch 15.746) train_loss=253.35453796 time/batch=0.28s
930/5900 (epoch 15.763) train_loss=118.70036316 time/batch=0.20s
931/5900 (epoch 15.780) train_loss=103.18052673 time/batch=0.17s
932/5900 (epoch 15.797) train_loss=98.71710968 time/batch=0.19s
933/5900 (epoch 15.814) train_loss=97.10421753 time/batch=0.17s
934/5900 (epoch 15.831) train_loss=99.00897980 time/batch=0.19s
935/5900 (epoch 15.847) train_loss=155.65710449 time/batch=0.22s
936/5900 (epoch 15.864) train_loss=104.53907776 time/batch=0.19s
937/5900 (epoch 15.881) train_loss=135.07943726 time/batch=0.22s
938/5900 (epoch 15.898) train_loss=100.49252319 time/batch=0.19s
939/5900 (epoch 15.915) train_loss=163.61776733 time/batch=0.26s
940/5900 (epoch 15.932) train_loss=274.74145508 time/batch=0.28s
941/5900 (epoch 15.949) train_loss=158.52497864 time/batch=0.39s
942/5900 (epoch 15.966) train_loss=99.37746429 time/batch=0.22s
943/5900 (epoch 15.983) train_loss=99.22715759 time/batch=0.17s
944/5900 (epoch 16.000) train_loss=101.63551331 time/batch=0.19s
945/5900 (epoch 16.017) train_loss=1405.29748535 time/batch=2.64s
946/5900 (epoch 16.034) train_loss=417.58709717 time/batch=0.80s
947/5900 (epoch 16.051) train_loss=276.18225098 time/batch=0.30s
948/5900 (epoch 16.068) train_loss=475.07040405 time/batch=0.42s
949/5900 (epoch 16.085) train_loss=717.90588379 time/batch=0.64s
950/5900 (epoch 16.102) train_loss=211.23652649 time/batch=0.33s
951/5900 (epoch 16.119) train_loss=556.22985840 time/batch=0.50s
952/5900 (epoch 16.136) train_loss=176.59445190 time/batch=0.28s
953/5900 (epoch 16.153) train_loss=490.96582031 time/batch=0.47s
954/5900 (epoch 16.169) train_loss=107.40704346 time/batch=0.22s
955/5900 (epoch 16.186) train_loss=221.14688110 time/batch=0.25s
956/5900 (epoch 16.203) train_loss=440.00927734 time/batch=0.47s
957/5900 (epoch 16.220) train_loss=250.69787598 time/batch=0.33s
958/5900 (epoch 16.237) train_loss=324.33517456 time/batch=0.33s
959/5900 (epoch 16.254) train_loss=100.32183838 time/batch=0.20s
960/5900 (epoch 16.271) train_loss=248.80926514 time/batch=0.28s
961/5900 (epoch 16.288) train_loss=364.01959229 time/batch=0.36s
962/5900 (epoch 16.305) train_loss=324.17102051 time/batch=0.34s
963/5900 (epoch 16.322) train_loss=235.42218018 time/batch=0.28s
964/5900 (epoch 16.339) train_loss=340.54815674 time/batch=0.34s
965/5900 (epoch 16.356) train_loss=143.47746277 time/batch=0.23s
966/5900 (epoch 16.373) train_loss=231.71092224 time/batch=0.25s
967/5900 (epoch 16.390) train_loss=206.77081299 time/batch=0.27s
968/5900 (epoch 16.407) train_loss=106.63060760 time/batch=0.19s
969/5900 (epoch 16.424) train_loss=429.81488037 time/batch=0.41s
970/5900 (epoch 16.441) train_loss=288.42797852 time/batch=0.34s
971/5900 (epoch 16.458) train_loss=399.17980957 time/batch=0.41s
972/5900 (epoch 16.475) train_loss=307.69674683 time/batch=0.33s
973/5900 (epoch 16.492) train_loss=375.66708374 time/batch=0.39s
974/5900 (epoch 16.508) train_loss=167.44561768 time/batch=0.25s
975/5900 (epoch 16.525) train_loss=335.79226685 time/batch=0.34s
976/5900 (epoch 16.542) train_loss=98.13730621 time/batch=0.20s
977/5900 (epoch 16.559) train_loss=270.05679321 time/batch=0.29s
978/5900 (epoch 16.576) train_loss=342.93798828 time/batch=1.77s
979/5900 (epoch 16.593) train_loss=291.42517090 time/batch=0.58s
980/5900 (epoch 16.610) train_loss=303.33813477 time/batch=0.33s
981/5900 (epoch 16.627) train_loss=126.38179779 time/batch=0.20s
982/5900 (epoch 16.644) train_loss=326.19720459 time/batch=0.36s
983/5900 (epoch 16.661) train_loss=100.20912933 time/batch=0.20s
984/5900 (epoch 16.678) train_loss=104.55287170 time/batch=0.17s
985/5900 (epoch 16.695) train_loss=337.95367432 time/batch=0.36s
986/5900 (epoch 16.712) train_loss=311.07672119 time/batch=0.38s
987/5900 (epoch 16.729) train_loss=103.22485352 time/batch=0.21s
988/5900 (epoch 16.746) train_loss=98.18498993 time/batch=0.19s
989/5900 (epoch 16.763) train_loss=254.14862061 time/batch=0.28s
990/5900 (epoch 16.780) train_loss=301.12399292 time/batch=0.39s
991/5900 (epoch 16.797) train_loss=162.25424194 time/batch=0.26s
992/5900 (epoch 16.814) train_loss=101.83540344 time/batch=0.19s
993/5900 (epoch 16.831) train_loss=120.95137024 time/batch=0.20s
994/5900 (epoch 16.847) train_loss=100.16169739 time/batch=0.17s
995/5900 (epoch 16.864) train_loss=96.41049194 time/batch=0.17s
996/5900 (epoch 16.881) train_loss=96.68932343 time/batch=0.19s
997/5900 (epoch 16.898) train_loss=108.44744873 time/batch=0.17s
998/5900 (epoch 16.915) train_loss=112.41712952 time/batch=0.19s
999/5900 (epoch 16.932) train_loss=116.22039032 time/batch=0.20s
Validating
    loss:	220.822596

1000/5900 (epoch 16.949) train_loss=107.18247223 time/batch=0.60s
1001/5900 (epoch 16.966) train_loss=102.99829865 time/batch=0.19s
1002/5900 (epoch 16.983) train_loss=100.87772369 time/batch=0.19s
1003/5900 (epoch 17.000) train_loss=102.61793518 time/batch=0.17s
1004/5900 (epoch 17.017) train_loss=153.81823730 time/batch=0.20s
1005/5900 (epoch 17.034) train_loss=418.44519043 time/batch=0.39s
1006/5900 (epoch 17.051) train_loss=1466.69213867 time/batch=2.67s
1007/5900 (epoch 17.068) train_loss=380.44647217 time/batch=0.78s
1008/5900 (epoch 17.085) train_loss=208.88139343 time/batch=0.25s
1009/5900 (epoch 17.102) train_loss=704.53161621 time/batch=0.63s
1010/5900 (epoch 17.119) train_loss=268.76235962 time/batch=0.36s
1011/5900 (epoch 17.136) train_loss=233.42382812 time/batch=0.27s
1012/5900 (epoch 17.153) train_loss=367.90151978 time/batch=0.39s
1013/5900 (epoch 17.169) train_loss=514.91442871 time/batch=0.52s
1014/5900 (epoch 17.186) train_loss=441.65890503 time/batch=0.45s
1015/5900 (epoch 17.203) train_loss=215.15017700 time/batch=0.30s
1016/5900 (epoch 17.220) train_loss=417.47509766 time/batch=0.42s
1017/5900 (epoch 17.237) train_loss=293.89935303 time/batch=0.35s
1018/5900 (epoch 17.254) train_loss=527.62390137 time/batch=0.53s
1019/5900 (epoch 17.271) train_loss=352.20697021 time/batch=0.40s
1020/5900 (epoch 17.288) train_loss=177.50457764 time/batch=0.24s
1021/5900 (epoch 17.305) train_loss=388.93844604 time/batch=0.39s
1022/5900 (epoch 17.322) train_loss=361.45458984 time/batch=0.37s
1023/5900 (epoch 17.339) train_loss=287.27862549 time/batch=0.31s
1024/5900 (epoch 17.356) train_loss=267.44918823 time/batch=0.31s
1025/5900 (epoch 17.373) train_loss=201.63310242 time/batch=0.26s
1026/5900 (epoch 17.390) train_loss=351.76690674 time/batch=0.36s
1027/5900 (epoch 17.407) train_loss=314.63180542 time/batch=0.36s
1028/5900 (epoch 17.424) train_loss=163.12236023 time/batch=0.25s
1029/5900 (epoch 17.441) train_loss=249.77807617 time/batch=0.27s
1030/5900 (epoch 17.458) train_loss=330.10375977 time/batch=0.34s
1031/5900 (epoch 17.475) train_loss=403.20309448 time/batch=0.45s
1032/5900 (epoch 17.492) train_loss=118.91915131 time/batch=0.22s
1033/5900 (epoch 17.508) train_loss=110.02679443 time/batch=0.19s
1034/5900 (epoch 17.525) train_loss=336.53616333 time/batch=1.76s
1035/5900 (epoch 17.542) train_loss=301.00357056 time/batch=0.58s
1036/5900 (epoch 17.559) train_loss=100.02824402 time/batch=0.20s
1037/5900 (epoch 17.576) train_loss=263.91793823 time/batch=0.28s
1038/5900 (epoch 17.593) train_loss=252.93002319 time/batch=0.30s
1039/5900 (epoch 17.610) train_loss=96.01099396 time/batch=0.19s
1040/5900 (epoch 17.627) train_loss=294.04614258 time/batch=0.31s
1041/5900 (epoch 17.644) train_loss=114.28060913 time/batch=0.21s
1042/5900 (epoch 17.661) train_loss=96.50578308 time/batch=0.17s
1043/5900 (epoch 17.678) train_loss=325.16162109 time/batch=0.33s
1044/5900 (epoch 17.695) train_loss=238.87922668 time/batch=0.29s
1045/5900 (epoch 17.712) train_loss=241.06880188 time/batch=0.31s
1046/5900 (epoch 17.729) train_loss=269.21981812 time/batch=0.33s
1047/5900 (epoch 17.746) train_loss=141.38424683 time/batch=0.27s
1048/5900 (epoch 17.763) train_loss=104.62145233 time/batch=0.19s
1049/5900 (epoch 17.780) train_loss=101.25195312 time/batch=0.19s
1050/5900 (epoch 17.797) train_loss=109.36441040 time/batch=0.19s
1051/5900 (epoch 17.814) train_loss=116.53218842 time/batch=0.19s
1052/5900 (epoch 17.831) train_loss=103.00448608 time/batch=0.19s
1053/5900 (epoch 17.847) train_loss=119.68537903 time/batch=0.19s
1054/5900 (epoch 17.864) train_loss=102.75743103 time/batch=0.19s
1055/5900 (epoch 17.881) train_loss=97.13046265 time/batch=0.17s
1056/5900 (epoch 17.898) train_loss=108.40333557 time/batch=0.19s
1057/5900 (epoch 17.915) train_loss=97.19028473 time/batch=0.19s
1058/5900 (epoch 17.932) train_loss=101.41877747 time/batch=0.19s
1059/5900 (epoch 17.949) train_loss=97.92400360 time/batch=0.17s
1060/5900 (epoch 17.966) train_loss=99.36950684 time/batch=0.19s
1061/5900 (epoch 17.983) train_loss=98.53111267 time/batch=0.17s
1062/5900 (epoch 18.000) train_loss=103.00973511 time/batch=0.19s
1063/5900 (epoch 18.017) train_loss=110.05473328 time/batch=0.19s
1064/5900 (epoch 18.034) train_loss=248.27485657 time/batch=0.27s
1065/5900 (epoch 18.051) train_loss=389.12124634 time/batch=0.39s
1066/5900 (epoch 18.068) train_loss=558.84490967 time/batch=0.53s
1067/5900 (epoch 18.085) train_loss=371.53570557 time/batch=0.39s
1068/5900 (epoch 18.102) train_loss=199.94250488 time/batch=0.25s
1069/5900 (epoch 18.119) train_loss=432.65966797 time/batch=0.41s
1070/5900 (epoch 18.136) train_loss=216.87228394 time/batch=0.30s
1071/5900 (epoch 18.153) train_loss=203.46530151 time/batch=0.26s
1072/5900 (epoch 18.169) train_loss=138.78486633 time/batch=0.21s
1073/5900 (epoch 18.186) train_loss=307.02413940 time/batch=0.31s
1074/5900 (epoch 18.203) train_loss=366.02093506 time/batch=0.40s
1075/5900 (epoch 18.220) train_loss=346.28887939 time/batch=0.39s
1076/5900 (epoch 18.237) train_loss=270.35632324 time/batch=0.32s
1077/5900 (epoch 18.254) train_loss=705.37731934 time/batch=0.70s
1078/5900 (epoch 18.271) train_loss=386.17340088 time/batch=0.47s
1079/5900 (epoch 18.288) train_loss=295.91906738 time/batch=0.33s
1080/5900 (epoch 18.305) train_loss=521.50946045 time/batch=0.56s
1081/5900 (epoch 18.322) train_loss=847.92236328 time/batch=2.08s
1082/5900 (epoch 18.339) train_loss=250.46763611 time/batch=0.59s
1083/5900 (epoch 18.356) train_loss=170.37911987 time/batch=0.23s
1084/5900 (epoch 18.373) train_loss=98.67016602 time/batch=0.18s
1085/5900 (epoch 18.390) train_loss=290.73229980 time/batch=0.30s
1086/5900 (epoch 18.407) train_loss=810.40789795 time/batch=2.64s
1087/5900 (epoch 18.424) train_loss=237.59941101 time/batch=0.73s
1088/5900 (epoch 18.441) train_loss=559.18371582 time/batch=1.39s
1089/5900 (epoch 18.458) train_loss=258.98822021 time/batch=0.50s
1090/5900 (epoch 18.475) train_loss=318.45495605 time/batch=0.33s
1091/5900 (epoch 18.492) train_loss=209.52903748 time/batch=0.28s
1092/5900 (epoch 18.508) train_loss=229.03060913 time/batch=1.77s
1093/5900 (epoch 18.525) train_loss=103.47489929 time/batch=0.47s
1094/5900 (epoch 18.542) train_loss=177.75187683 time/batch=0.23s
1095/5900 (epoch 18.559) train_loss=74.55232239 time/batch=0.17s
1096/5900 (epoch 18.576) train_loss=110.69306946 time/batch=0.19s
1097/5900 (epoch 18.593) train_loss=108.23313141 time/batch=0.19s
1098/5900 (epoch 18.610) train_loss=351.05786133 time/batch=0.34s
1099/5900 (epoch 18.627) train_loss=102.92389679 time/batch=0.22s
1100/5900 (epoch 18.644) train_loss=347.96395874 time/batch=0.33s
1101/5900 (epoch 18.661) train_loss=266.91204834 time/batch=0.32s
1102/5900 (epoch 18.678) train_loss=317.44177246 time/batch=0.35s
1103/5900 (epoch 18.695) train_loss=321.42150879 time/batch=0.36s
1104/5900 (epoch 18.712) train_loss=98.88362122 time/batch=0.22s
1105/5900 (epoch 18.729) train_loss=260.76654053 time/batch=0.28s
1106/5900 (epoch 18.746) train_loss=105.36376190 time/batch=0.19s
1107/5900 (epoch 18.763) train_loss=290.23193359 time/batch=0.30s
1108/5900 (epoch 18.780) train_loss=229.11898804 time/batch=1.74s
1109/5900 (epoch 18.797) train_loss=104.28649902 time/batch=0.45s
1110/5900 (epoch 18.814) train_loss=129.67791748 time/batch=0.20s
1111/5900 (epoch 18.831) train_loss=117.99284363 time/batch=0.19s
1112/5900 (epoch 18.847) train_loss=189.17388916 time/batch=0.25s
1113/5900 (epoch 18.864) train_loss=97.46126556 time/batch=0.19s
1114/5900 (epoch 18.881) train_loss=115.14518738 time/batch=0.19s
1115/5900 (epoch 18.898) train_loss=222.46713257 time/batch=0.31s
1116/5900 (epoch 18.915) train_loss=103.76580048 time/batch=0.19s
1117/5900 (epoch 18.932) train_loss=99.88635254 time/batch=0.19s
1118/5900 (epoch 18.949) train_loss=100.25893402 time/batch=0.19s
1119/5900 (epoch 18.966) train_loss=97.50281525 time/batch=0.19s
1120/5900 (epoch 18.983) train_loss=99.07299805 time/batch=0.17s
1121/5900 (epoch 19.000) train_loss=96.62715149 time/batch=0.18s
1122/5900 (epoch 19.017) train_loss=1290.18579102 time/batch=2.65s
1123/5900 (epoch 19.034) train_loss=365.48541260 time/batch=0.76s
1124/5900 (epoch 19.051) train_loss=813.60156250 time/batch=1.42s
1125/5900 (epoch 19.068) train_loss=544.66290283 time/batch=0.70s
1126/5900 (epoch 19.085) train_loss=292.18524170 time/batch=0.36s
1127/5900 (epoch 19.102) train_loss=336.65780640 time/batch=0.36s
1128/5900 (epoch 19.119) train_loss=405.39874268 time/batch=0.42s
1129/5900 (epoch 19.136) train_loss=451.34994507 time/batch=0.49s
1130/5900 (epoch 19.153) train_loss=289.49047852 time/batch=0.35s
1131/5900 (epoch 19.169) train_loss=285.35552979 time/batch=0.33s
1132/5900 (epoch 19.186) train_loss=365.33633423 time/batch=0.39s
1133/5900 (epoch 19.203) train_loss=234.33517456 time/batch=0.28s
1134/5900 (epoch 19.220) train_loss=99.01901245 time/batch=0.19s
1135/5900 (epoch 19.237) train_loss=199.66462708 time/batch=0.25s
1136/5900 (epoch 19.254) train_loss=474.83996582 time/batch=0.51s
1137/5900 (epoch 19.271) train_loss=381.10345459 time/batch=0.42s
1138/5900 (epoch 19.288) train_loss=182.18150330 time/batch=0.27s
1139/5900 (epoch 19.305) train_loss=204.63403320 time/batch=0.25s
1140/5900 (epoch 19.322) train_loss=328.45446777 time/batch=0.34s
1141/5900 (epoch 19.339) train_loss=290.89398193 time/batch=0.33s
1142/5900 (epoch 19.356) train_loss=130.60852051 time/batch=0.22s
1143/5900 (epoch 19.373) train_loss=248.89617920 time/batch=0.27s
1144/5900 (epoch 19.390) train_loss=313.77008057 time/batch=0.33s
1145/5900 (epoch 19.407) train_loss=220.83985901 time/batch=0.28s
1146/5900 (epoch 19.424) train_loss=202.23701477 time/batch=1.80s
1147/5900 (epoch 19.441) train_loss=319.63497925 time/batch=0.62s
1148/5900 (epoch 19.458) train_loss=434.62011719 time/batch=0.43s
1149/5900 (epoch 19.475) train_loss=173.07040405 time/batch=0.25s
1150/5900 (epoch 19.492) train_loss=241.43826294 time/batch=0.28s
1151/5900 (epoch 19.508) train_loss=119.77006531 time/batch=0.20s
1152/5900 (epoch 19.525) train_loss=390.70697021 time/batch=0.39s
1153/5900 (epoch 19.542) train_loss=131.68344116 time/batch=0.23s
1154/5900 (epoch 19.559) train_loss=228.04425049 time/batch=0.27s
1155/5900 (epoch 19.576) train_loss=356.02160645 time/batch=0.37s
1156/5900 (epoch 19.593) train_loss=334.15380859 time/batch=0.37s
1157/5900 (epoch 19.610) train_loss=106.15736389 time/batch=0.21s
1158/5900 (epoch 19.627) train_loss=281.60739136 time/batch=0.30s
1159/5900 (epoch 19.644) train_loss=185.23510742 time/batch=0.27s
1160/5900 (epoch 19.661) train_loss=98.30619049 time/batch=0.19s
1161/5900 (epoch 19.678) train_loss=108.96981812 time/batch=0.19s
1162/5900 (epoch 19.695) train_loss=96.34596252 time/batch=0.18s
1163/5900 (epoch 19.712) train_loss=98.84974670 time/batch=0.17s
1164/5900 (epoch 19.729) train_loss=110.13833618 time/batch=0.19s
1165/5900 (epoch 19.746) train_loss=259.97369385 time/batch=0.28s
1166/5900 (epoch 19.763) train_loss=248.58038330 time/batch=0.29s
1167/5900 (epoch 19.780) train_loss=259.14331055 time/batch=0.31s
1168/5900 (epoch 19.797) train_loss=102.33897400 time/batch=0.19s
1169/5900 (epoch 19.814) train_loss=224.32112122 time/batch=1.72s
1170/5900 (epoch 19.831) train_loss=168.34201050 time/batch=0.55s
1171/5900 (epoch 19.847) train_loss=110.97651672 time/batch=0.20s
1172/5900 (epoch 19.864) train_loss=103.43906403 time/batch=0.19s
1173/5900 (epoch 19.881) train_loss=100.90477753 time/batch=0.19s
1174/5900 (epoch 19.898) train_loss=98.65315247 time/batch=0.17s
1175/5900 (epoch 19.915) train_loss=99.77824402 time/batch=0.19s
1176/5900 (epoch 19.932) train_loss=94.88820648 time/batch=0.19s
1177/5900 (epoch 19.949) train_loss=114.55134583 time/batch=0.19s
1178/5900 (epoch 19.966) train_loss=104.71984863 time/batch=0.17s
1179/5900 (epoch 19.983) train_loss=103.71380615 time/batch=0.19s
1180/5900 (epoch 20.000) train_loss=97.82199860 time/batch=0.19s
  saved to metadata/config5--20190119-190634.pkl
1181/5900 (epoch 20.017) train_loss=136.19216919 time/batch=7.20s
1182/5900 (epoch 20.034) train_loss=165.21258545 time/batch=0.23s
1183/5900 (epoch 20.051) train_loss=208.47586060 time/batch=0.25s
1184/5900 (epoch 20.068) train_loss=389.29260254 time/batch=0.39s
1185/5900 (epoch 20.085) train_loss=412.42510986 time/batch=0.43s
1186/5900 (epoch 20.102) train_loss=336.48651123 time/batch=0.36s
1187/5900 (epoch 20.119) train_loss=1234.40649414 time/batch=2.66s
1188/5900 (epoch 20.136) train_loss=277.92404175 time/batch=0.74s
1189/5900 (epoch 20.153) train_loss=438.91174316 time/batch=0.45s
1190/5900 (epoch 20.169) train_loss=661.03588867 time/batch=0.64s
1191/5900 (epoch 20.186) train_loss=254.30935669 time/batch=0.33s
1192/5900 (epoch 20.203) train_loss=348.00643921 time/batch=0.36s
1193/5900 (epoch 20.220) train_loss=718.84710693 time/batch=1.39s
1194/5900 (epoch 20.237) train_loss=487.86328125 time/batch=0.67s
1195/5900 (epoch 20.254) train_loss=288.00524902 time/batch=0.36s
1196/5900 (epoch 20.271) train_loss=253.40101624 time/batch=0.31s
1197/5900 (epoch 20.288) train_loss=119.24700928 time/batch=0.20s
1198/5900 (epoch 20.305) train_loss=406.50857544 time/batch=0.39s
1199/5900 (epoch 20.322) train_loss=99.20187378 time/batch=0.22s
1200/5900 (epoch 20.339) train_loss=385.34060669 time/batch=0.39s
1201/5900 (epoch 20.356) train_loss=373.77249146 time/batch=0.44s
1202/5900 (epoch 20.373) train_loss=97.19335938 time/batch=0.22s
1203/5900 (epoch 20.390) train_loss=349.99841309 time/batch=0.36s
1204/5900 (epoch 20.407) train_loss=283.45812988 time/batch=0.33s
1205/5900 (epoch 20.424) train_loss=334.74380493 time/batch=0.36s
1206/5900 (epoch 20.441) train_loss=158.72021484 time/batch=0.25s
1207/5900 (epoch 20.458) train_loss=173.97451782 time/batch=0.23s
1208/5900 (epoch 20.475) train_loss=248.94375610 time/batch=0.28s
1209/5900 (epoch 20.492) train_loss=309.17916870 time/batch=0.34s
1210/5900 (epoch 20.508) train_loss=247.47894287 time/batch=0.30s
1211/5900 (epoch 20.525) train_loss=230.70407104 time/batch=0.27s
1212/5900 (epoch 20.542) train_loss=285.62597656 time/batch=0.31s
1213/5900 (epoch 20.559) train_loss=98.08415222 time/batch=0.20s
1214/5900 (epoch 20.576) train_loss=209.52885437 time/batch=0.25s
1215/5900 (epoch 20.593) train_loss=286.32983398 time/batch=0.33s
1216/5900 (epoch 20.610) train_loss=251.26643372 time/batch=0.30s
1217/5900 (epoch 20.627) train_loss=194.32769775 time/batch=0.25s
1218/5900 (epoch 20.644) train_loss=295.06744385 time/batch=0.33s
1219/5900 (epoch 20.661) train_loss=227.65170288 time/batch=0.30s
1220/5900 (epoch 20.678) train_loss=190.95365906 time/batch=0.34s
1221/5900 (epoch 20.695) train_loss=325.22314453 time/batch=0.34s
1222/5900 (epoch 20.712) train_loss=101.17199707 time/batch=0.20s
1223/5900 (epoch 20.729) train_loss=321.39837646 time/batch=1.77s
1224/5900 (epoch 20.746) train_loss=99.65798950 time/batch=0.47s
1225/5900 (epoch 20.763) train_loss=118.44720459 time/batch=0.19s
1226/5900 (epoch 20.780) train_loss=103.29222107 time/batch=0.19s
1227/5900 (epoch 20.797) train_loss=98.87294769 time/batch=0.17s
1228/5900 (epoch 20.814) train_loss=108.98625183 time/batch=0.19s
1229/5900 (epoch 20.831) train_loss=109.79110718 time/batch=0.19s
1230/5900 (epoch 20.847) train_loss=151.46038818 time/batch=0.33s
1231/5900 (epoch 20.864) train_loss=99.08110046 time/batch=0.20s
1232/5900 (epoch 20.881) train_loss=106.37791443 time/batch=0.19s
1233/5900 (epoch 20.898) train_loss=97.67907715 time/batch=0.17s
1234/5900 (epoch 20.915) train_loss=98.67065430 time/batch=0.19s
1235/5900 (epoch 20.932) train_loss=103.70770264 time/batch=0.19s
1236/5900 (epoch 20.949) train_loss=101.78848267 time/batch=0.17s
1237/5900 (epoch 20.966) train_loss=101.67881775 time/batch=0.19s
1238/5900 (epoch 20.983) train_loss=96.66159821 time/batch=0.18s
1239/5900 (epoch 21.000) train_loss=99.64287567 time/batch=0.20s
1240/5900 (epoch 21.017) train_loss=295.33306885 time/batch=0.30s
1241/5900 (epoch 21.034) train_loss=381.52368164 time/batch=0.39s
1242/5900 (epoch 21.051) train_loss=219.51150513 time/batch=0.28s
1243/5900 (epoch 21.068) train_loss=391.55383301 time/batch=0.40s
1244/5900 (epoch 21.085) train_loss=362.39440918 time/batch=0.39s
1245/5900 (epoch 21.102) train_loss=132.48269653 time/batch=0.23s
1246/5900 (epoch 21.119) train_loss=957.59509277 time/batch=2.01s
1247/5900 (epoch 21.136) train_loss=1114.78125000 time/batch=2.97s
1248/5900 (epoch 21.153) train_loss=390.27178955 time/batch=0.83s
1249/5900 (epoch 21.169) train_loss=264.45010376 time/batch=0.33s
1250/5900 (epoch 21.186) train_loss=238.74246216 time/batch=0.28s
1251/5900 (epoch 21.203) train_loss=343.45843506 time/batch=0.36s
1252/5900 (epoch 21.220) train_loss=178.63943481 time/batch=0.25s
1253/5900 (epoch 21.237) train_loss=95.03784180 time/batch=0.18s
1254/5900 (epoch 21.254) train_loss=248.20010376 time/batch=0.28s
1255/5900 (epoch 21.271) train_loss=504.50378418 time/batch=0.49s
1256/5900 (epoch 21.288) train_loss=99.13265991 time/batch=0.23s
1257/5900 (epoch 21.305) train_loss=154.04489136 time/batch=0.20s
1258/5900 (epoch 21.322) train_loss=309.89447021 time/batch=1.77s
1259/5900 (epoch 21.339) train_loss=423.37634277 time/batch=0.70s
1260/5900 (epoch 21.356) train_loss=283.97235107 time/batch=0.34s
1261/5900 (epoch 21.373) train_loss=448.43676758 time/batch=0.48s
1262/5900 (epoch 21.390) train_loss=228.87948608 time/batch=0.31s
1263/5900 (epoch 21.407) train_loss=423.57754517 time/batch=0.45s
1264/5900 (epoch 21.424) train_loss=252.81402588 time/batch=0.32s
1265/5900 (epoch 21.441) train_loss=282.01391602 time/batch=0.32s
1266/5900 (epoch 21.458) train_loss=234.91079712 time/batch=0.30s
1267/5900 (epoch 21.475) train_loss=329.66040039 time/batch=0.34s
1268/5900 (epoch 21.492) train_loss=289.19409180 time/batch=0.33s
1269/5900 (epoch 21.508) train_loss=101.15441132 time/batch=0.19s
1270/5900 (epoch 21.525) train_loss=207.08636475 time/batch=0.25s
1271/5900 (epoch 21.542) train_loss=209.77957153 time/batch=0.27s
1272/5900 (epoch 21.559) train_loss=433.11706543 time/batch=0.52s
1273/5900 (epoch 21.576) train_loss=250.79115295 time/batch=0.33s
1274/5900 (epoch 21.593) train_loss=190.00335693 time/batch=0.25s
1275/5900 (epoch 21.610) train_loss=331.98062134 time/batch=0.36s
1276/5900 (epoch 21.627) train_loss=263.02249146 time/batch=0.33s
1277/5900 (epoch 21.644) train_loss=139.74401855 time/batch=0.24s
1278/5900 (epoch 21.661) train_loss=103.15950012 time/batch=0.19s
1279/5900 (epoch 21.678) train_loss=104.49726868 time/batch=0.18s
1280/5900 (epoch 21.695) train_loss=325.16821289 time/batch=0.33s
1281/5900 (epoch 21.712) train_loss=313.60748291 time/batch=0.35s
1282/5900 (epoch 21.729) train_loss=284.09963989 time/batch=0.36s
1283/5900 (epoch 21.746) train_loss=116.95468903 time/batch=0.21s
1284/5900 (epoch 21.763) train_loss=107.51188660 time/batch=0.19s
1285/5900 (epoch 21.780) train_loss=98.99154663 time/batch=0.19s
1286/5900 (epoch 21.797) train_loss=98.23881531 time/batch=0.18s
1287/5900 (epoch 21.814) train_loss=113.74560547 time/batch=0.19s
1288/5900 (epoch 21.831) train_loss=95.73206329 time/batch=0.19s
1289/5900 (epoch 21.847) train_loss=133.14242554 time/batch=0.23s
1290/5900 (epoch 21.864) train_loss=103.05925751 time/batch=0.19s
1291/5900 (epoch 21.881) train_loss=98.24534607 time/batch=0.19s
1292/5900 (epoch 21.898) train_loss=105.14257050 time/batch=0.19s
1293/5900 (epoch 21.915) train_loss=96.70254517 time/batch=0.17s
1294/5900 (epoch 21.932) train_loss=94.44927979 time/batch=0.17s
1295/5900 (epoch 21.949) train_loss=102.90374756 time/batch=0.20s
1296/5900 (epoch 21.966) train_loss=94.96882629 time/batch=0.17s
1297/5900 (epoch 21.983) train_loss=101.25559998 time/batch=0.19s
1298/5900 (epoch 22.000) train_loss=98.25963593 time/batch=0.17s
setting learning rate to 0.0029100
1299/5900 (epoch 22.017) train_loss=416.92956543 time/batch=0.42s
1300/5900 (epoch 22.034) train_loss=1022.79217529 time/batch=2.09s
1301/5900 (epoch 22.051) train_loss=244.19964600 time/batch=0.59s
1302/5900 (epoch 22.068) train_loss=353.47488403 time/batch=0.37s
1303/5900 (epoch 22.085) train_loss=1026.08203125 time/batch=2.67s
1304/5900 (epoch 22.102) train_loss=255.86384583 time/batch=0.73s
1305/5900 (epoch 22.119) train_loss=213.60415649 time/batch=0.28s
1306/5900 (epoch 22.136) train_loss=232.80946350 time/batch=0.28s
1307/5900 (epoch 22.153) train_loss=125.03692627 time/batch=0.21s
1308/5900 (epoch 22.169) train_loss=358.70642090 time/batch=0.38s
1309/5900 (epoch 22.186) train_loss=318.42813110 time/batch=0.36s
1310/5900 (epoch 22.203) train_loss=342.95874023 time/batch=0.38s
1311/5900 (epoch 22.220) train_loss=97.64108276 time/batch=0.21s
1312/5900 (epoch 22.237) train_loss=317.75878906 time/batch=0.34s
1313/5900 (epoch 22.254) train_loss=107.98859406 time/batch=0.21s
1314/5900 (epoch 22.271) train_loss=128.34523010 time/batch=0.21s
1315/5900 (epoch 22.288) train_loss=290.99066162 time/batch=0.32s
1316/5900 (epoch 22.305) train_loss=283.62829590 time/batch=0.34s
1317/5900 (epoch 22.322) train_loss=260.43017578 time/batch=0.31s
1318/5900 (epoch 22.339) train_loss=522.65582275 time/batch=0.52s
1319/5900 (epoch 22.356) train_loss=205.90025330 time/batch=0.32s
1320/5900 (epoch 22.373) train_loss=412.38882446 time/batch=0.42s
1321/5900 (epoch 22.390) train_loss=160.72219849 time/batch=0.25s
1322/5900 (epoch 22.407) train_loss=195.64549255 time/batch=0.25s
1323/5900 (epoch 22.424) train_loss=400.65002441 time/batch=0.40s
1324/5900 (epoch 22.441) train_loss=434.24389648 time/batch=0.48s
1325/5900 (epoch 22.458) train_loss=181.08969116 time/batch=0.26s
1326/5900 (epoch 22.475) train_loss=275.44244385 time/batch=0.32s
1327/5900 (epoch 22.492) train_loss=286.58197021 time/batch=0.34s
1328/5900 (epoch 22.508) train_loss=267.78826904 time/batch=0.32s
1329/5900 (epoch 22.525) train_loss=133.13189697 time/batch=0.23s
1330/5900 (epoch 22.542) train_loss=327.16213989 time/batch=0.34s
1331/5900 (epoch 22.559) train_loss=226.24797058 time/batch=0.29s
1332/5900 (epoch 22.576) train_loss=348.04479980 time/batch=0.39s
1333/5900 (epoch 22.593) train_loss=212.59031677 time/batch=0.31s
1334/5900 (epoch 22.610) train_loss=442.05114746 time/batch=0.46s
1335/5900 (epoch 22.627) train_loss=269.32751465 time/batch=0.35s
1336/5900 (epoch 22.644) train_loss=326.61911011 time/batch=0.39s
1337/5900 (epoch 22.661) train_loss=111.30433655 time/batch=0.21s
1338/5900 (epoch 22.678) train_loss=110.34314728 time/batch=0.19s
1339/5900 (epoch 22.695) train_loss=248.94532776 time/batch=0.27s
1340/5900 (epoch 22.712) train_loss=176.42050171 time/batch=0.29s
1341/5900 (epoch 22.729) train_loss=316.49847412 time/batch=1.77s
1342/5900 (epoch 22.746) train_loss=100.28483582 time/batch=0.47s
1343/5900 (epoch 22.763) train_loss=103.15476990 time/batch=0.19s
1344/5900 (epoch 22.780) train_loss=94.38202667 time/batch=0.17s
1345/5900 (epoch 22.797) train_loss=107.13118744 time/batch=0.18s
1346/5900 (epoch 22.814) train_loss=97.86106873 time/batch=0.19s
1347/5900 (epoch 22.831) train_loss=99.54881287 time/batch=0.17s
1348/5900 (epoch 22.847) train_loss=125.55737305 time/batch=0.31s
1349/5900 (epoch 22.864) train_loss=95.02137756 time/batch=0.19s
1350/5900 (epoch 22.881) train_loss=148.96376038 time/batch=0.31s
1351/5900 (epoch 22.898) train_loss=96.79577637 time/batch=0.19s
1352/5900 (epoch 22.915) train_loss=97.32289124 time/batch=0.17s
1353/5900 (epoch 22.932) train_loss=104.15669250 time/batch=0.19s
1354/5900 (epoch 22.949) train_loss=97.18622589 time/batch=0.19s
1355/5900 (epoch 22.966) train_loss=98.83811188 time/batch=0.18s
1356/5900 (epoch 22.983) train_loss=97.53944397 time/batch=0.17s
1357/5900 (epoch 23.000) train_loss=96.43006897 time/batch=0.17s
setting learning rate to 0.0028227
1358/5900 (epoch 23.017) train_loss=358.33529663 time/batch=0.37s
1359/5900 (epoch 23.034) train_loss=328.03005981 time/batch=0.38s
1360/5900 (epoch 23.051) train_loss=281.42382812 time/batch=0.33s
1361/5900 (epoch 23.068) train_loss=1264.93652344 time/batch=2.68s
1362/5900 (epoch 23.085) train_loss=189.08944702 time/batch=0.68s
1363/5900 (epoch 23.102) train_loss=343.54586792 time/batch=0.36s
1364/5900 (epoch 23.119) train_loss=226.09396362 time/batch=0.29s
1365/5900 (epoch 23.136) train_loss=756.83044434 time/batch=1.40s
1366/5900 (epoch 23.153) train_loss=421.93527222 time/batch=0.63s
1367/5900 (epoch 23.169) train_loss=108.16641235 time/batch=0.22s
1368/5900 (epoch 23.186) train_loss=409.00201416 time/batch=0.42s
1369/5900 (epoch 23.203) train_loss=421.83578491 time/batch=0.49s
1370/5900 (epoch 23.220) train_loss=187.09805298 time/batch=0.28s
1371/5900 (epoch 23.237) train_loss=166.49560547 time/batch=0.24s
1372/5900 (epoch 23.254) train_loss=171.26811218 time/batch=0.25s
1373/5900 (epoch 23.271) train_loss=285.01498413 time/batch=0.33s
1374/5900 (epoch 23.288) train_loss=325.98422241 time/batch=0.37s
1375/5900 (epoch 23.305) train_loss=98.43746948 time/batch=0.20s
1376/5900 (epoch 23.322) train_loss=222.94134521 time/batch=0.27s
1377/5900 (epoch 23.339) train_loss=94.84764099 time/batch=0.18s
1378/5900 (epoch 23.356) train_loss=519.32409668 time/batch=0.50s
1379/5900 (epoch 23.373) train_loss=101.91821289 time/batch=0.24s
1380/5900 (epoch 23.390) train_loss=452.63720703 time/batch=0.47s
1381/5900 (epoch 23.407) train_loss=378.57025146 time/batch=0.44s
1382/5900 (epoch 23.424) train_loss=192.57104492 time/batch=1.78s
1383/5900 (epoch 23.441) train_loss=206.25326538 time/batch=2.00s
1384/5900 (epoch 23.458) train_loss=99.29846191 time/batch=0.45s
1385/5900 (epoch 23.475) train_loss=137.18627930 time/batch=0.20s
1386/5900 (epoch 23.492) train_loss=286.68984985 time/batch=0.31s
1387/5900 (epoch 23.508) train_loss=269.93612671 time/batch=0.30s
1388/5900 (epoch 23.525) train_loss=326.28936768 time/batch=0.37s
1389/5900 (epoch 23.542) train_loss=99.31485748 time/batch=0.20s
1390/5900 (epoch 23.559) train_loss=218.99310303 time/batch=0.25s
1391/5900 (epoch 23.576) train_loss=259.77108765 time/batch=0.32s
1392/5900 (epoch 23.593) train_loss=203.13818359 time/batch=0.27s
1393/5900 (epoch 23.610) train_loss=371.15579224 time/batch=0.39s
1394/5900 (epoch 23.627) train_loss=279.25976562 time/batch=0.34s
1395/5900 (epoch 23.644) train_loss=234.49539185 time/batch=0.29s
1396/5900 (epoch 23.661) train_loss=117.24802399 time/batch=0.20s
1397/5900 (epoch 23.678) train_loss=103.50370789 time/batch=0.18s
1398/5900 (epoch 23.695) train_loss=321.05645752 time/batch=0.34s
1399/5900 (epoch 23.712) train_loss=312.78982544 time/batch=0.34s
1400/5900 (epoch 23.729) train_loss=210.95587158 time/batch=0.30s
1401/5900 (epoch 23.746) train_loss=257.77557373 time/batch=0.31s
1402/5900 (epoch 23.763) train_loss=118.74061584 time/batch=0.20s
1403/5900 (epoch 23.780) train_loss=126.30633545 time/batch=0.21s
1404/5900 (epoch 23.797) train_loss=101.83683014 time/batch=0.18s
1405/5900 (epoch 23.814) train_loss=250.58364868 time/batch=0.28s
1406/5900 (epoch 23.831) train_loss=234.15364075 time/batch=0.30s
1407/5900 (epoch 23.847) train_loss=102.75004578 time/batch=0.20s
1408/5900 (epoch 23.864) train_loss=99.78339386 time/batch=0.19s
1409/5900 (epoch 23.881) train_loss=105.78833771 time/batch=0.19s
1410/5900 (epoch 23.898) train_loss=98.72075653 time/batch=0.18s
1411/5900 (epoch 23.915) train_loss=165.33651733 time/batch=0.32s
1412/5900 (epoch 23.932) train_loss=97.16437531 time/batch=0.19s
1413/5900 (epoch 23.949) train_loss=106.89234161 time/batch=0.19s
1414/5900 (epoch 23.966) train_loss=102.77685547 time/batch=0.18s
1415/5900 (epoch 23.983) train_loss=95.53886414 time/batch=0.17s
1416/5900 (epoch 24.000) train_loss=94.95375824 time/batch=0.19s
setting learning rate to 0.0027380
1417/5900 (epoch 24.017) train_loss=158.78524780 time/batch=0.21s
1418/5900 (epoch 24.034) train_loss=287.11529541 time/batch=0.33s
1419/5900 (epoch 24.051) train_loss=263.21331787 time/batch=0.31s
1420/5900 (epoch 24.068) train_loss=432.11050415 time/batch=0.46s
1421/5900 (epoch 24.085) train_loss=388.03485107 time/batch=0.43s
1422/5900 (epoch 24.102) train_loss=276.96069336 time/batch=0.34s
1423/5900 (epoch 24.119) train_loss=1335.89526367 time/batch=2.66s
1424/5900 (epoch 24.136) train_loss=704.77935791 time/batch=1.06s
1425/5900 (epoch 24.153) train_loss=508.08892822 time/batch=0.53s
1426/5900 (epoch 24.169) train_loss=318.66839600 time/batch=0.39s
1427/5900 (epoch 24.186) train_loss=226.25082397 time/batch=0.30s
1428/5900 (epoch 24.203) train_loss=505.52465820 time/batch=0.52s
1429/5900 (epoch 24.220) train_loss=404.19857788 time/batch=0.45s
1430/5900 (epoch 24.237) train_loss=358.57800293 time/batch=0.42s
1431/5900 (epoch 24.254) train_loss=110.69608307 time/batch=0.22s
1432/5900 (epoch 24.271) train_loss=345.03781128 time/batch=0.36s
1433/5900 (epoch 24.288) train_loss=107.90548706 time/batch=0.22s
1434/5900 (epoch 24.305) train_loss=104.58728027 time/batch=0.19s
1435/5900 (epoch 24.322) train_loss=260.21081543 time/batch=0.29s
1436/5900 (epoch 24.339) train_loss=124.69450378 time/batch=0.21s
1437/5900 (epoch 24.356) train_loss=99.94477844 time/batch=0.19s
1438/5900 (epoch 24.373) train_loss=204.08026123 time/batch=0.24s
1439/5900 (epoch 24.390) train_loss=301.57144165 time/batch=1.78s
1440/5900 (epoch 24.407) train_loss=224.36718750 time/batch=0.55s
1441/5900 (epoch 24.424) train_loss=355.79586792 time/batch=0.39s
1442/5900 (epoch 24.441) train_loss=176.30749512 time/batch=0.26s
1443/5900 (epoch 24.458) train_loss=324.63070679 time/batch=0.34s
1444/5900 (epoch 24.475) train_loss=99.20315552 time/batch=0.21s
1445/5900 (epoch 24.492) train_loss=366.53137207 time/batch=0.39s
1446/5900 (epoch 24.508) train_loss=315.98828125 time/batch=0.37s
1447/5900 (epoch 24.525) train_loss=99.05429077 time/batch=0.20s
1448/5900 (epoch 24.542) train_loss=302.15820312 time/batch=0.32s
1449/5900 (epoch 24.559) train_loss=236.02827454 time/batch=0.31s
1450/5900 (epoch 24.576) train_loss=177.94422913 time/batch=0.25s
1451/5900 (epoch 24.593) train_loss=270.30862427 time/batch=0.31s
1452/5900 (epoch 24.610) train_loss=279.42730713 time/batch=0.34s
1453/5900 (epoch 24.627) train_loss=240.32904053 time/batch=0.31s
1454/5900 (epoch 24.644) train_loss=232.65794373 time/batch=0.30s
1455/5900 (epoch 24.661) train_loss=98.00637817 time/batch=0.20s
1456/5900 (epoch 24.678) train_loss=361.21401978 time/batch=0.45s
1457/5900 (epoch 24.695) train_loss=245.34509277 time/batch=0.32s
1458/5900 (epoch 24.712) train_loss=96.19471741 time/batch=0.20s
1459/5900 (epoch 24.729) train_loss=112.38327026 time/batch=0.19s
1460/5900 (epoch 24.746) train_loss=196.81100464 time/batch=0.24s
1461/5900 (epoch 24.763) train_loss=115.14773560 time/batch=0.21s
1462/5900 (epoch 24.780) train_loss=104.02305603 time/batch=0.17s
1463/5900 (epoch 24.797) train_loss=258.31295776 time/batch=0.31s
1464/5900 (epoch 24.814) train_loss=140.46488953 time/batch=0.27s
1465/5900 (epoch 24.831) train_loss=208.99700928 time/batch=0.26s
1466/5900 (epoch 24.847) train_loss=103.34785461 time/batch=0.19s
1467/5900 (epoch 24.864) train_loss=96.25334930 time/batch=0.19s
1468/5900 (epoch 24.881) train_loss=100.40373230 time/batch=0.18s
1469/5900 (epoch 24.898) train_loss=117.51023102 time/batch=0.25s
1470/5900 (epoch 24.915) train_loss=102.43089294 time/batch=0.19s
1471/5900 (epoch 24.932) train_loss=98.32014465 time/batch=0.19s
1472/5900 (epoch 24.949) train_loss=96.31046295 time/batch=0.19s
1473/5900 (epoch 24.966) train_loss=94.70332336 time/batch=0.17s
1474/5900 (epoch 24.983) train_loss=93.82109070 time/batch=0.19s
1475/5900 (epoch 25.000) train_loss=92.82154846 time/batch=0.17s
setting learning rate to 0.0026559
1476/5900 (epoch 25.017) train_loss=409.39514160 time/batch=0.42s
1477/5900 (epoch 25.034) train_loss=498.92727661 time/batch=0.52s
1478/5900 (epoch 25.051) train_loss=448.51345825 time/batch=0.49s
1479/5900 (epoch 25.068) train_loss=162.91471863 time/batch=0.27s
1480/5900 (epoch 25.085) train_loss=630.17785645 time/batch=0.62s
1481/5900 (epoch 25.102) train_loss=1371.92822266 time/batch=2.72s
1482/5900 (epoch 25.119) train_loss=382.62878418 time/batch=0.83s
1483/5900 (epoch 25.136) train_loss=480.81011963 time/batch=0.66s
1484/5900 (epoch 25.153) train_loss=271.90994263 time/batch=0.39s
1485/5900 (epoch 25.169) train_loss=304.33944702 time/batch=1.78s
1486/5900 (epoch 25.186) train_loss=338.79162598 time/batch=0.64s
1487/5900 (epoch 25.203) train_loss=244.35578918 time/batch=0.30s
1488/5900 (epoch 25.220) train_loss=264.41741943 time/batch=0.32s
1489/5900 (epoch 25.237) train_loss=148.15473938 time/batch=0.24s
1490/5900 (epoch 25.254) train_loss=332.30407715 time/batch=0.34s
1491/5900 (epoch 25.271) train_loss=263.52001953 time/batch=0.33s
1492/5900 (epoch 25.288) train_loss=179.45294189 time/batch=0.25s
1493/5900 (epoch 25.305) train_loss=199.50320435 time/batch=0.26s
1494/5900 (epoch 25.322) train_loss=326.64666748 time/batch=0.37s
1495/5900 (epoch 25.339) train_loss=134.47769165 time/batch=0.25s
1496/5900 (epoch 25.356) train_loss=289.23168945 time/batch=0.33s
1497/5900 (epoch 25.373) train_loss=228.43753052 time/batch=0.31s
1498/5900 (epoch 25.390) train_loss=233.27149963 time/batch=0.30s
1499/5900 (epoch 25.407) train_loss=350.90826416 time/batch=0.39s
1500/5900 (epoch 25.424) train_loss=250.08250427 time/batch=0.31s
1501/5900 (epoch 25.441) train_loss=269.46392822 time/batch=0.33s
1502/5900 (epoch 25.458) train_loss=317.38464355 time/batch=0.36s
1503/5900 (epoch 25.475) train_loss=225.61476135 time/batch=0.30s
1504/5900 (epoch 25.492) train_loss=383.10742188 time/batch=0.42s
1505/5900 (epoch 25.508) train_loss=295.84997559 time/batch=0.35s
1506/5900 (epoch 25.525) train_loss=239.98217773 time/batch=0.31s
1507/5900 (epoch 25.542) train_loss=221.51779175 time/batch=0.28s
1508/5900 (epoch 25.559) train_loss=107.76654053 time/batch=0.19s
1509/5900 (epoch 25.576) train_loss=97.53186798 time/batch=0.18s
1510/5900 (epoch 25.593) train_loss=122.39888763 time/batch=0.19s
1511/5900 (epoch 25.610) train_loss=109.66574097 time/batch=0.19s
1512/5900 (epoch 25.627) train_loss=191.88943481 time/batch=0.25s
1513/5900 (epoch 25.644) train_loss=121.83778381 time/batch=0.20s
1514/5900 (epoch 25.661) train_loss=218.32693481 time/batch=0.26s
1515/5900 (epoch 25.678) train_loss=318.49780273 time/batch=0.34s
1516/5900 (epoch 25.695) train_loss=120.65028381 time/batch=0.26s
1517/5900 (epoch 25.712) train_loss=97.56655884 time/batch=0.19s
1518/5900 (epoch 25.729) train_loss=282.41351318 time/batch=0.33s
1519/5900 (epoch 25.746) train_loss=109.18968201 time/batch=0.22s
1520/5900 (epoch 25.763) train_loss=250.28512573 time/batch=0.38s
1521/5900 (epoch 25.780) train_loss=174.25067139 time/batch=0.42s
1522/5900 (epoch 25.797) train_loss=107.71985626 time/batch=0.23s
1523/5900 (epoch 25.814) train_loss=98.57905579 time/batch=0.19s
1524/5900 (epoch 25.831) train_loss=95.18186188 time/batch=0.17s
1525/5900 (epoch 25.847) train_loss=99.87593842 time/batch=0.19s
1526/5900 (epoch 25.864) train_loss=94.78981781 time/batch=0.17s
1527/5900 (epoch 25.881) train_loss=102.36241150 time/batch=0.19s
1528/5900 (epoch 25.898) train_loss=94.95660400 time/batch=0.17s
1529/5900 (epoch 25.915) train_loss=93.10641479 time/batch=0.18s
1530/5900 (epoch 25.932) train_loss=96.23757172 time/batch=0.17s
1531/5900 (epoch 25.949) train_loss=94.99079895 time/batch=0.19s
1532/5900 (epoch 25.966) train_loss=95.55440521 time/batch=0.17s
1533/5900 (epoch 25.983) train_loss=99.33758545 time/batch=0.17s
1534/5900 (epoch 26.000) train_loss=96.77131653 time/batch=0.18s
setting learning rate to 0.0025762
1535/5900 (epoch 26.017) train_loss=490.66503906 time/batch=0.49s
1536/5900 (epoch 26.034) train_loss=420.26971436 time/batch=0.48s
1537/5900 (epoch 26.051) train_loss=1310.44165039 time/batch=2.69s
1538/5900 (epoch 26.068) train_loss=403.66558838 time/batch=0.84s
1539/5900 (epoch 26.085) train_loss=417.34823608 time/batch=0.47s
1540/5900 (epoch 26.102) train_loss=186.01531982 time/batch=0.25s
1541/5900 (epoch 26.119) train_loss=297.25744629 time/batch=0.34s
1542/5900 (epoch 26.136) train_loss=244.56472778 time/batch=0.30s
1543/5900 (epoch 26.153) train_loss=202.34445190 time/batch=0.28s
1544/5900 (epoch 26.169) train_loss=213.97045898 time/batch=0.27s
1545/5900 (epoch 26.186) train_loss=456.79806519 time/batch=0.52s
1546/5900 (epoch 26.203) train_loss=342.77899170 time/batch=0.42s
1547/5900 (epoch 26.220) train_loss=182.39773560 time/batch=0.28s
1548/5900 (epoch 26.237) train_loss=269.23309326 time/batch=0.31s
1549/5900 (epoch 26.254) train_loss=230.95025635 time/batch=0.30s
1550/5900 (epoch 26.271) train_loss=499.36761475 time/batch=0.59s
1551/5900 (epoch 26.288) train_loss=152.34057617 time/batch=0.27s
1552/5900 (epoch 26.305) train_loss=340.32818604 time/batch=0.37s
1553/5900 (epoch 26.322) train_loss=504.22375488 time/batch=0.65s
1554/5900 (epoch 26.339) train_loss=337.34878540 time/batch=0.45s
1555/5900 (epoch 26.356) train_loss=187.76486206 time/batch=0.28s
1556/5900 (epoch 26.373) train_loss=104.85867310 time/batch=0.20s
1557/5900 (epoch 26.390) train_loss=241.91123962 time/batch=0.27s
1558/5900 (epoch 26.407) train_loss=230.61111450 time/batch=0.29s
1559/5900 (epoch 26.424) train_loss=298.60675049 time/batch=1.78s
1560/5900 (epoch 26.441) train_loss=223.15084839 time/batch=0.56s
1561/5900 (epoch 26.458) train_loss=273.99203491 time/batch=0.31s
1562/5900 (epoch 26.475) train_loss=286.83984375 time/batch=0.33s
1563/5900 (epoch 26.492) train_loss=201.27690125 time/batch=0.28s
1564/5900 (epoch 26.508) train_loss=95.32212067 time/batch=0.19s
1565/5900 (epoch 26.525) train_loss=280.71667480 time/batch=0.33s
1566/5900 (epoch 26.542) train_loss=111.49934387 time/batch=0.21s
1567/5900 (epoch 26.559) train_loss=121.88327026 time/batch=0.20s
1568/5900 (epoch 26.576) train_loss=310.61523438 time/batch=0.34s
1569/5900 (epoch 26.593) train_loss=228.32037354 time/batch=0.32s
1570/5900 (epoch 26.610) train_loss=130.27548218 time/batch=0.22s
1571/5900 (epoch 26.627) train_loss=325.02444458 time/batch=0.35s
1572/5900 (epoch 26.644) train_loss=311.33242798 time/batch=0.36s
1573/5900 (epoch 26.661) train_loss=126.34214783 time/batch=0.25s
1574/5900 (epoch 26.678) train_loss=273.44934082 time/batch=0.32s
1575/5900 (epoch 26.695) train_loss=110.29354858 time/batch=0.19s
1576/5900 (epoch 26.712) train_loss=104.34619141 time/batch=0.19s
1577/5900 (epoch 26.729) train_loss=94.67632294 time/batch=0.18s
1578/5900 (epoch 26.746) train_loss=270.70339966 time/batch=0.30s
1579/5900 (epoch 26.763) train_loss=97.92068481 time/batch=0.21s
1580/5900 (epoch 26.780) train_loss=97.21537781 time/batch=0.19s
1581/5900 (epoch 26.797) train_loss=103.29785156 time/batch=0.19s
1582/5900 (epoch 26.814) train_loss=276.30706787 time/batch=0.34s
1583/5900 (epoch 26.831) train_loss=101.11208344 time/batch=0.21s
1584/5900 (epoch 26.847) train_loss=105.40411377 time/batch=0.19s
1585/5900 (epoch 26.864) train_loss=110.45713806 time/batch=0.19s
1586/5900 (epoch 26.881) train_loss=94.32707977 time/batch=0.19s
1587/5900 (epoch 26.898) train_loss=99.08775330 time/batch=0.18s
1588/5900 (epoch 26.915) train_loss=103.42239380 time/batch=0.19s
1589/5900 (epoch 26.932) train_loss=93.29328918 time/batch=0.19s
1590/5900 (epoch 26.949) train_loss=93.34320068 time/batch=0.17s
1591/5900 (epoch 26.966) train_loss=91.24116516 time/batch=0.19s
1592/5900 (epoch 26.983) train_loss=95.79637146 time/batch=0.17s
1593/5900 (epoch 27.000) train_loss=96.52909088 time/batch=0.19s
setting learning rate to 0.0024989
1594/5900 (epoch 27.017) train_loss=170.93557739 time/batch=0.21s
1595/5900 (epoch 27.034) train_loss=549.93157959 time/batch=0.56s
1596/5900 (epoch 27.051) train_loss=96.43237305 time/batch=0.25s
1597/5900 (epoch 27.068) train_loss=429.33999634 time/batch=0.42s
1598/5900 (epoch 27.085) train_loss=149.57400513 time/batch=0.28s
1599/5900 (epoch 27.102) train_loss=322.42965698 time/batch=0.35s
1600/5900 (epoch 27.119) train_loss=123.63536835 time/batch=0.23s
1601/5900 (epoch 27.136) train_loss=1224.48803711 time/batch=2.65s
1602/5900 (epoch 27.153) train_loss=556.99011230 time/batch=1.07s
1603/5900 (epoch 27.169) train_loss=371.85366821 time/batch=0.46s
1604/5900 (epoch 27.186) train_loss=395.12631226 time/batch=0.44s
1605/5900 (epoch 27.203) train_loss=251.09262085 time/batch=0.33s
1606/5900 (epoch 27.220) train_loss=345.57446289 time/batch=0.40s
1607/5900 (epoch 27.237) train_loss=415.47656250 time/batch=0.49s
1608/5900 (epoch 27.254) train_loss=184.62249756 time/batch=0.30s
1609/5900 (epoch 27.271) train_loss=193.58166504 time/batch=0.25s
1610/5900 (epoch 27.288) train_loss=341.41217041 time/batch=0.37s
1611/5900 (epoch 27.305) train_loss=97.64939117 time/batch=0.22s
1612/5900 (epoch 27.322) train_loss=372.87567139 time/batch=0.44s
1613/5900 (epoch 27.339) train_loss=306.44940186 time/batch=0.38s
1614/5900 (epoch 27.356) train_loss=132.20425415 time/batch=0.25s
1615/5900 (epoch 27.373) train_loss=225.74417114 time/batch=0.28s
1616/5900 (epoch 27.390) train_loss=320.18359375 time/batch=0.36s
1617/5900 (epoch 27.407) train_loss=219.78240967 time/batch=0.31s
1618/5900 (epoch 27.424) train_loss=487.83462524 time/batch=1.39s
1619/5900 (epoch 27.441) train_loss=95.09634399 time/batch=0.38s
1620/5900 (epoch 27.458) train_loss=264.29315186 time/batch=0.29s
1621/5900 (epoch 27.475) train_loss=91.93318939 time/batch=0.20s
1622/5900 (epoch 27.492) train_loss=216.43489075 time/batch=0.27s
1623/5900 (epoch 27.508) train_loss=215.59532166 time/batch=0.30s
1624/5900 (epoch 27.525) train_loss=128.38172913 time/batch=0.24s
1625/5900 (epoch 27.542) train_loss=264.87847900 time/batch=0.31s
1626/5900 (epoch 27.559) train_loss=254.55130005 time/batch=0.33s
1627/5900 (epoch 27.576) train_loss=303.10406494 time/batch=0.33s
1628/5900 (epoch 27.593) train_loss=124.80081177 time/batch=0.26s
1629/5900 (epoch 27.610) train_loss=297.12286377 time/batch=1.78s
1630/5900 (epoch 27.627) train_loss=300.96820068 time/batch=0.61s
1631/5900 (epoch 27.644) train_loss=280.52691650 time/batch=0.34s
1632/5900 (epoch 27.661) train_loss=103.64465332 time/batch=0.21s
1633/5900 (epoch 27.678) train_loss=237.24578857 time/batch=0.28s
1634/5900 (epoch 27.695) train_loss=101.14615631 time/batch=0.19s
1635/5900 (epoch 27.712) train_loss=279.84234619 time/batch=0.31s
1636/5900 (epoch 27.729) train_loss=241.06802368 time/batch=0.30s
1637/5900 (epoch 27.746) train_loss=193.00509644 time/batch=0.27s
1638/5900 (epoch 27.763) train_loss=245.86810303 time/batch=0.31s
1639/5900 (epoch 27.780) train_loss=203.50219727 time/batch=0.33s
1640/5900 (epoch 27.797) train_loss=108.87371826 time/batch=0.22s
1641/5900 (epoch 27.814) train_loss=101.94837952 time/batch=0.17s
1642/5900 (epoch 27.831) train_loss=95.81075287 time/batch=0.19s
1643/5900 (epoch 27.847) train_loss=91.34774780 time/batch=0.18s
1644/5900 (epoch 27.864) train_loss=92.21311188 time/batch=0.18s
1645/5900 (epoch 27.881) train_loss=99.01232910 time/batch=0.18s
1646/5900 (epoch 27.898) train_loss=103.94830322 time/batch=0.19s
1647/5900 (epoch 27.915) train_loss=105.85786438 time/batch=0.18s
1648/5900 (epoch 27.932) train_loss=105.79930115 time/batch=0.19s
1649/5900 (epoch 27.949) train_loss=94.69705200 time/batch=0.19s
1650/5900 (epoch 27.966) train_loss=95.37809753 time/batch=0.17s
1651/5900 (epoch 27.983) train_loss=92.98366547 time/batch=0.19s
1652/5900 (epoch 28.000) train_loss=99.90226746 time/batch=0.17s
setting learning rate to 0.0024239
1653/5900 (epoch 28.017) train_loss=544.58941650 time/batch=0.55s
1654/5900 (epoch 28.034) train_loss=376.61090088 time/batch=0.45s
1655/5900 (epoch 28.051) train_loss=1190.97570801 time/batch=2.67s
1656/5900 (epoch 28.068) train_loss=93.41887665 time/batch=0.63s
1657/5900 (epoch 28.085) train_loss=423.18585205 time/batch=0.45s
1658/5900 (epoch 28.102) train_loss=229.05540466 time/batch=0.31s
1659/5900 (epoch 28.119) train_loss=333.51586914 time/batch=0.39s
1660/5900 (epoch 28.136) train_loss=249.97491455 time/batch=0.33s
1661/5900 (epoch 28.153) train_loss=195.16275024 time/batch=0.28s
1662/5900 (epoch 28.169) train_loss=228.74505615 time/batch=0.28s
1663/5900 (epoch 28.186) train_loss=274.18814087 time/batch=0.33s
1664/5900 (epoch 28.203) train_loss=394.82171631 time/batch=0.43s
1665/5900 (epoch 28.220) train_loss=263.31832886 time/batch=0.34s
1666/5900 (epoch 28.237) train_loss=268.14715576 time/batch=0.33s
1667/5900 (epoch 28.254) train_loss=157.42453003 time/batch=0.24s
1668/5900 (epoch 28.271) train_loss=184.87500000 time/batch=0.25s
1669/5900 (epoch 28.288) train_loss=126.60659790 time/batch=0.20s
1670/5900 (epoch 28.305) train_loss=523.05541992 time/batch=0.59s
1671/5900 (epoch 28.322) train_loss=192.64491272 time/batch=1.83s
1672/5900 (epoch 28.339) train_loss=308.31188965 time/batch=0.62s
1673/5900 (epoch 28.356) train_loss=255.85388184 time/batch=0.33s
1674/5900 (epoch 28.373) train_loss=373.49316406 time/batch=0.41s
1675/5900 (epoch 28.390) train_loss=182.02281189 time/batch=0.28s
1676/5900 (epoch 28.407) train_loss=335.41348267 time/batch=0.38s
1677/5900 (epoch 28.424) train_loss=99.44244385 time/batch=0.21s
1678/5900 (epoch 28.441) train_loss=314.14923096 time/batch=0.35s
1679/5900 (epoch 28.458) train_loss=412.14031982 time/batch=0.48s
1680/5900 (epoch 28.475) train_loss=105.82064819 time/batch=0.24s
1681/5900 (epoch 28.492) train_loss=233.11518860 time/batch=0.30s
1682/5900 (epoch 28.508) train_loss=107.41538239 time/batch=0.19s
1683/5900 (epoch 28.525) train_loss=370.21087646 time/batch=0.63s
1684/5900 (epoch 28.542) train_loss=454.10037231 time/batch=1.44s
1685/5900 (epoch 28.559) train_loss=240.21398926 time/batch=0.50s
1686/5900 (epoch 28.576) train_loss=195.44793701 time/batch=0.26s
1687/5900 (epoch 28.593) train_loss=197.30931091 time/batch=0.28s
1688/5900 (epoch 28.610) train_loss=265.02313232 time/batch=0.32s
1689/5900 (epoch 28.627) train_loss=95.72930908 time/batch=0.19s
1690/5900 (epoch 28.644) train_loss=208.62449646 time/batch=0.27s
1691/5900 (epoch 28.661) train_loss=111.90275574 time/batch=0.21s
1692/5900 (epoch 28.678) train_loss=103.62879944 time/batch=0.18s
1693/5900 (epoch 28.695) train_loss=195.14529419 time/batch=1.73s
1694/5900 (epoch 28.712) train_loss=91.47763062 time/batch=0.45s
1695/5900 (epoch 28.729) train_loss=257.12976074 time/batch=0.32s
1696/5900 (epoch 28.746) train_loss=145.01838684 time/batch=0.23s
1697/5900 (epoch 28.763) train_loss=304.10818481 time/batch=0.33s
1698/5900 (epoch 28.780) train_loss=167.03884888 time/batch=0.30s
1699/5900 (epoch 28.797) train_loss=108.66088104 time/batch=0.20s
1700/5900 (epoch 28.814) train_loss=103.15861511 time/batch=0.17s
1701/5900 (epoch 28.831) train_loss=159.00245667 time/batch=0.27s
1702/5900 (epoch 28.847) train_loss=92.54023743 time/batch=0.20s
1703/5900 (epoch 28.864) train_loss=103.19796753 time/batch=0.19s
1704/5900 (epoch 28.881) train_loss=91.26805115 time/batch=0.19s
1705/5900 (epoch 28.898) train_loss=227.02154541 time/batch=0.33s
1706/5900 (epoch 28.915) train_loss=100.61454773 time/batch=0.20s
1707/5900 (epoch 28.932) train_loss=95.04268646 time/batch=0.19s
1708/5900 (epoch 28.949) train_loss=96.54731750 time/batch=0.17s
1709/5900 (epoch 28.966) train_loss=94.31912231 time/batch=0.19s
1710/5900 (epoch 28.983) train_loss=97.82505798 time/batch=0.19s
1711/5900 (epoch 29.000) train_loss=99.18611145 time/batch=0.17s
setting learning rate to 0.0023512
1712/5900 (epoch 29.017) train_loss=1257.23535156 time/batch=2.65s
1713/5900 (epoch 29.034) train_loss=670.61535645 time/batch=1.08s
1714/5900 (epoch 29.051) train_loss=318.01095581 time/batch=0.41s
1715/5900 (epoch 29.068) train_loss=224.10775757 time/batch=0.28s
1716/5900 (epoch 29.085) train_loss=224.17385864 time/batch=0.29s
1717/5900 (epoch 29.102) train_loss=395.78295898 time/batch=0.45s
1718/5900 (epoch 29.119) train_loss=462.30892944 time/batch=0.54s
1719/5900 (epoch 29.136) train_loss=171.56173706 time/batch=0.28s
1720/5900 (epoch 29.153) train_loss=203.61898804 time/batch=1.79s
1721/5900 (epoch 29.169) train_loss=317.74118042 time/batch=0.64s
1722/5900 (epoch 29.186) train_loss=168.18429565 time/batch=0.27s
1723/5900 (epoch 29.203) train_loss=353.54400635 time/batch=0.38s
1724/5900 (epoch 29.220) train_loss=325.95376587 time/batch=0.39s
1725/5900 (epoch 29.237) train_loss=230.68238831 time/batch=0.31s
1726/5900 (epoch 29.254) train_loss=221.51290894 time/batch=0.30s
1727/5900 (epoch 29.271) train_loss=413.82873535 time/batch=0.46s
1728/5900 (epoch 29.288) train_loss=295.28491211 time/batch=0.38s
1729/5900 (epoch 29.305) train_loss=254.85574341 time/batch=0.33s
1730/5900 (epoch 29.322) train_loss=306.90649414 time/batch=0.37s
1731/5900 (epoch 29.339) train_loss=123.60781860 time/batch=0.22s
1732/5900 (epoch 29.356) train_loss=257.66055298 time/batch=0.31s
1733/5900 (epoch 29.373) train_loss=276.22518921 time/batch=0.33s
1734/5900 (epoch 29.390) train_loss=178.19885254 time/batch=0.28s
1735/5900 (epoch 29.407) train_loss=142.33172607 time/batch=0.21s
1736/5900 (epoch 29.424) train_loss=217.90646362 time/batch=0.29s
1737/5900 (epoch 29.441) train_loss=242.01272583 time/batch=0.30s
1738/5900 (epoch 29.458) train_loss=204.06668091 time/batch=0.28s
1739/5900 (epoch 29.475) train_loss=214.83389282 time/batch=0.31s
1740/5900 (epoch 29.492) train_loss=185.10552979 time/batch=0.27s
1741/5900 (epoch 29.508) train_loss=145.32537842 time/batch=0.27s
1742/5900 (epoch 29.525) train_loss=394.42654419 time/batch=0.47s
1743/5900 (epoch 29.542) train_loss=277.45068359 time/batch=0.34s
1744/5900 (epoch 29.559) train_loss=359.38296509 time/batch=0.41s
1745/5900 (epoch 29.576) train_loss=76.11759186 time/batch=0.20s
1746/5900 (epoch 29.593) train_loss=380.29083252 time/batch=0.39s
1747/5900 (epoch 29.610) train_loss=101.34439850 time/batch=0.22s
1748/5900 (epoch 29.627) train_loss=264.81811523 time/batch=0.30s
1749/5900 (epoch 29.644) train_loss=204.21054077 time/batch=0.33s
1750/5900 (epoch 29.661) train_loss=287.01980591 time/batch=0.35s
1751/5900 (epoch 29.678) train_loss=368.31170654 time/batch=0.52s
1752/5900 (epoch 29.695) train_loss=100.43660736 time/batch=0.23s
1753/5900 (epoch 29.712) train_loss=96.50042725 time/batch=0.19s
1754/5900 (epoch 29.729) train_loss=99.56532288 time/batch=0.19s
1755/5900 (epoch 29.746) train_loss=110.42651367 time/batch=0.19s
1756/5900 (epoch 29.763) train_loss=130.66722107 time/batch=0.33s
1757/5900 (epoch 29.780) train_loss=192.81887817 time/batch=1.73s
1758/5900 (epoch 29.797) train_loss=93.73345947 time/batch=0.45s
1759/5900 (epoch 29.814) train_loss=91.25018311 time/batch=0.18s
1760/5900 (epoch 29.831) train_loss=107.41570282 time/batch=0.19s
1761/5900 (epoch 29.847) train_loss=98.83199310 time/batch=0.18s
1762/5900 (epoch 29.864) train_loss=92.00720978 time/batch=0.19s
1763/5900 (epoch 29.881) train_loss=93.76358032 time/batch=0.19s
1764/5900 (epoch 29.898) train_loss=105.90309143 time/batch=0.19s
1765/5900 (epoch 29.915) train_loss=94.01768494 time/batch=0.17s
1766/5900 (epoch 29.932) train_loss=100.47667694 time/batch=0.19s
1767/5900 (epoch 29.949) train_loss=102.21789551 time/batch=0.19s
1768/5900 (epoch 29.966) train_loss=94.70497131 time/batch=0.17s
1769/5900 (epoch 29.983) train_loss=96.81455994 time/batch=0.18s
1770/5900 (epoch 30.000) train_loss=101.16235352 time/batch=0.19s
setting learning rate to 0.0022807
  saved to metadata/config5--20190119-190634.pkl
1771/5900 (epoch 30.017) train_loss=330.83404541 time/batch=7.17s
1772/5900 (epoch 30.034) train_loss=243.29705811 time/batch=0.33s
1773/5900 (epoch 30.051) train_loss=1256.33032227 time/batch=2.66s
1774/5900 (epoch 30.068) train_loss=479.44012451 time/batch=0.92s
1775/5900 (epoch 30.085) train_loss=123.06863403 time/batch=0.23s
1776/5900 (epoch 30.102) train_loss=320.92700195 time/batch=0.35s
1777/5900 (epoch 30.119) train_loss=123.75232697 time/batch=0.23s
1778/5900 (epoch 30.136) train_loss=91.49113464 time/batch=0.19s
1779/5900 (epoch 30.153) train_loss=347.22076416 time/batch=0.38s
1780/5900 (epoch 30.169) train_loss=302.93975830 time/batch=0.38s
1781/5900 (epoch 30.186) train_loss=285.01504517 time/batch=0.34s
1782/5900 (epoch 30.203) train_loss=611.80834961 time/batch=0.66s
1783/5900 (epoch 30.220) train_loss=412.96914673 time/batch=0.48s
1784/5900 (epoch 30.237) train_loss=187.77027893 time/batch=1.80s
1785/5900 (epoch 30.254) train_loss=298.16888428 time/batch=0.61s
1786/5900 (epoch 30.271) train_loss=386.43786621 time/batch=0.45s
1787/5900 (epoch 30.288) train_loss=96.64643860 time/batch=0.22s
1788/5900 (epoch 30.305) train_loss=132.78967285 time/batch=0.22s
1789/5900 (epoch 30.322) train_loss=183.05053711 time/batch=0.25s
1790/5900 (epoch 30.339) train_loss=185.69842529 time/batch=0.25s
1791/5900 (epoch 30.356) train_loss=465.94207764 time/batch=0.51s
1792/5900 (epoch 30.373) train_loss=182.66186523 time/batch=0.28s
1793/5900 (epoch 30.390) train_loss=336.51684570 time/batch=0.39s
1794/5900 (epoch 30.407) train_loss=95.38594055 time/batch=0.22s
1795/5900 (epoch 30.424) train_loss=366.36187744 time/batch=0.39s
1796/5900 (epoch 30.441) train_loss=294.69720459 time/batch=0.37s
1797/5900 (epoch 30.458) train_loss=166.40167236 time/batch=0.25s
1798/5900 (epoch 30.475) train_loss=307.17352295 time/batch=0.36s
1799/5900 (epoch 30.492) train_loss=174.84756470 time/batch=0.27s
1800/5900 (epoch 30.508) train_loss=184.09515381 time/batch=1.73s
1801/5900 (epoch 30.525) train_loss=196.26765442 time/batch=0.53s
1802/5900 (epoch 30.542) train_loss=272.79666138 time/batch=0.36s
1803/5900 (epoch 30.559) train_loss=223.62995911 time/batch=0.29s
1804/5900 (epoch 30.576) train_loss=97.79568481 time/batch=0.19s
1805/5900 (epoch 30.593) train_loss=218.83250427 time/batch=0.27s
1806/5900 (epoch 30.610) train_loss=107.95426941 time/batch=0.20s
1807/5900 (epoch 30.627) train_loss=259.19500732 time/batch=0.31s
1808/5900 (epoch 30.644) train_loss=215.76776123 time/batch=0.30s
1809/5900 (epoch 30.661) train_loss=259.03869629 time/batch=0.30s
1810/5900 (epoch 30.678) train_loss=98.98098755 time/batch=0.20s
1811/5900 (epoch 30.695) train_loss=236.94937134 time/batch=0.28s
1812/5900 (epoch 30.712) train_loss=230.67420959 time/batch=0.30s
1813/5900 (epoch 30.729) train_loss=236.86636353 time/batch=0.31s
1814/5900 (epoch 30.746) train_loss=258.37438965 time/batch=0.34s
1815/5900 (epoch 30.763) train_loss=111.78354645 time/batch=0.21s
1816/5900 (epoch 30.780) train_loss=152.55528259 time/batch=0.28s
1817/5900 (epoch 30.797) train_loss=103.06727600 time/batch=0.20s
1818/5900 (epoch 30.814) train_loss=103.73867035 time/batch=0.19s
1819/5900 (epoch 30.831) train_loss=98.68737793 time/batch=0.19s
1820/5900 (epoch 30.847) train_loss=94.46020508 time/batch=0.17s
1821/5900 (epoch 30.864) train_loss=91.20596313 time/batch=0.19s
1822/5900 (epoch 30.881) train_loss=91.43150330 time/batch=0.17s
1823/5900 (epoch 30.898) train_loss=282.15264893 time/batch=0.31s
1824/5900 (epoch 30.915) train_loss=102.35346985 time/batch=0.20s
1825/5900 (epoch 30.932) train_loss=92.44964600 time/batch=0.17s
1826/5900 (epoch 30.949) train_loss=98.60393524 time/batch=0.19s
1827/5900 (epoch 30.966) train_loss=96.43678284 time/batch=0.19s
1828/5900 (epoch 30.983) train_loss=97.91749573 time/batch=0.19s
1829/5900 (epoch 31.000) train_loss=99.20460510 time/batch=0.19s
setting learning rate to 0.0022123
1830/5900 (epoch 31.017) train_loss=256.35455322 time/batch=0.30s
1831/5900 (epoch 31.034) train_loss=300.65432739 time/batch=0.36s
1832/5900 (epoch 31.051) train_loss=165.47407532 time/batch=0.25s
1833/5900 (epoch 31.068) train_loss=144.52629089 time/batch=0.22s
1834/5900 (epoch 31.085) train_loss=429.99218750 time/batch=0.47s
1835/5900 (epoch 31.102) train_loss=123.67962646 time/batch=0.25s
1836/5900 (epoch 31.119) train_loss=353.31460571 time/batch=0.39s
1837/5900 (epoch 31.136) train_loss=571.98706055 time/batch=0.64s
1838/5900 (epoch 31.153) train_loss=564.03912354 time/batch=0.75s
1839/5900 (epoch 31.169) train_loss=101.53594971 time/batch=0.27s
1840/5900 (epoch 31.186) train_loss=284.42831421 time/batch=0.32s
1841/5900 (epoch 31.203) train_loss=352.48236084 time/batch=0.43s
1842/5900 (epoch 31.220) train_loss=193.75878906 time/batch=0.28s
1843/5900 (epoch 31.237) train_loss=248.92089844 time/batch=0.33s
1844/5900 (epoch 31.254) train_loss=280.61477661 time/batch=0.34s
1845/5900 (epoch 31.271) train_loss=178.71478271 time/batch=0.27s
1846/5900 (epoch 31.288) train_loss=759.24719238 time/batch=2.05s
1847/5900 (epoch 31.305) train_loss=325.28619385 time/batch=0.70s
1848/5900 (epoch 31.322) train_loss=371.27124023 time/batch=0.44s
1849/5900 (epoch 31.339) train_loss=311.17483521 time/batch=0.36s
1850/5900 (epoch 31.356) train_loss=98.55661774 time/batch=0.22s
1851/5900 (epoch 31.373) train_loss=207.68727112 time/batch=0.25s
1852/5900 (epoch 31.390) train_loss=94.33132935 time/batch=0.20s
1853/5900 (epoch 31.407) train_loss=88.26300049 time/batch=0.17s
1854/5900 (epoch 31.424) train_loss=228.19577026 time/batch=0.28s
1855/5900 (epoch 31.441) train_loss=195.89862061 time/batch=0.28s
1856/5900 (epoch 31.458) train_loss=243.00161743 time/batch=0.30s
1857/5900 (epoch 31.475) train_loss=320.33801270 time/batch=0.38s
1858/5900 (epoch 31.492) train_loss=882.21929932 time/batch=2.66s
1859/5900 (epoch 31.508) train_loss=117.12326050 time/batch=0.64s
1860/5900 (epoch 31.525) train_loss=228.32241821 time/batch=0.27s
1861/5900 (epoch 31.542) train_loss=192.09962463 time/batch=0.28s
1862/5900 (epoch 31.559) train_loss=230.66889954 time/batch=0.31s
1863/5900 (epoch 31.576) train_loss=213.09625244 time/batch=0.28s
1864/5900 (epoch 31.593) train_loss=108.77055359 time/batch=0.20s
1865/5900 (epoch 31.610) train_loss=227.60382080 time/batch=0.28s
1866/5900 (epoch 31.627) train_loss=273.37188721 time/batch=0.35s
1867/5900 (epoch 31.644) train_loss=343.96942139 time/batch=0.43s
1868/5900 (epoch 31.661) train_loss=169.58015442 time/batch=0.32s
1869/5900 (epoch 31.678) train_loss=97.54272461 time/batch=0.19s
1870/5900 (epoch 31.695) train_loss=204.69822693 time/batch=1.76s
1871/5900 (epoch 31.712) train_loss=122.43966675 time/batch=0.47s
1872/5900 (epoch 31.729) train_loss=95.45621490 time/batch=0.19s
1873/5900 (epoch 31.746) train_loss=263.30145264 time/batch=0.31s
1874/5900 (epoch 31.763) train_loss=229.36090088 time/batch=0.31s
1875/5900 (epoch 31.780) train_loss=127.40747070 time/batch=0.31s
1876/5900 (epoch 31.797) train_loss=103.63568878 time/batch=0.22s
1877/5900 (epoch 31.814) train_loss=324.52075195 time/batch=0.36s
1878/5900 (epoch 31.831) train_loss=105.67422485 time/batch=0.22s
1879/5900 (epoch 31.847) train_loss=96.85401154 time/batch=0.18s
1880/5900 (epoch 31.864) train_loss=95.17131042 time/batch=0.18s
1881/5900 (epoch 31.881) train_loss=141.61331177 time/batch=0.35s
1882/5900 (epoch 31.898) train_loss=167.57156372 time/batch=1.75s
1883/5900 (epoch 31.915) train_loss=94.54968262 time/batch=0.45s
1884/5900 (epoch 31.932) train_loss=97.96852875 time/batch=0.19s
1885/5900 (epoch 31.949) train_loss=93.76619720 time/batch=0.19s
1886/5900 (epoch 31.966) train_loss=93.14601135 time/batch=0.18s
1887/5900 (epoch 31.983) train_loss=93.25721741 time/batch=0.19s
1888/5900 (epoch 32.000) train_loss=95.15191650 time/batch=0.17s
setting learning rate to 0.0021459
1889/5900 (epoch 32.017) train_loss=212.26388550 time/batch=0.28s
1890/5900 (epoch 32.034) train_loss=218.95950317 time/batch=0.29s
1891/5900 (epoch 32.051) train_loss=385.61682129 time/batch=0.41s
1892/5900 (epoch 32.068) train_loss=104.92793274 time/batch=0.22s
1893/5900 (epoch 32.085) train_loss=153.45491028 time/batch=0.22s
1894/5900 (epoch 32.102) train_loss=198.67126465 time/batch=0.26s
1895/5900 (epoch 32.119) train_loss=182.95809937 time/batch=0.26s
1896/5900 (epoch 32.136) train_loss=247.56039429 time/batch=0.31s
1897/5900 (epoch 32.153) train_loss=613.05664062 time/batch=0.69s
1898/5900 (epoch 32.169) train_loss=208.49658203 time/batch=0.35s
1899/5900 (epoch 32.186) train_loss=441.62322998 time/batch=0.49s
1900/5900 (epoch 32.203) train_loss=182.54043579 time/batch=1.81s
1901/5900 (epoch 32.220) train_loss=827.56756592 time/batch=2.33s
1902/5900 (epoch 32.237) train_loss=353.21490479 time/batch=0.71s
1903/5900 (epoch 32.254) train_loss=180.18229675 time/batch=0.30s
1904/5900 (epoch 32.271) train_loss=92.72972870 time/batch=0.19s
1905/5900 (epoch 32.288) train_loss=863.70336914 time/batch=2.66s
1906/5900 (epoch 32.305) train_loss=324.86215210 time/batch=0.79s
1907/5900 (epoch 32.322) train_loss=326.35250854 time/batch=0.38s
1908/5900 (epoch 32.339) train_loss=290.74185181 time/batch=0.35s
1909/5900 (epoch 32.356) train_loss=307.69018555 time/batch=0.39s
1910/5900 (epoch 32.373) train_loss=381.89697266 time/batch=0.47s
1911/5900 (epoch 32.390) train_loss=100.43146515 time/batch=0.22s
1912/5900 (epoch 32.407) train_loss=212.33792114 time/batch=0.27s
1913/5900 (epoch 32.424) train_loss=141.85223389 time/batch=0.24s
1914/5900 (epoch 32.441) train_loss=294.87347412 time/batch=0.36s
1915/5900 (epoch 32.458) train_loss=307.53887939 time/batch=0.39s
1916/5900 (epoch 32.475) train_loss=172.70771790 time/batch=0.27s
1917/5900 (epoch 32.492) train_loss=311.16476440 time/batch=0.38s
1918/5900 (epoch 32.508) train_loss=108.56676483 time/batch=0.21s
1919/5900 (epoch 32.525) train_loss=232.86021423 time/batch=0.29s
1920/5900 (epoch 32.542) train_loss=246.96286011 time/batch=0.34s
1921/5900 (epoch 32.559) train_loss=156.82424927 time/batch=0.25s
1922/5900 (epoch 32.576) train_loss=98.50444031 time/batch=0.19s
1923/5900 (epoch 32.593) train_loss=252.26190186 time/batch=0.31s
1924/5900 (epoch 32.610) train_loss=96.48007202 time/batch=0.20s
1925/5900 (epoch 32.627) train_loss=89.19306946 time/batch=0.19s
1926/5900 (epoch 32.644) train_loss=353.90310669 time/batch=0.38s
1927/5900 (epoch 32.661) train_loss=180.15145874 time/batch=1.76s
1928/5900 (epoch 32.678) train_loss=228.76866150 time/batch=0.57s
1929/5900 (epoch 32.695) train_loss=249.09945679 time/batch=0.30s
1930/5900 (epoch 32.712) train_loss=235.64624023 time/batch=0.31s
1931/5900 (epoch 32.729) train_loss=122.25292969 time/batch=0.22s
1932/5900 (epoch 32.746) train_loss=104.06322479 time/batch=0.18s
1933/5900 (epoch 32.763) train_loss=100.28942871 time/batch=0.19s
1934/5900 (epoch 32.780) train_loss=105.76309204 time/batch=0.20s
1935/5900 (epoch 32.797) train_loss=323.32580566 time/batch=0.39s
1936/5900 (epoch 32.814) train_loss=255.18179321 time/batch=0.35s
1937/5900 (epoch 32.831) train_loss=191.84651184 time/batch=0.33s
1938/5900 (epoch 32.847) train_loss=147.47052002 time/batch=0.34s
1939/5900 (epoch 32.864) train_loss=99.06277466 time/batch=0.21s
1940/5900 (epoch 32.881) train_loss=98.45880890 time/batch=0.18s
1941/5900 (epoch 32.898) train_loss=92.19051361 time/batch=0.19s
1942/5900 (epoch 32.915) train_loss=93.67549896 time/batch=0.18s
1943/5900 (epoch 32.932) train_loss=95.79857635 time/batch=0.18s
1944/5900 (epoch 32.949) train_loss=93.65280914 time/batch=0.19s
1945/5900 (epoch 32.966) train_loss=92.28260803 time/batch=0.17s
1946/5900 (epoch 32.983) train_loss=90.79904175 time/batch=0.17s
1947/5900 (epoch 33.000) train_loss=93.62866211 time/batch=0.19s
setting learning rate to 0.0020815
1948/5900 (epoch 33.017) train_loss=166.16366577 time/batch=0.23s
1949/5900 (epoch 33.034) train_loss=202.97465515 time/batch=0.27s
1950/5900 (epoch 33.051) train_loss=537.43231201 time/batch=0.61s
1951/5900 (epoch 33.068) train_loss=397.72320557 time/batch=0.47s
1952/5900 (epoch 33.085) train_loss=176.90423584 time/batch=0.28s
1953/5900 (epoch 33.102) train_loss=118.01411438 time/batch=0.21s
1954/5900 (epoch 33.119) train_loss=286.31219482 time/batch=0.35s
1955/5900 (epoch 33.136) train_loss=897.85119629 time/batch=2.05s
1956/5900 (epoch 33.153) train_loss=246.74255371 time/batch=0.61s
1957/5900 (epoch 33.169) train_loss=851.99322510 time/batch=2.66s
1958/5900 (epoch 33.186) train_loss=152.79943848 time/batch=0.66s
1959/5900 (epoch 33.203) train_loss=254.07093811 time/batch=0.30s
1960/5900 (epoch 33.220) train_loss=117.20509338 time/batch=0.22s
1961/5900 (epoch 33.237) train_loss=409.10757446 time/batch=0.45s
1962/5900 (epoch 33.254) train_loss=249.93586731 time/batch=0.36s
1963/5900 (epoch 33.271) train_loss=386.03833008 time/batch=0.47s
1964/5900 (epoch 33.288) train_loss=104.18178558 time/batch=0.23s
1965/5900 (epoch 33.305) train_loss=266.05688477 time/batch=0.33s
1966/5900 (epoch 33.322) train_loss=291.23007202 time/batch=0.36s
1967/5900 (epoch 33.339) train_loss=185.51876831 time/batch=0.28s
1968/5900 (epoch 33.356) train_loss=346.26251221 time/batch=0.41s
1969/5900 (epoch 33.373) train_loss=319.48785400 time/batch=0.39s
1970/5900 (epoch 33.390) train_loss=179.67243958 time/batch=0.28s
1971/5900 (epoch 33.407) train_loss=308.68899536 time/batch=0.37s
1972/5900 (epoch 33.424) train_loss=219.44638062 time/batch=0.31s
1973/5900 (epoch 33.441) train_loss=214.16366577 time/batch=0.28s
1974/5900 (epoch 33.458) train_loss=99.18910217 time/batch=0.20s
1975/5900 (epoch 33.475) train_loss=171.08732605 time/batch=0.25s
1976/5900 (epoch 33.492) train_loss=224.65310669 time/batch=0.30s
1977/5900 (epoch 33.508) train_loss=315.05502319 time/batch=0.39s
1978/5900 (epoch 33.525) train_loss=200.36730957 time/batch=1.80s
1979/5900 (epoch 33.542) train_loss=346.42608643 time/batch=0.66s
1980/5900 (epoch 33.559) train_loss=208.01539612 time/batch=0.31s
1981/5900 (epoch 33.576) train_loss=255.53578186 time/batch=0.33s
1982/5900 (epoch 33.593) train_loss=99.63304138 time/batch=0.20s
1983/5900 (epoch 33.610) train_loss=255.13700867 time/batch=0.31s
1984/5900 (epoch 33.627) train_loss=94.63100433 time/batch=0.19s
1985/5900 (epoch 33.644) train_loss=160.79962158 time/batch=1.71s
1986/5900 (epoch 33.661) train_loss=99.71571350 time/batch=0.46s
1987/5900 (epoch 33.678) train_loss=290.63543701 time/batch=0.33s
1988/5900 (epoch 33.695) train_loss=312.09887695 time/batch=0.39s
1989/5900 (epoch 33.712) train_loss=280.96478271 time/batch=0.36s
1990/5900 (epoch 33.729) train_loss=225.66949463 time/batch=0.33s
1991/5900 (epoch 33.746) train_loss=105.43391418 time/batch=0.19s
1992/5900 (epoch 33.763) train_loss=103.84517670 time/batch=0.19s
1993/5900 (epoch 33.780) train_loss=146.93197632 time/batch=0.25s
1994/5900 (epoch 33.797) train_loss=104.81356812 time/batch=0.20s
1995/5900 (epoch 33.814) train_loss=99.91137695 time/batch=0.19s
1996/5900 (epoch 33.831) train_loss=205.63673401 time/batch=0.30s
1997/5900 (epoch 33.847) train_loss=91.84515381 time/batch=0.20s
1998/5900 (epoch 33.864) train_loss=91.65190125 time/batch=0.17s
1999/5900 (epoch 33.881) train_loss=91.00236511 time/batch=0.17s
Validating
    loss:	222.069219

2000/5900 (epoch 33.898) train_loss=90.92696381 time/batch=0.56s
2001/5900 (epoch 33.915) train_loss=96.25415039 time/batch=0.17s
2002/5900 (epoch 33.932) train_loss=92.13533783 time/batch=0.19s
2003/5900 (epoch 33.949) train_loss=97.21701813 time/batch=0.19s
2004/5900 (epoch 33.966) train_loss=91.51138306 time/batch=0.17s
2005/5900 (epoch 33.983) train_loss=93.50936127 time/batch=0.19s
2006/5900 (epoch 34.000) train_loss=91.97483826 time/batch=0.19s
setting learning rate to 0.0020191
2007/5900 (epoch 34.017) train_loss=327.27984619 time/batch=0.38s
2008/5900 (epoch 34.034) train_loss=575.40612793 time/batch=0.64s
2009/5900 (epoch 34.051) train_loss=144.81437683 time/batch=0.28s
2010/5900 (epoch 34.068) train_loss=870.29974365 time/batch=2.05s
2011/5900 (epoch 34.085) train_loss=237.41043091 time/batch=0.62s
2012/5900 (epoch 34.102) train_loss=144.94828796 time/batch=0.24s
2013/5900 (epoch 34.119) train_loss=347.29763794 time/batch=0.39s
2014/5900 (epoch 34.136) train_loss=223.71029663 time/batch=0.32s
2015/5900 (epoch 34.153) train_loss=282.51663208 time/batch=0.36s
2016/5900 (epoch 34.169) train_loss=168.23736572 time/batch=0.27s
2017/5900 (epoch 34.186) train_loss=426.42962646 time/batch=0.47s
2018/5900 (epoch 34.203) train_loss=115.03211975 time/batch=0.25s
2019/5900 (epoch 34.220) train_loss=290.41271973 time/batch=0.34s
2020/5900 (epoch 34.237) train_loss=366.72955322 time/batch=0.44s
2021/5900 (epoch 34.254) train_loss=865.03332520 time/batch=2.67s
2022/5900 (epoch 34.271) train_loss=149.46493530 time/batch=0.66s
2023/5900 (epoch 34.288) train_loss=320.43524170 time/batch=0.37s
2024/5900 (epoch 34.305) train_loss=182.56697083 time/batch=0.27s
2025/5900 (epoch 34.322) train_loss=179.48901367 time/batch=0.26s
2026/5900 (epoch 34.339) train_loss=214.58334351 time/batch=0.30s
2027/5900 (epoch 34.356) train_loss=267.67922974 time/batch=0.33s
2028/5900 (epoch 34.373) train_loss=269.46636963 time/batch=0.35s
2029/5900 (epoch 34.390) train_loss=89.19996643 time/batch=0.19s
2030/5900 (epoch 34.407) train_loss=386.30706787 time/batch=0.43s
2031/5900 (epoch 34.424) train_loss=269.25250244 time/batch=0.37s
2032/5900 (epoch 34.441) train_loss=265.61126709 time/batch=1.79s
2033/5900 (epoch 34.458) train_loss=233.00823975 time/batch=0.56s
2034/5900 (epoch 34.475) train_loss=303.22326660 time/batch=0.38s
2035/5900 (epoch 34.492) train_loss=203.35574341 time/batch=0.29s
2036/5900 (epoch 34.508) train_loss=253.76141357 time/batch=0.34s
2037/5900 (epoch 34.525) train_loss=106.23880768 time/batch=0.22s
2038/5900 (epoch 34.542) train_loss=214.07058716 time/batch=0.27s
2039/5900 (epoch 34.559) train_loss=102.80480957 time/batch=0.20s
2040/5900 (epoch 34.576) train_loss=270.30975342 time/batch=0.36s
2041/5900 (epoch 34.593) train_loss=256.42108154 time/batch=0.38s
2042/5900 (epoch 34.610) train_loss=90.20806885 time/batch=0.22s
2043/5900 (epoch 34.627) train_loss=336.52978516 time/batch=0.41s
2044/5900 (epoch 34.644) train_loss=246.03189087 time/batch=0.33s
2045/5900 (epoch 34.661) train_loss=263.88601685 time/batch=0.38s
2046/5900 (epoch 34.678) train_loss=207.71844482 time/batch=0.30s
2047/5900 (epoch 34.695) train_loss=218.89645386 time/batch=0.31s
2048/5900 (epoch 34.712) train_loss=180.18881226 time/batch=0.27s
2049/5900 (epoch 34.729) train_loss=106.02757263 time/batch=0.20s
2050/5900 (epoch 34.746) train_loss=97.51335144 time/batch=0.18s
2051/5900 (epoch 34.763) train_loss=97.43145752 time/batch=0.19s
2052/5900 (epoch 34.780) train_loss=102.53041077 time/batch=0.19s
2053/5900 (epoch 34.797) train_loss=101.30969238 time/batch=0.18s
2054/5900 (epoch 34.814) train_loss=92.57719421 time/batch=0.17s
2055/5900 (epoch 34.831) train_loss=90.26987457 time/batch=0.19s
2056/5900 (epoch 34.847) train_loss=91.71362305 time/batch=0.17s
2057/5900 (epoch 34.864) train_loss=93.79964447 time/batch=0.18s
2058/5900 (epoch 34.881) train_loss=105.36696625 time/batch=0.19s
2059/5900 (epoch 34.898) train_loss=94.38336182 time/batch=0.19s
2060/5900 (epoch 34.915) train_loss=91.31449890 time/batch=0.19s
2061/5900 (epoch 34.932) train_loss=93.47363281 time/batch=0.19s
2062/5900 (epoch 34.949) train_loss=91.33500671 time/batch=0.17s
2063/5900 (epoch 34.966) train_loss=92.05221558 time/batch=0.17s
2064/5900 (epoch 34.983) train_loss=92.51418304 time/batch=0.19s
2065/5900 (epoch 35.000) train_loss=90.81278229 time/batch=0.17s
setting learning rate to 0.0019585
2066/5900 (epoch 35.017) train_loss=342.52728271 time/batch=0.39s
2067/5900 (epoch 35.034) train_loss=405.05117798 time/batch=0.48s
2068/5900 (epoch 35.051) train_loss=175.50369263 time/batch=0.28s
2069/5900 (epoch 35.068) train_loss=85.12137604 time/batch=0.19s
2070/5900 (epoch 35.085) train_loss=462.72460938 time/batch=0.50s
2071/5900 (epoch 35.102) train_loss=444.09829712 time/batch=0.59s
2072/5900 (epoch 35.119) train_loss=250.81901550 time/batch=0.36s
2073/5900 (epoch 35.136) train_loss=140.56970215 time/batch=0.24s
2074/5900 (epoch 35.153) train_loss=884.47302246 time/batch=2.04s
2075/5900 (epoch 35.169) train_loss=174.54156494 time/batch=0.58s
2076/5900 (epoch 35.186) train_loss=203.24382019 time/batch=0.28s
2077/5900 (epoch 35.203) train_loss=272.05313110 time/batch=1.77s
2078/5900 (epoch 35.220) train_loss=216.60539246 time/batch=0.55s
2079/5900 (epoch 35.237) train_loss=283.88781738 time/batch=0.35s
2080/5900 (epoch 35.254) train_loss=283.00711060 time/batch=0.36s
2081/5900 (epoch 35.271) train_loss=215.49023438 time/batch=0.29s
2082/5900 (epoch 35.288) train_loss=466.30603027 time/batch=0.87s
2083/5900 (epoch 35.305) train_loss=243.71299744 time/batch=0.44s
2084/5900 (epoch 35.322) train_loss=297.33181763 time/batch=0.36s
2085/5900 (epoch 35.339) train_loss=95.65145874 time/batch=0.22s
2086/5900 (epoch 35.356) train_loss=273.80294800 time/batch=0.32s
2087/5900 (epoch 35.373) train_loss=90.49698639 time/batch=0.20s
2088/5900 (epoch 35.390) train_loss=183.67587280 time/batch=0.25s
2089/5900 (epoch 35.407) train_loss=94.73381042 time/batch=0.19s
2090/5900 (epoch 35.424) train_loss=328.71838379 time/batch=0.39s
2091/5900 (epoch 35.441) train_loss=216.10939026 time/batch=0.33s
2092/5900 (epoch 35.458) train_loss=310.08963013 time/batch=0.38s
2093/5900 (epoch 35.475) train_loss=718.70544434 time/batch=2.69s
2094/5900 (epoch 35.492) train_loss=269.74893188 time/batch=0.77s
2095/5900 (epoch 35.508) train_loss=168.90083313 time/batch=0.27s
2096/5900 (epoch 35.525) train_loss=89.80194855 time/batch=0.19s
2097/5900 (epoch 35.542) train_loss=292.50396729 time/batch=0.34s
2098/5900 (epoch 35.559) train_loss=333.09277344 time/batch=0.41s
2099/5900 (epoch 35.576) train_loss=135.55253601 time/batch=0.27s
2100/5900 (epoch 35.593) train_loss=88.95606232 time/batch=0.19s
2101/5900 (epoch 35.610) train_loss=197.02658081 time/batch=0.25s
2102/5900 (epoch 35.627) train_loss=118.13027954 time/batch=0.20s
2103/5900 (epoch 35.644) train_loss=246.43951416 time/batch=0.32s
2104/5900 (epoch 35.661) train_loss=101.56675720 time/batch=0.20s
2105/5900 (epoch 35.678) train_loss=230.42156982 time/batch=0.30s
2106/5900 (epoch 35.695) train_loss=242.24134827 time/batch=0.31s
2107/5900 (epoch 35.712) train_loss=100.49597168 time/batch=0.20s
2108/5900 (epoch 35.729) train_loss=209.70422363 time/batch=0.26s
2109/5900 (epoch 35.746) train_loss=232.95793152 time/batch=0.31s
2110/5900 (epoch 35.763) train_loss=101.40792847 time/batch=0.20s
2111/5900 (epoch 35.780) train_loss=93.76083374 time/batch=0.17s
2112/5900 (epoch 35.797) train_loss=246.54727173 time/batch=0.34s
2113/5900 (epoch 35.814) train_loss=106.26982117 time/batch=0.22s
2114/5900 (epoch 35.831) train_loss=93.52481079 time/batch=0.17s
2115/5900 (epoch 35.847) train_loss=231.35554504 time/batch=0.36s
2116/5900 (epoch 35.864) train_loss=108.97920990 time/batch=0.21s
2117/5900 (epoch 35.881) train_loss=102.05366516 time/batch=0.19s
2118/5900 (epoch 35.898) train_loss=99.68510437 time/batch=0.21s
2119/5900 (epoch 35.915) train_loss=88.36229706 time/batch=0.18s
2120/5900 (epoch 35.932) train_loss=90.99318695 time/batch=0.17s
2121/5900 (epoch 35.949) train_loss=95.23582458 time/batch=0.18s
2122/5900 (epoch 35.966) train_loss=90.58181763 time/batch=0.19s
2123/5900 (epoch 35.983) train_loss=91.62858582 time/batch=0.17s
2124/5900 (epoch 36.000) train_loss=89.72120667 time/batch=0.18s
setting learning rate to 0.0018998
2125/5900 (epoch 36.017) train_loss=323.54998779 time/batch=0.38s
2126/5900 (epoch 36.034) train_loss=1194.36694336 time/batch=2.67s
2127/5900 (epoch 36.051) train_loss=413.43151855 time/batch=0.89s
2128/5900 (epoch 36.068) train_loss=280.31164551 time/batch=0.38s
2129/5900 (epoch 36.085) train_loss=431.22528076 time/batch=0.52s
2130/5900 (epoch 36.102) train_loss=314.58758545 time/batch=0.43s
2131/5900 (epoch 36.119) train_loss=357.97528076 time/batch=0.44s
2132/5900 (epoch 36.136) train_loss=347.42395020 time/batch=0.48s
2133/5900 (epoch 36.153) train_loss=102.49646759 time/batch=0.24s
2134/5900 (epoch 36.169) train_loss=224.97077942 time/batch=0.28s
2135/5900 (epoch 36.186) train_loss=167.32788086 time/batch=0.27s
2136/5900 (epoch 36.203) train_loss=270.54141235 time/batch=1.78s
2137/5900 (epoch 36.220) train_loss=579.61340332 time/batch=0.90s
2138/5900 (epoch 36.237) train_loss=305.99139404 time/batch=0.42s
2139/5900 (epoch 36.254) train_loss=194.81301880 time/batch=0.28s
2140/5900 (epoch 36.271) train_loss=286.85064697 time/batch=0.37s
2141/5900 (epoch 36.288) train_loss=334.22460938 time/batch=0.47s
2142/5900 (epoch 36.305) train_loss=299.85681152 time/batch=0.40s
2143/5900 (epoch 36.322) train_loss=311.16467285 time/batch=0.53s
2144/5900 (epoch 36.339) train_loss=236.00582886 time/batch=0.36s
2145/5900 (epoch 36.356) train_loss=281.40679932 time/batch=0.34s
2146/5900 (epoch 36.373) train_loss=94.41741943 time/batch=0.20s
2147/5900 (epoch 36.390) train_loss=136.18835449 time/batch=0.20s
2148/5900 (epoch 36.407) train_loss=180.88198853 time/batch=0.26s
2149/5900 (epoch 36.424) train_loss=179.64886475 time/batch=0.27s
2150/5900 (epoch 36.441) train_loss=235.15345764 time/batch=0.31s
2151/5900 (epoch 36.458) train_loss=205.31069946 time/batch=0.30s
2152/5900 (epoch 36.475) train_loss=229.46284485 time/batch=0.31s
2153/5900 (epoch 36.492) train_loss=221.41226196 time/batch=0.31s
2154/5900 (epoch 36.508) train_loss=189.54595947 time/batch=0.27s
2155/5900 (epoch 36.525) train_loss=261.26116943 time/batch=0.33s
2156/5900 (epoch 36.542) train_loss=208.88052368 time/batch=0.30s
2157/5900 (epoch 36.559) train_loss=166.24140930 time/batch=0.24s
2158/5900 (epoch 36.576) train_loss=94.82787323 time/batch=0.19s
2159/5900 (epoch 36.593) train_loss=243.21368408 time/batch=0.31s
2160/5900 (epoch 36.610) train_loss=128.37162781 time/batch=0.24s
2161/5900 (epoch 36.627) train_loss=156.21705627 time/batch=0.23s
2162/5900 (epoch 36.644) train_loss=235.83407593 time/batch=0.31s
2163/5900 (epoch 36.661) train_loss=94.07763672 time/batch=0.20s
2164/5900 (epoch 36.678) train_loss=98.21147919 time/batch=0.19s
2165/5900 (epoch 36.695) train_loss=217.54028320 time/batch=0.28s
2166/5900 (epoch 36.712) train_loss=101.81484985 time/batch=0.20s
2167/5900 (epoch 36.729) train_loss=275.74191284 time/batch=0.31s
2168/5900 (epoch 36.746) train_loss=101.19125366 time/batch=0.22s
2169/5900 (epoch 36.763) train_loss=170.87931824 time/batch=0.50s
2170/5900 (epoch 36.780) train_loss=108.86434937 time/batch=0.25s
2171/5900 (epoch 36.797) train_loss=98.44381714 time/batch=0.19s
2172/5900 (epoch 36.814) train_loss=90.68785095 time/batch=0.17s
2173/5900 (epoch 36.831) train_loss=88.58043671 time/batch=0.17s
2174/5900 (epoch 36.847) train_loss=96.30773163 time/batch=0.19s
2175/5900 (epoch 36.864) train_loss=90.85703278 time/batch=0.18s
2176/5900 (epoch 36.881) train_loss=89.98731995 time/batch=0.17s
2177/5900 (epoch 36.898) train_loss=95.84355927 time/batch=0.19s
2178/5900 (epoch 36.915) train_loss=86.66291046 time/batch=0.19s
2179/5900 (epoch 36.932) train_loss=89.86595154 time/batch=0.17s
2180/5900 (epoch 36.949) train_loss=96.53242493 time/batch=0.19s
2181/5900 (epoch 36.966) train_loss=95.76805878 time/batch=0.18s
2182/5900 (epoch 36.983) train_loss=94.80326843 time/batch=0.17s
2183/5900 (epoch 37.000) train_loss=94.18612671 time/batch=0.19s
setting learning rate to 0.0018428
2184/5900 (epoch 37.017) train_loss=448.06713867 time/batch=0.53s
2185/5900 (epoch 37.034) train_loss=278.03353882 time/batch=0.39s
2186/5900 (epoch 37.051) train_loss=177.52114868 time/batch=0.27s
2187/5900 (epoch 37.068) train_loss=317.42648315 time/batch=0.39s
2188/5900 (epoch 37.085) train_loss=396.49322510 time/batch=0.48s
2189/5900 (epoch 37.102) train_loss=350.21334839 time/batch=0.43s
2190/5900 (epoch 37.119) train_loss=1209.16162109 time/batch=2.68s
2191/5900 (epoch 37.136) train_loss=634.46899414 time/batch=1.08s
2192/5900 (epoch 37.153) train_loss=254.04948425 time/batch=0.39s
2193/5900 (epoch 37.169) train_loss=112.71120453 time/batch=0.21s
2194/5900 (epoch 37.186) train_loss=154.72277832 time/batch=0.23s
2195/5900 (epoch 37.203) train_loss=267.59509277 time/batch=1.78s
2196/5900 (epoch 37.220) train_loss=118.84968567 time/batch=0.48s
2197/5900 (epoch 37.237) train_loss=116.44605255 time/batch=0.21s
2198/5900 (epoch 37.254) train_loss=223.09069824 time/batch=0.30s
2199/5900 (epoch 37.271) train_loss=252.28614807 time/batch=0.33s
2200/5900 (epoch 37.288) train_loss=274.91540527 time/batch=0.36s
2201/5900 (epoch 37.305) train_loss=244.50497437 time/batch=0.34s
2202/5900 (epoch 37.322) train_loss=323.69976807 time/batch=0.41s
2203/5900 (epoch 37.339) train_loss=206.55184937 time/batch=0.31s
2204/5900 (epoch 37.356) train_loss=303.99523926 time/batch=0.40s
2205/5900 (epoch 37.373) train_loss=381.06665039 time/batch=0.49s
2206/5900 (epoch 37.390) train_loss=192.75825500 time/batch=0.30s
2207/5900 (epoch 37.407) train_loss=285.58917236 time/batch=0.36s
2208/5900 (epoch 37.424) train_loss=229.64523315 time/batch=0.32s
2209/5900 (epoch 37.441) train_loss=261.43994141 time/batch=0.35s
2210/5900 (epoch 37.458) train_loss=213.66281128 time/batch=0.30s
2211/5900 (epoch 37.475) train_loss=115.28811646 time/batch=0.22s
2212/5900 (epoch 37.492) train_loss=349.41613770 time/batch=0.42s
2213/5900 (epoch 37.508) train_loss=206.02445984 time/batch=0.31s
2214/5900 (epoch 37.525) train_loss=170.05175781 time/batch=0.25s
2215/5900 (epoch 37.542) train_loss=88.86204529 time/batch=0.18s
2216/5900 (epoch 37.559) train_loss=200.20007324 time/batch=0.28s
2217/5900 (epoch 37.576) train_loss=193.35514832 time/batch=0.28s
2218/5900 (epoch 37.593) train_loss=176.03747559 time/batch=0.27s
2219/5900 (epoch 37.610) train_loss=241.74467468 time/batch=0.31s
2220/5900 (epoch 37.627) train_loss=102.26239777 time/batch=0.20s
2221/5900 (epoch 37.644) train_loss=162.92512512 time/batch=0.26s
2222/5900 (epoch 37.661) train_loss=237.25030518 time/batch=0.31s
2223/5900 (epoch 37.678) train_loss=291.18896484 time/batch=0.37s
2224/5900 (epoch 37.695) train_loss=91.05864716 time/batch=0.19s
2225/5900 (epoch 37.712) train_loss=245.00279236 time/batch=0.34s
2226/5900 (epoch 37.729) train_loss=91.33146667 time/batch=0.20s
2227/5900 (epoch 37.746) train_loss=100.75444031 time/batch=0.19s
2228/5900 (epoch 37.763) train_loss=198.07281494 time/batch=0.36s
2229/5900 (epoch 37.780) train_loss=97.40733337 time/batch=0.21s
2230/5900 (epoch 37.797) train_loss=88.41199493 time/batch=0.17s
2231/5900 (epoch 37.814) train_loss=96.15327454 time/batch=0.19s
2232/5900 (epoch 37.831) train_loss=96.80119324 time/batch=0.19s
2233/5900 (epoch 37.847) train_loss=93.29009247 time/batch=0.18s
2234/5900 (epoch 37.864) train_loss=93.84461975 time/batch=0.19s
2235/5900 (epoch 37.881) train_loss=89.39266205 time/batch=0.19s
2236/5900 (epoch 37.898) train_loss=93.57853699 time/batch=0.18s
2237/5900 (epoch 37.915) train_loss=89.93580627 time/batch=0.17s
2238/5900 (epoch 37.932) train_loss=94.34983826 time/batch=0.19s
2239/5900 (epoch 37.949) train_loss=88.11340332 time/batch=0.17s
2240/5900 (epoch 37.966) train_loss=93.80762482 time/batch=0.19s
2241/5900 (epoch 37.983) train_loss=89.37164307 time/batch=0.19s
2242/5900 (epoch 38.000) train_loss=90.74029541 time/batch=0.17s
setting learning rate to 0.0017875
2243/5900 (epoch 38.017) train_loss=484.73300171 time/batch=0.58s
2244/5900 (epoch 38.034) train_loss=384.78817749 time/batch=0.49s
2245/5900 (epoch 38.051) train_loss=838.39514160 time/batch=2.08s
2246/5900 (epoch 38.068) train_loss=199.66899109 time/batch=0.58s
2247/5900 (epoch 38.085) train_loss=403.89376831 time/batch=0.47s
2248/5900 (epoch 38.102) train_loss=864.75646973 time/batch=2.68s
2249/5900 (epoch 38.119) train_loss=235.15104675 time/batch=0.74s
2250/5900 (epoch 38.136) train_loss=210.16664124 time/batch=0.30s
2251/5900 (epoch 38.153) train_loss=154.66040039 time/batch=0.25s
2252/5900 (epoch 38.169) train_loss=202.58248901 time/batch=0.28s
2253/5900 (epoch 38.186) train_loss=337.00805664 time/batch=0.41s
2254/5900 (epoch 38.203) train_loss=135.46035767 time/batch=0.26s
2255/5900 (epoch 38.220) train_loss=234.43150330 time/batch=0.31s
2256/5900 (epoch 38.237) train_loss=94.49657440 time/batch=0.20s
2257/5900 (epoch 38.254) train_loss=272.89831543 time/batch=0.33s
2258/5900 (epoch 38.271) train_loss=88.83209229 time/batch=0.20s
2259/5900 (epoch 38.288) train_loss=179.60896301 time/batch=0.25s
2260/5900 (epoch 38.305) train_loss=267.84811401 time/batch=0.34s
2261/5900 (epoch 38.322) train_loss=297.12042236 time/batch=0.39s
2262/5900 (epoch 38.339) train_loss=83.96852875 time/batch=0.21s
2263/5900 (epoch 38.356) train_loss=115.13537598 time/batch=0.20s
2264/5900 (epoch 38.373) train_loss=317.18350220 time/batch=0.38s
2265/5900 (epoch 38.390) train_loss=123.37366486 time/batch=0.25s
2266/5900 (epoch 38.407) train_loss=201.47232056 time/batch=0.28s
2267/5900 (epoch 38.424) train_loss=329.61425781 time/batch=0.40s
2268/5900 (epoch 38.441) train_loss=263.11398315 time/batch=1.82s
2269/5900 (epoch 38.458) train_loss=187.75418091 time/batch=0.53s
2270/5900 (epoch 38.475) train_loss=238.69201660 time/batch=0.31s
2271/5900 (epoch 38.492) train_loss=107.23210144 time/batch=0.22s
2272/5900 (epoch 38.508) train_loss=228.33229065 time/batch=0.30s
2273/5900 (epoch 38.525) train_loss=259.76535034 time/batch=0.33s
2274/5900 (epoch 38.542) train_loss=184.72103882 time/batch=0.30s
2275/5900 (epoch 38.559) train_loss=278.11087036 time/batch=0.36s
2276/5900 (epoch 38.576) train_loss=291.96984863 time/batch=0.38s
2277/5900 (epoch 38.593) train_loss=339.95196533 time/batch=0.48s
2278/5900 (epoch 38.610) train_loss=251.14573669 time/batch=0.36s
2279/5900 (epoch 38.627) train_loss=97.52377319 time/batch=0.20s
2280/5900 (epoch 38.644) train_loss=289.10449219 time/batch=0.34s
2281/5900 (epoch 38.661) train_loss=172.25830078 time/batch=0.27s
2282/5900 (epoch 38.678) train_loss=95.73888397 time/batch=0.20s
2283/5900 (epoch 38.695) train_loss=205.22991943 time/batch=0.27s
2284/5900 (epoch 38.712) train_loss=139.86312866 time/batch=0.26s
2285/5900 (epoch 38.729) train_loss=96.85490417 time/batch=0.19s
2286/5900 (epoch 38.746) train_loss=260.60067749 time/batch=0.33s
2287/5900 (epoch 38.763) train_loss=95.26301575 time/batch=0.22s
2288/5900 (epoch 38.780) train_loss=86.92369080 time/batch=0.17s
2289/5900 (epoch 38.797) train_loss=108.97636414 time/batch=0.28s
2290/5900 (epoch 38.814) train_loss=89.86947632 time/batch=0.20s
2291/5900 (epoch 38.831) train_loss=227.18641663 time/batch=0.30s
2292/5900 (epoch 38.847) train_loss=101.01487732 time/batch=0.22s
2293/5900 (epoch 38.864) train_loss=90.17568207 time/batch=0.17s
2294/5900 (epoch 38.881) train_loss=102.12092590 time/batch=0.29s
2295/5900 (epoch 38.898) train_loss=88.41236877 time/batch=0.20s
2296/5900 (epoch 38.915) train_loss=120.20686340 time/batch=0.28s
2297/5900 (epoch 38.932) train_loss=87.97747040 time/batch=0.19s
2298/5900 (epoch 38.949) train_loss=85.17237091 time/batch=0.19s
2299/5900 (epoch 38.966) train_loss=89.89407349 time/batch=0.19s
2300/5900 (epoch 38.983) train_loss=94.98051453 time/batch=0.17s
2301/5900 (epoch 39.000) train_loss=95.43301392 time/batch=0.19s
setting learning rate to 0.0017339
2302/5900 (epoch 39.017) train_loss=401.52297974 time/batch=0.48s
2303/5900 (epoch 39.034) train_loss=246.89019775 time/batch=0.34s
2304/5900 (epoch 39.051) train_loss=196.46116638 time/batch=0.29s
2305/5900 (epoch 39.068) train_loss=1146.53869629 time/batch=2.65s
2306/5900 (epoch 39.085) train_loss=618.01104736 time/batch=1.04s
2307/5900 (epoch 39.102) train_loss=183.22169495 time/batch=0.34s
2308/5900 (epoch 39.119) train_loss=113.85506439 time/batch=0.19s
2309/5900 (epoch 39.136) train_loss=201.32646179 time/batch=0.28s
2310/5900 (epoch 39.153) train_loss=312.55603027 time/batch=0.39s
2311/5900 (epoch 39.169) train_loss=93.33212280 time/batch=0.22s
2312/5900 (epoch 39.186) train_loss=276.59539795 time/batch=0.35s
2313/5900 (epoch 39.203) train_loss=152.08862305 time/batch=0.24s
2314/5900 (epoch 39.220) train_loss=396.42272949 time/batch=0.50s
2315/5900 (epoch 39.237) train_loss=292.17263794 time/batch=0.43s
2316/5900 (epoch 39.254) train_loss=266.46026611 time/batch=0.37s
2317/5900 (epoch 39.271) train_loss=87.67576599 time/batch=0.19s
2318/5900 (epoch 39.288) train_loss=405.82174683 time/batch=0.62s
2319/5900 (epoch 39.305) train_loss=216.62930298 time/batch=0.36s
2320/5900 (epoch 39.322) train_loss=266.80004883 time/batch=0.35s
2321/5900 (epoch 39.339) train_loss=168.54426575 time/batch=0.28s
2322/5900 (epoch 39.356) train_loss=235.37464905 time/batch=0.33s
2323/5900 (epoch 39.373) train_loss=248.96754456 time/batch=0.34s
2324/5900 (epoch 39.390) train_loss=158.20329285 time/batch=0.25s
2325/5900 (epoch 39.407) train_loss=271.64724731 time/batch=0.34s
2326/5900 (epoch 39.424) train_loss=234.39797974 time/batch=0.34s
2327/5900 (epoch 39.441) train_loss=194.16831970 time/batch=0.29s
2328/5900 (epoch 39.458) train_loss=349.07745361 time/batch=0.43s
2329/5900 (epoch 39.475) train_loss=89.09733582 time/batch=0.21s
2330/5900 (epoch 39.492) train_loss=287.15911865 time/batch=0.35s
2331/5900 (epoch 39.508) train_loss=137.78953552 time/batch=0.25s
2332/5900 (epoch 39.525) train_loss=324.26504517 time/batch=0.39s
2333/5900 (epoch 39.542) train_loss=199.31643677 time/batch=0.30s
2334/5900 (epoch 39.559) train_loss=109.59072113 time/batch=0.21s
2335/5900 (epoch 39.576) train_loss=169.70971680 time/batch=0.26s
2336/5900 (epoch 39.593) train_loss=93.36654663 time/batch=0.20s
2337/5900 (epoch 39.610) train_loss=320.31134033 time/batch=0.39s
2338/5900 (epoch 39.627) train_loss=129.51651001 time/batch=0.31s
2339/5900 (epoch 39.644) train_loss=227.68041992 time/batch=0.31s
2340/5900 (epoch 39.661) train_loss=168.39801025 time/batch=1.80s
2341/5900 (epoch 39.678) train_loss=275.76580811 time/batch=0.64s
2342/5900 (epoch 39.695) train_loss=226.91055298 time/batch=0.33s
2343/5900 (epoch 39.712) train_loss=96.94285583 time/batch=0.21s
2344/5900 (epoch 39.729) train_loss=219.76391602 time/batch=0.30s
2345/5900 (epoch 39.746) train_loss=104.31613922 time/batch=0.22s
2346/5900 (epoch 39.763) train_loss=91.90515900 time/batch=0.17s
2347/5900 (epoch 39.780) train_loss=219.58271790 time/batch=0.30s
2348/5900 (epoch 39.797) train_loss=95.98315430 time/batch=0.21s
2349/5900 (epoch 39.814) train_loss=105.51452637 time/batch=0.30s
2350/5900 (epoch 39.831) train_loss=93.55374146 time/batch=0.20s
2351/5900 (epoch 39.847) train_loss=96.82433319 time/batch=0.17s
2352/5900 (epoch 39.864) train_loss=178.26025391 time/batch=1.73s
2353/5900 (epoch 39.881) train_loss=97.95438385 time/batch=0.46s
2354/5900 (epoch 39.898) train_loss=88.11819458 time/batch=0.20s
2355/5900 (epoch 39.915) train_loss=86.31295776 time/batch=0.17s
2356/5900 (epoch 39.932) train_loss=91.08088684 time/batch=0.18s
2357/5900 (epoch 39.949) train_loss=92.01863098 time/batch=0.19s
2358/5900 (epoch 39.966) train_loss=86.54216003 time/batch=0.18s
2359/5900 (epoch 39.983) train_loss=87.34275818 time/batch=0.18s
2360/5900 (epoch 40.000) train_loss=90.14916992 time/batch=0.18s
setting learning rate to 0.0016818
  saved to metadata/config5--20190119-190634.pkl
2361/5900 (epoch 40.017) train_loss=539.99218750 time/batch=7.81s
2362/5900 (epoch 40.034) train_loss=398.81317139 time/batch=0.53s
2363/5900 (epoch 40.051) train_loss=357.82385254 time/batch=0.45s
2364/5900 (epoch 40.068) train_loss=239.67736816 time/batch=0.33s
2365/5900 (epoch 40.085) train_loss=161.79840088 time/batch=0.26s
2366/5900 (epoch 40.102) train_loss=228.70471191 time/batch=0.32s
2367/5900 (epoch 40.119) train_loss=302.29345703 time/batch=0.39s
2368/5900 (epoch 40.136) train_loss=402.97088623 time/batch=0.51s
2369/5900 (epoch 40.153) train_loss=351.94549561 time/batch=0.47s
2370/5900 (epoch 40.169) train_loss=132.48915100 time/batch=0.24s
2371/5900 (epoch 40.186) train_loss=264.64700317 time/batch=0.34s
2372/5900 (epoch 40.203) train_loss=261.60287476 time/batch=0.34s
2373/5900 (epoch 40.220) train_loss=194.22406006 time/batch=0.31s
2374/5900 (epoch 40.237) train_loss=165.14974976 time/batch=0.26s
2375/5900 (epoch 40.254) train_loss=215.09030151 time/batch=0.30s
2376/5900 (epoch 40.271) train_loss=227.15986633 time/batch=0.33s
2377/5900 (epoch 40.288) train_loss=335.82446289 time/batch=0.47s
2378/5900 (epoch 40.305) train_loss=1080.11120605 time/batch=2.69s
2379/5900 (epoch 40.322) train_loss=300.63635254 time/batch=0.80s
2380/5900 (epoch 40.339) train_loss=187.35595703 time/batch=0.28s
2381/5900 (epoch 40.356) train_loss=271.57360840 time/batch=0.34s
2382/5900 (epoch 40.373) train_loss=235.61647034 time/batch=0.34s
2383/5900 (epoch 40.390) train_loss=338.33496094 time/batch=0.50s
2384/5900 (epoch 40.407) train_loss=208.39355469 time/batch=0.34s
2385/5900 (epoch 40.424) train_loss=297.45159912 time/batch=0.38s
2386/5900 (epoch 40.441) train_loss=226.49800110 time/batch=0.36s
2387/5900 (epoch 40.458) train_loss=368.68435669 time/batch=1.39s
2388/5900 (epoch 40.475) train_loss=139.53936768 time/batch=0.43s
2389/5900 (epoch 40.492) train_loss=197.81860352 time/batch=0.28s
2390/5900 (epoch 40.508) train_loss=179.65794373 time/batch=0.27s
2391/5900 (epoch 40.525) train_loss=170.41700745 time/batch=0.27s
2392/5900 (epoch 40.542) train_loss=224.82473755 time/batch=0.33s
2393/5900 (epoch 40.559) train_loss=117.35682678 time/batch=0.22s
2394/5900 (epoch 40.576) train_loss=92.22804260 time/batch=0.19s
2395/5900 (epoch 40.593) train_loss=193.70179749 time/batch=0.27s
2396/5900 (epoch 40.610) train_loss=89.36300659 time/batch=0.20s
2397/5900 (epoch 40.627) train_loss=98.52161407 time/batch=0.19s
2398/5900 (epoch 40.644) train_loss=260.89675903 time/batch=0.34s
2399/5900 (epoch 40.661) train_loss=249.10644531 time/batch=1.79s
2400/5900 (epoch 40.678) train_loss=112.39688873 time/batch=0.48s
2401/5900 (epoch 40.695) train_loss=99.16234589 time/batch=0.19s
2402/5900 (epoch 40.712) train_loss=85.30988312 time/batch=0.17s
2403/5900 (epoch 40.729) train_loss=194.66722107 time/batch=0.29s
2404/5900 (epoch 40.746) train_loss=171.69793701 time/batch=0.34s
2405/5900 (epoch 40.763) train_loss=98.87560272 time/batch=0.20s
2406/5900 (epoch 40.780) train_loss=89.38388062 time/batch=0.17s
2407/5900 (epoch 40.797) train_loss=93.28785706 time/batch=0.19s
2408/5900 (epoch 40.814) train_loss=92.18558502 time/batch=0.19s
2409/5900 (epoch 40.831) train_loss=91.15998840 time/batch=0.19s
2410/5900 (epoch 40.847) train_loss=85.11912537 time/batch=0.17s
2411/5900 (epoch 40.864) train_loss=95.60392761 time/batch=0.19s
2412/5900 (epoch 40.881) train_loss=98.63105774 time/batch=0.18s
2413/5900 (epoch 40.898) train_loss=90.23816681 time/batch=0.18s
2414/5900 (epoch 40.915) train_loss=87.24201965 time/batch=0.19s
2415/5900 (epoch 40.932) train_loss=92.79576874 time/batch=0.18s
2416/5900 (epoch 40.949) train_loss=85.02667999 time/batch=0.19s
2417/5900 (epoch 40.966) train_loss=93.57839966 time/batch=0.17s
2418/5900 (epoch 40.983) train_loss=91.66017151 time/batch=0.19s
2419/5900 (epoch 41.000) train_loss=90.84478760 time/batch=0.19s
setting learning rate to 0.0016314
2420/5900 (epoch 41.017) train_loss=762.36523438 time/batch=2.04s
2421/5900 (epoch 41.034) train_loss=445.38308716 time/batch=0.78s
2422/5900 (epoch 41.051) train_loss=318.19952393 time/batch=0.39s
2423/5900 (epoch 41.068) train_loss=265.79650879 time/batch=0.36s
2424/5900 (epoch 41.085) train_loss=459.02087402 time/batch=0.56s
2425/5900 (epoch 41.102) train_loss=346.25848389 time/batch=0.47s
2426/5900 (epoch 41.119) train_loss=862.22924805 time/batch=2.67s
2427/5900 (epoch 41.136) train_loss=266.00823975 time/batch=0.79s
2428/5900 (epoch 41.153) train_loss=288.05444336 time/batch=0.39s
2429/5900 (epoch 41.169) train_loss=221.14462280 time/batch=0.32s
2430/5900 (epoch 41.186) train_loss=205.09107971 time/batch=0.31s
2431/5900 (epoch 41.203) train_loss=201.89683533 time/batch=0.29s
2432/5900 (epoch 41.220) train_loss=161.74150085 time/batch=0.26s
2433/5900 (epoch 41.237) train_loss=114.79498291 time/batch=0.21s
2434/5900 (epoch 41.254) train_loss=193.72796631 time/batch=0.28s
2435/5900 (epoch 41.271) train_loss=132.12191772 time/batch=0.23s
2436/5900 (epoch 41.288) train_loss=213.36947632 time/batch=0.30s
2437/5900 (epoch 41.305) train_loss=87.16011810 time/batch=0.19s
2438/5900 (epoch 41.322) train_loss=256.95703125 time/batch=0.33s
2439/5900 (epoch 41.339) train_loss=188.79898071 time/batch=0.28s
2440/5900 (epoch 41.356) train_loss=308.96411133 time/batch=0.41s
2441/5900 (epoch 41.373) train_loss=244.79650879 time/batch=1.80s
2442/5900 (epoch 41.390) train_loss=325.77890015 time/batch=0.70s
2443/5900 (epoch 41.407) train_loss=94.44299316 time/batch=0.22s
2444/5900 (epoch 41.424) train_loss=242.68887329 time/batch=0.31s
2445/5900 (epoch 41.441) train_loss=279.78656006 time/batch=0.38s
2446/5900 (epoch 41.458) train_loss=179.12039185 time/batch=0.29s
2447/5900 (epoch 41.475) train_loss=354.96923828 time/batch=0.47s
2448/5900 (epoch 41.492) train_loss=240.55734253 time/batch=0.36s
2449/5900 (epoch 41.508) train_loss=162.50869751 time/batch=0.27s
2450/5900 (epoch 41.525) train_loss=89.37474060 time/batch=0.19s
2451/5900 (epoch 41.542) train_loss=233.87066650 time/batch=0.31s
2452/5900 (epoch 41.559) train_loss=116.56607056 time/batch=0.23s
2453/5900 (epoch 41.576) train_loss=208.22338867 time/batch=0.30s
2454/5900 (epoch 41.593) train_loss=159.10067749 time/batch=0.26s
2455/5900 (epoch 41.610) train_loss=190.90551758 time/batch=0.28s
2456/5900 (epoch 41.627) train_loss=95.75344849 time/batch=0.19s
2457/5900 (epoch 41.644) train_loss=84.74711609 time/batch=0.19s
2458/5900 (epoch 41.661) train_loss=236.03637695 time/batch=0.31s
2459/5900 (epoch 41.678) train_loss=284.43115234 time/batch=0.36s
2460/5900 (epoch 41.695) train_loss=105.20771790 time/batch=0.22s
2461/5900 (epoch 41.712) train_loss=88.25699615 time/batch=0.19s
2462/5900 (epoch 41.729) train_loss=93.18833923 time/batch=0.17s
2463/5900 (epoch 41.746) train_loss=184.03134155 time/batch=0.26s
2464/5900 (epoch 41.763) train_loss=301.62905884 time/batch=0.38s
2465/5900 (epoch 41.780) train_loss=100.88030243 time/batch=0.23s
2466/5900 (epoch 41.797) train_loss=98.95063019 time/batch=0.19s
2467/5900 (epoch 41.814) train_loss=169.22473145 time/batch=0.32s
2468/5900 (epoch 41.831) train_loss=93.22937775 time/batch=0.21s
2469/5900 (epoch 41.847) train_loss=90.23441315 time/batch=0.17s
2470/5900 (epoch 41.864) train_loss=87.63034058 time/batch=0.18s
2471/5900 (epoch 41.881) train_loss=89.38676453 time/batch=0.18s
2472/5900 (epoch 41.898) train_loss=82.29991150 time/batch=0.17s
2473/5900 (epoch 41.915) train_loss=98.11225128 time/batch=0.19s
2474/5900 (epoch 41.932) train_loss=92.39262390 time/batch=0.17s
2475/5900 (epoch 41.949) train_loss=91.77335358 time/batch=0.19s
2476/5900 (epoch 41.966) train_loss=94.97787476 time/batch=0.19s
2477/5900 (epoch 41.983) train_loss=87.13511658 time/batch=0.19s
2478/5900 (epoch 42.000) train_loss=90.68701935 time/batch=0.17s
setting learning rate to 0.0015824
2479/5900 (epoch 42.017) train_loss=76.98090363 time/batch=0.19s
2480/5900 (epoch 42.034) train_loss=980.85650635 time/batch=2.63s
2481/5900 (epoch 42.051) train_loss=213.33602905 time/batch=0.70s
2482/5900 (epoch 42.068) train_loss=410.39410400 time/batch=0.48s
2483/5900 (epoch 42.085) train_loss=632.44348145 time/batch=1.38s
2484/5900 (epoch 42.102) train_loss=234.38813782 time/batch=0.47s
2485/5900 (epoch 42.119) train_loss=196.94943237 time/batch=0.28s
2486/5900 (epoch 42.136) train_loss=323.93127441 time/batch=0.39s
2487/5900 (epoch 42.153) train_loss=478.72201538 time/batch=1.41s
2488/5900 (epoch 42.169) train_loss=255.36097717 time/batch=0.53s
2489/5900 (epoch 42.186) train_loss=281.95465088 time/batch=0.38s
2490/5900 (epoch 42.203) train_loss=223.79106140 time/batch=0.34s
2491/5900 (epoch 42.220) train_loss=116.02894592 time/batch=0.22s
2492/5900 (epoch 42.237) train_loss=192.08422852 time/batch=0.28s
2493/5900 (epoch 42.254) train_loss=204.29644775 time/batch=0.30s
2494/5900 (epoch 42.271) train_loss=309.64743042 time/batch=0.42s
2495/5900 (epoch 42.288) train_loss=86.84465027 time/batch=0.22s
2496/5900 (epoch 42.305) train_loss=345.19335938 time/batch=0.40s
2497/5900 (epoch 42.322) train_loss=145.30218506 time/batch=0.27s
2498/5900 (epoch 42.339) train_loss=324.96145630 time/batch=0.44s
2499/5900 (epoch 42.356) train_loss=273.26159668 time/batch=0.38s
2500/5900 (epoch 42.373) train_loss=168.72201538 time/batch=0.30s
2501/5900 (epoch 42.390) train_loss=234.13525391 time/batch=0.32s
2502/5900 (epoch 42.407) train_loss=167.67501831 time/batch=0.29s
2503/5900 (epoch 42.424) train_loss=259.88128662 time/batch=0.35s
2504/5900 (epoch 42.441) train_loss=245.84954834 time/batch=1.78s
2505/5900 (epoch 42.458) train_loss=136.82098389 time/batch=0.50s
2506/5900 (epoch 42.475) train_loss=206.47647095 time/batch=0.28s
2507/5900 (epoch 42.492) train_loss=96.65403748 time/batch=0.20s
2508/5900 (epoch 42.508) train_loss=229.30639648 time/batch=0.31s
2509/5900 (epoch 42.525) train_loss=91.29682922 time/batch=0.20s
2510/5900 (epoch 42.542) train_loss=170.27072144 time/batch=0.27s
2511/5900 (epoch 42.559) train_loss=111.86063385 time/batch=0.22s
2512/5900 (epoch 42.576) train_loss=177.16818237 time/batch=0.27s
2513/5900 (epoch 42.593) train_loss=258.32348633 time/batch=0.35s
2514/5900 (epoch 42.610) train_loss=223.51728821 time/batch=0.33s
2515/5900 (epoch 42.627) train_loss=215.40357971 time/batch=0.33s
2516/5900 (epoch 42.644) train_loss=291.16284180 time/batch=0.36s
2517/5900 (epoch 42.661) train_loss=227.73846436 time/batch=0.34s
2518/5900 (epoch 42.678) train_loss=208.56387329 time/batch=0.34s
2519/5900 (epoch 42.695) train_loss=85.74767303 time/batch=0.20s
2520/5900 (epoch 42.712) train_loss=255.73622131 time/batch=0.34s
2521/5900 (epoch 42.729) train_loss=272.16448975 time/batch=0.41s
2522/5900 (epoch 42.746) train_loss=193.08062744 time/batch=0.40s
2523/5900 (epoch 42.763) train_loss=88.27183533 time/batch=0.20s
2524/5900 (epoch 42.780) train_loss=95.72637939 time/batch=0.19s
2525/5900 (epoch 42.797) train_loss=84.95854187 time/batch=0.17s
2526/5900 (epoch 42.814) train_loss=98.11189270 time/batch=0.19s
2527/5900 (epoch 42.831) train_loss=93.37037659 time/batch=0.19s
2528/5900 (epoch 42.847) train_loss=87.34634399 time/batch=0.17s
2529/5900 (epoch 42.864) train_loss=96.82296753 time/batch=0.19s
2530/5900 (epoch 42.881) train_loss=86.77182770 time/batch=0.19s
2531/5900 (epoch 42.898) train_loss=85.83691406 time/batch=0.17s
2532/5900 (epoch 42.915) train_loss=97.21175385 time/batch=0.19s
2533/5900 (epoch 42.932) train_loss=89.90071106 time/batch=0.19s
2534/5900 (epoch 42.949) train_loss=89.44926453 time/batch=0.18s
2535/5900 (epoch 42.966) train_loss=89.68302155 time/batch=0.18s
2536/5900 (epoch 42.983) train_loss=94.63348389 time/batch=0.19s
2537/5900 (epoch 43.000) train_loss=86.10215759 time/batch=0.19s
setting learning rate to 0.0015350
2538/5900 (epoch 43.017) train_loss=281.26831055 time/batch=0.37s
2539/5900 (epoch 43.034) train_loss=222.11935425 time/batch=0.32s
2540/5900 (epoch 43.051) train_loss=80.95099640 time/batch=0.20s
2541/5900 (epoch 43.068) train_loss=302.53887939 time/batch=0.35s
2542/5900 (epoch 43.085) train_loss=244.22445679 time/batch=0.33s
2543/5900 (epoch 43.102) train_loss=388.40747070 time/batch=0.50s
2544/5900 (epoch 43.119) train_loss=206.56353760 time/batch=0.34s
2545/5900 (epoch 43.136) train_loss=378.68154907 time/batch=0.51s
2546/5900 (epoch 43.153) train_loss=336.87960815 time/batch=0.46s
2547/5900 (epoch 43.169) train_loss=84.19480896 time/batch=0.22s
2548/5900 (epoch 43.186) train_loss=242.11065674 time/batch=0.31s
2549/5900 (epoch 43.203) train_loss=751.41693115 time/batch=2.06s
2550/5900 (epoch 43.220) train_loss=279.46997070 time/batch=0.67s
2551/5900 (epoch 43.237) train_loss=96.85499573 time/batch=0.22s
2552/5900 (epoch 43.254) train_loss=888.70068359 time/batch=2.65s
2553/5900 (epoch 43.271) train_loss=316.89288330 time/batch=0.82s
2554/5900 (epoch 43.288) train_loss=337.99624634 time/batch=0.45s
2555/5900 (epoch 43.305) train_loss=149.30145264 time/batch=0.27s
2556/5900 (epoch 43.322) train_loss=92.29496765 time/batch=0.20s
2557/5900 (epoch 43.339) train_loss=192.59066772 time/batch=0.25s
2558/5900 (epoch 43.356) train_loss=180.66555786 time/batch=0.28s
2559/5900 (epoch 43.373) train_loss=322.31036377 time/batch=0.42s
2560/5900 (epoch 43.390) train_loss=307.48437500 time/batch=0.55s
2561/5900 (epoch 43.407) train_loss=155.12771606 time/batch=0.28s
2562/5900 (epoch 43.424) train_loss=258.74963379 time/batch=0.35s
2563/5900 (epoch 43.441) train_loss=225.52560425 time/batch=0.33s
2564/5900 (epoch 43.458) train_loss=273.59475708 time/batch=0.52s
2565/5900 (epoch 43.475) train_loss=205.27125549 time/batch=0.33s
2566/5900 (epoch 43.492) train_loss=190.24554443 time/batch=0.28s
2567/5900 (epoch 43.508) train_loss=93.45426941 time/batch=0.20s
2568/5900 (epoch 43.525) train_loss=195.70199585 time/batch=0.28s
2569/5900 (epoch 43.542) train_loss=138.67318726 time/batch=0.25s
2570/5900 (epoch 43.559) train_loss=94.45027161 time/batch=0.21s
2571/5900 (epoch 43.576) train_loss=174.68464661 time/batch=0.25s
2572/5900 (epoch 43.593) train_loss=262.55078125 time/batch=0.34s
2573/5900 (epoch 43.610) train_loss=233.57408142 time/batch=0.34s
2574/5900 (epoch 43.627) train_loss=245.99949646 time/batch=0.36s
2575/5900 (epoch 43.644) train_loss=97.58083344 time/batch=0.22s
2576/5900 (epoch 43.661) train_loss=183.58718872 time/batch=0.27s
2577/5900 (epoch 43.678) train_loss=109.66804504 time/batch=0.20s
2578/5900 (epoch 43.695) train_loss=218.99914551 time/batch=0.30s
2579/5900 (epoch 43.712) train_loss=249.36337280 time/batch=1.78s
2580/5900 (epoch 43.729) train_loss=94.89252472 time/batch=0.47s
2581/5900 (epoch 43.746) train_loss=83.67414856 time/batch=0.19s
2582/5900 (epoch 43.763) train_loss=165.34626770 time/batch=0.25s
2583/5900 (epoch 43.780) train_loss=212.68672180 time/batch=0.30s
2584/5900 (epoch 43.797) train_loss=120.15368652 time/batch=0.22s
2585/5900 (epoch 43.814) train_loss=103.46937561 time/batch=0.20s
2586/5900 (epoch 43.831) train_loss=91.73815918 time/batch=0.19s
2587/5900 (epoch 43.847) train_loss=91.77884674 time/batch=0.19s
2588/5900 (epoch 43.864) train_loss=84.30796051 time/batch=0.18s
2589/5900 (epoch 43.881) train_loss=84.53960419 time/batch=0.17s
2590/5900 (epoch 43.898) train_loss=90.87631226 time/batch=0.19s
2591/5900 (epoch 43.915) train_loss=90.71538544 time/batch=0.17s
2592/5900 (epoch 43.932) train_loss=87.17807007 time/batch=0.19s
2593/5900 (epoch 43.949) train_loss=91.32836151 time/batch=0.17s
2594/5900 (epoch 43.966) train_loss=92.48582458 time/batch=0.19s
2595/5900 (epoch 43.983) train_loss=85.01618958 time/batch=0.19s
2596/5900 (epoch 44.000) train_loss=84.20432281 time/batch=0.18s
setting learning rate to 0.0014889
2597/5900 (epoch 44.017) train_loss=302.30999756 time/batch=0.40s
2598/5900 (epoch 44.034) train_loss=301.89736938 time/batch=0.38s
2599/5900 (epoch 44.051) train_loss=363.65032959 time/batch=0.45s
2600/5900 (epoch 44.068) train_loss=80.67931366 time/batch=0.22s
2601/5900 (epoch 44.085) train_loss=507.33508301 time/batch=0.61s
2602/5900 (epoch 44.102) train_loss=462.69073486 time/batch=0.75s
2603/5900 (epoch 44.119) train_loss=313.58319092 time/batch=0.47s
2604/5900 (epoch 44.136) train_loss=88.22669220 time/batch=0.22s
2605/5900 (epoch 44.153) train_loss=114.60089874 time/batch=0.20s
2606/5900 (epoch 44.169) train_loss=708.39343262 time/batch=2.05s
2607/5900 (epoch 44.186) train_loss=371.22784424 time/batch=0.78s
2608/5900 (epoch 44.203) train_loss=185.58444214 time/batch=0.31s
2609/5900 (epoch 44.220) train_loss=115.81198120 time/batch=0.22s
2610/5900 (epoch 44.237) train_loss=167.10260010 time/batch=0.25s
2611/5900 (epoch 44.254) train_loss=159.62101746 time/batch=0.26s
2612/5900 (epoch 44.271) train_loss=372.30853271 time/batch=0.85s
2613/5900 (epoch 44.288) train_loss=98.68802643 time/batch=0.31s
2614/5900 (epoch 44.305) train_loss=147.45228577 time/batch=0.23s
2615/5900 (epoch 44.322) train_loss=284.28442383 time/batch=0.38s
2616/5900 (epoch 44.339) train_loss=195.86141968 time/batch=0.31s
2617/5900 (epoch 44.356) train_loss=213.83067322 time/batch=0.31s
2618/5900 (epoch 44.373) train_loss=87.05224609 time/batch=0.21s
2619/5900 (epoch 44.390) train_loss=178.84057617 time/batch=0.25s
2620/5900 (epoch 44.407) train_loss=274.07785034 time/batch=0.37s
2621/5900 (epoch 44.424) train_loss=225.43576050 time/batch=0.33s
2622/5900 (epoch 44.441) train_loss=156.38226318 time/batch=0.25s
2623/5900 (epoch 44.458) train_loss=192.79708862 time/batch=0.29s
2624/5900 (epoch 44.475) train_loss=638.59649658 time/batch=2.66s
2625/5900 (epoch 44.492) train_loss=190.60543823 time/batch=0.70s
2626/5900 (epoch 44.508) train_loss=197.09683228 time/batch=0.30s
2627/5900 (epoch 44.525) train_loss=224.52590942 time/batch=0.33s
2628/5900 (epoch 44.542) train_loss=249.34838867 time/batch=1.79s
2629/5900 (epoch 44.559) train_loss=271.11801147 time/batch=0.64s
2630/5900 (epoch 44.576) train_loss=165.34590149 time/batch=0.28s
2631/5900 (epoch 44.593) train_loss=218.55944824 time/batch=0.32s
2632/5900 (epoch 44.610) train_loss=257.67462158 time/batch=0.36s
2633/5900 (epoch 44.627) train_loss=248.26568604 time/batch=0.33s
2634/5900 (epoch 44.644) train_loss=91.58427429 time/batch=0.20s
2635/5900 (epoch 44.661) train_loss=240.34973145 time/batch=0.33s
2636/5900 (epoch 44.678) train_loss=211.98074341 time/batch=0.30s
2637/5900 (epoch 44.695) train_loss=228.93295288 time/batch=0.34s
2638/5900 (epoch 44.712) train_loss=84.42291260 time/batch=0.21s
2639/5900 (epoch 44.729) train_loss=99.02650452 time/batch=0.19s
2640/5900 (epoch 44.746) train_loss=258.14044189 time/batch=0.34s
2641/5900 (epoch 44.763) train_loss=95.80010986 time/batch=0.20s
2642/5900 (epoch 44.780) train_loss=115.65099335 time/batch=0.20s
2643/5900 (epoch 44.797) train_loss=120.23703766 time/batch=0.34s
2644/5900 (epoch 44.814) train_loss=85.39513397 time/batch=0.19s
2645/5900 (epoch 44.831) train_loss=98.40213013 time/batch=0.19s
2646/5900 (epoch 44.847) train_loss=84.30074310 time/batch=0.18s
2647/5900 (epoch 44.864) train_loss=87.77066040 time/batch=0.17s
2648/5900 (epoch 44.881) train_loss=89.53463745 time/batch=0.18s
2649/5900 (epoch 44.898) train_loss=98.18817139 time/batch=0.19s
2650/5900 (epoch 44.915) train_loss=88.25125122 time/batch=0.17s
2651/5900 (epoch 44.932) train_loss=90.86219025 time/batch=0.19s
2652/5900 (epoch 44.949) train_loss=88.82540894 time/batch=0.19s
2653/5900 (epoch 44.966) train_loss=87.41770935 time/batch=0.17s
2654/5900 (epoch 44.983) train_loss=89.38079071 time/batch=0.19s
2655/5900 (epoch 45.000) train_loss=90.38455963 time/batch=0.19s
setting learning rate to 0.0014443
2656/5900 (epoch 45.017) train_loss=1061.03662109 time/batch=2.66s
2657/5900 (epoch 45.034) train_loss=82.22924805 time/batch=0.62s
2658/5900 (epoch 45.051) train_loss=301.64031982 time/batch=0.36s
2659/5900 (epoch 45.068) train_loss=490.52905273 time/batch=0.62s
2660/5900 (epoch 45.085) train_loss=348.84912109 time/batch=0.48s
2661/5900 (epoch 45.102) train_loss=272.02920532 time/batch=0.40s
2662/5900 (epoch 45.119) train_loss=92.51651001 time/batch=0.20s
2663/5900 (epoch 45.136) train_loss=201.84533691 time/batch=0.30s
2664/5900 (epoch 45.153) train_loss=422.29620361 time/batch=0.63s
2665/5900 (epoch 45.169) train_loss=215.61123657 time/batch=0.37s
2666/5900 (epoch 45.186) train_loss=247.29487610 time/batch=0.34s
2667/5900 (epoch 45.203) train_loss=273.31726074 time/batch=0.39s
2668/5900 (epoch 45.220) train_loss=164.75268555 time/batch=0.28s
2669/5900 (epoch 45.237) train_loss=138.65704346 time/batch=0.25s
2670/5900 (epoch 45.254) train_loss=245.35768127 time/batch=0.33s
2671/5900 (epoch 45.271) train_loss=207.55253601 time/batch=0.32s
2672/5900 (epoch 45.288) train_loss=288.55902100 time/batch=0.40s
2673/5900 (epoch 45.305) train_loss=262.98416138 time/batch=0.37s
2674/5900 (epoch 45.322) train_loss=252.62390137 time/batch=0.35s
2675/5900 (epoch 45.339) train_loss=182.52264404 time/batch=0.28s
2676/5900 (epoch 45.356) train_loss=149.38507080 time/batch=0.26s
2677/5900 (epoch 45.373) train_loss=85.12986755 time/batch=0.20s
2678/5900 (epoch 45.390) train_loss=398.55981445 time/batch=0.61s
2679/5900 (epoch 45.407) train_loss=171.49670410 time/batch=0.34s
2680/5900 (epoch 45.424) train_loss=202.35565186 time/batch=0.28s
2681/5900 (epoch 45.441) train_loss=188.60391235 time/batch=0.28s
2682/5900 (epoch 45.458) train_loss=319.19616699 time/batch=0.42s
2683/5900 (epoch 45.475) train_loss=245.58822632 time/batch=1.80s
2684/5900 (epoch 45.492) train_loss=151.76937866 time/batch=0.51s
2685/5900 (epoch 45.508) train_loss=235.26927185 time/batch=0.31s
2686/5900 (epoch 45.525) train_loss=102.48702240 time/batch=0.22s
2687/5900 (epoch 45.542) train_loss=189.26278687 time/batch=0.27s
2688/5900 (epoch 45.559) train_loss=133.42587280 time/batch=0.25s
2689/5900 (epoch 45.576) train_loss=83.15594482 time/batch=0.19s
2690/5900 (epoch 45.593) train_loss=317.11520386 time/batch=0.39s
2691/5900 (epoch 45.610) train_loss=299.03741455 time/batch=0.47s
2692/5900 (epoch 45.627) train_loss=239.54496765 time/batch=0.34s
2693/5900 (epoch 45.644) train_loss=226.57424927 time/batch=0.33s
2694/5900 (epoch 45.661) train_loss=87.43134308 time/batch=0.19s
2695/5900 (epoch 45.678) train_loss=220.38806152 time/batch=0.31s
2696/5900 (epoch 45.695) train_loss=203.00787354 time/batch=0.34s
2697/5900 (epoch 45.712) train_loss=108.05819702 time/batch=0.20s
2698/5900 (epoch 45.729) train_loss=124.96893311 time/batch=0.25s
2699/5900 (epoch 45.746) train_loss=189.01026917 time/batch=0.29s
2700/5900 (epoch 45.763) train_loss=91.00321960 time/batch=0.20s
2701/5900 (epoch 45.780) train_loss=80.60775757 time/batch=0.19s
2702/5900 (epoch 45.797) train_loss=91.15883636 time/batch=0.19s
2703/5900 (epoch 45.814) train_loss=83.24170685 time/batch=0.17s
2704/5900 (epoch 45.831) train_loss=109.40016174 time/batch=0.26s
2705/5900 (epoch 45.847) train_loss=81.30211639 time/batch=0.19s
2706/5900 (epoch 45.864) train_loss=92.12596130 time/batch=0.18s
2707/5900 (epoch 45.881) train_loss=94.82881165 time/batch=0.19s
2708/5900 (epoch 45.898) train_loss=83.64387512 time/batch=0.18s
2709/5900 (epoch 45.915) train_loss=90.06939697 time/batch=0.19s
2710/5900 (epoch 45.932) train_loss=86.34358215 time/batch=0.19s
2711/5900 (epoch 45.949) train_loss=88.29538727 time/batch=0.19s
2712/5900 (epoch 45.966) train_loss=91.52937317 time/batch=0.19s
2713/5900 (epoch 45.983) train_loss=89.24443817 time/batch=0.17s
2714/5900 (epoch 46.000) train_loss=90.85588074 time/batch=0.19s
setting learning rate to 0.0014009
2715/5900 (epoch 46.017) train_loss=216.30624390 time/batch=0.31s
2716/5900 (epoch 46.034) train_loss=170.70272827 time/batch=0.27s
2717/5900 (epoch 46.051) train_loss=156.77325439 time/batch=1.77s
2718/5900 (epoch 46.068) train_loss=303.09759521 time/batch=0.67s
2719/5900 (epoch 46.085) train_loss=431.57452393 time/batch=0.57s
2720/5900 (epoch 46.102) train_loss=491.21926880 time/batch=0.64s
2721/5900 (epoch 46.119) train_loss=720.52648926 time/batch=2.10s
2722/5900 (epoch 46.136) train_loss=930.96520996 time/batch=2.95s
2723/5900 (epoch 46.153) train_loss=242.80711365 time/batch=0.78s
2724/5900 (epoch 46.169) train_loss=246.79264832 time/batch=0.34s
2725/5900 (epoch 46.186) train_loss=224.07556152 time/batch=0.33s
2726/5900 (epoch 46.203) train_loss=215.91682434 time/batch=0.32s
2727/5900 (epoch 46.220) train_loss=327.93133545 time/batch=0.43s
2728/5900 (epoch 46.237) train_loss=148.67950439 time/batch=0.27s
2729/5900 (epoch 46.254) train_loss=93.90062714 time/batch=0.20s
2730/5900 (epoch 46.271) train_loss=211.91577148 time/batch=0.31s
2731/5900 (epoch 46.288) train_loss=195.64770508 time/batch=0.31s
2732/5900 (epoch 46.305) train_loss=255.29296875 time/batch=0.36s
2733/5900 (epoch 46.322) train_loss=332.15600586 time/batch=0.44s
2734/5900 (epoch 46.339) train_loss=285.72528076 time/batch=0.40s
2735/5900 (epoch 46.356) train_loss=125.46404266 time/batch=0.25s
2736/5900 (epoch 46.373) train_loss=291.24737549 time/batch=0.39s
2737/5900 (epoch 46.390) train_loss=122.52267456 time/batch=0.25s
2738/5900 (epoch 46.407) train_loss=147.81256104 time/batch=0.25s
2739/5900 (epoch 46.424) train_loss=84.11050415 time/batch=0.18s
2740/5900 (epoch 46.441) train_loss=259.19036865 time/batch=0.34s
2741/5900 (epoch 46.458) train_loss=252.68179321 time/batch=0.36s
2742/5900 (epoch 46.475) train_loss=183.74633789 time/batch=0.30s
2743/5900 (epoch 46.492) train_loss=270.43173218 time/batch=0.38s
2744/5900 (epoch 46.508) train_loss=88.77175903 time/batch=0.22s
2745/5900 (epoch 46.525) train_loss=209.72824097 time/batch=0.30s
2746/5900 (epoch 46.542) train_loss=96.12208557 time/batch=0.20s
2747/5900 (epoch 46.559) train_loss=207.99978638 time/batch=0.28s
2748/5900 (epoch 46.576) train_loss=278.35614014 time/batch=0.38s
2749/5900 (epoch 46.593) train_loss=92.25216675 time/batch=0.22s
2750/5900 (epoch 46.610) train_loss=185.13287354 time/batch=0.27s
2751/5900 (epoch 46.627) train_loss=259.64392090 time/batch=0.40s
2752/5900 (epoch 46.644) train_loss=201.93550110 time/batch=0.33s
2753/5900 (epoch 46.661) train_loss=91.83330536 time/batch=0.20s
2754/5900 (epoch 46.678) train_loss=81.96250916 time/batch=0.19s
2755/5900 (epoch 46.695) train_loss=190.66435242 time/batch=0.25s
2756/5900 (epoch 46.712) train_loss=180.66021729 time/batch=0.29s
2757/5900 (epoch 46.729) train_loss=92.63961792 time/batch=0.20s
2758/5900 (epoch 46.746) train_loss=108.36769104 time/batch=0.20s
2759/5900 (epoch 46.763) train_loss=138.19711304 time/batch=0.25s
2760/5900 (epoch 46.780) train_loss=168.74453735 time/batch=0.27s
2761/5900 (epoch 46.797) train_loss=155.19116211 time/batch=1.72s
2762/5900 (epoch 46.814) train_loss=101.46304321 time/batch=0.47s
2763/5900 (epoch 46.831) train_loss=90.46466064 time/batch=0.17s
2764/5900 (epoch 46.847) train_loss=88.68345642 time/batch=0.18s
2765/5900 (epoch 46.864) train_loss=110.50679016 time/batch=0.25s
2766/5900 (epoch 46.881) train_loss=84.20611572 time/batch=0.19s
2767/5900 (epoch 46.898) train_loss=88.61390686 time/batch=0.18s
2768/5900 (epoch 46.915) train_loss=91.51497650 time/batch=0.19s
2769/5900 (epoch 46.932) train_loss=89.12849426 time/batch=0.19s
2770/5900 (epoch 46.949) train_loss=81.41279602 time/batch=0.17s
2771/5900 (epoch 46.966) train_loss=87.72885132 time/batch=0.19s
2772/5900 (epoch 46.983) train_loss=85.35756683 time/batch=0.17s
2773/5900 (epoch 47.000) train_loss=85.48182678 time/batch=0.19s
setting learning rate to 0.0013589
2774/5900 (epoch 47.017) train_loss=247.22482300 time/batch=0.33s
2775/5900 (epoch 47.034) train_loss=300.92968750 time/batch=0.42s
2776/5900 (epoch 47.051) train_loss=974.76892090 time/batch=2.68s
2777/5900 (epoch 47.068) train_loss=159.05227661 time/batch=0.70s
2778/5900 (epoch 47.085) train_loss=679.05578613 time/batch=1.38s
2779/5900 (epoch 47.102) train_loss=299.75732422 time/batch=0.58s
2780/5900 (epoch 47.119) train_loss=195.99774170 time/batch=0.31s
2781/5900 (epoch 47.136) train_loss=189.27532959 time/batch=0.29s
2782/5900 (epoch 47.153) train_loss=140.52996826 time/batch=0.24s
2783/5900 (epoch 47.169) train_loss=306.01129150 time/batch=0.42s
2784/5900 (epoch 47.186) train_loss=249.52865601 time/batch=0.38s
2785/5900 (epoch 47.203) train_loss=242.13491821 time/batch=1.80s
2786/5900 (epoch 47.220) train_loss=379.15921021 time/batch=0.77s
2787/5900 (epoch 47.237) train_loss=395.66134644 time/batch=0.55s
2788/5900 (epoch 47.254) train_loss=248.32012939 time/batch=0.38s
2789/5900 (epoch 47.271) train_loss=261.72277832 time/batch=0.37s
2790/5900 (epoch 47.288) train_loss=214.59915161 time/batch=0.35s
2791/5900 (epoch 47.305) train_loss=88.09719086 time/batch=0.20s
2792/5900 (epoch 47.322) train_loss=338.66265869 time/batch=0.43s
2793/5900 (epoch 47.339) train_loss=291.47360229 time/batch=0.42s
2794/5900 (epoch 47.356) train_loss=205.70956421 time/batch=0.33s
2795/5900 (epoch 47.373) train_loss=123.34249878 time/batch=0.23s
2796/5900 (epoch 47.390) train_loss=221.46119690 time/batch=0.30s
2797/5900 (epoch 47.407) train_loss=106.59424591 time/batch=0.22s
2798/5900 (epoch 47.424) train_loss=220.01020813 time/batch=0.30s
2799/5900 (epoch 47.441) train_loss=218.50500488 time/batch=0.32s
2800/5900 (epoch 47.458) train_loss=201.68843079 time/batch=0.32s
2801/5900 (epoch 47.475) train_loss=94.97180939 time/batch=0.22s
2802/5900 (epoch 47.492) train_loss=180.29672241 time/batch=0.27s
2803/5900 (epoch 47.508) train_loss=258.15896606 time/batch=0.37s
2804/5900 (epoch 47.525) train_loss=80.75299072 time/batch=0.20s
2805/5900 (epoch 47.542) train_loss=239.10040283 time/batch=0.31s
2806/5900 (epoch 47.559) train_loss=146.84341431 time/batch=0.26s
2807/5900 (epoch 47.576) train_loss=91.48545074 time/batch=0.19s
2808/5900 (epoch 47.593) train_loss=200.61846924 time/batch=0.33s
2809/5900 (epoch 47.610) train_loss=157.97912598 time/batch=0.27s
2810/5900 (epoch 47.627) train_loss=95.52518463 time/batch=0.20s
2811/5900 (epoch 47.644) train_loss=293.46408081 time/batch=0.39s
2812/5900 (epoch 47.661) train_loss=235.34074402 time/batch=0.39s
2813/5900 (epoch 47.678) train_loss=87.01989746 time/batch=0.22s
2814/5900 (epoch 47.695) train_loss=102.54885864 time/batch=0.19s
2815/5900 (epoch 47.712) train_loss=182.73297119 time/batch=0.27s
2816/5900 (epoch 47.729) train_loss=89.91873169 time/batch=0.20s
2817/5900 (epoch 47.746) train_loss=82.43810272 time/batch=0.17s
2818/5900 (epoch 47.763) train_loss=180.14396667 time/batch=0.26s
2819/5900 (epoch 47.780) train_loss=172.23579407 time/batch=0.28s
2820/5900 (epoch 47.797) train_loss=84.78903961 time/batch=0.19s
2821/5900 (epoch 47.814) train_loss=81.60013580 time/batch=0.18s
2822/5900 (epoch 47.831) train_loss=133.21331787 time/batch=0.25s
2823/5900 (epoch 47.847) train_loss=82.78807068 time/batch=0.19s
2824/5900 (epoch 47.864) train_loss=87.69181824 time/batch=0.17s
2825/5900 (epoch 47.881) train_loss=85.02706146 time/batch=0.19s
2826/5900 (epoch 47.898) train_loss=90.58473969 time/batch=0.19s
2827/5900 (epoch 47.915) train_loss=86.07591248 time/batch=0.19s
2828/5900 (epoch 47.932) train_loss=89.87972260 time/batch=0.18s
2829/5900 (epoch 47.949) train_loss=89.61009216 time/batch=0.19s
2830/5900 (epoch 47.966) train_loss=84.73961639 time/batch=0.19s
2831/5900 (epoch 47.983) train_loss=85.75370789 time/batch=0.18s
2832/5900 (epoch 48.000) train_loss=86.60204315 time/batch=0.19s
setting learning rate to 0.0013181
2833/5900 (epoch 48.017) train_loss=1039.43591309 time/batch=2.64s
2834/5900 (epoch 48.034) train_loss=163.92964172 time/batch=0.69s
2835/5900 (epoch 48.051) train_loss=377.57342529 time/batch=0.47s
2836/5900 (epoch 48.068) train_loss=299.42694092 time/batch=0.43s
2837/5900 (epoch 48.085) train_loss=370.69927979 time/batch=0.50s
2838/5900 (epoch 48.102) train_loss=278.57559204 time/batch=0.42s
2839/5900 (epoch 48.119) train_loss=314.94580078 time/batch=0.44s
2840/5900 (epoch 48.136) train_loss=392.48519897 time/batch=0.56s
2841/5900 (epoch 48.153) train_loss=304.91729736 time/batch=0.45s
2842/5900 (epoch 48.169) train_loss=79.52734375 time/batch=0.22s
2843/5900 (epoch 48.186) train_loss=481.79968262 time/batch=0.61s
2844/5900 (epoch 48.203) train_loss=127.45364380 time/batch=0.28s
2845/5900 (epoch 48.220) train_loss=167.21504211 time/batch=0.26s
2846/5900 (epoch 48.237) train_loss=238.30743408 time/batch=0.34s
2847/5900 (epoch 48.254) train_loss=173.78289795 time/batch=0.30s
2848/5900 (epoch 48.271) train_loss=213.12788391 time/batch=0.31s
2849/5900 (epoch 48.288) train_loss=149.25863647 time/batch=0.25s
2850/5900 (epoch 48.305) train_loss=160.64633179 time/batch=0.26s
2851/5900 (epoch 48.322) train_loss=276.88891602 time/batch=0.39s
2852/5900 (epoch 48.339) train_loss=259.68078613 time/batch=0.40s
2853/5900 (epoch 48.356) train_loss=221.28862000 time/batch=0.34s
2854/5900 (epoch 48.373) train_loss=255.30967712 time/batch=0.35s
2855/5900 (epoch 48.390) train_loss=203.98027039 time/batch=0.31s
2856/5900 (epoch 48.407) train_loss=107.36329651 time/batch=0.22s
2857/5900 (epoch 48.424) train_loss=261.32730103 time/batch=0.34s
2858/5900 (epoch 48.441) train_loss=110.34391785 time/batch=0.22s
2859/5900 (epoch 48.458) train_loss=182.13668823 time/batch=0.28s
2860/5900 (epoch 48.475) train_loss=220.39654541 time/batch=0.33s
2861/5900 (epoch 48.492) train_loss=178.35707092 time/batch=0.28s
2862/5900 (epoch 48.508) train_loss=130.43310547 time/batch=0.25s
2863/5900 (epoch 48.525) train_loss=90.77488708 time/batch=0.20s
2864/5900 (epoch 48.542) train_loss=199.79595947 time/batch=0.28s
2865/5900 (epoch 48.559) train_loss=159.71255493 time/batch=0.30s
2866/5900 (epoch 48.576) train_loss=233.35694885 time/batch=1.78s
2867/5900 (epoch 48.593) train_loss=88.02427673 time/batch=0.47s
2868/5900 (epoch 48.610) train_loss=79.95867920 time/batch=0.17s
2869/5900 (epoch 48.627) train_loss=262.71432495 time/batch=0.33s
2870/5900 (epoch 48.644) train_loss=82.65077209 time/batch=0.21s
2871/5900 (epoch 48.661) train_loss=251.46490479 time/batch=0.34s
2872/5900 (epoch 48.678) train_loss=230.69825745 time/batch=0.35s
2873/5900 (epoch 48.695) train_loss=223.34719849 time/batch=0.33s
2874/5900 (epoch 48.712) train_loss=209.03077698 time/batch=0.31s
2875/5900 (epoch 48.729) train_loss=88.37207031 time/batch=0.21s
2876/5900 (epoch 48.746) train_loss=195.39135742 time/batch=0.27s
2877/5900 (epoch 48.763) train_loss=91.90834808 time/batch=0.20s
2878/5900 (epoch 48.780) train_loss=91.02088165 time/batch=0.19s
2879/5900 (epoch 48.797) train_loss=85.03841400 time/batch=0.18s
2880/5900 (epoch 48.814) train_loss=94.58341217 time/batch=0.19s
2881/5900 (epoch 48.831) train_loss=97.71498871 time/batch=0.19s
2882/5900 (epoch 48.847) train_loss=86.37792969 time/batch=0.18s
2883/5900 (epoch 48.864) train_loss=121.81617737 time/batch=0.28s
2884/5900 (epoch 48.881) train_loss=111.83723450 time/batch=0.31s
2885/5900 (epoch 48.898) train_loss=86.24446106 time/batch=0.19s
2886/5900 (epoch 48.915) train_loss=84.88075256 time/batch=0.19s
2887/5900 (epoch 48.932) train_loss=81.97293091 time/batch=0.17s
2888/5900 (epoch 48.949) train_loss=88.51473999 time/batch=0.19s
2889/5900 (epoch 48.966) train_loss=87.17942810 time/batch=0.19s
2890/5900 (epoch 48.983) train_loss=84.07464600 time/batch=0.17s
2891/5900 (epoch 49.000) train_loss=81.16164398 time/batch=0.17s
setting learning rate to 0.0012786
2892/5900 (epoch 49.017) train_loss=150.92453003 time/batch=0.25s
2893/5900 (epoch 49.034) train_loss=230.47923279 time/batch=0.33s
2894/5900 (epoch 49.051) train_loss=133.15870667 time/batch=0.22s
2895/5900 (epoch 49.068) train_loss=498.45947266 time/batch=0.69s
2896/5900 (epoch 49.085) train_loss=424.25149536 time/batch=0.57s
2897/5900 (epoch 49.102) train_loss=215.00045776 time/batch=0.35s
2898/5900 (epoch 49.119) train_loss=352.25936890 time/batch=0.47s
2899/5900 (epoch 49.136) train_loss=291.15368652 time/batch=0.44s
2900/5900 (epoch 49.153) train_loss=1056.60473633 time/batch=2.68s
2901/5900 (epoch 49.169) train_loss=302.00122070 time/batch=0.83s
2902/5900 (epoch 49.186) train_loss=273.52639771 time/batch=0.39s
2903/5900 (epoch 49.203) train_loss=91.78764343 time/batch=0.22s
2904/5900 (epoch 49.220) train_loss=252.71212769 time/batch=0.33s
2905/5900 (epoch 49.237) train_loss=241.41563416 time/batch=1.77s
2906/5900 (epoch 49.254) train_loss=322.13861084 time/batch=0.69s
2907/5900 (epoch 49.271) train_loss=272.86932373 time/batch=0.42s
2908/5900 (epoch 49.288) train_loss=86.43748474 time/batch=0.20s
2909/5900 (epoch 49.305) train_loss=254.37841797 time/batch=0.36s
2910/5900 (epoch 49.322) train_loss=82.30722046 time/batch=0.20s
2911/5900 (epoch 49.339) train_loss=236.76811218 time/batch=0.33s
2912/5900 (epoch 49.356) train_loss=76.58360291 time/batch=0.20s
2913/5900 (epoch 49.373) train_loss=356.69961548 time/batch=0.50s
2914/5900 (epoch 49.390) train_loss=156.83398438 time/batch=0.30s
2915/5900 (epoch 49.407) train_loss=222.48408508 time/batch=0.32s
2916/5900 (epoch 49.424) train_loss=192.52946472 time/batch=0.31s
2917/5900 (epoch 49.441) train_loss=127.41983032 time/batch=0.23s
2918/5900 (epoch 49.458) train_loss=255.30569458 time/batch=0.36s
2919/5900 (epoch 49.475) train_loss=78.86888123 time/batch=0.20s
2920/5900 (epoch 49.492) train_loss=180.84017944 time/batch=0.28s
2921/5900 (epoch 49.508) train_loss=249.53506470 time/batch=0.35s
2922/5900 (epoch 49.525) train_loss=81.44174957 time/batch=0.20s
2923/5900 (epoch 49.542) train_loss=245.63897705 time/batch=0.39s
2924/5900 (epoch 49.559) train_loss=146.04421997 time/batch=0.28s
2925/5900 (epoch 49.576) train_loss=96.32420349 time/batch=0.19s
2926/5900 (epoch 49.593) train_loss=137.91876221 time/batch=0.25s
2927/5900 (epoch 49.610) train_loss=88.09994507 time/batch=0.20s
2928/5900 (epoch 49.627) train_loss=216.68505859 time/batch=0.31s
2929/5900 (epoch 49.644) train_loss=83.46639252 time/batch=0.20s
2930/5900 (epoch 49.661) train_loss=167.50778198 time/batch=0.25s
2931/5900 (epoch 49.678) train_loss=178.62805176 time/batch=0.28s
2932/5900 (epoch 49.695) train_loss=209.36734009 time/batch=0.31s
2933/5900 (epoch 49.712) train_loss=230.87857056 time/batch=0.39s
2934/5900 (epoch 49.729) train_loss=181.04415894 time/batch=0.30s
2935/5900 (epoch 49.746) train_loss=182.83541870 time/batch=0.29s
2936/5900 (epoch 49.763) train_loss=94.90043640 time/batch=0.20s
2937/5900 (epoch 49.780) train_loss=187.37277222 time/batch=0.29s
2938/5900 (epoch 49.797) train_loss=105.75201416 time/batch=0.21s
2939/5900 (epoch 49.814) train_loss=201.05560303 time/batch=0.30s
2940/5900 (epoch 49.831) train_loss=84.74578857 time/batch=0.19s
2941/5900 (epoch 49.847) train_loss=108.69752502 time/batch=0.28s
2942/5900 (epoch 49.864) train_loss=85.35225677 time/batch=0.20s
2943/5900 (epoch 49.881) train_loss=83.07241821 time/batch=0.17s
2944/5900 (epoch 49.898) train_loss=85.88035583 time/batch=0.19s
2945/5900 (epoch 49.915) train_loss=87.64067078 time/batch=0.19s
2946/5900 (epoch 49.932) train_loss=87.05773163 time/batch=0.17s
2947/5900 (epoch 49.949) train_loss=88.33876038 time/batch=0.18s
2948/5900 (epoch 49.966) train_loss=85.81522369 time/batch=0.19s
2949/5900 (epoch 49.983) train_loss=87.17633057 time/batch=0.17s
2950/5900 (epoch 50.000) train_loss=85.96653748 time/batch=0.19s
setting learning rate to 0.0012402
  saved to metadata/config5--20190119-190634.pkl
2951/5900 (epoch 50.017) train_loss=261.92697144 time/batch=7.66s
2952/5900 (epoch 50.034) train_loss=297.18750000 time/batch=0.42s
2953/5900 (epoch 50.051) train_loss=455.01785278 time/batch=0.56s
2954/5900 (epoch 50.068) train_loss=749.73107910 time/batch=2.08s
2955/5900 (epoch 50.085) train_loss=145.87051392 time/batch=0.56s
2956/5900 (epoch 50.102) train_loss=79.31927490 time/batch=0.19s
2957/5900 (epoch 50.119) train_loss=124.64179993 time/batch=0.20s
2958/5900 (epoch 50.136) train_loss=239.98689270 time/batch=0.34s
2959/5900 (epoch 50.153) train_loss=346.90924072 time/batch=0.48s
2960/5900 (epoch 50.169) train_loss=178.68225098 time/batch=0.31s
2961/5900 (epoch 50.186) train_loss=278.22229004 time/batch=0.41s
2962/5900 (epoch 50.203) train_loss=221.64239502 time/batch=0.36s
2963/5900 (epoch 50.220) train_loss=315.87939453 time/batch=0.44s
2964/5900 (epoch 50.237) train_loss=314.69174194 time/batch=0.44s
2965/5900 (epoch 50.254) train_loss=161.45623779 time/batch=0.30s
2966/5900 (epoch 50.271) train_loss=236.96699524 time/batch=0.34s
2967/5900 (epoch 50.288) train_loss=240.07553101 time/batch=0.36s
2968/5900 (epoch 50.305) train_loss=165.50764465 time/batch=1.78s
2969/5900 (epoch 50.322) train_loss=105.52458191 time/batch=0.48s
2970/5900 (epoch 50.339) train_loss=231.94508362 time/batch=0.33s
2971/5900 (epoch 50.356) train_loss=137.63137817 time/batch=1.73s
2972/5900 (epoch 50.373) train_loss=225.45396423 time/batch=0.63s
2973/5900 (epoch 50.390) train_loss=179.87309265 time/batch=0.30s
2974/5900 (epoch 50.407) train_loss=107.85168457 time/batch=0.22s
2975/5900 (epoch 50.424) train_loss=151.22747803 time/batch=0.25s
2976/5900 (epoch 50.441) train_loss=218.31570435 time/batch=0.30s
2977/5900 (epoch 50.458) train_loss=258.33312988 time/batch=0.37s
2978/5900 (epoch 50.475) train_loss=173.63513184 time/batch=0.30s
2979/5900 (epoch 50.492) train_loss=151.73852539 time/batch=0.27s
2980/5900 (epoch 50.508) train_loss=86.88596344 time/batch=0.19s
2981/5900 (epoch 50.525) train_loss=201.52891541 time/batch=0.30s
2982/5900 (epoch 50.542) train_loss=302.73138428 time/batch=0.48s
2983/5900 (epoch 50.559) train_loss=839.14208984 time/batch=2.69s
2984/5900 (epoch 50.576) train_loss=263.53344727 time/batch=0.82s
2985/5900 (epoch 50.593) train_loss=171.43815613 time/batch=0.30s
2986/5900 (epoch 50.610) train_loss=87.64985657 time/batch=0.19s
2987/5900 (epoch 50.627) train_loss=90.80145264 time/batch=0.18s
2988/5900 (epoch 50.644) train_loss=78.03880310 time/batch=0.19s
2989/5900 (epoch 50.661) train_loss=90.66192627 time/batch=0.19s
2990/5900 (epoch 50.678) train_loss=201.97779846 time/batch=0.28s
2991/5900 (epoch 50.695) train_loss=92.50451660 time/batch=0.20s
2992/5900 (epoch 50.712) train_loss=215.32698059 time/batch=0.30s
2993/5900 (epoch 50.729) train_loss=159.35169983 time/batch=0.28s
2994/5900 (epoch 50.746) train_loss=205.61968994 time/batch=0.31s
2995/5900 (epoch 50.763) train_loss=186.78509521 time/batch=0.30s
2996/5900 (epoch 50.780) train_loss=95.26889038 time/batch=0.20s
2997/5900 (epoch 50.797) train_loss=209.58163452 time/batch=0.31s
2998/5900 (epoch 50.814) train_loss=93.96881866 time/batch=0.20s
2999/5900 (epoch 50.831) train_loss=112.26609039 time/batch=0.28s
Validating
    loss:	238.085032

3000/5900 (epoch 50.847) train_loss=85.96330261 time/batch=0.58s
3001/5900 (epoch 50.864) train_loss=83.18456268 time/batch=0.19s
3002/5900 (epoch 50.881) train_loss=82.87846375 time/batch=0.17s
3003/5900 (epoch 50.898) train_loss=89.23407745 time/batch=0.19s
3004/5900 (epoch 50.915) train_loss=82.65978241 time/batch=0.19s
3005/5900 (epoch 50.932) train_loss=80.58662415 time/batch=0.17s
3006/5900 (epoch 50.949) train_loss=89.67475891 time/batch=0.19s
3007/5900 (epoch 50.966) train_loss=79.99820709 time/batch=0.19s
3008/5900 (epoch 50.983) train_loss=85.18980408 time/batch=0.17s
3009/5900 (epoch 51.000) train_loss=89.53376007 time/batch=0.19s
setting learning rate to 0.0012030
3010/5900 (epoch 51.017) train_loss=209.15240479 time/batch=0.30s
3011/5900 (epoch 51.034) train_loss=262.46218872 time/batch=0.39s
3012/5900 (epoch 51.051) train_loss=318.87893677 time/batch=0.45s
3013/5900 (epoch 51.068) train_loss=377.18136597 time/batch=0.52s
3014/5900 (epoch 51.085) train_loss=493.34069824 time/batch=0.65s
3015/5900 (epoch 51.102) train_loss=376.52676392 time/batch=0.56s
3016/5900 (epoch 51.119) train_loss=104.27543640 time/batch=0.25s
3017/5900 (epoch 51.136) train_loss=199.61621094 time/batch=0.30s
3018/5900 (epoch 51.153) train_loss=140.61488342 time/batch=0.25s
3019/5900 (epoch 51.169) train_loss=249.10786438 time/batch=0.36s
3020/5900 (epoch 51.186) train_loss=696.33728027 time/batch=2.06s
3021/5900 (epoch 51.203) train_loss=90.76816559 time/batch=0.52s
3022/5900 (epoch 51.220) train_loss=118.93887329 time/batch=0.20s
3023/5900 (epoch 51.237) train_loss=245.11740112 time/batch=0.33s
3024/5900 (epoch 51.254) train_loss=92.15513611 time/batch=0.22s
3025/5900 (epoch 51.271) train_loss=387.42987061 time/batch=0.89s
3026/5900 (epoch 51.288) train_loss=243.32368469 time/batch=0.45s
3027/5900 (epoch 51.305) train_loss=206.69778442 time/batch=0.33s
3028/5900 (epoch 51.322) train_loss=138.61117554 time/batch=0.25s
3029/5900 (epoch 51.339) train_loss=284.77862549 time/batch=0.39s
3030/5900 (epoch 51.356) train_loss=79.19482422 time/batch=0.20s
3031/5900 (epoch 51.373) train_loss=234.89630127 time/batch=0.34s
3032/5900 (epoch 51.390) train_loss=224.19400024 time/batch=1.77s
3033/5900 (epoch 51.407) train_loss=85.45541382 time/batch=0.47s
3034/5900 (epoch 51.424) train_loss=184.24375916 time/batch=0.28s
3035/5900 (epoch 51.441) train_loss=595.89843750 time/batch=2.64s
3036/5900 (epoch 51.458) train_loss=234.66195679 time/batch=0.78s
3037/5900 (epoch 51.475) train_loss=203.43803406 time/batch=0.33s
3038/5900 (epoch 51.492) train_loss=262.42510986 time/batch=0.37s
3039/5900 (epoch 51.508) train_loss=84.15100098 time/batch=0.20s
3040/5900 (epoch 51.525) train_loss=218.34300232 time/batch=0.31s
3041/5900 (epoch 51.542) train_loss=190.87829590 time/batch=0.30s
3042/5900 (epoch 51.559) train_loss=190.33287048 time/batch=0.31s
3043/5900 (epoch 51.576) train_loss=271.98980713 time/batch=0.39s
3044/5900 (epoch 51.593) train_loss=80.90872955 time/batch=0.20s
3045/5900 (epoch 51.610) train_loss=181.34271240 time/batch=0.27s
3046/5900 (epoch 51.627) train_loss=149.08700562 time/batch=0.26s
3047/5900 (epoch 51.644) train_loss=230.09609985 time/batch=0.35s
3048/5900 (epoch 51.661) train_loss=137.18820190 time/batch=0.26s
3049/5900 (epoch 51.678) train_loss=128.49472046 time/batch=0.25s
3050/5900 (epoch 51.695) train_loss=192.61477661 time/batch=0.32s
3051/5900 (epoch 51.712) train_loss=168.20875549 time/batch=0.28s
3052/5900 (epoch 51.729) train_loss=176.01919556 time/batch=0.27s
3053/5900 (epoch 51.746) train_loss=88.44421387 time/batch=0.20s
3054/5900 (epoch 51.763) train_loss=86.98580933 time/batch=0.19s
3055/5900 (epoch 51.780) train_loss=76.71231079 time/batch=0.19s
3056/5900 (epoch 51.797) train_loss=167.75363159 time/batch=0.25s
3057/5900 (epoch 51.814) train_loss=81.12874603 time/batch=0.19s
3058/5900 (epoch 51.831) train_loss=114.20809937 time/batch=0.27s
3059/5900 (epoch 51.847) train_loss=82.03816223 time/batch=0.19s
3060/5900 (epoch 51.864) train_loss=90.28396606 time/batch=0.19s
3061/5900 (epoch 51.881) train_loss=80.15094757 time/batch=0.17s
3062/5900 (epoch 51.898) train_loss=79.71117401 time/batch=0.19s
3063/5900 (epoch 51.915) train_loss=83.53274536 time/batch=0.17s
3064/5900 (epoch 51.932) train_loss=86.38345337 time/batch=0.19s
3065/5900 (epoch 51.949) train_loss=85.00150299 time/batch=0.17s
3066/5900 (epoch 51.966) train_loss=86.22859955 time/batch=0.19s
3067/5900 (epoch 51.983) train_loss=90.93152618 time/batch=0.19s
3068/5900 (epoch 52.000) train_loss=91.65518188 time/batch=0.19s
setting learning rate to 0.0011669
3069/5900 (epoch 52.017) train_loss=195.23590088 time/batch=0.32s
3070/5900 (epoch 52.034) train_loss=280.56991577 time/batch=0.41s
3071/5900 (epoch 52.051) train_loss=200.27021790 time/batch=0.33s
3072/5900 (epoch 52.068) train_loss=1042.37695312 time/batch=2.65s
3073/5900 (epoch 52.085) train_loss=371.91271973 time/batch=0.91s
3074/5900 (epoch 52.102) train_loss=151.57379150 time/batch=0.28s
3075/5900 (epoch 52.119) train_loss=487.72021484 time/batch=0.63s
3076/5900 (epoch 52.136) train_loss=277.23907471 time/batch=0.45s
3077/5900 (epoch 52.153) train_loss=381.13256836 time/batch=0.52s
3078/5900 (epoch 52.169) train_loss=188.24899292 time/batch=0.34s
3079/5900 (epoch 52.186) train_loss=131.97692871 time/batch=0.23s
3080/5900 (epoch 52.203) train_loss=166.21853638 time/batch=0.25s
3081/5900 (epoch 52.220) train_loss=106.70178223 time/batch=0.22s
3082/5900 (epoch 52.237) train_loss=300.38171387 time/batch=0.41s
3083/5900 (epoch 52.254) train_loss=336.56970215 time/batch=0.54s
3084/5900 (epoch 52.271) train_loss=196.56350708 time/batch=0.34s
3085/5900 (epoch 52.288) train_loss=238.80496216 time/batch=0.36s
3086/5900 (epoch 52.305) train_loss=145.13708496 time/batch=0.27s
3087/5900 (epoch 52.322) train_loss=163.51640320 time/batch=0.28s
3088/5900 (epoch 52.339) train_loss=231.07739258 time/batch=0.33s
3089/5900 (epoch 52.356) train_loss=224.64085388 time/batch=1.80s
3090/5900 (epoch 52.373) train_loss=166.85275269 time/batch=0.55s
3091/5900 (epoch 52.390) train_loss=90.50984955 time/batch=0.20s
3092/5900 (epoch 52.407) train_loss=138.67568970 time/batch=0.25s
3093/5900 (epoch 52.424) train_loss=267.84436035 time/batch=0.41s
3094/5900 (epoch 52.441) train_loss=269.74475098 time/batch=0.41s
3095/5900 (epoch 52.458) train_loss=159.22534180 time/batch=0.28s
3096/5900 (epoch 52.475) train_loss=240.20999146 time/batch=0.34s
3097/5900 (epoch 52.492) train_loss=140.19631958 time/batch=0.28s
3098/5900 (epoch 52.508) train_loss=213.28692627 time/batch=0.31s
3099/5900 (epoch 52.525) train_loss=95.19818115 time/batch=0.21s
3100/5900 (epoch 52.542) train_loss=222.76971436 time/batch=0.32s
3101/5900 (epoch 52.559) train_loss=80.24350739 time/batch=0.20s
3102/5900 (epoch 52.576) train_loss=181.53366089 time/batch=0.28s
3103/5900 (epoch 52.593) train_loss=187.22106934 time/batch=0.28s
3104/5900 (epoch 52.610) train_loss=212.35433960 time/batch=0.33s
3105/5900 (epoch 52.627) train_loss=242.56811523 time/batch=0.34s
3106/5900 (epoch 52.644) train_loss=83.95744324 time/batch=0.22s
3107/5900 (epoch 52.661) train_loss=77.58631134 time/batch=0.17s
3108/5900 (epoch 52.678) train_loss=237.46324158 time/batch=0.34s
3109/5900 (epoch 52.695) train_loss=93.67971039 time/batch=0.20s
3110/5900 (epoch 52.712) train_loss=193.66592407 time/batch=0.34s
3111/5900 (epoch 52.729) train_loss=132.05545044 time/batch=0.38s
3112/5900 (epoch 52.746) train_loss=264.48101807 time/batch=0.38s
3113/5900 (epoch 52.763) train_loss=90.20935822 time/batch=0.22s
3114/5900 (epoch 52.780) train_loss=78.87829590 time/batch=0.17s
3115/5900 (epoch 52.797) train_loss=89.44602966 time/batch=0.19s
3116/5900 (epoch 52.814) train_loss=121.67765808 time/batch=0.34s
3117/5900 (epoch 52.831) train_loss=84.41166687 time/batch=0.21s
3118/5900 (epoch 52.847) train_loss=82.88339233 time/batch=0.19s
3119/5900 (epoch 52.864) train_loss=86.02880096 time/batch=0.17s
3120/5900 (epoch 52.881) train_loss=86.23197937 time/batch=0.19s
3121/5900 (epoch 52.898) train_loss=86.28535461 time/batch=0.19s
3122/5900 (epoch 52.915) train_loss=81.24114990 time/batch=0.17s
3123/5900 (epoch 52.932) train_loss=87.45513916 time/batch=0.19s
3124/5900 (epoch 52.949) train_loss=82.05345917 time/batch=0.17s
3125/5900 (epoch 52.966) train_loss=81.48965454 time/batch=0.19s
3126/5900 (epoch 52.983) train_loss=80.21048737 time/batch=0.19s
3127/5900 (epoch 53.000) train_loss=80.26274109 time/batch=0.17s
setting learning rate to 0.0011319
3128/5900 (epoch 53.017) train_loss=140.16476440 time/batch=0.23s
3129/5900 (epoch 53.034) train_loss=252.17706299 time/batch=0.37s
3130/5900 (epoch 53.051) train_loss=384.64364624 time/batch=0.50s
3131/5900 (epoch 53.068) train_loss=307.63690186 time/batch=0.45s
3132/5900 (epoch 53.085) train_loss=1047.80737305 time/batch=2.68s
3133/5900 (epoch 53.102) train_loss=280.95526123 time/batch=0.80s
3134/5900 (epoch 53.119) train_loss=237.92214966 time/batch=1.78s
3135/5900 (epoch 53.136) train_loss=146.52670288 time/batch=0.55s
3136/5900 (epoch 53.153) train_loss=102.46343994 time/batch=0.20s
3137/5900 (epoch 53.169) train_loss=236.56240845 time/batch=0.33s
3138/5900 (epoch 53.186) train_loss=292.79989624 time/batch=0.44s
3139/5900 (epoch 53.203) train_loss=465.08386230 time/batch=0.66s
3140/5900 (epoch 53.220) train_loss=241.03878784 time/batch=0.41s
3141/5900 (epoch 53.237) train_loss=142.82135010 time/batch=0.28s
3142/5900 (epoch 53.254) train_loss=387.02960205 time/batch=0.62s
3143/5900 (epoch 53.271) train_loss=196.00387573 time/batch=0.36s
3144/5900 (epoch 53.288) train_loss=202.07794189 time/batch=0.33s
3145/5900 (epoch 53.305) train_loss=214.73991394 time/batch=0.33s
3146/5900 (epoch 53.322) train_loss=102.38007355 time/batch=0.23s
3147/5900 (epoch 53.339) train_loss=124.94201660 time/batch=0.20s
3148/5900 (epoch 53.356) train_loss=203.73069763 time/batch=0.33s
3149/5900 (epoch 53.373) train_loss=295.92327881 time/batch=0.44s
3150/5900 (epoch 53.390) train_loss=178.99478149 time/batch=0.31s
3151/5900 (epoch 53.407) train_loss=232.64332581 time/batch=0.34s
3152/5900 (epoch 53.424) train_loss=156.94143677 time/batch=0.28s
3153/5900 (epoch 53.441) train_loss=273.99948120 time/batch=0.39s
3154/5900 (epoch 53.458) train_loss=92.50437927 time/batch=0.22s
3155/5900 (epoch 53.475) train_loss=137.35784912 time/batch=0.23s
3156/5900 (epoch 53.492) train_loss=275.10559082 time/batch=0.44s
3157/5900 (epoch 53.508) train_loss=208.24989319 time/batch=0.36s
3158/5900 (epoch 53.525) train_loss=185.33848572 time/batch=0.30s
3159/5900 (epoch 53.542) train_loss=201.09729004 time/batch=0.30s
3160/5900 (epoch 53.559) train_loss=241.21861267 time/batch=0.37s
3161/5900 (epoch 53.576) train_loss=192.44705200 time/batch=0.30s
3162/5900 (epoch 53.593) train_loss=174.62957764 time/batch=0.30s
3163/5900 (epoch 53.610) train_loss=231.59158325 time/batch=0.34s
3164/5900 (epoch 53.627) train_loss=131.83129883 time/batch=0.28s
3165/5900 (epoch 53.644) train_loss=198.96253967 time/batch=0.31s
3166/5900 (epoch 53.661) train_loss=175.23550415 time/batch=0.31s
3167/5900 (epoch 53.678) train_loss=83.73670197 time/batch=0.19s
3168/5900 (epoch 53.695) train_loss=86.67633820 time/batch=0.19s
3169/5900 (epoch 53.712) train_loss=84.05250549 time/batch=0.18s
3170/5900 (epoch 53.729) train_loss=125.74630737 time/batch=0.26s
3171/5900 (epoch 53.746) train_loss=78.42391968 time/batch=0.19s
3172/5900 (epoch 53.763) train_loss=86.52770996 time/batch=0.19s
3173/5900 (epoch 53.780) train_loss=113.54653931 time/batch=0.25s
3174/5900 (epoch 53.797) train_loss=85.84596252 time/batch=0.20s
3175/5900 (epoch 53.814) train_loss=81.19232178 time/batch=0.17s
3176/5900 (epoch 53.831) train_loss=94.11592102 time/batch=0.20s
3177/5900 (epoch 53.847) train_loss=82.15853882 time/batch=0.17s
3178/5900 (epoch 53.864) train_loss=88.65937042 time/batch=0.19s
3179/5900 (epoch 53.881) train_loss=85.05651855 time/batch=0.19s
3180/5900 (epoch 53.898) train_loss=79.72249603 time/batch=0.17s
3181/5900 (epoch 53.915) train_loss=87.11154175 time/batch=0.19s
3182/5900 (epoch 53.932) train_loss=84.61444855 time/batch=0.17s
3183/5900 (epoch 53.949) train_loss=77.24278259 time/batch=0.17s
3184/5900 (epoch 53.966) train_loss=81.48109436 time/batch=0.19s
3185/5900 (epoch 53.983) train_loss=80.38988495 time/batch=0.17s
3186/5900 (epoch 54.000) train_loss=82.02204132 time/batch=0.19s
setting learning rate to 0.0010980
3187/5900 (epoch 54.017) train_loss=134.31106567 time/batch=0.22s
3188/5900 (epoch 54.034) train_loss=158.33300781 time/batch=0.26s
3189/5900 (epoch 54.051) train_loss=755.47290039 time/batch=2.05s
3190/5900 (epoch 54.068) train_loss=810.95849609 time/batch=2.95s
3191/5900 (epoch 54.085) train_loss=355.49514771 time/batch=0.87s
3192/5900 (epoch 54.102) train_loss=162.78051758 time/batch=0.30s
3193/5900 (epoch 54.119) train_loss=175.99453735 time/batch=0.30s
3194/5900 (epoch 54.136) train_loss=203.58786011 time/batch=0.33s
3195/5900 (epoch 54.153) train_loss=195.32139587 time/batch=0.31s
3196/5900 (epoch 54.169) train_loss=165.38732910 time/batch=0.30s
3197/5900 (epoch 54.186) train_loss=256.18826294 time/batch=0.38s
3198/5900 (epoch 54.203) train_loss=239.10479736 time/batch=0.37s
3199/5900 (epoch 54.220) train_loss=229.36529541 time/batch=0.34s
3200/5900 (epoch 54.237) train_loss=296.00012207 time/batch=0.45s
3201/5900 (epoch 54.254) train_loss=321.51507568 time/batch=0.50s
3202/5900 (epoch 54.271) train_loss=374.35443115 time/batch=0.54s
3203/5900 (epoch 54.288) train_loss=199.33822632 time/batch=0.36s
3204/5900 (epoch 54.305) train_loss=148.07394409 time/batch=0.28s
3205/5900 (epoch 54.322) train_loss=288.10565186 time/batch=0.47s
3206/5900 (epoch 54.339) train_loss=253.01956177 time/batch=0.41s
3207/5900 (epoch 54.356) train_loss=224.42288208 time/batch=0.36s
3208/5900 (epoch 54.373) train_loss=178.75250244 time/batch=0.31s
3209/5900 (epoch 54.390) train_loss=247.39564514 time/batch=0.37s
3210/5900 (epoch 54.407) train_loss=78.94269562 time/batch=0.20s
3211/5900 (epoch 54.424) train_loss=227.48468018 time/batch=0.32s
3212/5900 (epoch 54.441) train_loss=141.53408813 time/batch=0.27s
3213/5900 (epoch 54.458) train_loss=121.19441986 time/batch=0.23s
3214/5900 (epoch 54.475) train_loss=181.62156677 time/batch=0.28s
3215/5900 (epoch 54.492) train_loss=136.78454590 time/batch=0.25s
3216/5900 (epoch 54.508) train_loss=155.88331604 time/batch=0.27s
3217/5900 (epoch 54.525) train_loss=267.06961060 time/batch=0.39s
3218/5900 (epoch 54.542) train_loss=83.34919739 time/batch=0.20s
3219/5900 (epoch 54.559) train_loss=173.27981567 time/batch=0.29s
3220/5900 (epoch 54.576) train_loss=248.44065857 time/batch=0.39s
3221/5900 (epoch 54.593) train_loss=123.89689636 time/batch=0.30s
3222/5900 (epoch 54.610) train_loss=195.85598755 time/batch=0.30s
3223/5900 (epoch 54.627) train_loss=227.41874695 time/batch=1.78s
3224/5900 (epoch 54.644) train_loss=168.47874451 time/batch=0.58s
3225/5900 (epoch 54.661) train_loss=213.75393677 time/batch=0.33s
3226/5900 (epoch 54.678) train_loss=91.14524078 time/batch=0.21s
3227/5900 (epoch 54.695) train_loss=184.94454956 time/batch=0.33s
3228/5900 (epoch 54.712) train_loss=86.41825867 time/batch=0.20s
3229/5900 (epoch 54.729) train_loss=86.02925873 time/batch=0.19s
3230/5900 (epoch 54.746) train_loss=93.89305115 time/batch=0.19s
3231/5900 (epoch 54.763) train_loss=79.49178314 time/batch=0.17s
3232/5900 (epoch 54.780) train_loss=85.56074524 time/batch=0.19s
3233/5900 (epoch 54.797) train_loss=94.48024750 time/batch=0.19s
3234/5900 (epoch 54.814) train_loss=78.19303894 time/batch=0.17s
3235/5900 (epoch 54.831) train_loss=85.67565918 time/batch=0.20s
3236/5900 (epoch 54.847) train_loss=89.81727600 time/batch=0.17s
3237/5900 (epoch 54.864) train_loss=81.81246185 time/batch=0.19s
3238/5900 (epoch 54.881) train_loss=76.88130188 time/batch=0.17s
3239/5900 (epoch 54.898) train_loss=80.53128052 time/batch=0.19s
3240/5900 (epoch 54.915) train_loss=81.80442810 time/batch=0.19s
3241/5900 (epoch 54.932) train_loss=86.29986572 time/batch=0.17s
3242/5900 (epoch 54.949) train_loss=86.15494537 time/batch=0.19s
3243/5900 (epoch 54.966) train_loss=83.10903931 time/batch=0.17s
3244/5900 (epoch 54.983) train_loss=84.52273560 time/batch=0.19s
3245/5900 (epoch 55.000) train_loss=82.08133698 time/batch=0.19s
setting learning rate to 0.0010650
3246/5900 (epoch 55.017) train_loss=241.59902954 time/batch=0.36s
3247/5900 (epoch 55.034) train_loss=142.81750488 time/batch=0.27s
3248/5900 (epoch 55.051) train_loss=137.62937927 time/batch=0.26s
3249/5900 (epoch 55.068) train_loss=307.11257935 time/batch=0.42s
3250/5900 (epoch 55.085) train_loss=1056.60461426 time/batch=2.69s
3251/5900 (epoch 55.102) train_loss=257.21917725 time/batch=0.78s
3252/5900 (epoch 55.119) train_loss=415.60430908 time/batch=0.56s
3253/5900 (epoch 55.136) train_loss=165.34997559 time/batch=0.34s
3254/5900 (epoch 55.153) train_loss=434.06585693 time/batch=0.63s
3255/5900 (epoch 55.169) train_loss=280.69039917 time/batch=0.48s
3256/5900 (epoch 55.186) train_loss=76.82125854 time/batch=0.21s
3257/5900 (epoch 55.203) train_loss=152.37351990 time/batch=0.26s
3258/5900 (epoch 55.220) train_loss=117.20237732 time/batch=0.22s
3259/5900 (epoch 55.237) train_loss=136.06332397 time/batch=0.25s
3260/5900 (epoch 55.254) train_loss=290.36737061 time/batch=0.44s
3261/5900 (epoch 55.271) train_loss=215.10203552 time/batch=0.37s
3262/5900 (epoch 55.288) train_loss=306.53295898 time/batch=0.47s
3263/5900 (epoch 55.305) train_loss=246.63580322 time/batch=0.39s
3264/5900 (epoch 55.322) train_loss=161.30020142 time/batch=0.28s
3265/5900 (epoch 55.339) train_loss=83.66153717 time/batch=0.20s
3266/5900 (epoch 55.356) train_loss=231.47137451 time/batch=0.34s
3267/5900 (epoch 55.373) train_loss=173.88003540 time/batch=0.30s
3268/5900 (epoch 55.390) train_loss=88.50608063 time/batch=0.19s
3269/5900 (epoch 55.407) train_loss=204.27777100 time/batch=0.31s
3270/5900 (epoch 55.424) train_loss=264.60516357 time/batch=0.39s
3271/5900 (epoch 55.441) train_loss=180.69619751 time/batch=0.31s
3272/5900 (epoch 55.458) train_loss=198.04061890 time/batch=0.33s
3273/5900 (epoch 55.475) train_loss=221.39305115 time/batch=1.78s
3274/5900 (epoch 55.492) train_loss=138.16917419 time/batch=0.53s
3275/5900 (epoch 55.508) train_loss=182.76956177 time/batch=0.28s
3276/5900 (epoch 55.525) train_loss=75.45404053 time/batch=0.20s
3277/5900 (epoch 55.542) train_loss=74.96977997 time/batch=0.17s
3278/5900 (epoch 55.559) train_loss=78.75557709 time/batch=0.18s
3279/5900 (epoch 55.576) train_loss=193.13534546 time/batch=0.28s
3280/5900 (epoch 55.593) train_loss=81.49175262 time/batch=0.20s
3281/5900 (epoch 55.610) train_loss=223.06033325 time/batch=0.33s
3282/5900 (epoch 55.627) train_loss=187.16015625 time/batch=0.31s
3283/5900 (epoch 55.644) train_loss=238.93348694 time/batch=0.36s
3284/5900 (epoch 55.661) train_loss=259.14312744 time/batch=0.39s
3285/5900 (epoch 55.678) train_loss=141.43669128 time/batch=0.28s
3286/5900 (epoch 55.695) train_loss=91.48889923 time/batch=0.20s
3287/5900 (epoch 55.712) train_loss=261.47042847 time/batch=0.38s
3288/5900 (epoch 55.729) train_loss=177.87316895 time/batch=0.31s
3289/5900 (epoch 55.746) train_loss=206.73141479 time/batch=0.31s
3290/5900 (epoch 55.763) train_loss=106.07208252 time/batch=0.22s
3291/5900 (epoch 55.780) train_loss=201.40609741 time/batch=0.31s
3292/5900 (epoch 55.797) train_loss=82.51737976 time/batch=0.20s
3293/5900 (epoch 55.814) train_loss=103.39382935 time/batch=0.28s
3294/5900 (epoch 55.831) train_loss=80.61190796 time/batch=0.21s
3295/5900 (epoch 55.847) train_loss=89.06877136 time/batch=0.19s
3296/5900 (epoch 55.864) train_loss=85.46221924 time/batch=0.19s
3297/5900 (epoch 55.881) train_loss=84.77610779 time/batch=0.17s
3298/5900 (epoch 55.898) train_loss=82.81491852 time/batch=0.19s
3299/5900 (epoch 55.915) train_loss=78.67970276 time/batch=0.19s
3300/5900 (epoch 55.932) train_loss=85.56907654 time/batch=0.17s
3301/5900 (epoch 55.949) train_loss=87.45173645 time/batch=0.19s
3302/5900 (epoch 55.966) train_loss=81.67519379 time/batch=0.19s
3303/5900 (epoch 55.983) train_loss=82.82928467 time/batch=0.19s
3304/5900 (epoch 56.000) train_loss=81.84346771 time/batch=0.17s
setting learning rate to 0.0010331
3305/5900 (epoch 56.017) train_loss=267.40032959 time/batch=0.41s
3306/5900 (epoch 56.034) train_loss=198.38836670 time/batch=0.34s
3307/5900 (epoch 56.051) train_loss=187.73834229 time/batch=0.31s
3308/5900 (epoch 56.068) train_loss=1010.74005127 time/batch=2.65s
3309/5900 (epoch 56.085) train_loss=90.89442444 time/batch=0.64s
3310/5900 (epoch 56.102) train_loss=424.90917969 time/batch=0.50s
3311/5900 (epoch 56.119) train_loss=397.92156982 time/batch=0.62s
3312/5900 (epoch 56.136) train_loss=118.12361145 time/batch=0.27s
3313/5900 (epoch 56.153) train_loss=362.39907837 time/batch=0.59s
3314/5900 (epoch 56.169) train_loss=251.07582092 time/batch=0.44s
3315/5900 (epoch 56.186) train_loss=236.27124023 time/batch=0.38s
3316/5900 (epoch 56.203) train_loss=215.47979736 time/batch=1.80s
3317/5900 (epoch 56.220) train_loss=220.11322021 time/batch=0.61s
3318/5900 (epoch 56.237) train_loss=220.11508179 time/batch=0.36s
3319/5900 (epoch 56.254) train_loss=230.06137085 time/batch=0.38s
3320/5900 (epoch 56.271) train_loss=77.77616119 time/batch=0.20s
3321/5900 (epoch 56.288) train_loss=352.84994507 time/batch=0.62s
3322/5900 (epoch 56.305) train_loss=181.80554199 time/batch=0.35s
3323/5900 (epoch 56.322) train_loss=81.41751099 time/batch=0.20s
3324/5900 (epoch 56.339) train_loss=137.48435974 time/batch=0.22s
3325/5900 (epoch 56.356) train_loss=99.51092529 time/batch=0.20s
3326/5900 (epoch 56.373) train_loss=74.27543640 time/batch=0.19s
3327/5900 (epoch 56.390) train_loss=198.10662842 time/batch=0.30s
3328/5900 (epoch 56.407) train_loss=80.57260132 time/batch=0.20s
3329/5900 (epoch 56.424) train_loss=155.57019043 time/batch=0.25s
3330/5900 (epoch 56.441) train_loss=145.49349976 time/batch=0.25s
3331/5900 (epoch 56.458) train_loss=259.15655518 time/batch=0.39s
3332/5900 (epoch 56.475) train_loss=82.75064087 time/batch=0.22s
3333/5900 (epoch 56.492) train_loss=132.10784912 time/batch=0.24s
3334/5900 (epoch 56.508) train_loss=206.71708679 time/batch=0.33s
3335/5900 (epoch 56.525) train_loss=268.79263306 time/batch=0.41s
3336/5900 (epoch 56.542) train_loss=237.17527771 time/batch=0.36s
3337/5900 (epoch 56.559) train_loss=181.65203857 time/batch=0.30s
3338/5900 (epoch 56.576) train_loss=174.40603638 time/batch=0.29s
3339/5900 (epoch 56.593) train_loss=191.77732849 time/batch=0.33s
3340/5900 (epoch 56.610) train_loss=118.10913086 time/batch=0.27s
3341/5900 (epoch 56.627) train_loss=74.91028595 time/batch=0.19s
3342/5900 (epoch 56.644) train_loss=84.47377014 time/batch=0.17s
3343/5900 (epoch 56.661) train_loss=213.86145020 time/batch=0.33s
3344/5900 (epoch 56.678) train_loss=81.08863831 time/batch=0.20s
3345/5900 (epoch 56.695) train_loss=82.98020172 time/batch=0.19s
3346/5900 (epoch 56.712) train_loss=172.39857483 time/batch=0.25s
3347/5900 (epoch 56.729) train_loss=83.40357971 time/batch=0.20s
3348/5900 (epoch 56.746) train_loss=243.48068237 time/batch=0.34s
3349/5900 (epoch 56.763) train_loss=165.38943481 time/batch=0.28s
3350/5900 (epoch 56.780) train_loss=82.51536560 time/batch=0.19s
3351/5900 (epoch 56.797) train_loss=77.38644409 time/batch=0.19s
3352/5900 (epoch 56.814) train_loss=195.35690308 time/batch=0.28s
3353/5900 (epoch 56.831) train_loss=88.49738312 time/batch=0.22s
3354/5900 (epoch 56.847) train_loss=187.73104858 time/batch=0.29s
3355/5900 (epoch 56.864) train_loss=164.63836670 time/batch=0.28s
3356/5900 (epoch 56.881) train_loss=257.04876709 time/batch=0.41s
3357/5900 (epoch 56.898) train_loss=103.27172089 time/batch=0.28s
3358/5900 (epoch 56.915) train_loss=82.48921204 time/batch=0.19s
3359/5900 (epoch 56.932) train_loss=89.16204834 time/batch=0.19s
3360/5900 (epoch 56.949) train_loss=80.06063843 time/batch=0.17s
3361/5900 (epoch 56.966) train_loss=91.00767517 time/batch=0.19s
3362/5900 (epoch 56.983) train_loss=81.78059387 time/batch=0.19s
3363/5900 (epoch 57.000) train_loss=84.89001465 time/batch=0.19s
setting learning rate to 0.0010021
3364/5900 (epoch 57.017) train_loss=139.89137268 time/batch=0.25s
3365/5900 (epoch 57.034) train_loss=975.02563477 time/batch=2.61s
3366/5900 (epoch 57.051) train_loss=472.32040405 time/batch=1.01s
3367/5900 (epoch 57.068) train_loss=240.18362427 time/batch=0.39s
3368/5900 (epoch 57.085) train_loss=143.72341919 time/batch=0.28s
3369/5900 (epoch 57.102) train_loss=160.94418335 time/batch=0.27s
3370/5900 (epoch 57.119) train_loss=322.00225830 time/batch=0.47s
3371/5900 (epoch 57.136) train_loss=214.22100830 time/batch=0.37s
3372/5900 (epoch 57.153) train_loss=282.39572144 time/batch=0.42s
3373/5900 (epoch 57.169) train_loss=230.19494629 time/batch=0.39s
3374/5900 (epoch 57.186) train_loss=76.58920288 time/batch=0.21s
3375/5900 (epoch 57.203) train_loss=421.38854980 time/batch=0.61s
3376/5900 (epoch 57.220) train_loss=214.66145325 time/batch=1.83s
3377/5900 (epoch 57.237) train_loss=296.32269287 time/batch=0.71s
3378/5900 (epoch 57.254) train_loss=178.66851807 time/batch=0.31s
3379/5900 (epoch 57.271) train_loss=151.17733765 time/batch=0.28s
3380/5900 (epoch 57.288) train_loss=222.77531433 time/batch=0.34s
3381/5900 (epoch 57.305) train_loss=257.20324707 time/batch=0.41s
3382/5900 (epoch 57.322) train_loss=79.84037781 time/batch=0.20s
3383/5900 (epoch 57.339) train_loss=133.86279297 time/batch=0.23s
3384/5900 (epoch 57.356) train_loss=146.54815674 time/batch=0.27s
3385/5900 (epoch 57.373) train_loss=221.24807739 time/batch=0.34s
3386/5900 (epoch 57.390) train_loss=259.17950439 time/batch=0.41s
3387/5900 (epoch 57.407) train_loss=245.34223938 time/batch=0.40s
3388/5900 (epoch 57.424) train_loss=262.29272461 time/batch=0.42s
3389/5900 (epoch 57.441) train_loss=260.19494629 time/batch=0.40s
3390/5900 (epoch 57.458) train_loss=198.06793213 time/batch=0.34s
3391/5900 (epoch 57.475) train_loss=161.26950073 time/batch=0.29s
3392/5900 (epoch 57.492) train_loss=101.48473358 time/batch=0.22s
3393/5900 (epoch 57.508) train_loss=85.51852417 time/batch=0.18s
3394/5900 (epoch 57.525) train_loss=217.68144226 time/batch=0.36s
3395/5900 (epoch 57.542) train_loss=123.98054504 time/batch=0.25s
3396/5900 (epoch 57.559) train_loss=109.53726196 time/batch=0.21s
3397/5900 (epoch 57.576) train_loss=78.94314575 time/batch=0.19s
3398/5900 (epoch 57.593) train_loss=199.34719849 time/batch=0.31s
3399/5900 (epoch 57.610) train_loss=184.94827271 time/batch=0.31s
3400/5900 (epoch 57.627) train_loss=188.91516113 time/batch=0.31s
3401/5900 (epoch 57.644) train_loss=79.97007751 time/batch=0.20s
3402/5900 (epoch 57.661) train_loss=83.91620636 time/batch=0.17s
3403/5900 (epoch 57.678) train_loss=77.91001129 time/batch=0.18s
3404/5900 (epoch 57.695) train_loss=183.45440674 time/batch=0.28s
3405/5900 (epoch 57.712) train_loss=92.48075867 time/batch=0.22s
3406/5900 (epoch 57.729) train_loss=75.06619263 time/batch=0.17s
3407/5900 (epoch 57.746) train_loss=177.42994690 time/batch=0.29s
3408/5900 (epoch 57.763) train_loss=165.83010864 time/batch=0.29s
3409/5900 (epoch 57.780) train_loss=77.94734192 time/batch=0.20s
3410/5900 (epoch 57.797) train_loss=105.53962708 time/batch=0.26s
3411/5900 (epoch 57.814) train_loss=195.77264404 time/batch=0.35s
3412/5900 (epoch 57.831) train_loss=85.96345520 time/batch=0.21s
3413/5900 (epoch 57.847) train_loss=78.99768829 time/batch=0.19s
3414/5900 (epoch 57.864) train_loss=168.74069214 time/batch=0.30s
3415/5900 (epoch 57.881) train_loss=89.24140930 time/batch=0.19s
3416/5900 (epoch 57.898) train_loss=78.61849976 time/batch=0.19s
3417/5900 (epoch 57.915) train_loss=89.74423981 time/batch=0.17s
3418/5900 (epoch 57.932) train_loss=82.05468750 time/batch=0.18s
3419/5900 (epoch 57.949) train_loss=90.49360657 time/batch=0.18s
3420/5900 (epoch 57.966) train_loss=85.15937042 time/batch=0.19s
3421/5900 (epoch 57.983) train_loss=87.40634918 time/batch=0.18s
3422/5900 (epoch 58.000) train_loss=84.38452148 time/batch=0.19s
setting learning rate to 0.0009720
3423/5900 (epoch 58.017) train_loss=420.56127930 time/batch=0.63s
3424/5900 (epoch 58.034) train_loss=162.40756226 time/batch=0.32s
3425/5900 (epoch 58.051) train_loss=242.70489502 time/batch=0.37s
3426/5900 (epoch 58.068) train_loss=232.82498169 time/batch=0.37s
3427/5900 (epoch 58.085) train_loss=217.32255554 time/batch=0.36s
3428/5900 (epoch 58.102) train_loss=244.92457581 time/batch=0.39s
3429/5900 (epoch 58.119) train_loss=108.41428375 time/batch=0.24s
3430/5900 (epoch 58.136) train_loss=242.68519592 time/batch=0.37s
3431/5900 (epoch 58.153) train_loss=208.42541504 time/batch=1.80s
3432/5900 (epoch 58.169) train_loss=188.25663757 time/batch=0.59s
3433/5900 (epoch 58.186) train_loss=177.01277161 time/batch=0.33s
3434/5900 (epoch 58.203) train_loss=295.08465576 time/batch=0.44s
3435/5900 (epoch 58.220) train_loss=268.90106201 time/batch=0.44s
3436/5900 (epoch 58.237) train_loss=131.45755005 time/batch=0.26s
3437/5900 (epoch 58.254) train_loss=165.31982422 time/batch=0.28s
3438/5900 (epoch 58.271) train_loss=160.16354370 time/batch=0.28s
3439/5900 (epoch 58.288) train_loss=170.25042725 time/batch=0.29s
3440/5900 (epoch 58.305) train_loss=163.92962646 time/batch=0.31s
3441/5900 (epoch 58.322) train_loss=192.75949097 time/batch=0.32s
3442/5900 (epoch 58.339) train_loss=137.54684448 time/batch=0.26s
3443/5900 (epoch 58.356) train_loss=273.49926758 time/batch=0.41s
3444/5900 (epoch 58.373) train_loss=179.42771912 time/batch=0.33s
3445/5900 (epoch 58.390) train_loss=285.00512695 time/batch=0.45s
3446/5900 (epoch 58.407) train_loss=106.55957031 time/batch=0.25s
3447/5900 (epoch 58.424) train_loss=197.06301880 time/batch=0.32s
3448/5900 (epoch 58.441) train_loss=226.45547485 time/batch=0.34s
3449/5900 (epoch 58.458) train_loss=386.36901855 time/batch=0.64s
3450/5900 (epoch 58.475) train_loss=603.08032227 time/batch=2.11s
3451/5900 (epoch 58.492) train_loss=244.92953491 time/batch=0.67s
3452/5900 (epoch 58.508) train_loss=247.24554443 time/batch=0.41s
3453/5900 (epoch 58.525) train_loss=753.87548828 time/batch=2.69s
3454/5900 (epoch 58.542) train_loss=83.90879059 time/batch=0.63s
3455/5900 (epoch 58.559) train_loss=77.26838684 time/batch=0.18s
3456/5900 (epoch 58.576) train_loss=167.16490173 time/batch=0.26s
3457/5900 (epoch 58.593) train_loss=171.97390747 time/batch=0.29s
3458/5900 (epoch 58.610) train_loss=211.74839783 time/batch=0.34s
3459/5900 (epoch 58.627) train_loss=81.71128082 time/batch=0.21s
3460/5900 (epoch 58.644) train_loss=87.93898010 time/batch=0.19s
3461/5900 (epoch 58.661) train_loss=149.66992188 time/batch=0.25s
3462/5900 (epoch 58.678) train_loss=75.10006714 time/batch=0.18s
3463/5900 (epoch 58.695) train_loss=182.69241333 time/batch=0.30s
3464/5900 (epoch 58.712) train_loss=101.88677979 time/batch=0.21s
3465/5900 (epoch 58.729) train_loss=73.73902893 time/batch=0.18s
3466/5900 (epoch 58.746) train_loss=153.32958984 time/batch=0.29s
3467/5900 (epoch 58.763) train_loss=87.02484131 time/batch=0.21s
3468/5900 (epoch 58.780) train_loss=82.21247101 time/batch=0.19s
3469/5900 (epoch 58.797) train_loss=77.92977905 time/batch=0.18s
3470/5900 (epoch 58.814) train_loss=113.49417114 time/batch=0.30s
3471/5900 (epoch 58.831) train_loss=86.17805481 time/batch=0.19s
3472/5900 (epoch 58.847) train_loss=81.67053223 time/batch=0.19s
3473/5900 (epoch 58.864) train_loss=84.95072174 time/batch=0.18s
3474/5900 (epoch 58.881) train_loss=87.44474792 time/batch=0.18s
3475/5900 (epoch 58.898) train_loss=78.22332764 time/batch=0.18s
3476/5900 (epoch 58.915) train_loss=78.63246155 time/batch=0.18s
3477/5900 (epoch 58.932) train_loss=78.89862061 time/batch=0.19s
3478/5900 (epoch 58.949) train_loss=86.92591858 time/batch=0.18s
3479/5900 (epoch 58.966) train_loss=88.01654053 time/batch=0.19s
3480/5900 (epoch 58.983) train_loss=83.04907227 time/batch=0.18s
3481/5900 (epoch 59.000) train_loss=79.67089844 time/batch=0.19s
setting learning rate to 0.0009429
3482/5900 (epoch 59.017) train_loss=986.02947998 time/batch=2.64s
3483/5900 (epoch 59.034) train_loss=295.79067993 time/batch=2.22s
3484/5900 (epoch 59.051) train_loss=431.62573242 time/batch=0.83s
3485/5900 (epoch 59.068) train_loss=197.10533142 time/batch=0.35s
3486/5900 (epoch 59.085) train_loss=243.38792419 time/batch=0.39s
3487/5900 (epoch 59.102) train_loss=296.68103027 time/batch=0.47s
3488/5900 (epoch 59.119) train_loss=318.97323608 time/batch=0.50s
3489/5900 (epoch 59.136) train_loss=295.07128906 time/batch=0.51s
3490/5900 (epoch 59.153) train_loss=177.40026855 time/batch=0.34s
3491/5900 (epoch 59.169) train_loss=140.72793579 time/batch=0.27s
3492/5900 (epoch 59.186) train_loss=128.70919800 time/batch=0.24s
3493/5900 (epoch 59.203) train_loss=159.83409119 time/batch=0.28s
3494/5900 (epoch 59.220) train_loss=96.90444946 time/batch=0.21s
3495/5900 (epoch 59.237) train_loss=145.38467407 time/batch=0.26s
3496/5900 (epoch 59.254) train_loss=247.19900513 time/batch=0.39s
3497/5900 (epoch 59.271) train_loss=227.96369934 time/batch=0.39s
3498/5900 (epoch 59.288) train_loss=73.81346893 time/batch=0.20s
3499/5900 (epoch 59.305) train_loss=202.65509033 time/batch=0.31s
3500/5900 (epoch 59.322) train_loss=136.55969238 time/batch=0.26s
3501/5900 (epoch 59.339) train_loss=216.88011169 time/batch=0.34s
3502/5900 (epoch 59.356) train_loss=74.91051483 time/batch=0.19s
3503/5900 (epoch 59.373) train_loss=78.70991516 time/batch=0.18s
3504/5900 (epoch 59.390) train_loss=265.06735229 time/batch=0.39s
3505/5900 (epoch 59.407) train_loss=82.85826111 time/batch=0.22s
3506/5900 (epoch 59.424) train_loss=201.08523560 time/batch=0.30s
3507/5900 (epoch 59.441) train_loss=383.87713623 time/batch=0.65s
3508/5900 (epoch 59.458) train_loss=157.15811157 time/batch=0.33s
3509/5900 (epoch 59.475) train_loss=75.23435974 time/batch=0.19s
3510/5900 (epoch 59.492) train_loss=174.27743530 time/batch=0.29s
3511/5900 (epoch 59.508) train_loss=82.78316498 time/batch=0.20s
3512/5900 (epoch 59.525) train_loss=242.55392456 time/batch=0.39s
3513/5900 (epoch 59.542) train_loss=102.59733582 time/batch=0.24s
3514/5900 (epoch 59.559) train_loss=141.22056580 time/batch=0.27s
3515/5900 (epoch 59.576) train_loss=102.04568481 time/batch=0.22s
3516/5900 (epoch 59.593) train_loss=191.91783142 time/batch=0.31s
3517/5900 (epoch 59.610) train_loss=232.80120850 time/batch=0.35s
3518/5900 (epoch 59.627) train_loss=138.28587341 time/batch=0.29s
3519/5900 (epoch 59.644) train_loss=236.81825256 time/batch=0.34s
3520/5900 (epoch 59.661) train_loss=240.24713135 time/batch=0.43s
3521/5900 (epoch 59.678) train_loss=230.43704224 time/batch=0.37s
3522/5900 (epoch 59.695) train_loss=74.54426575 time/batch=0.20s
3523/5900 (epoch 59.712) train_loss=179.09687805 time/batch=0.28s
3524/5900 (epoch 59.729) train_loss=200.47338867 time/batch=0.33s
3525/5900 (epoch 59.746) train_loss=179.83795166 time/batch=0.30s
3526/5900 (epoch 59.763) train_loss=82.82796478 time/batch=0.20s
3527/5900 (epoch 59.780) train_loss=143.38105774 time/batch=0.27s
3528/5900 (epoch 59.797) train_loss=88.67892456 time/batch=0.20s
3529/5900 (epoch 59.814) train_loss=80.03887939 time/batch=0.19s
3530/5900 (epoch 59.831) train_loss=87.09059143 time/batch=0.18s
3531/5900 (epoch 59.847) train_loss=93.56053162 time/batch=0.18s
3532/5900 (epoch 59.864) train_loss=78.40333557 time/batch=0.19s
3533/5900 (epoch 59.881) train_loss=181.11923218 time/batch=0.31s
3534/5900 (epoch 59.898) train_loss=75.08401489 time/batch=0.20s
3535/5900 (epoch 59.915) train_loss=86.52899933 time/batch=0.18s
3536/5900 (epoch 59.932) train_loss=81.24173737 time/batch=0.18s
3537/5900 (epoch 59.949) train_loss=85.99037170 time/batch=0.19s
3538/5900 (epoch 59.966) train_loss=88.45144653 time/batch=0.18s
3539/5900 (epoch 59.983) train_loss=85.10089111 time/batch=0.19s
3540/5900 (epoch 60.000) train_loss=82.02575684 time/batch=0.19s
setting learning rate to 0.0009146
  saved to metadata/config5--20190119-190634.pkl
3541/5900 (epoch 60.017) train_loss=111.18142700 time/batch=7.22s
3542/5900 (epoch 60.034) train_loss=203.33380127 time/batch=0.33s
3543/5900 (epoch 60.051) train_loss=139.28936768 time/batch=0.27s
3544/5900 (epoch 60.068) train_loss=229.42254639 time/batch=0.36s
3545/5900 (epoch 60.085) train_loss=363.90478516 time/batch=0.50s
3546/5900 (epoch 60.102) train_loss=223.83792114 time/batch=0.37s
3547/5900 (epoch 60.119) train_loss=123.26341248 time/batch=0.24s
3548/5900 (epoch 60.136) train_loss=419.91766357 time/batch=0.63s
3549/5900 (epoch 60.153) train_loss=70.20843506 time/batch=0.25s
3550/5900 (epoch 60.169) train_loss=85.24139404 time/batch=0.17s
3551/5900 (epoch 60.186) train_loss=183.34976196 time/batch=0.31s
3552/5900 (epoch 60.203) train_loss=209.29852295 time/batch=1.77s
3553/5900 (epoch 60.220) train_loss=220.17504883 time/batch=0.63s
3554/5900 (epoch 60.237) train_loss=188.72764587 time/batch=0.33s
3555/5900 (epoch 60.254) train_loss=241.27125549 time/batch=0.41s
3556/5900 (epoch 60.271) train_loss=307.32470703 time/batch=0.48s
3557/5900 (epoch 60.288) train_loss=96.18254089 time/batch=0.24s
3558/5900 (epoch 60.305) train_loss=245.24366760 time/batch=0.39s
3559/5900 (epoch 60.322) train_loss=242.02694702 time/batch=0.40s
3560/5900 (epoch 60.339) train_loss=169.42582703 time/batch=0.30s
3561/5900 (epoch 60.356) train_loss=78.55082703 time/batch=0.20s
3562/5900 (epoch 60.373) train_loss=133.20487976 time/batch=0.24s
3563/5900 (epoch 60.390) train_loss=239.66488647 time/batch=0.38s
3564/5900 (epoch 60.407) train_loss=325.09356689 time/batch=0.52s
3565/5900 (epoch 60.424) train_loss=273.15130615 time/batch=0.45s
3566/5900 (epoch 60.441) train_loss=71.62855530 time/batch=0.22s
3567/5900 (epoch 60.458) train_loss=134.70115662 time/batch=0.23s
3568/5900 (epoch 60.475) train_loss=1080.83007812 time/batch=2.66s
3569/5900 (epoch 60.492) train_loss=206.10031128 time/batch=0.73s
3570/5900 (epoch 60.508) train_loss=308.82351685 time/batch=0.63s
3571/5900 (epoch 60.525) train_loss=90.44123077 time/batch=0.26s
3572/5900 (epoch 60.542) train_loss=178.97515869 time/batch=0.28s
3573/5900 (epoch 60.559) train_loss=226.29731750 time/batch=0.35s
3574/5900 (epoch 60.576) train_loss=214.77166748 time/batch=0.36s
3575/5900 (epoch 60.593) train_loss=170.00823975 time/batch=0.28s
3576/5900 (epoch 60.610) train_loss=164.17893982 time/batch=0.30s
3577/5900 (epoch 60.627) train_loss=198.60708618 time/batch=0.32s
3578/5900 (epoch 60.644) train_loss=147.00260925 time/batch=0.28s
3579/5900 (epoch 60.661) train_loss=83.33413696 time/batch=0.19s
3580/5900 (epoch 60.678) train_loss=86.21936035 time/batch=0.18s
3581/5900 (epoch 60.695) train_loss=74.29296875 time/batch=0.19s
3582/5900 (epoch 60.712) train_loss=160.93734741 time/batch=0.27s
3583/5900 (epoch 60.729) train_loss=116.23179626 time/batch=0.27s
3584/5900 (epoch 60.746) train_loss=186.64091492 time/batch=0.31s
3585/5900 (epoch 60.763) train_loss=86.11235046 time/batch=0.20s
3586/5900 (epoch 60.780) train_loss=215.43228149 time/batch=0.35s
3587/5900 (epoch 60.797) train_loss=161.33767700 time/batch=0.29s
3588/5900 (epoch 60.814) train_loss=83.37054443 time/batch=0.19s
3589/5900 (epoch 60.831) train_loss=86.62030029 time/batch=0.18s
3590/5900 (epoch 60.847) train_loss=81.45952606 time/batch=0.18s
3591/5900 (epoch 60.864) train_loss=121.42081451 time/batch=0.31s
3592/5900 (epoch 60.881) train_loss=81.07888794 time/batch=0.20s
3593/5900 (epoch 60.898) train_loss=77.27024078 time/batch=0.18s
3594/5900 (epoch 60.915) train_loss=81.11821747 time/batch=0.18s
3595/5900 (epoch 60.932) train_loss=83.39077759 time/batch=0.18s
3596/5900 (epoch 60.949) train_loss=79.14848328 time/batch=0.18s
3597/5900 (epoch 60.966) train_loss=80.68290710 time/batch=0.18s
3598/5900 (epoch 60.983) train_loss=79.80681610 time/batch=0.18s
3599/5900 (epoch 61.000) train_loss=79.10284424 time/batch=0.19s
setting learning rate to 0.0008871
3600/5900 (epoch 61.017) train_loss=298.74774170 time/batch=0.47s
3601/5900 (epoch 61.034) train_loss=435.58825684 time/batch=0.72s
3602/5900 (epoch 61.051) train_loss=256.51831055 time/batch=0.47s
3603/5900 (epoch 61.068) train_loss=191.51156616 time/batch=0.33s
3604/5900 (epoch 61.085) train_loss=122.84856415 time/batch=0.24s
3605/5900 (epoch 61.102) train_loss=275.36154175 time/batch=0.42s
3606/5900 (epoch 61.119) train_loss=958.01599121 time/batch=2.68s
3607/5900 (epoch 61.136) train_loss=79.47051239 time/batch=0.63s
3608/5900 (epoch 61.153) train_loss=262.16577148 time/batch=0.41s
3609/5900 (epoch 61.169) train_loss=142.89245605 time/batch=0.30s
3610/5900 (epoch 61.186) train_loss=180.56599426 time/batch=0.31s
3611/5900 (epoch 61.203) train_loss=195.85675049 time/batch=0.34s
3612/5900 (epoch 61.220) train_loss=152.84988403 time/batch=0.27s
3613/5900 (epoch 61.237) train_loss=348.95031738 time/batch=0.52s
3614/5900 (epoch 61.254) train_loss=133.54959106 time/batch=0.30s
3615/5900 (epoch 61.271) train_loss=233.69592285 time/batch=0.39s
3616/5900 (epoch 61.288) train_loss=76.73365021 time/batch=0.21s
3617/5900 (epoch 61.305) train_loss=182.87145996 time/batch=0.31s
3618/5900 (epoch 61.322) train_loss=214.37039185 time/batch=1.78s
3619/5900 (epoch 61.339) train_loss=112.42266846 time/batch=0.48s
3620/5900 (epoch 61.356) train_loss=283.41238403 time/batch=0.42s
3621/5900 (epoch 61.373) train_loss=210.42764282 time/batch=0.36s
3622/5900 (epoch 61.390) train_loss=167.26068115 time/batch=0.31s
3623/5900 (epoch 61.407) train_loss=216.46488953 time/batch=0.34s
3624/5900 (epoch 61.424) train_loss=237.13685608 time/batch=0.37s
3625/5900 (epoch 61.441) train_loss=176.33541870 time/batch=0.31s
3626/5900 (epoch 61.458) train_loss=225.21859741 time/batch=0.36s
3627/5900 (epoch 61.475) train_loss=145.56112671 time/batch=0.28s
3628/5900 (epoch 61.492) train_loss=157.77413940 time/batch=0.28s
3629/5900 (epoch 61.508) train_loss=214.24432373 time/batch=0.34s
3630/5900 (epoch 61.525) train_loss=162.37936401 time/batch=0.31s
3631/5900 (epoch 61.542) train_loss=186.88040161 time/batch=0.31s
3632/5900 (epoch 61.559) train_loss=176.71969604 time/batch=0.30s
3633/5900 (epoch 61.576) train_loss=103.36131287 time/batch=0.23s
3634/5900 (epoch 61.593) train_loss=204.94766235 time/batch=0.33s
3635/5900 (epoch 61.610) train_loss=138.24565125 time/batch=0.28s
3636/5900 (epoch 61.627) train_loss=146.96655273 time/batch=0.27s
3637/5900 (epoch 61.644) train_loss=87.39064789 time/batch=0.21s
3638/5900 (epoch 61.661) train_loss=258.14605713 time/batch=0.38s
3639/5900 (epoch 61.678) train_loss=75.63430023 time/batch=0.22s
3640/5900 (epoch 61.695) train_loss=226.71362305 time/batch=0.33s
3641/5900 (epoch 61.712) train_loss=128.76890564 time/batch=0.31s
3642/5900 (epoch 61.729) train_loss=91.23900604 time/batch=0.21s
3643/5900 (epoch 61.746) train_loss=91.47141266 time/batch=0.20s
3644/5900 (epoch 61.763) train_loss=81.82316589 time/batch=0.17s
3645/5900 (epoch 61.780) train_loss=72.19532776 time/batch=0.19s
3646/5900 (epoch 61.797) train_loss=76.94258881 time/batch=0.17s
3647/5900 (epoch 61.814) train_loss=83.93079376 time/batch=0.19s
3648/5900 (epoch 61.831) train_loss=75.35759735 time/batch=0.17s
3649/5900 (epoch 61.847) train_loss=84.33177185 time/batch=0.19s
3650/5900 (epoch 61.864) train_loss=83.68359375 time/batch=0.19s
3651/5900 (epoch 61.881) train_loss=76.45397949 time/batch=0.19s
3652/5900 (epoch 61.898) train_loss=84.23194122 time/batch=0.17s
3653/5900 (epoch 61.915) train_loss=77.31095123 time/batch=0.19s
3654/5900 (epoch 61.932) train_loss=79.24127960 time/batch=0.17s
3655/5900 (epoch 61.949) train_loss=81.52053833 time/batch=0.19s
3656/5900 (epoch 61.966) train_loss=81.82669067 time/batch=0.17s
3657/5900 (epoch 61.983) train_loss=86.29075623 time/batch=0.19s
3658/5900 (epoch 62.000) train_loss=88.72624207 time/batch=0.19s
setting learning rate to 0.0008605
3659/5900 (epoch 62.017) train_loss=72.02444458 time/batch=0.17s
3660/5900 (epoch 62.034) train_loss=69.19157410 time/batch=0.17s
3661/5900 (epoch 62.051) train_loss=98.67092896 time/batch=0.20s
3662/5900 (epoch 62.068) train_loss=241.50926208 time/batch=0.38s
3663/5900 (epoch 62.085) train_loss=128.12582397 time/batch=0.26s
3664/5900 (epoch 62.102) train_loss=240.28976440 time/batch=0.39s
3665/5900 (epoch 62.119) train_loss=179.03210449 time/batch=0.34s
3666/5900 (epoch 62.136) train_loss=307.82019043 time/batch=0.48s
3667/5900 (epoch 62.153) train_loss=83.95598602 time/batch=0.22s
3668/5900 (epoch 62.169) train_loss=184.59576416 time/batch=0.29s
3669/5900 (epoch 62.186) train_loss=412.52633667 time/batch=0.59s
3670/5900 (epoch 62.203) train_loss=749.80578613 time/batch=2.10s
3671/5900 (epoch 62.220) train_loss=181.25875854 time/batch=0.61s
3672/5900 (epoch 62.237) train_loss=787.13311768 time/batch=2.64s
3673/5900 (epoch 62.254) train_loss=247.05261230 time/batch=0.81s
3674/5900 (epoch 62.271) train_loss=191.49063110 time/batch=0.33s
3675/5900 (epoch 62.288) train_loss=283.14685059 time/batch=0.48s
3676/5900 (epoch 62.305) train_loss=97.45677185 time/batch=0.24s
3677/5900 (epoch 62.322) train_loss=138.24020386 time/batch=1.78s
3678/5900 (epoch 62.339) train_loss=83.60006714 time/batch=0.46s
3679/5900 (epoch 62.356) train_loss=220.58195496 time/batch=0.36s
3680/5900 (epoch 62.373) train_loss=174.66647339 time/batch=0.33s
3681/5900 (epoch 62.390) train_loss=211.53497314 time/batch=0.34s
3682/5900 (epoch 62.407) train_loss=139.00041199 time/batch=0.28s
3683/5900 (epoch 62.424) train_loss=215.30194092 time/batch=0.34s
3684/5900 (epoch 62.441) train_loss=141.35559082 time/batch=0.28s
3685/5900 (epoch 62.458) train_loss=186.84686279 time/batch=0.31s
3686/5900 (epoch 62.475) train_loss=167.25228882 time/batch=0.31s
3687/5900 (epoch 62.492) train_loss=150.40290833 time/batch=0.27s
3688/5900 (epoch 62.508) train_loss=261.26168823 time/batch=0.42s
3689/5900 (epoch 62.525) train_loss=165.91110229 time/batch=0.31s
3690/5900 (epoch 62.542) train_loss=214.48251343 time/batch=0.36s
3691/5900 (epoch 62.559) train_loss=201.50302124 time/batch=0.33s
3692/5900 (epoch 62.576) train_loss=173.65478516 time/batch=0.33s
3693/5900 (epoch 62.593) train_loss=158.37271118 time/batch=0.27s
3694/5900 (epoch 62.610) train_loss=215.03073120 time/batch=0.36s
3695/5900 (epoch 62.627) train_loss=248.15907288 time/batch=0.44s
3696/5900 (epoch 62.644) train_loss=232.18641663 time/batch=0.39s
3697/5900 (epoch 62.661) train_loss=162.53076172 time/batch=0.31s
3698/5900 (epoch 62.678) train_loss=84.25271606 time/batch=0.19s
3699/5900 (epoch 62.695) train_loss=121.99434662 time/batch=0.23s
3700/5900 (epoch 62.712) train_loss=162.57409668 time/batch=0.34s
3701/5900 (epoch 62.729) train_loss=108.16851807 time/batch=0.26s
3702/5900 (epoch 62.746) train_loss=121.92669678 time/batch=0.25s
3703/5900 (epoch 62.763) train_loss=78.48397827 time/batch=0.19s
3704/5900 (epoch 62.780) train_loss=149.65841675 time/batch=1.72s
3705/5900 (epoch 62.797) train_loss=75.63160706 time/batch=0.45s
3706/5900 (epoch 62.814) train_loss=77.80104065 time/batch=0.17s
3707/5900 (epoch 62.831) train_loss=76.72653961 time/batch=0.17s
3708/5900 (epoch 62.847) train_loss=80.63607788 time/batch=0.19s
3709/5900 (epoch 62.864) train_loss=84.44444275 time/batch=0.19s
3710/5900 (epoch 62.881) train_loss=80.97680664 time/batch=0.19s
3711/5900 (epoch 62.898) train_loss=80.77027893 time/batch=0.17s
3712/5900 (epoch 62.915) train_loss=86.81021118 time/batch=0.19s
3713/5900 (epoch 62.932) train_loss=80.63140869 time/batch=0.18s
3714/5900 (epoch 62.949) train_loss=77.41770935 time/batch=0.19s
3715/5900 (epoch 62.966) train_loss=79.69249725 time/batch=0.19s
3716/5900 (epoch 62.983) train_loss=85.11714935 time/batch=0.19s
3717/5900 (epoch 63.000) train_loss=90.22048187 time/batch=0.19s
setting learning rate to 0.0008347
3718/5900 (epoch 63.017) train_loss=163.25047302 time/batch=0.28s
3719/5900 (epoch 63.034) train_loss=234.22607422 time/batch=0.38s
3720/5900 (epoch 63.051) train_loss=204.30718994 time/batch=0.34s
3721/5900 (epoch 63.068) train_loss=160.97433472 time/batch=0.30s
3722/5900 (epoch 63.085) train_loss=219.54937744 time/batch=0.36s
3723/5900 (epoch 63.102) train_loss=955.27160645 time/batch=2.66s
3724/5900 (epoch 63.119) train_loss=256.44006348 time/batch=0.81s
3725/5900 (epoch 63.136) train_loss=192.07911682 time/batch=0.34s
3726/5900 (epoch 63.153) train_loss=128.47546387 time/batch=0.25s
3727/5900 (epoch 63.169) train_loss=142.16265869 time/batch=0.27s
3728/5900 (epoch 63.186) train_loss=237.35411072 time/batch=0.39s
3729/5900 (epoch 63.203) train_loss=426.22073364 time/batch=0.65s
3730/5900 (epoch 63.220) train_loss=142.23963928 time/batch=1.84s
3731/5900 (epoch 63.237) train_loss=253.07412720 time/batch=0.69s
3732/5900 (epoch 63.254) train_loss=96.32865143 time/batch=0.23s
3733/5900 (epoch 63.271) train_loss=134.22030640 time/batch=0.25s
3734/5900 (epoch 63.288) train_loss=274.95123291 time/batch=0.42s
3735/5900 (epoch 63.305) train_loss=72.96173859 time/batch=0.22s
3736/5900 (epoch 63.322) train_loss=108.74154663 time/batch=0.20s
3737/5900 (epoch 63.339) train_loss=302.53610229 time/batch=0.45s
3738/5900 (epoch 63.356) train_loss=256.88006592 time/batch=0.44s
3739/5900 (epoch 63.373) train_loss=115.69325256 time/batch=0.25s
3740/5900 (epoch 63.390) train_loss=160.66230774 time/batch=0.27s
3741/5900 (epoch 63.407) train_loss=162.12448120 time/batch=0.28s
3742/5900 (epoch 63.424) train_loss=136.05087280 time/batch=0.27s
3743/5900 (epoch 63.441) train_loss=341.46182251 time/batch=0.51s
3744/5900 (epoch 63.458) train_loss=77.25924683 time/batch=0.23s
3745/5900 (epoch 63.475) train_loss=157.78660583 time/batch=0.28s
3746/5900 (epoch 63.492) train_loss=180.31442261 time/batch=0.30s
3747/5900 (epoch 63.508) train_loss=155.59669495 time/batch=0.30s
3748/5900 (epoch 63.525) train_loss=197.20953369 time/batch=0.33s
3749/5900 (epoch 63.542) train_loss=194.15670776 time/batch=0.34s
3750/5900 (epoch 63.559) train_loss=92.88861847 time/batch=0.22s
3751/5900 (epoch 63.576) train_loss=255.14117432 time/batch=0.45s
3752/5900 (epoch 63.593) train_loss=80.66874695 time/batch=0.23s
3753/5900 (epoch 63.610) train_loss=78.44834137 time/batch=0.17s
3754/5900 (epoch 63.627) train_loss=113.04850769 time/batch=0.23s
3755/5900 (epoch 63.644) train_loss=219.48612976 time/batch=0.34s
3756/5900 (epoch 63.661) train_loss=223.81932068 time/batch=0.35s
3757/5900 (epoch 63.678) train_loss=187.06826782 time/batch=0.32s
3758/5900 (epoch 63.695) train_loss=91.57034302 time/batch=0.26s
3759/5900 (epoch 63.712) train_loss=76.19305420 time/batch=0.19s
3760/5900 (epoch 63.729) train_loss=217.36950684 time/batch=0.33s
3761/5900 (epoch 63.746) train_loss=164.80361938 time/batch=0.33s
3762/5900 (epoch 63.763) train_loss=144.41760254 time/batch=1.74s
3763/5900 (epoch 63.780) train_loss=201.15075684 time/batch=0.61s
3764/5900 (epoch 63.797) train_loss=75.24684906 time/batch=0.22s
3765/5900 (epoch 63.814) train_loss=112.84954834 time/batch=0.28s
3766/5900 (epoch 63.831) train_loss=72.95578003 time/batch=0.20s
3767/5900 (epoch 63.847) train_loss=80.97372437 time/batch=0.19s
3768/5900 (epoch 63.864) train_loss=79.81809235 time/batch=0.19s
3769/5900 (epoch 63.881) train_loss=84.87876892 time/batch=0.19s
3770/5900 (epoch 63.898) train_loss=77.38194275 time/batch=0.18s
3771/5900 (epoch 63.915) train_loss=82.92753601 time/batch=0.19s
3772/5900 (epoch 63.932) train_loss=86.77969360 time/batch=0.17s
3773/5900 (epoch 63.949) train_loss=79.97982025 time/batch=0.19s
3774/5900 (epoch 63.966) train_loss=75.63465881 time/batch=0.19s
3775/5900 (epoch 63.983) train_loss=82.52092743 time/batch=0.19s
3776/5900 (epoch 64.000) train_loss=79.42993164 time/batch=0.17s
setting learning rate to 0.0008097
3777/5900 (epoch 64.017) train_loss=109.71513367 time/batch=0.20s
3778/5900 (epoch 64.034) train_loss=952.03405762 time/batch=2.65s
3779/5900 (epoch 64.051) train_loss=200.11730957 time/batch=0.73s
3780/5900 (epoch 64.068) train_loss=232.76312256 time/batch=0.39s
3781/5900 (epoch 64.085) train_loss=318.20709229 time/batch=0.47s
3782/5900 (epoch 64.102) train_loss=340.88388062 time/batch=0.54s
3783/5900 (epoch 64.119) train_loss=212.24990845 time/batch=0.38s
3784/5900 (epoch 64.136) train_loss=415.98535156 time/batch=0.64s
3785/5900 (epoch 64.153) train_loss=154.61883545 time/batch=0.34s
3786/5900 (epoch 64.169) train_loss=207.77682495 time/batch=0.35s
3787/5900 (epoch 64.186) train_loss=218.12976074 time/batch=0.37s
3788/5900 (epoch 64.203) train_loss=208.94294739 time/batch=0.38s
3789/5900 (epoch 64.220) train_loss=227.89581299 time/batch=0.39s
3790/5900 (epoch 64.237) train_loss=145.23956299 time/batch=1.78s
3791/5900 (epoch 64.254) train_loss=126.73910522 time/batch=0.50s
3792/5900 (epoch 64.271) train_loss=287.62890625 time/batch=0.47s
3793/5900 (epoch 64.288) train_loss=165.05543518 time/batch=0.33s
3794/5900 (epoch 64.305) train_loss=166.20034790 time/batch=0.30s
3795/5900 (epoch 64.322) train_loss=82.77587891 time/batch=0.20s
3796/5900 (epoch 64.339) train_loss=94.03743744 time/batch=0.19s
3797/5900 (epoch 64.356) train_loss=192.84201050 time/batch=0.33s
3798/5900 (epoch 64.373) train_loss=127.26971436 time/batch=0.27s
3799/5900 (epoch 64.390) train_loss=161.41546631 time/batch=0.30s
3800/5900 (epoch 64.407) train_loss=98.64161682 time/batch=0.22s
3801/5900 (epoch 64.424) train_loss=73.27497101 time/batch=0.19s
3802/5900 (epoch 64.441) train_loss=259.27526855 time/batch=0.41s
3803/5900 (epoch 64.458) train_loss=255.78540039 time/batch=0.53s
3804/5900 (epoch 64.475) train_loss=250.96804810 time/batch=0.44s
3805/5900 (epoch 64.492) train_loss=187.88504028 time/batch=0.34s
3806/5900 (epoch 64.508) train_loss=212.23802185 time/batch=0.34s
3807/5900 (epoch 64.525) train_loss=139.70213318 time/batch=1.75s
3808/5900 (epoch 64.542) train_loss=218.14160156 time/batch=0.63s
3809/5900 (epoch 64.559) train_loss=154.06005859 time/batch=0.30s
3810/5900 (epoch 64.576) train_loss=85.24275208 time/batch=0.20s
3811/5900 (epoch 64.593) train_loss=126.21873474 time/batch=0.24s
3812/5900 (epoch 64.610) train_loss=157.13693237 time/batch=0.28s
3813/5900 (epoch 64.627) train_loss=190.50852966 time/batch=0.33s
3814/5900 (epoch 64.644) train_loss=148.74943542 time/batch=0.28s
3815/5900 (epoch 64.661) train_loss=142.02088928 time/batch=0.27s
3816/5900 (epoch 64.678) train_loss=187.62791443 time/batch=0.31s
3817/5900 (epoch 64.695) train_loss=148.39936829 time/batch=0.31s
3818/5900 (epoch 64.712) train_loss=79.36189270 time/batch=0.19s
3819/5900 (epoch 64.729) train_loss=75.56161499 time/batch=0.19s
3820/5900 (epoch 64.746) train_loss=78.41648865 time/batch=0.17s
3821/5900 (epoch 64.763) train_loss=73.37521362 time/batch=0.17s
3822/5900 (epoch 64.780) train_loss=78.92989349 time/batch=0.19s
3823/5900 (epoch 64.797) train_loss=190.29942322 time/batch=0.31s
3824/5900 (epoch 64.814) train_loss=81.32235718 time/batch=0.20s
3825/5900 (epoch 64.831) train_loss=114.44519043 time/batch=0.28s
3826/5900 (epoch 64.847) train_loss=77.75365448 time/batch=0.20s
3827/5900 (epoch 64.864) train_loss=83.73468018 time/batch=0.19s
3828/5900 (epoch 64.881) train_loss=88.78747559 time/batch=0.19s
3829/5900 (epoch 64.898) train_loss=77.39285278 time/batch=0.17s
3830/5900 (epoch 64.915) train_loss=78.74880219 time/batch=0.19s
3831/5900 (epoch 64.932) train_loss=84.55674744 time/batch=0.19s
3832/5900 (epoch 64.949) train_loss=82.10324860 time/batch=0.19s
3833/5900 (epoch 64.966) train_loss=80.32533264 time/batch=0.17s
3834/5900 (epoch 64.983) train_loss=73.07598114 time/batch=0.19s
3835/5900 (epoch 65.000) train_loss=81.36616516 time/batch=0.19s
setting learning rate to 0.0007854
3836/5900 (epoch 65.017) train_loss=388.62298584 time/batch=0.61s
3837/5900 (epoch 65.034) train_loss=249.32394409 time/batch=0.45s
3838/5900 (epoch 65.051) train_loss=971.37646484 time/batch=2.67s
3839/5900 (epoch 65.068) train_loss=285.80926514 time/batch=0.84s
3840/5900 (epoch 65.085) train_loss=365.76605225 time/batch=0.53s
3841/5900 (epoch 65.102) train_loss=206.11901855 time/batch=0.38s
3842/5900 (epoch 65.119) train_loss=147.07812500 time/batch=0.28s
3843/5900 (epoch 65.136) train_loss=95.77021790 time/batch=0.22s
3844/5900 (epoch 65.153) train_loss=119.67575073 time/batch=0.22s
3845/5900 (epoch 65.169) train_loss=189.46302795 time/batch=0.33s
3846/5900 (epoch 65.186) train_loss=207.23991394 time/batch=0.36s
3847/5900 (epoch 65.203) train_loss=147.62887573 time/batch=1.78s
3848/5900 (epoch 65.220) train_loss=169.86128235 time/batch=0.58s
3849/5900 (epoch 65.237) train_loss=122.11537170 time/batch=0.27s
3850/5900 (epoch 65.254) train_loss=257.39819336 time/batch=0.42s
3851/5900 (epoch 65.271) train_loss=117.92552185 time/batch=0.27s
3852/5900 (epoch 65.288) train_loss=168.42880249 time/batch=0.31s
3853/5900 (epoch 65.305) train_loss=130.33938599 time/batch=0.27s
3854/5900 (epoch 65.322) train_loss=180.54231262 time/batch=0.33s
3855/5900 (epoch 65.339) train_loss=71.09843445 time/batch=0.19s
3856/5900 (epoch 65.356) train_loss=286.59915161 time/batch=0.45s
3857/5900 (epoch 65.373) train_loss=218.54373169 time/batch=0.38s
3858/5900 (epoch 65.390) train_loss=83.03295898 time/batch=0.22s
3859/5900 (epoch 65.407) train_loss=175.21301270 time/batch=0.28s
3860/5900 (epoch 65.424) train_loss=200.14770508 time/batch=0.34s
3861/5900 (epoch 65.441) train_loss=176.62847900 time/batch=0.33s
3862/5900 (epoch 65.458) train_loss=201.58132935 time/batch=0.36s
3863/5900 (epoch 65.475) train_loss=81.10810852 time/batch=0.20s
3864/5900 (epoch 65.492) train_loss=73.47563171 time/batch=0.19s
3865/5900 (epoch 65.508) train_loss=73.43969727 time/batch=0.17s
3866/5900 (epoch 65.525) train_loss=238.53259277 time/batch=0.36s
3867/5900 (epoch 65.542) train_loss=308.17022705 time/batch=0.48s
3868/5900 (epoch 65.559) train_loss=156.25749207 time/batch=0.30s
3869/5900 (epoch 65.576) train_loss=72.07397461 time/batch=0.19s
3870/5900 (epoch 65.593) train_loss=233.18981934 time/batch=0.36s
3871/5900 (epoch 65.610) train_loss=87.44322205 time/batch=0.23s
3872/5900 (epoch 65.627) train_loss=161.86486816 time/batch=0.25s
3873/5900 (epoch 65.644) train_loss=127.07640839 time/batch=0.25s
3874/5900 (epoch 65.661) train_loss=80.46739197 time/batch=0.19s
3875/5900 (epoch 65.678) train_loss=126.72042084 time/batch=0.27s
3876/5900 (epoch 65.695) train_loss=240.13262939 time/batch=0.40s
3877/5900 (epoch 65.712) train_loss=192.81689453 time/batch=0.38s
3878/5900 (epoch 65.729) train_loss=163.81774902 time/batch=0.29s
3879/5900 (epoch 65.746) train_loss=75.59687042 time/batch=0.20s
3880/5900 (epoch 65.763) train_loss=76.41610718 time/batch=0.19s
3881/5900 (epoch 65.780) train_loss=86.35197449 time/batch=0.17s
3882/5900 (epoch 65.797) train_loss=164.55929565 time/batch=0.28s
3883/5900 (epoch 65.814) train_loss=135.66964722 time/batch=1.73s
3884/5900 (epoch 65.831) train_loss=125.78509521 time/batch=0.54s
3885/5900 (epoch 65.847) train_loss=184.65039062 time/batch=0.29s
3886/5900 (epoch 65.864) train_loss=98.54595947 time/batch=0.30s
3887/5900 (epoch 65.881) train_loss=82.51526642 time/batch=0.20s
3888/5900 (epoch 65.898) train_loss=79.20795441 time/batch=0.19s
3889/5900 (epoch 65.915) train_loss=78.75952911 time/batch=0.17s
3890/5900 (epoch 65.932) train_loss=80.35089111 time/batch=0.19s
3891/5900 (epoch 65.949) train_loss=79.52145386 time/batch=0.19s
3892/5900 (epoch 65.966) train_loss=75.05038452 time/batch=0.17s
3893/5900 (epoch 65.983) train_loss=78.60850525 time/batch=0.19s
3894/5900 (epoch 66.000) train_loss=81.25875092 time/batch=0.17s
setting learning rate to 0.0007618
3895/5900 (epoch 66.017) train_loss=654.77117920 time/batch=2.05s
3896/5900 (epoch 66.034) train_loss=328.85754395 time/batch=0.76s
3897/5900 (epoch 66.051) train_loss=236.35813904 time/batch=0.44s
3898/5900 (epoch 66.068) train_loss=333.07849121 time/batch=0.52s
3899/5900 (epoch 66.085) train_loss=604.84362793 time/batch=2.69s
3900/5900 (epoch 66.102) train_loss=80.58606720 time/batch=0.64s
3901/5900 (epoch 66.119) train_loss=68.53590393 time/batch=0.17s
3902/5900 (epoch 66.136) train_loss=133.78683472 time/batch=0.25s
3903/5900 (epoch 66.153) train_loss=226.57864380 time/batch=0.41s
3904/5900 (epoch 66.169) train_loss=203.13354492 time/batch=0.37s
3905/5900 (epoch 66.186) train_loss=70.24613953 time/batch=0.20s
3906/5900 (epoch 66.203) train_loss=109.56011963 time/batch=0.20s
3907/5900 (epoch 66.220) train_loss=225.46415710 time/batch=0.36s
3908/5900 (epoch 66.237) train_loss=175.59890747 time/batch=0.33s
3909/5900 (epoch 66.254) train_loss=142.25538635 time/batch=0.29s
3910/5900 (epoch 66.271) train_loss=351.63931274 time/batch=1.38s
3911/5900 (epoch 66.288) train_loss=149.36642456 time/batch=0.48s
3912/5900 (epoch 66.305) train_loss=252.69436646 time/batch=0.42s
3913/5900 (epoch 66.322) train_loss=166.37870789 time/batch=0.31s
3914/5900 (epoch 66.339) train_loss=194.92758179 time/batch=0.33s
3915/5900 (epoch 66.356) train_loss=195.21220398 time/batch=0.34s
3916/5900 (epoch 66.373) train_loss=234.13148499 time/batch=0.39s
3917/5900 (epoch 66.390) train_loss=224.86215210 time/batch=0.44s
3918/5900 (epoch 66.407) train_loss=121.09674835 time/batch=0.25s
3919/5900 (epoch 66.424) train_loss=119.84928894 time/batch=0.23s
3920/5900 (epoch 66.441) train_loss=190.78321838 time/batch=0.33s
3921/5900 (epoch 66.458) train_loss=154.03320312 time/batch=0.28s
3922/5900 (epoch 66.475) train_loss=79.12803650 time/batch=0.20s
3923/5900 (epoch 66.492) train_loss=207.72259521 time/batch=0.34s
3924/5900 (epoch 66.508) train_loss=78.27671814 time/batch=0.22s
3925/5900 (epoch 66.525) train_loss=134.69815063 time/batch=0.25s
3926/5900 (epoch 66.542) train_loss=169.37750244 time/batch=0.30s
3927/5900 (epoch 66.559) train_loss=180.03523254 time/batch=0.32s
3928/5900 (epoch 66.576) train_loss=172.52346802 time/batch=0.33s
3929/5900 (epoch 66.593) train_loss=100.60644531 time/batch=0.22s
3930/5900 (epoch 66.610) train_loss=176.28109741 time/batch=0.28s
3931/5900 (epoch 66.627) train_loss=206.44934082 time/batch=1.78s
3932/5900 (epoch 66.644) train_loss=74.80989838 time/batch=0.46s
3933/5900 (epoch 66.661) train_loss=134.88500977 time/batch=0.25s
3934/5900 (epoch 66.678) train_loss=85.25858307 time/batch=0.19s
3935/5900 (epoch 66.695) train_loss=116.68627167 time/batch=0.25s
3936/5900 (epoch 66.712) train_loss=78.67141724 time/batch=0.19s
3937/5900 (epoch 66.729) train_loss=172.66532898 time/batch=0.29s
3938/5900 (epoch 66.746) train_loss=208.25384521 time/batch=0.35s
3939/5900 (epoch 66.763) train_loss=122.35939026 time/batch=0.28s
3940/5900 (epoch 66.780) train_loss=80.38745117 time/batch=0.19s
3941/5900 (epoch 66.797) train_loss=75.05215454 time/batch=0.18s
3942/5900 (epoch 66.814) train_loss=229.08657837 time/batch=0.34s
3943/5900 (epoch 66.831) train_loss=145.31915283 time/batch=0.36s
3944/5900 (epoch 66.847) train_loss=77.42823029 time/batch=0.20s
3945/5900 (epoch 66.864) train_loss=80.73454285 time/batch=0.17s
3946/5900 (epoch 66.881) train_loss=91.62068176 time/batch=0.19s
3947/5900 (epoch 66.898) train_loss=82.24967194 time/batch=0.19s
3948/5900 (epoch 66.915) train_loss=76.87797546 time/batch=0.19s
3949/5900 (epoch 66.932) train_loss=81.35757446 time/batch=0.17s
3950/5900 (epoch 66.949) train_loss=78.03581238 time/batch=0.19s
3951/5900 (epoch 66.966) train_loss=80.33926392 time/batch=0.19s
3952/5900 (epoch 66.983) train_loss=79.42810822 time/batch=0.17s
3953/5900 (epoch 67.000) train_loss=76.88380432 time/batch=0.19s
setting learning rate to 0.0007390
3954/5900 (epoch 67.017) train_loss=391.40054321 time/batch=0.69s
3955/5900 (epoch 67.034) train_loss=143.47441101 time/batch=0.35s
3956/5900 (epoch 67.051) train_loss=227.29010010 time/batch=0.37s
3957/5900 (epoch 67.068) train_loss=283.56417847 time/batch=0.45s
3958/5900 (epoch 67.085) train_loss=925.59429932 time/batch=2.69s
3959/5900 (epoch 67.102) train_loss=182.60246277 time/batch=0.74s
3960/5900 (epoch 67.119) train_loss=343.62945557 time/batch=0.52s
3961/5900 (epoch 67.136) train_loss=85.68186188 time/batch=0.24s
3962/5900 (epoch 67.153) train_loss=170.83149719 time/batch=0.30s
3963/5900 (epoch 67.169) train_loss=171.32829285 time/batch=0.33s
3964/5900 (epoch 67.186) train_loss=260.84130859 time/batch=0.47s
3965/5900 (epoch 67.203) train_loss=163.41459656 time/batch=0.34s
3966/5900 (epoch 67.220) train_loss=242.59701538 time/batch=0.41s
3967/5900 (epoch 67.237) train_loss=128.53195190 time/batch=0.27s
3968/5900 (epoch 67.254) train_loss=227.68847656 time/batch=0.39s
3969/5900 (epoch 67.271) train_loss=204.09246826 time/batch=0.36s
3970/5900 (epoch 67.288) train_loss=110.02053833 time/batch=0.22s
3971/5900 (epoch 67.305) train_loss=225.31033325 time/batch=0.38s
3972/5900 (epoch 67.322) train_loss=91.90966797 time/batch=0.22s
3973/5900 (epoch 67.339) train_loss=126.42108154 time/batch=0.25s
3974/5900 (epoch 67.356) train_loss=117.34500885 time/batch=0.23s
3975/5900 (epoch 67.373) train_loss=219.02821350 time/batch=0.41s
3976/5900 (epoch 67.390) train_loss=212.50579834 time/batch=0.38s
3977/5900 (epoch 67.407) train_loss=92.99290466 time/batch=0.23s
3978/5900 (epoch 67.424) train_loss=150.94633484 time/batch=0.27s
3979/5900 (epoch 67.441) train_loss=138.34045410 time/batch=0.28s
3980/5900 (epoch 67.458) train_loss=176.64929199 time/batch=0.31s
3981/5900 (epoch 67.475) train_loss=131.30212402 time/batch=0.28s
3982/5900 (epoch 67.492) train_loss=70.49252319 time/batch=0.19s
3983/5900 (epoch 67.508) train_loss=192.33447266 time/batch=0.31s
3984/5900 (epoch 67.525) train_loss=218.93969727 time/batch=0.41s
3985/5900 (epoch 67.542) train_loss=81.29695129 time/batch=0.23s
3986/5900 (epoch 67.559) train_loss=93.84358215 time/batch=0.25s
3987/5900 (epoch 67.576) train_loss=177.67948914 time/batch=0.31s
3988/5900 (epoch 67.593) train_loss=202.14468384 time/batch=1.78s
3989/5900 (epoch 67.610) train_loss=167.41618347 time/batch=0.60s
3990/5900 (epoch 67.627) train_loss=167.98553467 time/batch=0.33s
3991/5900 (epoch 67.644) train_loss=77.63187408 time/batch=0.20s
3992/5900 (epoch 67.661) train_loss=71.75386047 time/batch=0.17s
3993/5900 (epoch 67.678) train_loss=202.44512939 time/batch=0.34s
3994/5900 (epoch 67.695) train_loss=260.73623657 time/batch=0.48s
3995/5900 (epoch 67.712) train_loss=74.60827637 time/batch=0.23s
3996/5900 (epoch 67.729) train_loss=72.28291321 time/batch=0.17s
3997/5900 (epoch 67.746) train_loss=160.32281494 time/batch=0.28s
3998/5900 (epoch 67.763) train_loss=200.08776855 time/batch=0.34s
3999/5900 (epoch 67.780) train_loss=165.34124756 time/batch=0.35s
Validating
    loss:	257.130366

4000/5900 (epoch 67.797) train_loss=83.51837158 time/batch=0.62s
4001/5900 (epoch 67.814) train_loss=73.00197601 time/batch=0.17s
4002/5900 (epoch 67.831) train_loss=76.02928162 time/batch=0.17s
4003/5900 (epoch 67.847) train_loss=77.20053101 time/batch=0.19s
4004/5900 (epoch 67.864) train_loss=86.75053406 time/batch=0.19s
4005/5900 (epoch 67.881) train_loss=89.01734924 time/batch=0.25s
4006/5900 (epoch 67.898) train_loss=75.03468323 time/batch=0.20s
4007/5900 (epoch 67.915) train_loss=75.80201721 time/batch=0.17s
4008/5900 (epoch 67.932) train_loss=77.36015320 time/batch=0.19s
4009/5900 (epoch 67.949) train_loss=93.16439819 time/batch=0.25s
4010/5900 (epoch 67.966) train_loss=77.67047119 time/batch=0.19s
4011/5900 (epoch 67.983) train_loss=78.22263336 time/batch=0.19s
4012/5900 (epoch 68.000) train_loss=80.14746857 time/batch=0.19s
setting learning rate to 0.0007168
4013/5900 (epoch 68.017) train_loss=140.34216309 time/batch=0.27s
4014/5900 (epoch 68.034) train_loss=216.78149414 time/batch=0.40s
4015/5900 (epoch 68.051) train_loss=239.81634521 time/batch=0.41s
4016/5900 (epoch 68.068) train_loss=134.62013245 time/batch=0.27s
4017/5900 (epoch 68.085) train_loss=200.51687622 time/batch=0.36s
4018/5900 (epoch 68.102) train_loss=928.29211426 time/batch=2.69s
4019/5900 (epoch 68.119) train_loss=334.60168457 time/batch=0.89s
4020/5900 (epoch 68.136) train_loss=133.00337219 time/batch=0.30s
4021/5900 (epoch 68.153) train_loss=140.49285889 time/batch=0.27s
4022/5900 (epoch 68.169) train_loss=253.12245178 time/batch=0.42s
4023/5900 (epoch 68.186) train_loss=117.70993042 time/batch=0.28s
4024/5900 (epoch 68.203) train_loss=205.33035278 time/batch=0.36s
4025/5900 (epoch 68.220) train_loss=232.47224426 time/batch=0.42s
4026/5900 (epoch 68.237) train_loss=67.59537506 time/batch=0.22s
4027/5900 (epoch 68.254) train_loss=173.88381958 time/batch=0.30s
4028/5900 (epoch 68.271) train_loss=354.07882690 time/batch=0.56s
4029/5900 (epoch 68.288) train_loss=389.16415405 time/batch=0.67s
4030/5900 (epoch 68.305) train_loss=178.31097412 time/batch=0.37s
4031/5900 (epoch 68.322) train_loss=164.16864014 time/batch=0.31s
4032/5900 (epoch 68.339) train_loss=199.69403076 time/batch=1.78s
4033/5900 (epoch 68.356) train_loss=171.44134521 time/batch=0.59s
4034/5900 (epoch 68.373) train_loss=109.26463318 time/batch=0.22s
4035/5900 (epoch 68.390) train_loss=81.69828796 time/batch=0.20s
4036/5900 (epoch 68.407) train_loss=222.63330078 time/batch=0.39s
4037/5900 (epoch 68.424) train_loss=202.32531738 time/batch=0.36s
4038/5900 (epoch 68.441) train_loss=257.42001343 time/batch=0.48s
4039/5900 (epoch 68.458) train_loss=211.26341248 time/batch=0.39s
4040/5900 (epoch 68.475) train_loss=202.74905396 time/batch=0.35s
4041/5900 (epoch 68.492) train_loss=195.78604126 time/batch=0.36s
4042/5900 (epoch 68.508) train_loss=122.05139160 time/batch=0.27s
4043/5900 (epoch 68.525) train_loss=147.95408630 time/batch=0.27s
4044/5900 (epoch 68.542) train_loss=169.55534363 time/batch=0.31s
4045/5900 (epoch 68.559) train_loss=136.96957397 time/batch=0.28s
4046/5900 (epoch 68.576) train_loss=95.63109589 time/batch=0.20s
4047/5900 (epoch 68.593) train_loss=174.78051758 time/batch=0.31s
4048/5900 (epoch 68.610) train_loss=168.21655273 time/batch=0.31s
4049/5900 (epoch 68.627) train_loss=150.31491089 time/batch=0.30s
4050/5900 (epoch 68.644) train_loss=68.24911499 time/batch=0.19s
4051/5900 (epoch 68.661) train_loss=180.40399170 time/batch=0.33s
4052/5900 (epoch 68.678) train_loss=118.19609833 time/batch=0.30s
4053/5900 (epoch 68.695) train_loss=87.06050110 time/batch=0.20s
4054/5900 (epoch 68.712) train_loss=162.89678955 time/batch=0.28s
4055/5900 (epoch 68.729) train_loss=96.61757660 time/batch=0.28s
4056/5900 (epoch 68.746) train_loss=81.50804901 time/batch=0.20s
4057/5900 (epoch 68.763) train_loss=78.32994080 time/batch=0.19s
4058/5900 (epoch 68.780) train_loss=76.70063019 time/batch=0.19s
4059/5900 (epoch 68.797) train_loss=82.13611603 time/batch=0.18s
4060/5900 (epoch 68.814) train_loss=74.53788757 time/batch=0.17s
4061/5900 (epoch 68.831) train_loss=80.90385437 time/batch=0.19s
4062/5900 (epoch 68.847) train_loss=76.43392944 time/batch=0.19s
4063/5900 (epoch 68.864) train_loss=74.44081116 time/batch=0.17s
4064/5900 (epoch 68.881) train_loss=82.92198944 time/batch=0.19s
4065/5900 (epoch 68.898) train_loss=75.16886139 time/batch=0.19s
4066/5900 (epoch 68.915) train_loss=81.37803650 time/batch=0.17s
4067/5900 (epoch 68.932) train_loss=75.25975800 time/batch=0.19s
4068/5900 (epoch 68.949) train_loss=78.39151001 time/batch=0.19s
4069/5900 (epoch 68.966) train_loss=75.87146759 time/batch=0.17s
4070/5900 (epoch 68.983) train_loss=78.57282257 time/batch=0.19s
4071/5900 (epoch 69.000) train_loss=77.88919067 time/batch=0.19s
setting learning rate to 0.0006953
4072/5900 (epoch 69.017) train_loss=260.25567627 time/batch=0.44s
4073/5900 (epoch 69.034) train_loss=265.21917725 time/batch=0.42s
4074/5900 (epoch 69.051) train_loss=932.59082031 time/batch=2.68s
4075/5900 (epoch 69.068) train_loss=377.17547607 time/batch=0.98s
4076/5900 (epoch 69.085) train_loss=223.48129272 time/batch=0.42s
4077/5900 (epoch 69.102) train_loss=163.98875427 time/batch=0.34s
4078/5900 (epoch 69.119) train_loss=164.77720642 time/batch=0.33s
4079/5900 (epoch 69.136) train_loss=298.64337158 time/batch=0.56s
4080/5900 (epoch 69.153) train_loss=216.83895874 time/batch=0.45s
4081/5900 (epoch 69.169) train_loss=136.46176147 time/batch=0.31s
4082/5900 (epoch 69.186) train_loss=122.53968811 time/batch=0.25s
4083/5900 (epoch 69.203) train_loss=243.43153381 time/batch=0.55s
4084/5900 (epoch 69.220) train_loss=193.46656799 time/batch=1.83s
4085/5900 (epoch 69.237) train_loss=155.61105347 time/batch=0.57s
4086/5900 (epoch 69.254) train_loss=162.04751587 time/batch=0.30s
4087/5900 (epoch 69.271) train_loss=119.33608246 time/batch=0.25s
4088/5900 (epoch 69.288) train_loss=146.93092346 time/batch=0.28s
4089/5900 (epoch 69.305) train_loss=230.13246155 time/batch=0.41s
4090/5900 (epoch 69.322) train_loss=67.60414124 time/batch=0.22s
4091/5900 (epoch 69.339) train_loss=195.40350342 time/batch=0.33s
4092/5900 (epoch 69.356) train_loss=70.01793671 time/batch=0.19s
4093/5900 (epoch 69.373) train_loss=251.10913086 time/batch=0.58s
4094/5900 (epoch 69.390) train_loss=67.58798981 time/batch=0.25s
4095/5900 (epoch 69.407) train_loss=70.19841766 time/batch=0.17s
4096/5900 (epoch 69.424) train_loss=226.81994629 time/batch=0.58s
4097/5900 (epoch 69.441) train_loss=93.13595581 time/batch=0.26s
4098/5900 (epoch 69.458) train_loss=197.03369141 time/batch=0.33s
4099/5900 (epoch 69.475) train_loss=207.78793335 time/batch=0.37s
4100/5900 (epoch 69.492) train_loss=279.15948486 time/batch=0.64s
4101/5900 (epoch 69.508) train_loss=156.45858765 time/batch=0.33s
4102/5900 (epoch 69.525) train_loss=188.94042969 time/batch=0.34s
4103/5900 (epoch 69.542) train_loss=87.68133545 time/batch=0.21s
4104/5900 (epoch 69.559) train_loss=147.55952454 time/batch=0.27s
4105/5900 (epoch 69.576) train_loss=75.32477570 time/batch=0.20s
4106/5900 (epoch 69.593) train_loss=143.58964539 time/batch=0.28s
4107/5900 (epoch 69.610) train_loss=179.90042114 time/batch=0.32s
4108/5900 (epoch 69.627) train_loss=196.68778992 time/batch=0.36s
4109/5900 (epoch 69.644) train_loss=111.01304626 time/batch=0.22s
4110/5900 (epoch 69.661) train_loss=76.71524048 time/batch=0.19s
4111/5900 (epoch 69.678) train_loss=176.12872314 time/batch=0.30s
4112/5900 (epoch 69.695) train_loss=79.81723785 time/batch=0.20s
4113/5900 (epoch 69.712) train_loss=76.46008301 time/batch=0.19s
4114/5900 (epoch 69.729) train_loss=75.91796875 time/batch=0.17s
4115/5900 (epoch 69.746) train_loss=137.02038574 time/batch=0.25s
4116/5900 (epoch 69.763) train_loss=140.29075623 time/batch=0.27s
4117/5900 (epoch 69.780) train_loss=102.17726898 time/batch=0.23s
4118/5900 (epoch 69.797) train_loss=82.55204773 time/batch=0.19s
4119/5900 (epoch 69.814) train_loss=80.18147278 time/batch=0.19s
4120/5900 (epoch 69.831) train_loss=74.00630188 time/batch=0.19s
4121/5900 (epoch 69.847) train_loss=160.84008789 time/batch=0.28s
4122/5900 (epoch 69.864) train_loss=171.52885437 time/batch=0.31s
4123/5900 (epoch 69.881) train_loss=94.83081818 time/batch=0.25s
4124/5900 (epoch 69.898) train_loss=83.51326752 time/batch=0.19s
4125/5900 (epoch 69.915) train_loss=75.15626526 time/batch=0.19s
4126/5900 (epoch 69.932) train_loss=85.54138947 time/batch=0.19s
4127/5900 (epoch 69.949) train_loss=75.45645142 time/batch=0.17s
4128/5900 (epoch 69.966) train_loss=85.85427856 time/batch=0.19s
4129/5900 (epoch 69.983) train_loss=76.94276428 time/batch=0.19s
4130/5900 (epoch 70.000) train_loss=77.47355652 time/batch=0.17s
setting learning rate to 0.0006744
  saved to metadata/config5--20190119-190634.pkl
4131/5900 (epoch 70.017) train_loss=212.13386536 time/batch=7.62s
4132/5900 (epoch 70.034) train_loss=194.20803833 time/batch=0.34s
4133/5900 (epoch 70.051) train_loss=148.72735596 time/batch=1.78s
4134/5900 (epoch 70.068) train_loss=217.46780396 time/batch=0.65s
4135/5900 (epoch 70.085) train_loss=717.19403076 time/batch=2.06s
4136/5900 (epoch 70.102) train_loss=310.95742798 time/batch=0.78s
4137/5900 (epoch 70.119) train_loss=274.40045166 time/batch=0.47s
4138/5900 (epoch 70.136) train_loss=195.88674927 time/batch=0.36s
4139/5900 (epoch 70.153) train_loss=607.70422363 time/batch=2.66s
4140/5900 (epoch 70.169) train_loss=246.14933777 time/batch=0.92s
4141/5900 (epoch 70.186) train_loss=199.30133057 time/batch=0.38s
4142/5900 (epoch 70.203) train_loss=148.50305176 time/batch=0.31s
4143/5900 (epoch 70.220) train_loss=78.71791840 time/batch=0.20s
4144/5900 (epoch 70.237) train_loss=183.21270752 time/batch=0.33s
4145/5900 (epoch 70.254) train_loss=105.02386475 time/batch=0.23s
4146/5900 (epoch 70.271) train_loss=288.13452148 time/batch=0.50s
4147/5900 (epoch 70.288) train_loss=223.40010071 time/batch=0.43s
4148/5900 (epoch 70.305) train_loss=145.33329773 time/batch=0.30s
4149/5900 (epoch 70.322) train_loss=86.00682068 time/batch=0.20s
4150/5900 (epoch 70.339) train_loss=94.79222107 time/batch=0.20s
4151/5900 (epoch 70.356) train_loss=131.18887329 time/batch=0.25s
4152/5900 (epoch 70.373) train_loss=125.33389282 time/batch=0.27s
4153/5900 (epoch 70.390) train_loss=134.66792297 time/batch=0.27s
4154/5900 (epoch 70.407) train_loss=262.47442627 time/batch=0.51s
4155/5900 (epoch 70.424) train_loss=205.42442322 time/batch=0.40s
4156/5900 (epoch 70.441) train_loss=204.92840576 time/batch=0.36s
4157/5900 (epoch 70.458) train_loss=174.21726990 time/batch=0.33s
4158/5900 (epoch 70.475) train_loss=154.78540039 time/batch=0.30s
4159/5900 (epoch 70.492) train_loss=124.70635223 time/batch=0.27s
4160/5900 (epoch 70.508) train_loss=83.23274994 time/batch=0.20s
4161/5900 (epoch 70.525) train_loss=78.17581940 time/batch=0.19s
4162/5900 (epoch 70.542) train_loss=172.43765259 time/batch=0.31s
4163/5900 (epoch 70.559) train_loss=81.37715912 time/batch=0.20s
4164/5900 (epoch 70.576) train_loss=193.91323853 time/batch=0.35s
4165/5900 (epoch 70.593) train_loss=116.92984772 time/batch=1.75s
4166/5900 (epoch 70.610) train_loss=151.52772522 time/batch=0.55s
4167/5900 (epoch 70.627) train_loss=121.78105927 time/batch=0.24s
4168/5900 (epoch 70.644) train_loss=159.96543884 time/batch=0.30s
4169/5900 (epoch 70.661) train_loss=168.69116211 time/batch=0.31s
4170/5900 (epoch 70.678) train_loss=183.65597534 time/batch=0.34s
4171/5900 (epoch 70.695) train_loss=154.12289429 time/batch=0.30s
4172/5900 (epoch 70.712) train_loss=81.75989532 time/batch=0.20s
4173/5900 (epoch 70.729) train_loss=162.44194031 time/batch=0.28s
4174/5900 (epoch 70.746) train_loss=95.07595825 time/batch=0.22s
4175/5900 (epoch 70.763) train_loss=137.89787292 time/batch=0.30s
4176/5900 (epoch 70.780) train_loss=100.09802246 time/batch=0.33s
4177/5900 (epoch 70.797) train_loss=74.95948792 time/batch=0.20s
4178/5900 (epoch 70.814) train_loss=72.03027344 time/batch=0.17s
4179/5900 (epoch 70.831) train_loss=76.41284180 time/batch=0.19s
4180/5900 (epoch 70.847) train_loss=82.68924713 time/batch=0.17s
4181/5900 (epoch 70.864) train_loss=80.73397064 time/batch=0.19s
4182/5900 (epoch 70.881) train_loss=71.94813538 time/batch=0.17s
4183/5900 (epoch 70.898) train_loss=71.90184021 time/batch=0.19s
4184/5900 (epoch 70.915) train_loss=73.88639832 time/batch=0.17s
4185/5900 (epoch 70.932) train_loss=74.40995026 time/batch=0.19s
4186/5900 (epoch 70.949) train_loss=80.25889587 time/batch=0.17s
4187/5900 (epoch 70.966) train_loss=76.58598328 time/batch=0.18s
4188/5900 (epoch 70.983) train_loss=74.46684265 time/batch=0.19s
4189/5900 (epoch 71.000) train_loss=79.60104370 time/batch=0.17s
setting learning rate to 0.0006542
4190/5900 (epoch 71.017) train_loss=574.31451416 time/batch=2.03s
4191/5900 (epoch 71.034) train_loss=174.85644531 time/batch=0.61s
4192/5900 (epoch 71.051) train_loss=196.31852722 time/batch=0.34s
4193/5900 (epoch 71.068) train_loss=270.43640137 time/batch=0.39s
4194/5900 (epoch 71.085) train_loss=82.61941528 time/batch=0.22s
4195/5900 (epoch 71.102) train_loss=162.38275146 time/batch=0.25s
4196/5900 (epoch 71.119) train_loss=123.69689941 time/batch=0.23s
4197/5900 (epoch 71.136) train_loss=155.27203369 time/batch=0.30s
4198/5900 (epoch 71.153) train_loss=209.76666260 time/batch=0.38s
4199/5900 (epoch 71.169) train_loss=85.04301453 time/batch=0.22s
4200/5900 (epoch 71.186) train_loss=256.82568359 time/batch=0.42s
4201/5900 (epoch 71.203) train_loss=225.77641296 time/batch=0.44s
4202/5900 (epoch 71.220) train_loss=283.81109619 time/batch=0.49s
4203/5900 (epoch 71.237) train_loss=156.08015442 time/batch=0.33s
4204/5900 (epoch 71.254) train_loss=201.99446106 time/batch=0.37s
4205/5900 (epoch 71.271) train_loss=136.90496826 time/batch=0.30s
4206/5900 (epoch 71.288) train_loss=282.40676880 time/batch=0.50s
4207/5900 (epoch 71.305) train_loss=67.69052124 time/batch=0.23s
4208/5900 (epoch 71.322) train_loss=69.73308563 time/batch=0.17s
4209/5900 (epoch 71.339) train_loss=197.05148315 time/batch=1.75s
4210/5900 (epoch 71.356) train_loss=108.06914520 time/batch=0.51s
4211/5900 (epoch 71.373) train_loss=131.56454468 time/batch=0.27s
4212/5900 (epoch 71.390) train_loss=158.98194885 time/batch=0.31s
4213/5900 (epoch 71.407) train_loss=177.00885010 time/batch=0.34s
4214/5900 (epoch 71.424) train_loss=162.00074768 time/batch=0.31s
4215/5900 (epoch 71.441) train_loss=220.66201782 time/batch=0.41s
4216/5900 (epoch 71.458) train_loss=673.30175781 time/batch=2.66s
4217/5900 (epoch 71.475) train_loss=323.22369385 time/batch=0.95s
4218/5900 (epoch 71.492) train_loss=76.21393585 time/batch=0.24s
4219/5900 (epoch 71.508) train_loss=71.40185547 time/batch=0.19s
4220/5900 (epoch 71.525) train_loss=135.78811646 time/batch=0.25s
4221/5900 (epoch 71.542) train_loss=92.41608429 time/batch=0.22s
4222/5900 (epoch 71.559) train_loss=166.28369141 time/batch=0.29s
4223/5900 (epoch 71.576) train_loss=218.89938354 time/batch=0.41s
4224/5900 (epoch 71.593) train_loss=201.14823914 time/batch=0.36s
4225/5900 (epoch 71.610) train_loss=78.01737213 time/batch=0.20s
4226/5900 (epoch 71.627) train_loss=71.05680847 time/batch=0.17s
4227/5900 (epoch 71.644) train_loss=208.42543030 time/batch=0.34s
4228/5900 (epoch 71.661) train_loss=134.83227539 time/batch=0.28s
4229/5900 (epoch 71.678) train_loss=122.92250824 time/batch=0.25s
4230/5900 (epoch 71.695) train_loss=165.36247253 time/batch=0.31s
4231/5900 (epoch 71.712) train_loss=74.15621948 time/batch=0.20s
4232/5900 (epoch 71.729) train_loss=204.63812256 time/batch=0.33s
4233/5900 (epoch 71.746) train_loss=147.06173706 time/batch=0.30s
4234/5900 (epoch 71.763) train_loss=105.82995605 time/batch=0.25s
4235/5900 (epoch 71.780) train_loss=185.26870728 time/batch=0.33s
4236/5900 (epoch 71.797) train_loss=90.52598572 time/batch=0.21s
4237/5900 (epoch 71.814) train_loss=134.56915283 time/batch=0.31s
4238/5900 (epoch 71.831) train_loss=74.72271729 time/batch=0.20s
4239/5900 (epoch 71.847) train_loss=72.02355194 time/batch=0.17s
4240/5900 (epoch 71.864) train_loss=69.76750183 time/batch=0.19s
4241/5900 (epoch 71.881) train_loss=75.57416534 time/batch=0.17s
4242/5900 (epoch 71.898) train_loss=83.04251099 time/batch=0.19s
4243/5900 (epoch 71.915) train_loss=83.94139862 time/batch=0.19s
4244/5900 (epoch 71.932) train_loss=82.60662842 time/batch=0.19s
4245/5900 (epoch 71.949) train_loss=79.76760101 time/batch=0.19s
4246/5900 (epoch 71.966) train_loss=71.48023987 time/batch=0.17s
4247/5900 (epoch 71.983) train_loss=76.45777130 time/batch=0.18s
4248/5900 (epoch 72.000) train_loss=80.72678375 time/batch=0.17s
setting learning rate to 0.0006346
4249/5900 (epoch 72.017) train_loss=131.07443237 time/batch=1.77s
4250/5900 (epoch 72.034) train_loss=879.52185059 time/batch=2.92s
4251/5900 (epoch 72.051) train_loss=291.75616455 time/batch=0.86s
4252/5900 (epoch 72.068) train_loss=131.54098511 time/batch=0.28s
4253/5900 (epoch 72.085) train_loss=306.40893555 time/batch=0.50s
4254/5900 (epoch 72.102) train_loss=67.50577545 time/batch=0.23s
4255/5900 (epoch 72.119) train_loss=218.46649170 time/batch=0.36s
4256/5900 (epoch 72.136) train_loss=242.18898010 time/batch=0.45s
4257/5900 (epoch 72.153) train_loss=118.99594879 time/batch=0.27s
4258/5900 (epoch 72.169) train_loss=221.75115967 time/batch=0.43s
4259/5900 (epoch 72.186) train_loss=187.40614319 time/batch=0.37s
4260/5900 (epoch 72.203) train_loss=176.48355103 time/batch=0.34s
4261/5900 (epoch 72.220) train_loss=235.38415527 time/batch=0.45s
4262/5900 (epoch 72.237) train_loss=105.67736816 time/batch=0.25s
4263/5900 (epoch 72.254) train_loss=77.90650940 time/batch=0.19s
4264/5900 (epoch 72.271) train_loss=312.63250732 time/batch=0.56s
4265/5900 (epoch 72.288) train_loss=128.10408020 time/batch=1.77s
4266/5900 (epoch 72.305) train_loss=78.78135681 time/batch=0.45s
4267/5900 (epoch 72.322) train_loss=140.02090454 time/batch=0.27s
4268/5900 (epoch 72.339) train_loss=223.37635803 time/batch=0.44s
4269/5900 (epoch 72.356) train_loss=163.61619568 time/batch=0.34s
4270/5900 (epoch 72.373) train_loss=81.07886505 time/batch=0.22s
4271/5900 (epoch 72.390) train_loss=82.27202606 time/batch=0.19s
4272/5900 (epoch 72.407) train_loss=146.01515198 time/batch=0.28s
4273/5900 (epoch 72.424) train_loss=163.46199036 time/batch=0.31s
4274/5900 (epoch 72.441) train_loss=108.72257996 time/batch=0.25s
4275/5900 (epoch 72.458) train_loss=204.10195923 time/batch=0.36s
4276/5900 (epoch 72.475) train_loss=124.35205078 time/batch=0.27s
4277/5900 (epoch 72.492) train_loss=89.95106506 time/batch=0.20s
4278/5900 (epoch 72.508) train_loss=113.12869263 time/batch=0.25s
4279/5900 (epoch 72.525) train_loss=333.23388672 time/batch=0.62s
4280/5900 (epoch 72.542) train_loss=157.17796326 time/batch=0.35s
4281/5900 (epoch 72.559) train_loss=150.34426880 time/batch=0.28s
4282/5900 (epoch 72.576) train_loss=197.58569336 time/batch=0.34s
4283/5900 (epoch 72.593) train_loss=198.14517212 time/batch=0.37s
4284/5900 (epoch 72.610) train_loss=170.58395386 time/batch=0.33s
4285/5900 (epoch 72.627) train_loss=80.23722839 time/batch=0.20s
4286/5900 (epoch 72.644) train_loss=198.05218506 time/batch=0.33s
4287/5900 (epoch 72.661) train_loss=75.07677460 time/batch=0.20s
4288/5900 (epoch 72.678) train_loss=174.03234863 time/batch=0.30s
4289/5900 (epoch 72.695) train_loss=169.32191467 time/batch=0.33s
4290/5900 (epoch 72.712) train_loss=152.37203979 time/batch=0.30s
4291/5900 (epoch 72.729) train_loss=157.32780457 time/batch=0.31s
4292/5900 (epoch 72.746) train_loss=76.87374878 time/batch=0.21s
4293/5900 (epoch 72.763) train_loss=78.05026245 time/batch=0.19s
4294/5900 (epoch 72.780) train_loss=134.92355347 time/batch=0.25s
4295/5900 (epoch 72.797) train_loss=82.03845978 time/batch=0.20s
4296/5900 (epoch 72.814) train_loss=172.29449463 time/batch=0.31s
4297/5900 (epoch 72.831) train_loss=106.90994263 time/batch=0.28s
4298/5900 (epoch 72.847) train_loss=158.31170654 time/batch=0.35s
4299/5900 (epoch 72.864) train_loss=76.26091003 time/batch=0.21s
4300/5900 (epoch 72.881) train_loss=79.61225891 time/batch=0.19s
4301/5900 (epoch 72.898) train_loss=74.72009277 time/batch=0.17s
4302/5900 (epoch 72.915) train_loss=72.69389343 time/batch=0.17s
4303/5900 (epoch 72.932) train_loss=71.08459473 time/batch=0.19s
4304/5900 (epoch 72.949) train_loss=72.21356201 time/batch=0.19s
4305/5900 (epoch 72.966) train_loss=72.57585144 time/batch=0.17s
4306/5900 (epoch 72.983) train_loss=77.32641602 time/batch=0.19s
4307/5900 (epoch 73.000) train_loss=78.70703125 time/batch=0.17s
setting learning rate to 0.0006155
4308/5900 (epoch 73.017) train_loss=102.30987549 time/batch=0.20s
4309/5900 (epoch 73.034) train_loss=341.10675049 time/batch=0.62s
4310/5900 (epoch 73.051) train_loss=313.54272461 time/batch=0.55s
4311/5900 (epoch 73.068) train_loss=177.48999023 time/batch=0.36s
4312/5900 (epoch 73.085) train_loss=147.58703613 time/batch=0.30s
4313/5900 (epoch 73.102) train_loss=563.49499512 time/batch=2.05s
4314/5900 (epoch 73.119) train_loss=250.67428589 time/batch=0.73s
4315/5900 (epoch 73.136) train_loss=317.96716309 time/batch=0.87s
4316/5900 (epoch 73.153) train_loss=175.60192871 time/batch=0.42s
4317/5900 (epoch 73.169) train_loss=66.88851929 time/batch=0.20s
4318/5900 (epoch 73.186) train_loss=157.39901733 time/batch=0.30s
4319/5900 (epoch 73.203) train_loss=78.75763702 time/batch=0.20s
4320/5900 (epoch 73.220) train_loss=121.07607269 time/batch=0.25s
4321/5900 (epoch 73.237) train_loss=116.29986572 time/batch=0.24s
4322/5900 (epoch 73.254) train_loss=554.84423828 time/batch=2.65s
4323/5900 (epoch 73.271) train_loss=215.89761353 time/batch=0.79s
4324/5900 (epoch 73.288) train_loss=231.35824585 time/batch=0.42s
4325/5900 (epoch 73.305) train_loss=222.12107849 time/batch=0.42s
4326/5900 (epoch 73.322) train_loss=91.00157166 time/batch=0.22s
4327/5900 (epoch 73.339) train_loss=142.49645996 time/batch=0.27s
4328/5900 (epoch 73.356) train_loss=123.70442200 time/batch=0.25s
4329/5900 (epoch 73.373) train_loss=145.83276367 time/batch=1.77s
4330/5900 (epoch 73.390) train_loss=172.59230042 time/batch=0.61s
4331/5900 (epoch 73.407) train_loss=214.81900024 time/batch=0.39s
4332/5900 (epoch 73.424) train_loss=188.60360718 time/batch=0.36s
4333/5900 (epoch 73.441) train_loss=157.90625000 time/batch=0.32s
4334/5900 (epoch 73.458) train_loss=166.34851074 time/batch=0.33s
4335/5900 (epoch 73.475) train_loss=125.53896332 time/batch=0.27s
4336/5900 (epoch 73.492) train_loss=126.22341919 time/batch=0.27s
4337/5900 (epoch 73.508) train_loss=83.22892761 time/batch=0.22s
4338/5900 (epoch 73.525) train_loss=78.26507568 time/batch=0.19s
4339/5900 (epoch 73.542) train_loss=166.38729858 time/batch=0.31s
4340/5900 (epoch 73.559) train_loss=147.55683899 time/batch=0.30s
4341/5900 (epoch 73.576) train_loss=158.64331055 time/batch=0.31s
4342/5900 (epoch 73.593) train_loss=78.88015747 time/batch=0.20s
4343/5900 (epoch 73.610) train_loss=130.93563843 time/batch=0.27s
4344/5900 (epoch 73.627) train_loss=80.34635925 time/batch=0.20s
4345/5900 (epoch 73.644) train_loss=147.89178467 time/batch=0.28s
4346/5900 (epoch 73.661) train_loss=198.81652832 time/batch=0.36s
4347/5900 (epoch 73.678) train_loss=198.14492798 time/batch=0.37s
4348/5900 (epoch 73.695) train_loss=119.50170135 time/batch=1.73s
4349/5900 (epoch 73.712) train_loss=199.57980347 time/batch=0.62s
4350/5900 (epoch 73.729) train_loss=186.83041382 time/batch=0.35s
4351/5900 (epoch 73.746) train_loss=110.62365723 time/batch=0.24s
4352/5900 (epoch 73.763) train_loss=171.19242859 time/batch=0.38s
4353/5900 (epoch 73.780) train_loss=80.82384491 time/batch=0.22s
4354/5900 (epoch 73.797) train_loss=74.24300385 time/batch=0.17s
4355/5900 (epoch 73.814) train_loss=70.99958801 time/batch=0.19s
4356/5900 (epoch 73.831) train_loss=79.86621094 time/batch=0.19s
4357/5900 (epoch 73.847) train_loss=95.24665833 time/batch=0.36s
4358/5900 (epoch 73.864) train_loss=75.33895874 time/batch=0.22s
4359/5900 (epoch 73.881) train_loss=77.47504425 time/batch=0.19s
4360/5900 (epoch 73.898) train_loss=69.11589050 time/batch=0.17s
4361/5900 (epoch 73.915) train_loss=72.68585968 time/batch=0.19s
4362/5900 (epoch 73.932) train_loss=73.21333313 time/batch=0.17s
4363/5900 (epoch 73.949) train_loss=77.78558350 time/batch=0.19s
4364/5900 (epoch 73.966) train_loss=72.44883728 time/batch=0.17s
4365/5900 (epoch 73.983) train_loss=76.73405457 time/batch=0.19s
4366/5900 (epoch 74.000) train_loss=76.08729553 time/batch=0.19s
setting learning rate to 0.0005971
4367/5900 (epoch 74.017) train_loss=208.11087036 time/batch=0.38s
4368/5900 (epoch 74.034) train_loss=620.61828613 time/batch=2.08s
4369/5900 (epoch 74.051) train_loss=228.36141968 time/batch=2.10s
4370/5900 (epoch 74.068) train_loss=106.59850311 time/batch=0.50s
4371/5900 (epoch 74.085) train_loss=234.09948730 time/batch=0.39s
4372/5900 (epoch 74.102) train_loss=136.64031982 time/batch=0.31s
4373/5900 (epoch 74.119) train_loss=241.27957153 time/batch=0.42s
4374/5900 (epoch 74.136) train_loss=144.90151978 time/batch=0.33s
4375/5900 (epoch 74.153) train_loss=167.02543640 time/batch=0.33s
4376/5900 (epoch 74.169) train_loss=181.67633057 time/batch=0.36s
4377/5900 (epoch 74.186) train_loss=141.60980225 time/batch=0.30s
4378/5900 (epoch 74.203) train_loss=106.54333496 time/batch=0.25s
4379/5900 (epoch 74.220) train_loss=153.65490723 time/batch=0.31s
4380/5900 (epoch 74.237) train_loss=177.91011047 time/batch=0.35s
4381/5900 (epoch 74.254) train_loss=273.08026123 time/batch=0.47s
4382/5900 (epoch 74.271) train_loss=161.85195923 time/batch=0.34s
4383/5900 (epoch 74.288) train_loss=124.11856079 time/batch=0.28s
4384/5900 (epoch 74.305) train_loss=118.51297760 time/batch=0.25s
4385/5900 (epoch 74.322) train_loss=208.69558716 time/batch=0.36s
4386/5900 (epoch 74.339) train_loss=395.94409180 time/batch=0.94s
4387/5900 (epoch 74.356) train_loss=145.37573242 time/batch=0.39s
4388/5900 (epoch 74.373) train_loss=179.35510254 time/batch=0.34s
4389/5900 (epoch 74.390) train_loss=132.34037781 time/batch=0.28s
4390/5900 (epoch 74.407) train_loss=286.59844971 time/batch=0.50s
4391/5900 (epoch 74.424) train_loss=190.83309937 time/batch=0.39s
4392/5900 (epoch 74.441) train_loss=194.10832214 time/batch=0.38s
4393/5900 (epoch 74.458) train_loss=150.69926453 time/batch=0.31s
4394/5900 (epoch 74.475) train_loss=189.93476868 time/batch=0.37s
4395/5900 (epoch 74.492) train_loss=360.17752075 time/batch=2.67s
4396/5900 (epoch 74.508) train_loss=124.98730469 time/batch=0.69s
4397/5900 (epoch 74.525) train_loss=79.14311218 time/batch=0.20s
4398/5900 (epoch 74.542) train_loss=160.62728882 time/batch=0.33s
4399/5900 (epoch 74.559) train_loss=158.94281006 time/batch=0.31s
4400/5900 (epoch 74.576) train_loss=67.09530640 time/batch=0.20s
4401/5900 (epoch 74.593) train_loss=352.25143433 time/batch=1.36s
4402/5900 (epoch 74.610) train_loss=70.93751526 time/batch=0.39s
4403/5900 (epoch 74.627) train_loss=79.36393738 time/batch=0.19s
4404/5900 (epoch 74.644) train_loss=177.35623169 time/batch=0.37s
4405/5900 (epoch 74.661) train_loss=113.91641235 time/batch=0.26s
4406/5900 (epoch 74.678) train_loss=71.46575928 time/batch=0.19s
4407/5900 (epoch 74.695) train_loss=142.72396851 time/batch=0.27s
4408/5900 (epoch 74.712) train_loss=73.61431885 time/batch=0.20s
4409/5900 (epoch 74.729) train_loss=77.14807129 time/batch=0.17s
4410/5900 (epoch 74.746) train_loss=93.12855530 time/batch=0.20s
4411/5900 (epoch 74.763) train_loss=89.23209381 time/batch=0.19s
4412/5900 (epoch 74.780) train_loss=68.62096405 time/batch=0.18s
4413/5900 (epoch 74.797) train_loss=74.91304016 time/batch=0.19s
4414/5900 (epoch 74.814) train_loss=77.26544189 time/batch=0.19s
4415/5900 (epoch 74.831) train_loss=138.48510742 time/batch=0.30s
4416/5900 (epoch 74.847) train_loss=80.82921600 time/batch=0.20s
4417/5900 (epoch 74.864) train_loss=84.60929108 time/batch=0.19s
4418/5900 (epoch 74.881) train_loss=70.77767944 time/batch=0.19s
4419/5900 (epoch 74.898) train_loss=72.59619141 time/batch=0.19s
4420/5900 (epoch 74.915) train_loss=78.89457703 time/batch=0.18s
4421/5900 (epoch 74.932) train_loss=74.54814911 time/batch=0.18s
4422/5900 (epoch 74.949) train_loss=78.70016479 time/batch=0.19s
4423/5900 (epoch 74.966) train_loss=79.88514709 time/batch=0.19s
4424/5900 (epoch 74.983) train_loss=72.75176239 time/batch=0.17s
4425/5900 (epoch 75.000) train_loss=77.78433228 time/batch=0.19s
setting learning rate to 0.0005792
4426/5900 (epoch 75.017) train_loss=167.27044678 time/batch=0.33s
4427/5900 (epoch 75.034) train_loss=149.37338257 time/batch=0.28s
4428/5900 (epoch 75.051) train_loss=117.36134338 time/batch=0.25s
4429/5900 (epoch 75.068) train_loss=340.13500977 time/batch=0.62s
4430/5900 (epoch 75.085) train_loss=919.23895264 time/batch=2.71s
4431/5900 (epoch 75.102) train_loss=437.44335938 time/batch=1.07s
4432/5900 (epoch 75.119) train_loss=119.23397064 time/batch=0.28s
4433/5900 (epoch 75.136) train_loss=121.88481140 time/batch=0.25s
4434/5900 (epoch 75.153) train_loss=91.53982544 time/batch=0.20s
4435/5900 (epoch 75.169) train_loss=254.03250122 time/batch=0.41s
4436/5900 (epoch 75.186) train_loss=108.77445984 time/batch=0.26s
4437/5900 (epoch 75.203) train_loss=166.61227417 time/batch=0.31s
4438/5900 (epoch 75.220) train_loss=261.14608765 time/batch=0.47s
4439/5900 (epoch 75.237) train_loss=195.44052124 time/batch=1.78s
4440/5900 (epoch 75.254) train_loss=125.14485931 time/batch=0.55s
4441/5900 (epoch 75.271) train_loss=203.20584106 time/batch=0.40s
4442/5900 (epoch 75.288) train_loss=188.28482056 time/batch=0.36s
4443/5900 (epoch 75.305) train_loss=199.82336426 time/batch=0.41s
4444/5900 (epoch 75.322) train_loss=151.64205933 time/batch=0.34s
4445/5900 (epoch 75.339) train_loss=90.74159241 time/batch=0.25s
4446/5900 (epoch 75.356) train_loss=117.09646606 time/batch=0.25s
4447/5900 (epoch 75.373) train_loss=146.90647888 time/batch=0.30s
4448/5900 (epoch 75.390) train_loss=177.08122253 time/batch=0.36s
4449/5900 (epoch 75.407) train_loss=209.39932251 time/batch=0.42s
4450/5900 (epoch 75.424) train_loss=252.99771118 time/batch=0.50s
4451/5900 (epoch 75.441) train_loss=153.02435303 time/batch=0.34s
4452/5900 (epoch 75.458) train_loss=189.02703857 time/batch=0.34s
4453/5900 (epoch 75.475) train_loss=204.40830994 time/batch=0.37s
4454/5900 (epoch 75.492) train_loss=201.22914124 time/batch=0.38s
4455/5900 (epoch 75.508) train_loss=149.34687805 time/batch=0.31s
4456/5900 (epoch 75.525) train_loss=135.92050171 time/batch=0.28s
4457/5900 (epoch 75.542) train_loss=80.07960510 time/batch=0.20s
4458/5900 (epoch 75.559) train_loss=138.51548767 time/batch=0.28s
4459/5900 (epoch 75.576) train_loss=177.01586914 time/batch=0.33s
4460/5900 (epoch 75.593) train_loss=80.48197174 time/batch=0.22s
4461/5900 (epoch 75.610) train_loss=165.28903198 time/batch=0.30s
4462/5900 (epoch 75.627) train_loss=75.14787292 time/batch=0.20s
4463/5900 (epoch 75.644) train_loss=166.11698914 time/batch=0.30s
4464/5900 (epoch 75.661) train_loss=154.44567871 time/batch=0.30s
4465/5900 (epoch 75.678) train_loss=75.28589630 time/batch=0.20s
4466/5900 (epoch 75.695) train_loss=72.88960266 time/batch=0.19s
4467/5900 (epoch 75.712) train_loss=193.19363403 time/batch=0.38s
4468/5900 (epoch 75.729) train_loss=152.07380676 time/batch=0.35s
4469/5900 (epoch 75.746) train_loss=76.17887878 time/batch=0.20s
4470/5900 (epoch 75.763) train_loss=70.42961884 time/batch=0.19s
4471/5900 (epoch 75.780) train_loss=67.52182007 time/batch=0.17s
4472/5900 (epoch 75.797) train_loss=70.16001892 time/batch=0.17s
4473/5900 (epoch 75.814) train_loss=103.80940247 time/batch=0.25s
4474/5900 (epoch 75.831) train_loss=73.27888489 time/batch=0.20s
4475/5900 (epoch 75.847) train_loss=80.58833313 time/batch=0.18s
4476/5900 (epoch 75.864) train_loss=72.05802155 time/batch=0.19s
4477/5900 (epoch 75.881) train_loss=69.67913818 time/batch=0.19s
4478/5900 (epoch 75.898) train_loss=70.84033966 time/batch=0.17s
4479/5900 (epoch 75.915) train_loss=69.65274811 time/batch=0.19s
4480/5900 (epoch 75.932) train_loss=80.38804626 time/batch=0.19s
4481/5900 (epoch 75.949) train_loss=79.03663635 time/batch=0.19s
4482/5900 (epoch 75.966) train_loss=81.15345764 time/batch=0.17s
4483/5900 (epoch 75.983) train_loss=80.20899963 time/batch=0.19s
4484/5900 (epoch 76.000) train_loss=78.49070740 time/batch=0.18s
setting learning rate to 0.0005618
4485/5900 (epoch 76.017) train_loss=108.61130524 time/batch=0.25s
4486/5900 (epoch 76.034) train_loss=130.48916626 time/batch=0.27s
4487/5900 (epoch 76.051) train_loss=792.38061523 time/batch=2.66s
4488/5900 (epoch 76.068) train_loss=335.39242554 time/batch=0.95s
4489/5900 (epoch 76.085) train_loss=157.96221924 time/batch=0.33s
4490/5900 (epoch 76.102) train_loss=332.51550293 time/batch=0.61s
4491/5900 (epoch 76.119) train_loss=119.22402191 time/batch=0.31s
4492/5900 (epoch 76.136) train_loss=379.61895752 time/batch=1.39s
4493/5900 (epoch 76.153) train_loss=200.96235657 time/batch=0.59s
4494/5900 (epoch 76.169) train_loss=194.16513062 time/batch=0.39s
4495/5900 (epoch 76.186) train_loss=220.12426758 time/batch=0.42s
4496/5900 (epoch 76.203) train_loss=191.95973206 time/batch=0.36s
4497/5900 (epoch 76.220) train_loss=150.91717529 time/batch=0.33s
4498/5900 (epoch 76.237) train_loss=86.21187592 time/batch=0.20s
4499/5900 (epoch 76.254) train_loss=145.17187500 time/batch=0.30s
4500/5900 (epoch 76.271) train_loss=177.23367310 time/batch=0.34s
4501/5900 (epoch 76.288) train_loss=124.16993713 time/batch=0.27s
4502/5900 (epoch 76.305) train_loss=107.85182190 time/batch=0.24s
4503/5900 (epoch 76.322) train_loss=100.62431335 time/batch=0.22s
4504/5900 (epoch 76.339) train_loss=151.62246704 time/batch=0.30s
4505/5900 (epoch 76.356) train_loss=251.19589233 time/batch=0.45s
4506/5900 (epoch 76.373) train_loss=241.36766052 time/batch=0.45s
4507/5900 (epoch 76.390) train_loss=145.22265625 time/batch=0.31s
4508/5900 (epoch 76.407) train_loss=191.06994629 time/batch=1.77s
4509/5900 (epoch 76.424) train_loss=157.11181641 time/batch=0.59s
4510/5900 (epoch 76.441) train_loss=117.26586914 time/batch=0.25s
4511/5900 (epoch 76.458) train_loss=149.13685608 time/batch=0.27s
4512/5900 (epoch 76.475) train_loss=171.59611511 time/batch=0.33s
4513/5900 (epoch 76.492) train_loss=129.76832581 time/batch=0.30s
4514/5900 (epoch 76.508) train_loss=80.62274170 time/batch=0.20s
4515/5900 (epoch 76.525) train_loss=161.82489014 time/batch=0.31s
4516/5900 (epoch 76.542) train_loss=161.46569824 time/batch=0.33s
4517/5900 (epoch 76.559) train_loss=82.93980408 time/batch=0.21s
4518/5900 (epoch 76.576) train_loss=147.16708374 time/batch=0.28s
4519/5900 (epoch 76.593) train_loss=67.03684998 time/batch=0.19s
4520/5900 (epoch 76.610) train_loss=191.97979736 time/batch=0.34s
4521/5900 (epoch 76.627) train_loss=79.71018982 time/batch=0.22s
4522/5900 (epoch 76.644) train_loss=184.90899658 time/batch=0.34s
4523/5900 (epoch 76.661) train_loss=226.03224182 time/batch=0.41s
4524/5900 (epoch 76.678) train_loss=128.02243042 time/batch=0.33s
4525/5900 (epoch 76.695) train_loss=196.16963196 time/batch=0.37s
4526/5900 (epoch 76.712) train_loss=75.11689758 time/batch=0.21s
4527/5900 (epoch 76.729) train_loss=178.76278687 time/batch=0.34s
4528/5900 (epoch 76.746) train_loss=76.48245239 time/batch=0.20s
4529/5900 (epoch 76.763) train_loss=68.49311829 time/batch=0.19s
4530/5900 (epoch 76.780) train_loss=67.60993958 time/batch=0.17s
4531/5900 (epoch 76.797) train_loss=73.35929108 time/batch=0.19s
4532/5900 (epoch 76.814) train_loss=68.74386597 time/batch=0.17s
4533/5900 (epoch 76.831) train_loss=75.59164429 time/batch=0.19s
4534/5900 (epoch 76.847) train_loss=82.39820862 time/batch=0.19s
4535/5900 (epoch 76.864) train_loss=77.90441132 time/batch=0.19s
4536/5900 (epoch 76.881) train_loss=75.09506226 time/batch=0.17s
4537/5900 (epoch 76.898) train_loss=78.79890442 time/batch=0.19s
4538/5900 (epoch 76.915) train_loss=81.44219208 time/batch=0.19s
4539/5900 (epoch 76.932) train_loss=78.86538696 time/batch=0.17s
4540/5900 (epoch 76.949) train_loss=70.61663818 time/batch=0.19s
4541/5900 (epoch 76.966) train_loss=73.28170013 time/batch=0.17s
4542/5900 (epoch 76.983) train_loss=72.24180603 time/batch=0.19s
4543/5900 (epoch 77.000) train_loss=73.79496765 time/batch=0.19s
setting learning rate to 0.0005449
4544/5900 (epoch 77.017) train_loss=240.80958557 time/batch=0.44s
4545/5900 (epoch 77.034) train_loss=195.36280823 time/batch=1.81s
4546/5900 (epoch 77.051) train_loss=266.70602417 time/batch=0.73s
4547/5900 (epoch 77.068) train_loss=125.80575562 time/batch=0.30s
4548/5900 (epoch 77.085) train_loss=212.55819702 time/batch=0.39s
4549/5900 (epoch 77.102) train_loss=74.80226135 time/batch=0.22s
4550/5900 (epoch 77.119) train_loss=119.74667358 time/batch=0.24s
4551/5900 (epoch 77.136) train_loss=156.22981262 time/batch=0.31s
4552/5900 (epoch 77.153) train_loss=173.47816467 time/batch=0.35s
4553/5900 (epoch 77.169) train_loss=610.49291992 time/batch=2.05s
4554/5900 (epoch 77.186) train_loss=133.59963989 time/batch=0.58s
4555/5900 (epoch 77.203) train_loss=186.98913574 time/batch=0.36s
4556/5900 (epoch 77.220) train_loss=194.50805664 time/batch=0.39s
4557/5900 (epoch 77.237) train_loss=599.52868652 time/batch=2.67s
4558/5900 (epoch 77.254) train_loss=112.41793823 time/batch=0.69s
4559/5900 (epoch 77.271) train_loss=151.75469971 time/batch=0.30s
4560/5900 (epoch 77.288) train_loss=302.85430908 time/batch=0.52s
4561/5900 (epoch 77.305) train_loss=107.06457520 time/batch=0.30s
4562/5900 (epoch 77.322) train_loss=155.80627441 time/batch=0.33s
4563/5900 (epoch 77.339) train_loss=159.14208984 time/batch=0.33s
4564/5900 (epoch 77.356) train_loss=215.37811279 time/batch=0.42s
4565/5900 (epoch 77.373) train_loss=64.12248230 time/batch=0.20s
4566/5900 (epoch 77.390) train_loss=182.31491089 time/batch=0.34s
4567/5900 (epoch 77.407) train_loss=142.09288025 time/batch=0.31s
4568/5900 (epoch 77.424) train_loss=69.25056458 time/batch=0.19s
4569/5900 (epoch 77.441) train_loss=77.96141815 time/batch=0.19s
4570/5900 (epoch 77.458) train_loss=76.22229004 time/batch=0.20s
4571/5900 (epoch 77.475) train_loss=143.00369263 time/batch=0.28s
4572/5900 (epoch 77.492) train_loss=135.21775818 time/batch=0.28s
4573/5900 (epoch 77.508) train_loss=185.58352661 time/batch=0.34s
4574/5900 (epoch 77.525) train_loss=87.27323914 time/batch=0.22s
4575/5900 (epoch 77.542) train_loss=183.94477844 time/batch=0.35s
4576/5900 (epoch 77.559) train_loss=207.98054504 time/batch=0.41s
4577/5900 (epoch 77.576) train_loss=157.92428589 time/batch=0.32s
4578/5900 (epoch 77.593) train_loss=165.11968994 time/batch=0.33s
4579/5900 (epoch 77.610) train_loss=128.70329285 time/batch=0.28s
4580/5900 (epoch 77.627) train_loss=70.77720642 time/batch=0.20s
4581/5900 (epoch 77.644) train_loss=70.89291382 time/batch=0.17s
4582/5900 (epoch 77.661) train_loss=105.75270081 time/batch=0.21s
4583/5900 (epoch 77.678) train_loss=163.91609192 time/batch=0.31s
4584/5900 (epoch 77.695) train_loss=140.10850525 time/batch=0.28s
4585/5900 (epoch 77.712) train_loss=225.43548584 time/batch=0.47s
4586/5900 (epoch 77.729) train_loss=200.39733887 time/batch=0.42s
4587/5900 (epoch 77.746) train_loss=148.81961060 time/batch=0.31s
4588/5900 (epoch 77.763) train_loss=140.40354919 time/batch=0.33s
4589/5900 (epoch 77.780) train_loss=65.61654663 time/batch=0.20s
4590/5900 (epoch 77.797) train_loss=68.63640594 time/batch=0.17s
4591/5900 (epoch 77.814) train_loss=69.01588440 time/batch=0.19s
4592/5900 (epoch 77.831) train_loss=83.25431824 time/batch=0.19s
4593/5900 (epoch 77.847) train_loss=75.88056183 time/batch=0.19s
4594/5900 (epoch 77.864) train_loss=72.11557770 time/batch=0.17s
4595/5900 (epoch 77.881) train_loss=80.92117310 time/batch=0.19s
4596/5900 (epoch 77.898) train_loss=80.48852539 time/batch=0.19s
4597/5900 (epoch 77.915) train_loss=69.52611542 time/batch=0.17s
4598/5900 (epoch 77.932) train_loss=73.69380951 time/batch=0.19s
4599/5900 (epoch 77.949) train_loss=78.34456635 time/batch=0.19s
4600/5900 (epoch 77.966) train_loss=73.40872192 time/batch=0.19s
4601/5900 (epoch 77.983) train_loss=76.15225220 time/batch=0.17s
4602/5900 (epoch 78.000) train_loss=80.07437897 time/batch=0.20s
setting learning rate to 0.0005286
4603/5900 (epoch 78.017) train_loss=245.21105957 time/batch=0.47s
4604/5900 (epoch 78.034) train_loss=568.35479736 time/batch=2.07s
4605/5900 (epoch 78.051) train_loss=161.90341187 time/batch=0.61s
4606/5900 (epoch 78.068) train_loss=122.80102539 time/batch=0.28s
4607/5900 (epoch 78.085) train_loss=230.06697083 time/batch=0.41s
4608/5900 (epoch 78.102) train_loss=649.85565186 time/batch=2.67s
4609/5900 (epoch 78.119) train_loss=140.94837952 time/batch=0.72s
4610/5900 (epoch 78.136) train_loss=252.51123047 time/batch=0.44s
4611/5900 (epoch 78.153) train_loss=220.17776489 time/batch=0.47s
4612/5900 (epoch 78.169) train_loss=245.28056335 time/batch=0.53s
4613/5900 (epoch 78.186) train_loss=238.75744629 time/batch=0.55s
4614/5900 (epoch 78.203) train_loss=103.85456848 time/batch=0.27s
4615/5900 (epoch 78.220) train_loss=75.61879730 time/batch=0.19s
4616/5900 (epoch 78.237) train_loss=159.79086304 time/batch=0.33s
4617/5900 (epoch 78.254) train_loss=185.39367676 time/batch=1.78s
4618/5900 (epoch 78.271) train_loss=178.97370911 time/batch=0.61s
4619/5900 (epoch 78.288) train_loss=153.86134338 time/batch=0.33s
4620/5900 (epoch 78.305) train_loss=86.75329590 time/batch=0.22s
4621/5900 (epoch 78.322) train_loss=113.54325104 time/batch=0.23s
4622/5900 (epoch 78.339) train_loss=77.00758362 time/batch=0.20s
4623/5900 (epoch 78.356) train_loss=196.75946045 time/batch=0.36s
4624/5900 (epoch 78.373) train_loss=154.17010498 time/batch=0.33s
4625/5900 (epoch 78.390) train_loss=149.68563843 time/batch=0.31s
4626/5900 (epoch 78.407) train_loss=104.25657654 time/batch=0.24s
4627/5900 (epoch 78.424) train_loss=179.89881897 time/batch=0.33s
4628/5900 (epoch 78.441) train_loss=117.32247925 time/batch=0.27s
4629/5900 (epoch 78.458) train_loss=126.27130890 time/batch=0.28s
4630/5900 (epoch 78.475) train_loss=195.78688049 time/batch=0.38s
4631/5900 (epoch 78.492) train_loss=105.96618652 time/batch=0.28s
4632/5900 (epoch 78.508) train_loss=177.87452698 time/batch=0.34s
4633/5900 (epoch 78.525) train_loss=140.61357117 time/batch=0.30s
4634/5900 (epoch 78.542) train_loss=183.31019592 time/batch=0.35s
4635/5900 (epoch 78.559) train_loss=184.79281616 time/batch=0.38s
4636/5900 (epoch 78.576) train_loss=162.95704651 time/batch=0.33s
4637/5900 (epoch 78.593) train_loss=190.61502075 time/batch=0.36s
4638/5900 (epoch 78.610) train_loss=164.39251709 time/batch=0.33s
4639/5900 (epoch 78.627) train_loss=168.56243896 time/batch=0.33s
4640/5900 (epoch 78.644) train_loss=151.62768555 time/batch=0.30s
4641/5900 (epoch 78.661) train_loss=63.96421051 time/batch=0.20s
4642/5900 (epoch 78.678) train_loss=129.60871887 time/batch=0.25s
4643/5900 (epoch 78.695) train_loss=149.04777527 time/batch=0.36s
4644/5900 (epoch 78.712) train_loss=76.17581177 time/batch=0.22s
4645/5900 (epoch 78.729) train_loss=72.45737457 time/batch=0.17s
4646/5900 (epoch 78.746) train_loss=84.76941681 time/batch=0.27s
4647/5900 (epoch 78.763) train_loss=74.95304871 time/batch=0.20s
4648/5900 (epoch 78.780) train_loss=76.28898621 time/batch=0.19s
4649/5900 (epoch 78.797) train_loss=67.91545105 time/batch=0.17s
4650/5900 (epoch 78.814) train_loss=69.16097260 time/batch=0.19s
4651/5900 (epoch 78.831) train_loss=80.32875061 time/batch=0.17s
4652/5900 (epoch 78.847) train_loss=68.94169617 time/batch=0.19s
4653/5900 (epoch 78.864) train_loss=75.03871155 time/batch=0.19s
4654/5900 (epoch 78.881) train_loss=71.87478638 time/batch=0.17s
4655/5900 (epoch 78.898) train_loss=74.26136780 time/batch=0.19s
4656/5900 (epoch 78.915) train_loss=82.41750336 time/batch=0.17s
4657/5900 (epoch 78.932) train_loss=78.63545227 time/batch=0.19s
4658/5900 (epoch 78.949) train_loss=75.07679749 time/batch=0.19s
4659/5900 (epoch 78.966) train_loss=71.65547943 time/batch=0.19s
4660/5900 (epoch 78.983) train_loss=71.87980652 time/batch=0.17s
4661/5900 (epoch 79.000) train_loss=70.89039612 time/batch=0.17s
setting learning rate to 0.0005127
4662/5900 (epoch 79.017) train_loss=216.54335022 time/batch=0.42s
4663/5900 (epoch 79.034) train_loss=185.85705566 time/batch=0.36s
4664/5900 (epoch 79.051) train_loss=154.36543274 time/batch=0.30s
4665/5900 (epoch 79.068) train_loss=845.25585938 time/batch=2.67s
4666/5900 (epoch 79.085) train_loss=240.19265747 time/batch=0.83s
4667/5900 (epoch 79.102) train_loss=70.63011169 time/batch=0.20s
4668/5900 (epoch 79.119) train_loss=193.27203369 time/batch=1.77s
4669/5900 (epoch 79.136) train_loss=266.27749634 time/batch=0.72s
4670/5900 (epoch 79.153) train_loss=286.71325684 time/batch=0.55s
4671/5900 (epoch 79.169) train_loss=122.62393951 time/batch=0.31s
4672/5900 (epoch 79.186) train_loss=135.81886292 time/batch=0.28s
4673/5900 (epoch 79.203) train_loss=342.37918091 time/batch=0.64s
4674/5900 (epoch 79.220) train_loss=101.47699738 time/batch=0.28s
4675/5900 (epoch 79.237) train_loss=129.69998169 time/batch=0.27s
4676/5900 (epoch 79.254) train_loss=106.28382874 time/batch=0.25s
4677/5900 (epoch 79.271) train_loss=122.40562439 time/batch=0.28s
4678/5900 (epoch 79.288) train_loss=172.22286987 time/batch=0.33s
4679/5900 (epoch 79.305) train_loss=195.98550415 time/batch=0.40s
4680/5900 (epoch 79.322) train_loss=116.73227692 time/batch=0.27s
4681/5900 (epoch 79.339) train_loss=210.02536011 time/batch=0.41s
4682/5900 (epoch 79.356) train_loss=190.32650757 time/batch=0.36s
4683/5900 (epoch 79.373) train_loss=157.81541443 time/batch=0.33s
4684/5900 (epoch 79.390) train_loss=115.17953491 time/batch=0.28s
4685/5900 (epoch 79.407) train_loss=141.66366577 time/batch=0.28s
4686/5900 (epoch 79.424) train_loss=189.43344116 time/batch=0.37s
4687/5900 (epoch 79.441) train_loss=178.21047974 time/batch=0.39s
4688/5900 (epoch 79.458) train_loss=155.34017944 time/batch=0.33s
4689/5900 (epoch 79.475) train_loss=67.23045349 time/batch=0.19s
4690/5900 (epoch 79.492) train_loss=172.82711792 time/batch=0.33s
4691/5900 (epoch 79.508) train_loss=137.68066406 time/batch=0.30s
4692/5900 (epoch 79.525) train_loss=140.44815063 time/batch=0.30s
4693/5900 (epoch 79.542) train_loss=108.78249359 time/batch=0.27s
4694/5900 (epoch 79.559) train_loss=164.21496582 time/batch=0.36s
4695/5900 (epoch 79.576) train_loss=234.11337280 time/batch=0.47s
4696/5900 (epoch 79.593) train_loss=146.35786438 time/batch=0.34s
4697/5900 (epoch 79.610) train_loss=198.65344238 time/batch=0.52s
4698/5900 (epoch 79.627) train_loss=66.14376831 time/batch=0.23s
4699/5900 (epoch 79.644) train_loss=69.41020203 time/batch=0.19s
4700/5900 (epoch 79.661) train_loss=80.39971924 time/batch=0.17s
4701/5900 (epoch 79.678) train_loss=91.92991638 time/batch=0.20s
4702/5900 (epoch 79.695) train_loss=163.73950195 time/batch=0.34s
4703/5900 (epoch 79.712) train_loss=82.63436890 time/batch=0.21s
4704/5900 (epoch 79.729) train_loss=154.81547546 time/batch=0.31s
4705/5900 (epoch 79.746) train_loss=85.96833801 time/batch=0.22s
4706/5900 (epoch 79.763) train_loss=77.70887756 time/batch=0.17s
4707/5900 (epoch 79.780) train_loss=69.17045593 time/batch=0.19s
4708/5900 (epoch 79.797) train_loss=109.64748383 time/batch=0.28s
4709/5900 (epoch 79.814) train_loss=68.08102417 time/batch=0.20s
4710/5900 (epoch 79.831) train_loss=77.27892303 time/batch=0.19s
4711/5900 (epoch 79.847) train_loss=73.95600891 time/batch=0.17s
4712/5900 (epoch 79.864) train_loss=74.67730713 time/batch=0.19s
4713/5900 (epoch 79.881) train_loss=68.15660095 time/batch=0.17s
4714/5900 (epoch 79.898) train_loss=76.00267029 time/batch=0.19s
4715/5900 (epoch 79.915) train_loss=72.79496765 time/batch=0.17s
4716/5900 (epoch 79.932) train_loss=80.63090515 time/batch=0.19s
4717/5900 (epoch 79.949) train_loss=72.64926910 time/batch=0.18s
4718/5900 (epoch 79.966) train_loss=75.15046692 time/batch=0.19s
4719/5900 (epoch 79.983) train_loss=71.42601013 time/batch=0.19s
4720/5900 (epoch 80.000) train_loss=73.39070129 time/batch=0.17s
setting learning rate to 0.0004973
  saved to metadata/config5--20190119-190634.pkl
4721/5900 (epoch 80.017) train_loss=323.81927490 time/batch=7.84s
4722/5900 (epoch 80.034) train_loss=94.32681274 time/batch=0.27s
4723/5900 (epoch 80.051) train_loss=177.85528564 time/batch=0.33s
4724/5900 (epoch 80.068) train_loss=831.92089844 time/batch=2.67s
4725/5900 (epoch 80.085) train_loss=325.49963379 time/batch=0.95s
4726/5900 (epoch 80.102) train_loss=189.09683228 time/batch=0.38s
4727/5900 (epoch 80.119) train_loss=207.83398438 time/batch=0.42s
4728/5900 (epoch 80.136) train_loss=133.75314331 time/batch=0.30s
4729/5900 (epoch 80.153) train_loss=119.50389099 time/batch=0.27s
4730/5900 (epoch 80.169) train_loss=214.72274780 time/batch=0.42s
4731/5900 (epoch 80.186) train_loss=125.81671143 time/batch=0.31s
4732/5900 (epoch 80.203) train_loss=246.74967957 time/batch=0.45s
4733/5900 (epoch 80.220) train_loss=117.98406982 time/batch=0.33s
4734/5900 (epoch 80.237) train_loss=183.08818054 time/batch=0.38s
4735/5900 (epoch 80.254) train_loss=233.83813477 time/batch=0.48s
4736/5900 (epoch 80.271) train_loss=116.25973511 time/batch=0.28s
4737/5900 (epoch 80.288) train_loss=106.16712952 time/batch=0.23s
4738/5900 (epoch 80.305) train_loss=202.15686035 time/batch=0.39s
4739/5900 (epoch 80.322) train_loss=143.18368530 time/batch=0.31s
4740/5900 (epoch 80.339) train_loss=189.39337158 time/batch=0.41s
4741/5900 (epoch 80.356) train_loss=155.26150513 time/batch=0.33s
4742/5900 (epoch 80.373) train_loss=69.14616394 time/batch=0.20s
4743/5900 (epoch 80.390) train_loss=60.41096497 time/batch=0.17s
4744/5900 (epoch 80.407) train_loss=116.47058868 time/batch=0.25s
4745/5900 (epoch 80.424) train_loss=139.45098877 time/batch=0.28s
4746/5900 (epoch 80.441) train_loss=145.83776855 time/batch=0.31s
4747/5900 (epoch 80.458) train_loss=179.26092529 time/batch=0.36s
4748/5900 (epoch 80.475) train_loss=69.31434631 time/batch=0.20s
4749/5900 (epoch 80.492) train_loss=178.65148926 time/batch=0.34s
4750/5900 (epoch 80.508) train_loss=175.44781494 time/batch=0.36s
4751/5900 (epoch 80.525) train_loss=151.18653870 time/batch=0.34s
4752/5900 (epoch 80.542) train_loss=167.42214966 time/batch=0.36s
4753/5900 (epoch 80.559) train_loss=65.26562500 time/batch=0.22s
4754/5900 (epoch 80.576) train_loss=134.34716797 time/batch=1.75s
4755/5900 (epoch 80.593) train_loss=159.76657104 time/batch=0.59s
4756/5900 (epoch 80.610) train_loss=90.70272827 time/batch=0.21s
4757/5900 (epoch 80.627) train_loss=106.71859741 time/batch=0.20s
4758/5900 (epoch 80.644) train_loss=69.28100586 time/batch=0.20s
4759/5900 (epoch 80.661) train_loss=144.84411621 time/batch=0.28s
4760/5900 (epoch 80.678) train_loss=175.37065125 time/batch=0.36s
4761/5900 (epoch 80.695) train_loss=121.98030853 time/batch=0.28s
4762/5900 (epoch 80.712) train_loss=78.49316406 time/batch=0.20s
4763/5900 (epoch 80.729) train_loss=140.01957703 time/batch=0.28s
4764/5900 (epoch 80.746) train_loss=125.68856812 time/batch=1.73s
4765/5900 (epoch 80.763) train_loss=173.61584473 time/batch=0.66s
4766/5900 (epoch 80.780) train_loss=82.83943176 time/batch=0.22s
4767/5900 (epoch 80.797) train_loss=86.33666229 time/batch=0.28s
4768/5900 (epoch 80.814) train_loss=70.14521790 time/batch=0.20s
4769/5900 (epoch 80.831) train_loss=75.32688141 time/batch=0.19s
4770/5900 (epoch 80.847) train_loss=74.50236511 time/batch=0.17s
4771/5900 (epoch 80.864) train_loss=67.92970276 time/batch=0.17s
4772/5900 (epoch 80.881) train_loss=74.18032074 time/batch=0.19s
4773/5900 (epoch 80.898) train_loss=70.96423340 time/batch=0.18s
4774/5900 (epoch 80.915) train_loss=75.84274292 time/batch=0.19s
4775/5900 (epoch 80.932) train_loss=76.88884735 time/batch=0.17s
4776/5900 (epoch 80.949) train_loss=78.70313263 time/batch=0.19s
4777/5900 (epoch 80.966) train_loss=71.19253540 time/batch=0.19s
4778/5900 (epoch 80.983) train_loss=76.12355042 time/batch=0.19s
4779/5900 (epoch 81.000) train_loss=73.22061920 time/batch=0.17s
setting learning rate to 0.0004824
4780/5900 (epoch 81.017) train_loss=521.62048340 time/batch=2.04s
4781/5900 (epoch 81.034) train_loss=420.08361816 time/batch=1.14s
4782/5900 (epoch 81.051) train_loss=211.76829529 time/batch=0.52s
4783/5900 (epoch 81.068) train_loss=112.03727722 time/batch=0.28s
4784/5900 (epoch 81.085) train_loss=168.79522705 time/batch=0.34s
4785/5900 (epoch 81.102) train_loss=71.03971100 time/batch=0.20s
4786/5900 (epoch 81.119) train_loss=184.88095093 time/batch=0.36s
4787/5900 (epoch 81.136) train_loss=171.64294434 time/batch=0.37s
4788/5900 (epoch 81.153) train_loss=114.63606262 time/batch=0.28s
4789/5900 (epoch 81.169) train_loss=186.52774048 time/batch=0.38s
4790/5900 (epoch 81.186) train_loss=137.09190369 time/batch=0.33s
4791/5900 (epoch 81.203) train_loss=105.04493713 time/batch=0.23s
4792/5900 (epoch 81.220) train_loss=561.80718994 time/batch=2.64s
4793/5900 (epoch 81.237) train_loss=111.50859833 time/batch=0.69s
4794/5900 (epoch 81.254) train_loss=245.61828613 time/batch=0.46s
4795/5900 (epoch 81.271) train_loss=150.48947144 time/batch=0.36s
4796/5900 (epoch 81.288) train_loss=199.01307678 time/batch=0.42s
4797/5900 (epoch 81.305) train_loss=230.77229309 time/batch=0.44s
4798/5900 (epoch 81.322) train_loss=112.60256195 time/batch=0.30s
4799/5900 (epoch 81.339) train_loss=210.09060669 time/batch=0.45s
4800/5900 (epoch 81.356) train_loss=178.24069214 time/batch=0.39s
4801/5900 (epoch 81.373) train_loss=154.76596069 time/batch=0.33s
4802/5900 (epoch 81.390) train_loss=95.96939850 time/batch=0.23s
4803/5900 (epoch 81.407) train_loss=179.20120239 time/batch=0.35s
4804/5900 (epoch 81.424) train_loss=150.96343994 time/batch=0.34s
4805/5900 (epoch 81.441) train_loss=66.51312256 time/batch=0.20s
4806/5900 (epoch 81.458) train_loss=180.70933533 time/batch=1.76s
4807/5900 (epoch 81.475) train_loss=131.64370728 time/batch=0.55s
4808/5900 (epoch 81.492) train_loss=62.57135010 time/batch=0.19s
4809/5900 (epoch 81.508) train_loss=131.97801208 time/batch=0.27s
4810/5900 (epoch 81.525) train_loss=148.92649841 time/batch=0.31s
4811/5900 (epoch 81.542) train_loss=73.00715637 time/batch=0.20s
4812/5900 (epoch 81.559) train_loss=181.52468872 time/batch=0.33s
4813/5900 (epoch 81.576) train_loss=191.40255737 time/batch=0.39s
4814/5900 (epoch 81.593) train_loss=164.92538452 time/batch=0.34s
4815/5900 (epoch 81.610) train_loss=79.80216217 time/batch=0.22s
4816/5900 (epoch 81.627) train_loss=77.74579620 time/batch=0.19s
4817/5900 (epoch 81.644) train_loss=67.14699554 time/batch=0.19s
4818/5900 (epoch 81.661) train_loss=98.31295013 time/batch=0.25s
4819/5900 (epoch 81.678) train_loss=133.78138733 time/batch=0.27s
4820/5900 (epoch 81.695) train_loss=131.77468872 time/batch=0.29s
4821/5900 (epoch 81.712) train_loss=87.13414001 time/batch=0.20s
4822/5900 (epoch 81.729) train_loss=69.82891846 time/batch=0.17s
4823/5900 (epoch 81.746) train_loss=155.61929321 time/batch=0.30s
4824/5900 (epoch 81.763) train_loss=76.83068848 time/batch=0.20s
4825/5900 (epoch 81.780) train_loss=71.45953369 time/batch=0.19s
4826/5900 (epoch 81.797) train_loss=71.51536560 time/batch=0.19s
4827/5900 (epoch 81.814) train_loss=76.47772217 time/batch=0.19s
4828/5900 (epoch 81.831) train_loss=65.95898438 time/batch=0.17s
4829/5900 (epoch 81.847) train_loss=75.95579529 time/batch=0.19s
4830/5900 (epoch 81.864) train_loss=142.34278870 time/batch=0.28s
4831/5900 (epoch 81.881) train_loss=76.04496765 time/batch=0.20s
4832/5900 (epoch 81.898) train_loss=153.59634399 time/batch=0.27s
4833/5900 (epoch 81.915) train_loss=89.80613708 time/batch=0.30s
4834/5900 (epoch 81.932) train_loss=68.75365448 time/batch=0.19s
4835/5900 (epoch 81.949) train_loss=70.35786438 time/batch=0.19s
4836/5900 (epoch 81.966) train_loss=74.27311707 time/batch=0.17s
4837/5900 (epoch 81.983) train_loss=74.26180267 time/batch=0.17s
4838/5900 (epoch 82.000) train_loss=72.75479126 time/batch=0.19s
setting learning rate to 0.0004679
4839/5900 (epoch 82.017) train_loss=166.57368469 time/batch=0.32s
4840/5900 (epoch 82.034) train_loss=121.17426300 time/batch=0.28s
4841/5900 (epoch 82.051) train_loss=168.07617188 time/batch=0.34s
4842/5900 (epoch 82.068) train_loss=811.40551758 time/batch=2.67s
4843/5900 (epoch 82.085) train_loss=100.95126343 time/batch=0.66s
4844/5900 (epoch 82.102) train_loss=203.26144409 time/batch=0.36s
4845/5900 (epoch 82.119) train_loss=168.10316467 time/batch=0.36s
4846/5900 (epoch 82.136) train_loss=338.09985352 time/batch=0.64s
4847/5900 (epoch 82.153) train_loss=307.92233276 time/batch=0.58s
4848/5900 (epoch 82.169) train_loss=132.34019470 time/batch=0.33s
4849/5900 (epoch 82.186) train_loss=181.09516907 time/batch=0.36s
4850/5900 (epoch 82.203) train_loss=107.60543823 time/batch=0.25s
4851/5900 (epoch 82.220) train_loss=232.64183044 time/batch=0.44s
4852/5900 (epoch 82.237) train_loss=128.28854370 time/batch=0.33s
4853/5900 (epoch 82.254) train_loss=186.96954346 time/batch=0.41s
4854/5900 (epoch 82.271) train_loss=235.46046448 time/batch=0.49s
4855/5900 (epoch 82.288) train_loss=184.89941406 time/batch=0.39s
4856/5900 (epoch 82.305) train_loss=191.12129211 time/batch=0.42s
4857/5900 (epoch 82.322) train_loss=136.23907471 time/batch=0.31s
4858/5900 (epoch 82.339) train_loss=207.50953674 time/batch=0.42s
4859/5900 (epoch 82.356) train_loss=165.64962769 time/batch=0.38s
4860/5900 (epoch 82.373) train_loss=109.11491394 time/batch=0.26s
4861/5900 (epoch 82.390) train_loss=107.19436646 time/batch=0.25s
4862/5900 (epoch 82.407) train_loss=177.85784912 time/batch=0.36s
4863/5900 (epoch 82.424) train_loss=70.10275269 time/batch=0.20s
4864/5900 (epoch 82.441) train_loss=63.24939728 time/batch=0.17s
4865/5900 (epoch 82.458) train_loss=145.12646484 time/batch=0.31s
4866/5900 (epoch 82.475) train_loss=62.20391464 time/batch=0.19s
4867/5900 (epoch 82.492) train_loss=95.04435730 time/batch=0.25s
4868/5900 (epoch 82.508) train_loss=97.21125031 time/batch=0.25s
4869/5900 (epoch 82.525) train_loss=141.28134155 time/batch=0.30s
4870/5900 (epoch 82.542) train_loss=121.41826630 time/batch=0.27s
4871/5900 (epoch 82.559) train_loss=122.00073242 time/batch=0.28s
4872/5900 (epoch 82.576) train_loss=125.71253967 time/batch=1.77s
4873/5900 (epoch 82.593) train_loss=152.12695312 time/batch=0.59s
4874/5900 (epoch 82.610) train_loss=162.27752686 time/batch=0.37s
4875/5900 (epoch 82.627) train_loss=69.58750916 time/batch=0.20s
4876/5900 (epoch 82.644) train_loss=146.49606323 time/batch=0.28s
4877/5900 (epoch 82.661) train_loss=70.56214142 time/batch=0.20s
4878/5900 (epoch 82.678) train_loss=74.61071777 time/batch=0.17s
4879/5900 (epoch 82.695) train_loss=200.95874023 time/batch=0.37s
4880/5900 (epoch 82.712) train_loss=152.86894226 time/batch=0.33s
4881/5900 (epoch 82.729) train_loss=91.36339569 time/batch=0.27s
4882/5900 (epoch 82.746) train_loss=78.65988159 time/batch=0.20s
4883/5900 (epoch 82.763) train_loss=69.80523682 time/batch=0.19s
4884/5900 (epoch 82.780) train_loss=122.68997955 time/batch=0.25s
4885/5900 (epoch 82.797) train_loss=129.68331909 time/batch=1.74s
4886/5900 (epoch 82.814) train_loss=128.78639221 time/batch=0.58s
4887/5900 (epoch 82.831) train_loss=75.14224243 time/batch=0.19s
4888/5900 (epoch 82.847) train_loss=67.75758362 time/batch=0.19s
4889/5900 (epoch 82.864) train_loss=73.36673737 time/batch=0.19s
4890/5900 (epoch 82.881) train_loss=70.78348541 time/batch=0.17s
4891/5900 (epoch 82.898) train_loss=69.95320129 time/batch=0.19s
4892/5900 (epoch 82.915) train_loss=97.05749512 time/batch=0.30s
4893/5900 (epoch 82.932) train_loss=76.00076294 time/batch=0.21s
4894/5900 (epoch 82.949) train_loss=77.54057312 time/batch=0.18s
4895/5900 (epoch 82.966) train_loss=68.60919189 time/batch=0.19s
4896/5900 (epoch 82.983) train_loss=70.74070740 time/batch=0.17s
4897/5900 (epoch 83.000) train_loss=77.66188049 time/batch=0.19s
setting learning rate to 0.0004539
4898/5900 (epoch 83.017) train_loss=166.01928711 time/batch=0.34s
4899/5900 (epoch 83.034) train_loss=824.78710938 time/batch=2.66s
4900/5900 (epoch 83.051) train_loss=121.90211487 time/batch=0.67s
4901/5900 (epoch 83.068) train_loss=181.33013916 time/batch=0.34s
4902/5900 (epoch 83.085) train_loss=111.48007965 time/batch=0.25s
4903/5900 (epoch 83.102) train_loss=242.04319763 time/batch=0.47s
4904/5900 (epoch 83.119) train_loss=204.17337036 time/batch=0.44s
4905/5900 (epoch 83.136) train_loss=309.04388428 time/batch=0.61s
4906/5900 (epoch 83.153) train_loss=124.61751556 time/batch=0.34s
4907/5900 (epoch 83.169) train_loss=171.49591064 time/batch=0.36s
4908/5900 (epoch 83.186) train_loss=176.82951355 time/batch=1.79s
4909/5900 (epoch 83.203) train_loss=176.44589233 time/batch=0.64s
4910/5900 (epoch 83.220) train_loss=122.99373627 time/batch=0.30s
4911/5900 (epoch 83.237) train_loss=289.41299438 time/batch=0.63s
4912/5900 (epoch 83.254) train_loss=127.68804932 time/batch=0.35s
4913/5900 (epoch 83.271) train_loss=135.61169434 time/batch=0.29s
4914/5900 (epoch 83.288) train_loss=80.64736938 time/batch=0.20s
4915/5900 (epoch 83.305) train_loss=185.76261902 time/batch=0.38s
4916/5900 (epoch 83.322) train_loss=169.07543945 time/batch=0.37s
4917/5900 (epoch 83.339) train_loss=194.60058594 time/batch=0.42s
4918/5900 (epoch 83.356) train_loss=60.64286804 time/batch=0.22s
4919/5900 (epoch 83.373) train_loss=147.29092407 time/batch=0.31s
4920/5900 (epoch 83.390) train_loss=204.74749756 time/batch=0.42s
4921/5900 (epoch 83.407) train_loss=144.59228516 time/batch=0.33s
4922/5900 (epoch 83.424) train_loss=221.70803833 time/batch=0.44s
4923/5900 (epoch 83.441) train_loss=145.75471497 time/batch=0.33s
4924/5900 (epoch 83.458) train_loss=74.22982788 time/batch=0.21s
4925/5900 (epoch 83.475) train_loss=110.87847137 time/batch=0.25s
4926/5900 (epoch 83.492) train_loss=143.63494873 time/batch=0.31s
4927/5900 (epoch 83.508) train_loss=91.35664368 time/batch=0.22s
4928/5900 (epoch 83.525) train_loss=156.23341370 time/batch=0.31s
4929/5900 (epoch 83.542) train_loss=106.91355896 time/batch=0.25s
4930/5900 (epoch 83.559) train_loss=65.01927185 time/batch=0.19s
4931/5900 (epoch 83.576) train_loss=88.95823669 time/batch=0.24s
4932/5900 (epoch 83.593) train_loss=125.19020844 time/batch=0.30s
4933/5900 (epoch 83.610) train_loss=151.55224609 time/batch=0.33s
4934/5900 (epoch 83.627) train_loss=117.65286255 time/batch=0.28s
4935/5900 (epoch 83.644) train_loss=154.58546448 time/batch=0.33s
4936/5900 (epoch 83.661) train_loss=201.39666748 time/batch=0.45s
4937/5900 (epoch 83.678) train_loss=74.72563171 time/batch=0.24s
4938/5900 (epoch 83.695) train_loss=182.89669800 time/batch=0.33s
4939/5900 (epoch 83.712) train_loss=64.65238190 time/batch=0.20s
4940/5900 (epoch 83.729) train_loss=80.83499146 time/batch=0.17s
4941/5900 (epoch 83.746) train_loss=74.67798615 time/batch=0.19s
4942/5900 (epoch 83.763) train_loss=76.35942078 time/batch=0.19s
4943/5900 (epoch 83.780) train_loss=76.51123810 time/batch=0.19s
4944/5900 (epoch 83.797) train_loss=122.00666046 time/batch=0.25s
4945/5900 (epoch 83.814) train_loss=71.13244629 time/batch=0.20s
4946/5900 (epoch 83.831) train_loss=68.95716858 time/batch=0.17s
4947/5900 (epoch 83.847) train_loss=125.23115540 time/batch=0.31s
4948/5900 (epoch 83.864) train_loss=72.38859558 time/batch=0.21s
4949/5900 (epoch 83.881) train_loss=72.37644958 time/batch=0.19s
4950/5900 (epoch 83.898) train_loss=71.75772858 time/batch=0.17s
4951/5900 (epoch 83.915) train_loss=68.05828857 time/batch=0.17s
4952/5900 (epoch 83.932) train_loss=72.71325684 time/batch=0.19s
4953/5900 (epoch 83.949) train_loss=71.93122101 time/batch=0.19s
4954/5900 (epoch 83.966) train_loss=74.81996918 time/batch=0.17s
4955/5900 (epoch 83.983) train_loss=68.53601074 time/batch=0.19s
4956/5900 (epoch 84.000) train_loss=66.55765533 time/batch=0.19s
setting learning rate to 0.0004403
4957/5900 (epoch 84.017) train_loss=170.77273560 time/batch=0.36s
4958/5900 (epoch 84.034) train_loss=136.59500122 time/batch=0.31s
4959/5900 (epoch 84.051) train_loss=143.08468628 time/batch=0.31s
4960/5900 (epoch 84.068) train_loss=131.88011169 time/batch=1.78s
4961/5900 (epoch 84.085) train_loss=810.35961914 time/batch=2.92s
4962/5900 (epoch 84.102) train_loss=133.82083130 time/batch=0.69s
4963/5900 (epoch 84.119) train_loss=219.89421082 time/batch=0.42s
4964/5900 (epoch 84.136) train_loss=324.49035645 time/batch=0.66s
4965/5900 (epoch 84.153) train_loss=114.38567352 time/batch=0.33s
4966/5900 (epoch 84.169) train_loss=190.47966003 time/batch=0.42s
4967/5900 (epoch 84.186) train_loss=178.52633667 time/batch=0.41s
4968/5900 (epoch 84.203) train_loss=203.34365845 time/batch=0.45s
4969/5900 (epoch 84.220) train_loss=102.03158569 time/batch=0.26s
4970/5900 (epoch 84.237) train_loss=272.20153809 time/batch=0.51s
4971/5900 (epoch 84.254) train_loss=184.33525085 time/batch=0.43s
4972/5900 (epoch 84.271) train_loss=104.48931885 time/batch=0.28s
4973/5900 (epoch 84.288) train_loss=91.38670349 time/batch=0.20s
4974/5900 (epoch 84.305) train_loss=165.34191895 time/batch=0.34s
4975/5900 (epoch 84.322) train_loss=234.64788818 time/batch=0.48s
4976/5900 (epoch 84.339) train_loss=126.38098145 time/batch=0.30s
4977/5900 (epoch 84.356) train_loss=116.57329559 time/batch=0.29s
4978/5900 (epoch 84.373) train_loss=123.71994781 time/batch=0.28s
4979/5900 (epoch 84.390) train_loss=114.85000610 time/batch=0.27s
4980/5900 (epoch 84.407) train_loss=164.58573914 time/batch=0.34s
4981/5900 (epoch 84.424) train_loss=151.79924011 time/batch=0.33s
4982/5900 (epoch 84.441) train_loss=97.23917389 time/batch=0.28s
4983/5900 (epoch 84.458) train_loss=137.13450623 time/batch=0.30s
4984/5900 (epoch 84.475) train_loss=177.09497070 time/batch=0.36s
4985/5900 (epoch 84.492) train_loss=108.47573853 time/batch=1.74s
4986/5900 (epoch 84.508) train_loss=150.76535034 time/batch=0.58s
4987/5900 (epoch 84.525) train_loss=128.93139648 time/batch=0.28s
4988/5900 (epoch 84.542) train_loss=167.67611694 time/batch=0.34s
4989/5900 (epoch 84.559) train_loss=84.74587250 time/batch=0.22s
4990/5900 (epoch 84.576) train_loss=151.21655273 time/batch=0.33s
4991/5900 (epoch 84.593) train_loss=115.35711670 time/batch=0.30s
4992/5900 (epoch 84.610) train_loss=72.82355499 time/batch=0.19s
4993/5900 (epoch 84.627) train_loss=151.19422913 time/batch=0.28s
4994/5900 (epoch 84.644) train_loss=193.01554871 time/batch=0.41s
4995/5900 (epoch 84.661) train_loss=150.09025574 time/batch=0.34s
4996/5900 (epoch 84.678) train_loss=106.81498718 time/batch=0.28s
4997/5900 (epoch 84.695) train_loss=76.51776123 time/batch=0.33s
4998/5900 (epoch 84.712) train_loss=74.51464844 time/batch=0.20s
4999/5900 (epoch 84.729) train_loss=71.06793976 time/batch=0.19s
Validating
    loss:	275.474182

5000/5900 (epoch 84.746) train_loss=76.74523926 time/batch=0.63s
5001/5900 (epoch 84.763) train_loss=73.11271667 time/batch=0.19s
5002/5900 (epoch 84.780) train_loss=119.48682404 time/batch=0.31s
5003/5900 (epoch 84.797) train_loss=67.53084564 time/batch=0.19s
5004/5900 (epoch 84.814) train_loss=152.48899841 time/batch=0.36s
5005/5900 (epoch 84.831) train_loss=68.32093811 time/batch=0.21s
5006/5900 (epoch 84.847) train_loss=74.14230347 time/batch=0.19s
5007/5900 (epoch 84.864) train_loss=72.22624207 time/batch=0.17s
5008/5900 (epoch 84.881) train_loss=73.09057617 time/batch=0.19s
5009/5900 (epoch 84.898) train_loss=71.98435211 time/batch=0.17s
5010/5900 (epoch 84.915) train_loss=72.02587891 time/batch=0.19s
5011/5900 (epoch 84.932) train_loss=63.33351898 time/batch=0.17s
5012/5900 (epoch 84.949) train_loss=68.60739136 time/batch=0.18s
5013/5900 (epoch 84.966) train_loss=69.73776245 time/batch=0.17s
5014/5900 (epoch 84.983) train_loss=69.72859192 time/batch=0.17s
5015/5900 (epoch 85.000) train_loss=69.91345978 time/batch=0.19s
setting learning rate to 0.0004271
5016/5900 (epoch 85.017) train_loss=204.26045227 time/batch=0.42s
5017/5900 (epoch 85.034) train_loss=175.54289246 time/batch=0.39s
5018/5900 (epoch 85.051) train_loss=192.44781494 time/batch=1.78s
5019/5900 (epoch 85.068) train_loss=86.98362732 time/batch=0.48s
5020/5900 (epoch 85.085) train_loss=179.60621643 time/batch=0.36s
5021/5900 (epoch 85.102) train_loss=64.13694763 time/batch=0.20s
5022/5900 (epoch 85.119) train_loss=289.79467773 time/batch=0.56s
5023/5900 (epoch 85.136) train_loss=214.38064575 time/batch=0.46s
5024/5900 (epoch 85.153) train_loss=833.57678223 time/batch=2.68s
5025/5900 (epoch 85.169) train_loss=214.09982300 time/batch=0.83s
5026/5900 (epoch 85.186) train_loss=121.78389740 time/batch=0.28s
5027/5900 (epoch 85.203) train_loss=258.91607666 time/batch=0.59s
5028/5900 (epoch 85.220) train_loss=181.02429199 time/batch=0.45s
5029/5900 (epoch 85.237) train_loss=136.20095825 time/batch=0.34s
5030/5900 (epoch 85.254) train_loss=285.75180054 time/batch=0.63s
5031/5900 (epoch 85.271) train_loss=115.63081360 time/batch=0.33s
5032/5900 (epoch 85.288) train_loss=186.49679565 time/batch=0.40s
5033/5900 (epoch 85.305) train_loss=64.66566467 time/batch=0.21s
5034/5900 (epoch 85.322) train_loss=157.35789490 time/batch=0.34s
5035/5900 (epoch 85.339) train_loss=89.96163940 time/batch=0.22s
5036/5900 (epoch 85.356) train_loss=109.11598206 time/batch=0.25s
5037/5900 (epoch 85.373) train_loss=134.81094360 time/batch=0.30s
5038/5900 (epoch 85.390) train_loss=127.95291138 time/batch=0.30s
5039/5900 (epoch 85.407) train_loss=117.72917175 time/batch=0.30s
5040/5900 (epoch 85.424) train_loss=129.22381592 time/batch=0.28s
5041/5900 (epoch 85.441) train_loss=103.86249542 time/batch=0.24s
5042/5900 (epoch 85.458) train_loss=167.61416626 time/batch=0.34s
5043/5900 (epoch 85.475) train_loss=116.14431763 time/batch=0.27s
5044/5900 (epoch 85.492) train_loss=166.98472595 time/batch=0.34s
5045/5900 (epoch 85.508) train_loss=166.60791016 time/batch=0.36s
5046/5900 (epoch 85.525) train_loss=133.71090698 time/batch=0.31s
5047/5900 (epoch 85.542) train_loss=86.10469055 time/batch=0.24s
5048/5900 (epoch 85.559) train_loss=76.13591003 time/batch=0.19s
5049/5900 (epoch 85.576) train_loss=64.90501404 time/batch=0.19s
5050/5900 (epoch 85.593) train_loss=76.13729858 time/batch=0.19s
5051/5900 (epoch 85.610) train_loss=165.49246216 time/batch=0.34s
5052/5900 (epoch 85.627) train_loss=142.84741211 time/batch=0.31s
5053/5900 (epoch 85.644) train_loss=131.58462524 time/batch=0.30s
5054/5900 (epoch 85.661) train_loss=175.03727722 time/batch=0.45s
5055/5900 (epoch 85.678) train_loss=154.80635071 time/batch=0.35s
5056/5900 (epoch 85.695) train_loss=148.73521423 time/batch=0.33s
5057/5900 (epoch 85.712) train_loss=76.40401459 time/batch=0.20s
5058/5900 (epoch 85.729) train_loss=65.29274750 time/batch=0.17s
5059/5900 (epoch 85.746) train_loss=148.18804932 time/batch=0.30s
5060/5900 (epoch 85.763) train_loss=119.63970947 time/batch=0.28s
5061/5900 (epoch 85.780) train_loss=69.50369263 time/batch=0.19s
5062/5900 (epoch 85.797) train_loss=66.41417694 time/batch=0.17s
5063/5900 (epoch 85.814) train_loss=67.14620972 time/batch=0.19s
5064/5900 (epoch 85.831) train_loss=68.16377258 time/batch=0.17s
5065/5900 (epoch 85.847) train_loss=89.23335266 time/batch=0.23s
5066/5900 (epoch 85.864) train_loss=72.46475220 time/batch=0.19s
5067/5900 (epoch 85.881) train_loss=64.63511658 time/batch=0.19s
5068/5900 (epoch 85.898) train_loss=71.07534790 time/batch=0.17s
5069/5900 (epoch 85.915) train_loss=73.71023560 time/batch=0.19s
5070/5900 (epoch 85.932) train_loss=73.59407806 time/batch=0.17s
5071/5900 (epoch 85.949) train_loss=70.03488922 time/batch=0.19s
5072/5900 (epoch 85.966) train_loss=74.07283020 time/batch=0.17s
5073/5900 (epoch 85.983) train_loss=76.93746948 time/batch=0.19s
5074/5900 (epoch 86.000) train_loss=79.22462463 time/batch=0.19s
setting learning rate to 0.0004143
5075/5900 (epoch 86.017) train_loss=101.31097412 time/batch=0.24s
5076/5900 (epoch 86.034) train_loss=207.52062988 time/batch=0.47s
5077/5900 (epoch 86.051) train_loss=141.10510254 time/batch=0.33s
5078/5900 (epoch 86.068) train_loss=188.43859863 time/batch=0.38s
5079/5900 (epoch 86.085) train_loss=343.65396118 time/batch=0.58s
5080/5900 (epoch 86.102) train_loss=244.69332886 time/batch=0.60s
5081/5900 (epoch 86.119) train_loss=194.60421753 time/batch=0.45s
5082/5900 (epoch 86.136) train_loss=798.73986816 time/batch=2.66s
5083/5900 (epoch 86.153) train_loss=148.35798645 time/batch=0.76s
5084/5900 (epoch 86.169) train_loss=103.37071991 time/batch=0.25s
5085/5900 (epoch 86.186) train_loss=145.51087952 time/batch=0.33s
5086/5900 (epoch 86.203) train_loss=291.73257446 time/batch=0.63s
5087/5900 (epoch 86.220) train_loss=93.17565918 time/batch=0.28s
5088/5900 (epoch 86.237) train_loss=192.43453979 time/batch=0.41s
5089/5900 (epoch 86.254) train_loss=173.66551208 time/batch=0.39s
5090/5900 (epoch 86.271) train_loss=65.68218231 time/batch=0.20s
5091/5900 (epoch 86.288) train_loss=124.43080139 time/batch=0.28s
5092/5900 (epoch 86.305) train_loss=161.69467163 time/batch=0.36s
5093/5900 (epoch 86.322) train_loss=182.98664856 time/batch=1.78s
5094/5900 (epoch 86.339) train_loss=190.14738464 time/batch=0.66s
5095/5900 (epoch 86.356) train_loss=124.37425232 time/batch=0.30s
5096/5900 (epoch 86.373) train_loss=129.67263794 time/batch=0.31s
5097/5900 (epoch 86.390) train_loss=173.39236450 time/batch=0.44s
5098/5900 (epoch 86.407) train_loss=75.13197327 time/batch=0.22s
5099/5900 (epoch 86.424) train_loss=135.46662903 time/batch=0.31s
5100/5900 (epoch 86.441) train_loss=130.98056030 time/batch=0.30s
5101/5900 (epoch 86.458) train_loss=110.12617493 time/batch=0.27s
5102/5900 (epoch 86.475) train_loss=69.19023132 time/batch=0.20s
5103/5900 (epoch 86.492) train_loss=59.79003143 time/batch=0.17s
5104/5900 (epoch 86.508) train_loss=133.00019836 time/batch=0.30s
5105/5900 (epoch 86.525) train_loss=110.39178467 time/batch=0.27s
5106/5900 (epoch 86.542) train_loss=160.78326416 time/batch=0.35s
5107/5900 (epoch 86.559) train_loss=123.51376343 time/batch=0.28s
5108/5900 (epoch 86.576) train_loss=169.45640564 time/batch=0.34s
5109/5900 (epoch 86.593) train_loss=155.12402344 time/batch=0.33s
5110/5900 (epoch 86.610) train_loss=153.78115845 time/batch=0.34s
5111/5900 (epoch 86.627) train_loss=139.14321899 time/batch=0.30s
5112/5900 (epoch 86.644) train_loss=138.90191650 time/batch=0.34s
5113/5900 (epoch 86.661) train_loss=73.71215057 time/batch=0.21s
5114/5900 (epoch 86.678) train_loss=93.58088684 time/batch=0.22s
5115/5900 (epoch 86.695) train_loss=170.64892578 time/batch=0.33s
5116/5900 (epoch 86.712) train_loss=90.95617676 time/batch=0.22s
5117/5900 (epoch 86.729) train_loss=90.16105652 time/batch=0.24s
5118/5900 (epoch 86.746) train_loss=63.75129700 time/batch=0.19s
5119/5900 (epoch 86.763) train_loss=96.91354370 time/batch=0.25s
5120/5900 (epoch 86.780) train_loss=68.27511597 time/batch=0.19s
5121/5900 (epoch 86.797) train_loss=62.29209900 time/batch=0.19s
5122/5900 (epoch 86.814) train_loss=67.21266174 time/batch=0.19s
5123/5900 (epoch 86.831) train_loss=65.63922882 time/batch=0.17s
5124/5900 (epoch 86.847) train_loss=72.12570190 time/batch=0.19s
5125/5900 (epoch 86.864) train_loss=102.72932434 time/batch=0.33s
5126/5900 (epoch 86.881) train_loss=71.92773438 time/batch=0.20s
5127/5900 (epoch 86.898) train_loss=70.00438690 time/batch=0.17s
5128/5900 (epoch 86.915) train_loss=74.00928497 time/batch=0.19s
5129/5900 (epoch 86.932) train_loss=68.34899139 time/batch=0.19s
5130/5900 (epoch 86.949) train_loss=70.37683105 time/batch=0.17s
5131/5900 (epoch 86.966) train_loss=68.05210876 time/batch=0.19s
5132/5900 (epoch 86.983) train_loss=74.26023102 time/batch=0.19s
5133/5900 (epoch 87.000) train_loss=74.43430328 time/batch=0.17s
setting learning rate to 0.0004018
5134/5900 (epoch 87.017) train_loss=219.15794373 time/batch=0.45s
5135/5900 (epoch 87.034) train_loss=320.45959473 time/batch=0.59s
5136/5900 (epoch 87.051) train_loss=189.01327515 time/batch=0.39s
5137/5900 (epoch 87.068) train_loss=128.24913025 time/batch=0.30s
5138/5900 (epoch 87.085) train_loss=784.02124023 time/batch=2.66s
5139/5900 (epoch 87.102) train_loss=185.40493774 time/batch=0.81s
5140/5900 (epoch 87.119) train_loss=104.69856262 time/batch=0.28s
5141/5900 (epoch 87.136) train_loss=107.66903687 time/batch=0.25s
5142/5900 (epoch 87.153) train_loss=205.41882324 time/batch=0.42s
5143/5900 (epoch 87.169) train_loss=285.87661743 time/batch=0.66s
5144/5900 (epoch 87.186) train_loss=178.72723389 time/batch=1.83s
5145/5900 (epoch 87.203) train_loss=153.97015381 time/batch=0.62s
5146/5900 (epoch 87.220) train_loss=69.02047729 time/batch=0.22s
5147/5900 (epoch 87.237) train_loss=117.31629944 time/batch=0.27s
5148/5900 (epoch 87.254) train_loss=100.72000122 time/batch=0.25s
5149/5900 (epoch 87.271) train_loss=172.33341980 time/batch=0.37s
5150/5900 (epoch 87.288) train_loss=161.45196533 time/batch=0.38s
5151/5900 (epoch 87.305) train_loss=148.40742493 time/batch=0.34s
5152/5900 (epoch 87.322) train_loss=112.34114075 time/batch=0.27s
5153/5900 (epoch 87.339) train_loss=96.80308533 time/batch=0.23s
5154/5900 (epoch 87.356) train_loss=60.75911713 time/batch=0.17s
5155/5900 (epoch 87.373) train_loss=184.95156860 time/batch=0.39s
5156/5900 (epoch 87.390) train_loss=121.03005981 time/batch=0.30s
5157/5900 (epoch 87.407) train_loss=193.21731567 time/batch=0.41s
5158/5900 (epoch 87.424) train_loss=89.64903259 time/batch=0.23s
5159/5900 (epoch 87.441) train_loss=195.08555603 time/batch=0.42s
5160/5900 (epoch 87.458) train_loss=84.25754547 time/batch=0.23s
5161/5900 (epoch 87.475) train_loss=130.55522156 time/batch=0.28s
5162/5900 (epoch 87.492) train_loss=137.94354248 time/batch=0.33s
5163/5900 (epoch 87.508) train_loss=174.47055054 time/batch=0.39s
5164/5900 (epoch 87.525) train_loss=112.81694794 time/batch=0.30s
5165/5900 (epoch 87.542) train_loss=83.14575195 time/batch=0.22s
5166/5900 (epoch 87.559) train_loss=162.02047729 time/batch=0.33s
5167/5900 (epoch 87.576) train_loss=142.29025269 time/batch=0.34s
5168/5900 (epoch 87.593) train_loss=141.97489929 time/batch=0.31s
5169/5900 (epoch 87.610) train_loss=72.22868347 time/batch=0.19s
5170/5900 (epoch 87.627) train_loss=134.75439453 time/batch=0.28s
5171/5900 (epoch 87.644) train_loss=142.96124268 time/batch=0.31s
5172/5900 (epoch 87.661) train_loss=188.10003662 time/batch=0.47s
5173/5900 (epoch 87.678) train_loss=137.18824768 time/batch=0.33s
5174/5900 (epoch 87.695) train_loss=139.26296997 time/batch=0.33s
5175/5900 (epoch 87.712) train_loss=66.06331635 time/batch=0.19s
5176/5900 (epoch 87.729) train_loss=128.55609131 time/batch=0.31s
5177/5900 (epoch 87.746) train_loss=65.06079102 time/batch=0.19s
5178/5900 (epoch 87.763) train_loss=68.68223572 time/batch=0.19s
5179/5900 (epoch 87.780) train_loss=66.34806824 time/batch=0.17s
5180/5900 (epoch 87.797) train_loss=75.97825623 time/batch=0.19s
5181/5900 (epoch 87.814) train_loss=65.03572083 time/batch=0.19s
5182/5900 (epoch 87.831) train_loss=72.72404480 time/batch=0.19s
5183/5900 (epoch 87.847) train_loss=70.36988831 time/batch=0.19s
5184/5900 (epoch 87.864) train_loss=69.69067383 time/batch=0.17s
5185/5900 (epoch 87.881) train_loss=70.98024750 time/batch=0.17s
5186/5900 (epoch 87.898) train_loss=79.73786926 time/batch=0.19s
5187/5900 (epoch 87.915) train_loss=70.90437317 time/batch=0.19s
5188/5900 (epoch 87.932) train_loss=72.63044739 time/batch=0.19s
5189/5900 (epoch 87.949) train_loss=82.76512146 time/batch=0.19s
5190/5900 (epoch 87.966) train_loss=70.99035645 time/batch=0.19s
5191/5900 (epoch 87.983) train_loss=72.48996735 time/batch=0.17s
5192/5900 (epoch 88.000) train_loss=70.82176971 time/batch=0.19s
setting learning rate to 0.0003898
5193/5900 (epoch 88.017) train_loss=289.03991699 time/batch=0.62s
5194/5900 (epoch 88.034) train_loss=147.01364136 time/batch=0.38s
5195/5900 (epoch 88.051) train_loss=237.79486084 time/batch=0.52s
5196/5900 (epoch 88.068) train_loss=255.96513367 time/batch=0.49s
5197/5900 (epoch 88.085) train_loss=199.34945679 time/batch=0.41s
5198/5900 (epoch 88.102) train_loss=178.06242371 time/batch=1.78s
5199/5900 (epoch 88.119) train_loss=792.79058838 time/batch=2.92s
5200/5900 (epoch 88.136) train_loss=173.13912964 time/batch=0.80s
5201/5900 (epoch 88.153) train_loss=127.44700623 time/batch=0.31s
5202/5900 (epoch 88.169) train_loss=171.15403748 time/batch=0.39s
5203/5900 (epoch 88.186) train_loss=152.23895264 time/batch=0.35s
5204/5900 (epoch 88.203) train_loss=190.90739441 time/batch=0.44s
5205/5900 (epoch 88.220) train_loss=92.89944458 time/batch=0.25s
5206/5900 (epoch 88.237) train_loss=204.87066650 time/batch=0.45s
5207/5900 (epoch 88.254) train_loss=209.94018555 time/batch=0.55s
5208/5900 (epoch 88.271) train_loss=143.11834717 time/batch=0.36s
5209/5900 (epoch 88.288) train_loss=87.85141754 time/batch=0.23s
5210/5900 (epoch 88.305) train_loss=97.78327942 time/batch=0.23s
5211/5900 (epoch 88.322) train_loss=69.53656006 time/batch=0.19s
5212/5900 (epoch 88.339) train_loss=100.19377136 time/batch=0.25s
5213/5900 (epoch 88.356) train_loss=111.75447083 time/batch=0.27s
5214/5900 (epoch 88.373) train_loss=119.08731079 time/batch=0.28s
5215/5900 (epoch 88.390) train_loss=160.56390381 time/batch=0.39s
5216/5900 (epoch 88.407) train_loss=71.80079651 time/batch=0.22s
5217/5900 (epoch 88.424) train_loss=145.41729736 time/batch=0.31s
5218/5900 (epoch 88.441) train_loss=109.72784424 time/batch=0.27s
5219/5900 (epoch 88.458) train_loss=135.24856567 time/batch=0.31s
5220/5900 (epoch 88.475) train_loss=103.00032043 time/batch=0.25s
5221/5900 (epoch 88.492) train_loss=122.45155334 time/batch=0.27s
5222/5900 (epoch 88.508) train_loss=118.45152283 time/batch=0.28s
5223/5900 (epoch 88.525) train_loss=79.37831116 time/batch=0.20s
5224/5900 (epoch 88.542) train_loss=101.84703827 time/batch=0.26s
5225/5900 (epoch 88.559) train_loss=159.24232483 time/batch=0.33s
5226/5900 (epoch 88.576) train_loss=197.89297485 time/batch=0.41s
5227/5900 (epoch 88.593) train_loss=60.84832001 time/batch=0.20s
5228/5900 (epoch 88.610) train_loss=155.97106934 time/batch=0.30s
5229/5900 (epoch 88.627) train_loss=133.75564575 time/batch=0.31s
5230/5900 (epoch 88.644) train_loss=145.58103943 time/batch=0.34s
5231/5900 (epoch 88.661) train_loss=64.38478088 time/batch=0.19s
5232/5900 (epoch 88.678) train_loss=123.25168610 time/batch=0.28s
5233/5900 (epoch 88.695) train_loss=74.40332031 time/batch=0.20s
5234/5900 (epoch 88.712) train_loss=174.04580688 time/batch=0.38s
5235/5900 (epoch 88.729) train_loss=169.62457275 time/batch=0.36s
5236/5900 (epoch 88.746) train_loss=69.93582153 time/batch=0.21s
5237/5900 (epoch 88.763) train_loss=71.49603271 time/batch=0.19s
5238/5900 (epoch 88.780) train_loss=77.17250824 time/batch=0.19s
5239/5900 (epoch 88.797) train_loss=69.49028015 time/batch=0.19s
5240/5900 (epoch 88.814) train_loss=67.57971191 time/batch=0.18s
5241/5900 (epoch 88.831) train_loss=126.02986145 time/batch=0.33s
5242/5900 (epoch 88.847) train_loss=67.56388855 time/batch=0.20s
5243/5900 (epoch 88.864) train_loss=69.31912231 time/batch=0.17s
5244/5900 (epoch 88.881) train_loss=71.38108826 time/batch=0.19s
5245/5900 (epoch 88.898) train_loss=74.42060089 time/batch=0.19s
5246/5900 (epoch 88.915) train_loss=66.63804626 time/batch=0.17s
5247/5900 (epoch 88.932) train_loss=72.67045593 time/batch=0.19s
5248/5900 (epoch 88.949) train_loss=72.19651794 time/batch=0.17s
5249/5900 (epoch 88.966) train_loss=64.96712494 time/batch=0.19s
5250/5900 (epoch 88.983) train_loss=67.31798553 time/batch=0.17s
5251/5900 (epoch 89.000) train_loss=65.68177795 time/batch=0.18s
setting learning rate to 0.0003781
5252/5900 (epoch 89.017) train_loss=270.03387451 time/batch=0.59s
5253/5900 (epoch 89.034) train_loss=846.74987793 time/batch=2.72s
5254/5900 (epoch 89.051) train_loss=167.30528259 time/batch=0.75s
5255/5900 (epoch 89.068) train_loss=81.29814148 time/batch=0.22s
5256/5900 (epoch 89.085) train_loss=234.65959167 time/batch=0.45s
5257/5900 (epoch 89.102) train_loss=174.49240112 time/batch=0.44s
5258/5900 (epoch 89.119) train_loss=157.18618774 time/batch=0.36s
5259/5900 (epoch 89.136) train_loss=112.24337769 time/batch=0.28s
5260/5900 (epoch 89.153) train_loss=237.48146057 time/batch=0.62s
5261/5900 (epoch 89.169) train_loss=100.47758484 time/batch=0.28s
5262/5900 (epoch 89.186) train_loss=227.21669006 time/batch=0.62s
5263/5900 (epoch 89.203) train_loss=108.50714874 time/batch=0.31s
5264/5900 (epoch 89.220) train_loss=156.80120850 time/batch=0.36s
5265/5900 (epoch 89.237) train_loss=126.99613953 time/batch=0.31s
5266/5900 (epoch 89.254) train_loss=147.55459595 time/batch=0.36s
5267/5900 (epoch 89.271) train_loss=75.79736328 time/batch=0.22s
5268/5900 (epoch 89.288) train_loss=95.20903015 time/batch=0.22s
5269/5900 (epoch 89.305) train_loss=188.94604492 time/batch=0.41s
5270/5900 (epoch 89.322) train_loss=178.23388672 time/batch=0.45s
5271/5900 (epoch 89.339) train_loss=91.57518005 time/batch=0.24s
5272/5900 (epoch 89.356) train_loss=121.37828064 time/batch=1.76s
5273/5900 (epoch 89.373) train_loss=58.47569656 time/batch=0.45s
5274/5900 (epoch 89.390) train_loss=127.46589661 time/batch=0.30s
5275/5900 (epoch 89.407) train_loss=62.83844757 time/batch=0.19s
5276/5900 (epoch 89.424) train_loss=135.81533813 time/batch=0.31s
5277/5900 (epoch 89.441) train_loss=122.93747711 time/batch=1.74s
5278/5900 (epoch 89.458) train_loss=127.71287537 time/batch=0.55s
5279/5900 (epoch 89.475) train_loss=102.15639496 time/batch=0.27s
5280/5900 (epoch 89.492) train_loss=74.03095245 time/batch=0.19s
5281/5900 (epoch 89.508) train_loss=125.53879547 time/batch=0.29s
5282/5900 (epoch 89.525) train_loss=162.02627563 time/batch=0.36s
5283/5900 (epoch 89.542) train_loss=139.20785522 time/batch=0.33s
5284/5900 (epoch 89.559) train_loss=174.36495972 time/batch=0.39s
5285/5900 (epoch 89.576) train_loss=116.47231293 time/batch=0.30s
5286/5900 (epoch 89.593) train_loss=78.96488953 time/batch=0.21s
5287/5900 (epoch 89.610) train_loss=112.04324341 time/batch=0.27s
5288/5900 (epoch 89.627) train_loss=65.12018585 time/batch=0.19s
5289/5900 (epoch 89.644) train_loss=127.75540924 time/batch=0.28s
5290/5900 (epoch 89.661) train_loss=180.35522461 time/batch=0.37s
5291/5900 (epoch 89.678) train_loss=179.42140198 time/batch=0.39s
5292/5900 (epoch 89.695) train_loss=130.20352173 time/batch=0.31s
5293/5900 (epoch 89.712) train_loss=103.17845154 time/batch=0.28s
5294/5900 (epoch 89.729) train_loss=145.64555359 time/batch=0.33s
5295/5900 (epoch 89.746) train_loss=76.23442078 time/batch=0.21s
5296/5900 (epoch 89.763) train_loss=150.89562988 time/batch=0.33s
5297/5900 (epoch 89.780) train_loss=64.89667511 time/batch=0.20s
5298/5900 (epoch 89.797) train_loss=153.92425537 time/batch=0.33s
5299/5900 (epoch 89.814) train_loss=64.23071289 time/batch=0.20s
5300/5900 (epoch 89.831) train_loss=71.50048065 time/batch=0.19s
5301/5900 (epoch 89.847) train_loss=74.13873291 time/batch=0.19s
5302/5900 (epoch 89.864) train_loss=67.31257629 time/batch=0.17s
5303/5900 (epoch 89.881) train_loss=70.23059082 time/batch=0.19s
5304/5900 (epoch 89.898) train_loss=74.26706696 time/batch=0.19s
5305/5900 (epoch 89.915) train_loss=68.15885925 time/batch=0.19s
5306/5900 (epoch 89.932) train_loss=65.91297150 time/batch=0.18s
5307/5900 (epoch 89.949) train_loss=64.95614624 time/batch=0.19s
5308/5900 (epoch 89.966) train_loss=72.19340515 time/batch=0.17s
5309/5900 (epoch 89.983) train_loss=69.06763458 time/batch=0.19s
5310/5900 (epoch 90.000) train_loss=67.48898315 time/batch=0.17s
setting learning rate to 0.0003668
  saved to metadata/config5--20190119-190634.pkl
5311/5900 (epoch 90.017) train_loss=268.44122314 time/batch=7.56s
5312/5900 (epoch 90.034) train_loss=264.95388794 time/batch=0.53s
5313/5900 (epoch 90.051) train_loss=875.48291016 time/batch=2.69s
5314/5900 (epoch 90.068) train_loss=154.16781616 time/batch=0.76s
5315/5900 (epoch 90.085) train_loss=176.21914673 time/batch=0.39s
5316/5900 (epoch 90.102) train_loss=108.67726898 time/batch=0.30s
5317/5900 (epoch 90.119) train_loss=129.85058594 time/batch=1.78s
5318/5900 (epoch 90.136) train_loss=224.93417358 time/batch=0.75s
5319/5900 (epoch 90.153) train_loss=90.45899963 time/batch=0.25s
5320/5900 (epoch 90.169) train_loss=150.19210815 time/batch=0.36s
5321/5900 (epoch 90.186) train_loss=161.79368591 time/batch=0.39s
5322/5900 (epoch 90.203) train_loss=68.71650696 time/batch=0.22s
5323/5900 (epoch 90.220) train_loss=105.88914490 time/batch=0.25s
5324/5900 (epoch 90.237) train_loss=107.39334106 time/batch=1.72s
5325/5900 (epoch 90.254) train_loss=119.56681824 time/batch=0.56s
5326/5900 (epoch 90.271) train_loss=171.34201050 time/batch=0.42s
5327/5900 (epoch 90.288) train_loss=166.10043335 time/batch=0.39s
5328/5900 (epoch 90.305) train_loss=112.14620972 time/batch=0.28s
5329/5900 (epoch 90.322) train_loss=142.52761841 time/batch=0.31s
5330/5900 (epoch 90.339) train_loss=191.50360107 time/batch=0.42s
5331/5900 (epoch 90.356) train_loss=158.47763062 time/batch=0.37s
5332/5900 (epoch 90.373) train_loss=136.40679932 time/batch=0.33s
5333/5900 (epoch 90.390) train_loss=112.99768066 time/batch=0.30s
5334/5900 (epoch 90.407) train_loss=151.23664856 time/batch=0.34s
5335/5900 (epoch 90.424) train_loss=242.85897827 time/batch=0.64s
5336/5900 (epoch 90.441) train_loss=81.10283661 time/batch=0.27s
5337/5900 (epoch 90.458) train_loss=67.33420563 time/batch=0.19s
5338/5900 (epoch 90.475) train_loss=103.38833618 time/batch=0.22s
5339/5900 (epoch 90.492) train_loss=103.45793915 time/batch=0.23s
5340/5900 (epoch 90.508) train_loss=130.26800537 time/batch=0.31s
5341/5900 (epoch 90.525) train_loss=158.15522766 time/batch=0.36s
5342/5900 (epoch 90.542) train_loss=155.01928711 time/batch=0.34s
5343/5900 (epoch 90.559) train_loss=126.77293396 time/batch=0.30s
5344/5900 (epoch 90.576) train_loss=124.32344055 time/batch=0.30s
5345/5900 (epoch 90.593) train_loss=76.15870667 time/batch=0.20s
5346/5900 (epoch 90.610) train_loss=88.52272034 time/batch=0.23s
5347/5900 (epoch 90.627) train_loss=64.73507690 time/batch=0.19s
5348/5900 (epoch 90.644) train_loss=138.44058228 time/batch=0.32s
5349/5900 (epoch 90.661) train_loss=131.56684875 time/batch=0.28s
5350/5900 (epoch 90.678) train_loss=139.43508911 time/batch=0.31s
5351/5900 (epoch 90.695) train_loss=72.16039276 time/batch=0.21s
5352/5900 (epoch 90.712) train_loss=176.02409363 time/batch=0.39s
5353/5900 (epoch 90.729) train_loss=67.22274017 time/batch=0.21s
5354/5900 (epoch 90.746) train_loss=69.30614471 time/batch=0.19s
5355/5900 (epoch 90.763) train_loss=62.96947861 time/batch=0.19s
5356/5900 (epoch 90.780) train_loss=97.01579285 time/batch=0.25s
5357/5900 (epoch 90.797) train_loss=73.07434082 time/batch=0.19s
5358/5900 (epoch 90.814) train_loss=71.97970581 time/batch=0.19s
5359/5900 (epoch 90.831) train_loss=72.03687286 time/batch=0.19s
5360/5900 (epoch 90.847) train_loss=70.22897339 time/batch=0.18s
5361/5900 (epoch 90.864) train_loss=141.91188049 time/batch=0.33s
5362/5900 (epoch 90.881) train_loss=67.06392670 time/batch=0.20s
5363/5900 (epoch 90.898) train_loss=68.08612061 time/batch=0.18s
5364/5900 (epoch 90.915) train_loss=73.24395752 time/batch=0.19s
5365/5900 (epoch 90.932) train_loss=76.69142151 time/batch=0.25s
5366/5900 (epoch 90.949) train_loss=81.46000671 time/batch=0.27s
5367/5900 (epoch 90.966) train_loss=67.12741089 time/batch=0.18s
5368/5900 (epoch 90.983) train_loss=66.91244507 time/batch=0.19s
5369/5900 (epoch 91.000) train_loss=66.97428131 time/batch=0.17s
setting learning rate to 0.0003557
5370/5900 (epoch 91.017) train_loss=161.52108765 time/batch=0.39s
5371/5900 (epoch 91.034) train_loss=139.78718567 time/batch=0.33s
5372/5900 (epoch 91.051) train_loss=93.93419647 time/batch=0.23s
5373/5900 (epoch 91.068) train_loss=114.85643005 time/batch=0.27s
5374/5900 (epoch 91.085) train_loss=124.65757751 time/batch=0.31s
5375/5900 (epoch 91.102) train_loss=155.70309448 time/batch=0.33s
5376/5900 (epoch 91.119) train_loss=59.36535645 time/batch=0.20s
5377/5900 (epoch 91.136) train_loss=142.86476135 time/batch=0.31s
5378/5900 (epoch 91.153) train_loss=158.76492310 time/batch=0.36s
5379/5900 (epoch 91.169) train_loss=495.03137207 time/batch=2.05s
5380/5900 (epoch 91.186) train_loss=239.54368591 time/batch=0.77s
5381/5900 (epoch 91.203) train_loss=80.86470795 time/batch=0.25s
5382/5900 (epoch 91.220) train_loss=493.48339844 time/batch=2.62s
5383/5900 (epoch 91.237) train_loss=119.12496948 time/batch=0.72s
5384/5900 (epoch 91.254) train_loss=169.14707947 time/batch=0.41s
5385/5900 (epoch 91.271) train_loss=215.02156067 time/batch=0.52s
5386/5900 (epoch 91.288) train_loss=83.34105682 time/batch=0.25s
5387/5900 (epoch 91.305) train_loss=334.43145752 time/batch=1.37s
5388/5900 (epoch 91.322) train_loss=161.50944519 time/batch=0.55s
5389/5900 (epoch 91.339) train_loss=74.40634155 time/batch=0.22s
5390/5900 (epoch 91.356) train_loss=77.48876953 time/batch=0.21s
5391/5900 (epoch 91.373) train_loss=119.62030029 time/batch=0.29s
5392/5900 (epoch 91.390) train_loss=110.90250397 time/batch=0.28s
5393/5900 (epoch 91.407) train_loss=167.87811279 time/batch=0.38s
5394/5900 (epoch 91.424) train_loss=81.06549072 time/batch=0.25s
5395/5900 (epoch 91.441) train_loss=121.52081299 time/batch=0.28s
5396/5900 (epoch 91.458) train_loss=68.63541412 time/batch=0.20s
5397/5900 (epoch 91.475) train_loss=58.73291016 time/batch=0.19s
5398/5900 (epoch 91.492) train_loss=142.62066650 time/batch=0.30s
5399/5900 (epoch 91.508) train_loss=156.50689697 time/batch=0.36s
5400/5900 (epoch 91.525) train_loss=171.54302979 time/batch=0.40s
5401/5900 (epoch 91.542) train_loss=110.65840912 time/batch=0.27s
5402/5900 (epoch 91.559) train_loss=105.55698395 time/batch=0.25s
5403/5900 (epoch 91.576) train_loss=153.79411316 time/batch=0.33s
5404/5900 (epoch 91.593) train_loss=128.89459229 time/batch=1.78s
5405/5900 (epoch 91.610) train_loss=178.30981445 time/batch=0.67s
5406/5900 (epoch 91.627) train_loss=64.83302307 time/batch=0.22s
5407/5900 (epoch 91.644) train_loss=181.73042297 time/batch=0.41s
5408/5900 (epoch 91.661) train_loss=147.56474304 time/batch=0.38s
5409/5900 (epoch 91.678) train_loss=103.68340302 time/batch=0.28s
5410/5900 (epoch 91.695) train_loss=69.02967834 time/batch=0.19s
5411/5900 (epoch 91.712) train_loss=104.34210205 time/batch=0.25s
5412/5900 (epoch 91.729) train_loss=114.30786133 time/batch=1.72s
5413/5900 (epoch 91.746) train_loss=105.81820679 time/batch=0.53s
5414/5900 (epoch 91.763) train_loss=72.99478912 time/batch=0.25s
5415/5900 (epoch 91.780) train_loss=66.99290466 time/batch=0.19s
5416/5900 (epoch 91.797) train_loss=129.74913025 time/batch=0.31s
5417/5900 (epoch 91.814) train_loss=133.53666687 time/batch=0.31s
5418/5900 (epoch 91.831) train_loss=89.86520386 time/batch=0.30s
5419/5900 (epoch 91.847) train_loss=67.12832642 time/batch=0.19s
5420/5900 (epoch 91.864) train_loss=73.99379730 time/batch=0.19s
5421/5900 (epoch 91.881) train_loss=67.80815125 time/batch=0.19s
5422/5900 (epoch 91.898) train_loss=73.57994080 time/batch=0.17s
5423/5900 (epoch 91.915) train_loss=74.18405151 time/batch=0.19s
5424/5900 (epoch 91.932) train_loss=69.56033325 time/batch=0.19s
5425/5900 (epoch 91.949) train_loss=66.74847412 time/batch=0.17s
5426/5900 (epoch 91.966) train_loss=67.45703125 time/batch=0.19s
5427/5900 (epoch 91.983) train_loss=70.39059448 time/batch=0.17s
5428/5900 (epoch 92.000) train_loss=70.70167542 time/batch=0.19s
setting learning rate to 0.0003451
5429/5900 (epoch 92.017) train_loss=144.14869690 time/batch=0.34s
5430/5900 (epoch 92.034) train_loss=100.90173340 time/batch=0.28s
5431/5900 (epoch 92.051) train_loss=288.24639893 time/batch=0.63s
5432/5900 (epoch 92.068) train_loss=153.15579224 time/batch=0.38s
5433/5900 (epoch 92.085) train_loss=82.99773407 time/batch=0.22s
5434/5900 (epoch 92.102) train_loss=103.59741211 time/batch=0.27s
5435/5900 (epoch 92.119) train_loss=163.91549683 time/batch=0.39s
5436/5900 (epoch 92.136) train_loss=191.18914795 time/batch=0.44s
5437/5900 (epoch 92.153) train_loss=98.06513214 time/batch=0.28s
5438/5900 (epoch 92.169) train_loss=167.60604858 time/batch=0.37s
5439/5900 (epoch 92.186) train_loss=438.79934692 time/batch=2.05s
5440/5900 (epoch 92.203) train_loss=102.54902649 time/batch=0.56s
5441/5900 (epoch 92.220) train_loss=199.72328186 time/batch=0.41s
5442/5900 (epoch 92.237) train_loss=231.00152588 time/batch=0.46s
5443/5900 (epoch 92.254) train_loss=98.95645142 time/batch=0.28s
5444/5900 (epoch 92.271) train_loss=175.14233398 time/batch=1.77s
5445/5900 (epoch 92.288) train_loss=155.65745544 time/batch=0.63s
5446/5900 (epoch 92.305) train_loss=82.43701935 time/batch=0.22s
5447/5900 (epoch 92.322) train_loss=229.58917236 time/batch=0.81s
5448/5900 (epoch 92.339) train_loss=143.80154419 time/batch=0.42s
5449/5900 (epoch 92.356) train_loss=126.84873962 time/batch=0.31s
5450/5900 (epoch 92.373) train_loss=448.03906250 time/batch=2.64s
5451/5900 (epoch 92.390) train_loss=83.77356720 time/batch=0.64s
5452/5900 (epoch 92.407) train_loss=119.58448792 time/batch=0.28s
5453/5900 (epoch 92.424) train_loss=76.47811890 time/batch=0.22s
5454/5900 (epoch 92.441) train_loss=147.75274658 time/batch=0.33s
5455/5900 (epoch 92.458) train_loss=137.81033325 time/batch=0.34s
5456/5900 (epoch 92.475) train_loss=162.21162415 time/batch=0.41s
5457/5900 (epoch 92.492) train_loss=157.71881104 time/batch=0.37s
5458/5900 (epoch 92.508) train_loss=130.93940735 time/batch=0.31s
5459/5900 (epoch 92.525) train_loss=58.90355682 time/batch=0.19s
5460/5900 (epoch 92.542) train_loss=129.85456848 time/batch=0.31s
5461/5900 (epoch 92.559) train_loss=127.59302521 time/batch=0.27s
5462/5900 (epoch 92.576) train_loss=157.47033691 time/batch=0.36s
5463/5900 (epoch 92.593) train_loss=111.91263580 time/batch=0.28s
5464/5900 (epoch 92.610) train_loss=147.28929138 time/batch=0.44s
5465/5900 (epoch 92.627) train_loss=107.73651123 time/batch=0.30s
5466/5900 (epoch 92.644) train_loss=62.65300751 time/batch=0.19s
5467/5900 (epoch 92.661) train_loss=77.73626709 time/batch=0.27s
5468/5900 (epoch 92.678) train_loss=73.08135986 time/batch=0.20s
5469/5900 (epoch 92.695) train_loss=64.36138153 time/batch=0.17s
5470/5900 (epoch 92.712) train_loss=127.30965424 time/batch=0.28s
5471/5900 (epoch 92.729) train_loss=72.20700073 time/batch=0.20s
5472/5900 (epoch 92.746) train_loss=244.93846130 time/batch=1.36s
5473/5900 (epoch 92.763) train_loss=130.69013977 time/batch=0.50s
5474/5900 (epoch 92.780) train_loss=74.63792419 time/batch=0.20s
5475/5900 (epoch 92.797) train_loss=61.81532669 time/batch=0.17s
5476/5900 (epoch 92.814) train_loss=65.05061340 time/batch=0.17s
5477/5900 (epoch 92.831) train_loss=68.40051270 time/batch=0.19s
5478/5900 (epoch 92.847) train_loss=74.31687927 time/batch=0.28s
5479/5900 (epoch 92.864) train_loss=68.19303894 time/batch=0.20s
5480/5900 (epoch 92.881) train_loss=64.08181763 time/batch=0.17s
5481/5900 (epoch 92.898) train_loss=81.15325928 time/batch=0.28s
5482/5900 (epoch 92.915) train_loss=68.05575562 time/batch=0.20s
5483/5900 (epoch 92.932) train_loss=70.64148712 time/batch=0.18s
5484/5900 (epoch 92.949) train_loss=69.30812073 time/batch=0.19s
5485/5900 (epoch 92.966) train_loss=72.35824585 time/batch=0.17s
5486/5900 (epoch 92.983) train_loss=70.02490997 time/batch=0.19s
5487/5900 (epoch 93.000) train_loss=71.94701385 time/batch=0.17s
setting learning rate to 0.0003347
5488/5900 (epoch 93.017) train_loss=163.91354370 time/batch=1.77s
5489/5900 (epoch 93.034) train_loss=123.81936646 time/batch=0.58s
5490/5900 (epoch 93.051) train_loss=130.50225830 time/batch=0.32s
5491/5900 (epoch 93.068) train_loss=108.94159698 time/batch=0.26s
5492/5900 (epoch 93.085) train_loss=739.16064453 time/batch=2.66s
5493/5900 (epoch 93.102) train_loss=233.10758972 time/batch=0.86s
5494/5900 (epoch 93.119) train_loss=125.80410767 time/batch=0.30s
5495/5900 (epoch 93.136) train_loss=144.90142822 time/batch=0.36s
5496/5900 (epoch 93.153) train_loss=127.54422760 time/batch=0.33s
5497/5900 (epoch 93.169) train_loss=275.83013916 time/batch=0.62s
5498/5900 (epoch 93.186) train_loss=121.43203735 time/batch=0.34s
5499/5900 (epoch 93.203) train_loss=85.56515503 time/batch=0.22s
5500/5900 (epoch 93.220) train_loss=120.58470154 time/batch=0.29s
5501/5900 (epoch 93.237) train_loss=94.16232300 time/batch=0.27s
5502/5900 (epoch 93.254) train_loss=209.84747314 time/batch=0.46s
5503/5900 (epoch 93.271) train_loss=178.56303406 time/batch=0.40s
5504/5900 (epoch 93.288) train_loss=236.08071899 time/batch=0.64s
5505/5900 (epoch 93.305) train_loss=152.13281250 time/batch=0.41s
5506/5900 (epoch 93.322) train_loss=118.17467499 time/batch=0.30s
5507/5900 (epoch 93.339) train_loss=150.79893494 time/batch=0.34s
5508/5900 (epoch 93.356) train_loss=102.81916809 time/batch=0.27s
5509/5900 (epoch 93.373) train_loss=112.94926453 time/batch=0.30s
5510/5900 (epoch 93.390) train_loss=152.66931152 time/batch=0.36s
5511/5900 (epoch 93.407) train_loss=101.78833771 time/batch=0.26s
5512/5900 (epoch 93.424) train_loss=107.58226013 time/batch=0.27s
5513/5900 (epoch 93.441) train_loss=168.08522034 time/batch=0.41s
5514/5900 (epoch 93.458) train_loss=98.78255463 time/batch=0.25s
5515/5900 (epoch 93.475) train_loss=129.44027710 time/batch=0.31s
5516/5900 (epoch 93.492) train_loss=199.98377991 time/batch=0.64s
5517/5900 (epoch 93.508) train_loss=153.75393677 time/batch=0.40s
5518/5900 (epoch 93.525) train_loss=112.77163696 time/batch=0.31s
5519/5900 (epoch 93.542) train_loss=84.06097412 time/batch=0.21s
5520/5900 (epoch 93.559) train_loss=179.88601685 time/batch=0.39s
5521/5900 (epoch 93.576) train_loss=165.98016357 time/batch=0.41s
5522/5900 (epoch 93.593) train_loss=140.64410400 time/batch=0.34s
5523/5900 (epoch 93.610) train_loss=62.97650909 time/batch=0.20s
5524/5900 (epoch 93.627) train_loss=147.81768799 time/batch=0.34s
5525/5900 (epoch 93.644) train_loss=125.70544434 time/batch=0.33s
5526/5900 (epoch 93.661) train_loss=64.68258667 time/batch=0.20s
5527/5900 (epoch 93.678) train_loss=126.18592072 time/batch=0.36s
5528/5900 (epoch 93.695) train_loss=65.60152435 time/batch=0.22s
5529/5900 (epoch 93.712) train_loss=61.23690796 time/batch=0.17s
5530/5900 (epoch 93.729) train_loss=66.64279938 time/batch=0.19s
5531/5900 (epoch 93.746) train_loss=69.23146820 time/batch=0.19s
5532/5900 (epoch 93.763) train_loss=74.59387970 time/batch=0.19s
5533/5900 (epoch 93.780) train_loss=76.93470764 time/batch=0.19s
5534/5900 (epoch 93.797) train_loss=60.27425385 time/batch=0.19s
5535/5900 (epoch 93.814) train_loss=62.87656403 time/batch=0.17s
5536/5900 (epoch 93.831) train_loss=65.21852112 time/batch=0.18s
5537/5900 (epoch 93.847) train_loss=68.91134644 time/batch=0.19s
5538/5900 (epoch 93.864) train_loss=72.40632629 time/batch=0.17s
5539/5900 (epoch 93.881) train_loss=72.26162720 time/batch=0.19s
5540/5900 (epoch 93.898) train_loss=67.46505737 time/batch=0.19s
5541/5900 (epoch 93.915) train_loss=63.87701416 time/batch=0.17s
5542/5900 (epoch 93.932) train_loss=70.89115906 time/batch=0.19s
5543/5900 (epoch 93.949) train_loss=72.68215942 time/batch=0.19s
5544/5900 (epoch 93.966) train_loss=70.70861816 time/batch=0.19s
5545/5900 (epoch 93.983) train_loss=69.61088562 time/batch=0.17s
5546/5900 (epoch 94.000) train_loss=70.14604187 time/batch=0.19s
setting learning rate to 0.0003247
5547/5900 (epoch 94.017) train_loss=239.51179504 time/batch=0.55s
5548/5900 (epoch 94.034) train_loss=254.49392700 time/batch=0.64s
5549/5900 (epoch 94.051) train_loss=186.45764160 time/batch=1.84s
5550/5900 (epoch 94.068) train_loss=119.61029053 time/batch=0.56s
5551/5900 (epoch 94.085) train_loss=132.98466492 time/batch=0.34s
5552/5900 (epoch 94.102) train_loss=126.32777405 time/batch=0.33s
5553/5900 (epoch 94.119) train_loss=100.92205811 time/batch=0.28s
5554/5900 (epoch 94.136) train_loss=112.48638916 time/batch=0.27s
5555/5900 (epoch 94.153) train_loss=141.69432068 time/batch=0.34s
5556/5900 (epoch 94.169) train_loss=181.86683655 time/batch=0.41s
5557/5900 (epoch 94.186) train_loss=157.33599854 time/batch=0.42s
5558/5900 (epoch 94.203) train_loss=109.24729919 time/batch=0.31s
5559/5900 (epoch 94.220) train_loss=88.32507324 time/batch=0.22s
5560/5900 (epoch 94.237) train_loss=94.64766693 time/batch=0.24s
5561/5900 (epoch 94.254) train_loss=136.17671204 time/batch=0.33s
5562/5900 (epoch 94.271) train_loss=184.97447205 time/batch=0.44s
5563/5900 (epoch 94.288) train_loss=249.02609253 time/batch=0.66s
5564/5900 (epoch 94.305) train_loss=55.95967865 time/batch=0.25s
5565/5900 (epoch 94.322) train_loss=93.91384888 time/batch=0.23s
5566/5900 (epoch 94.339) train_loss=323.65982056 time/batch=2.05s
5567/5900 (epoch 94.356) train_loss=124.94542694 time/batch=0.62s
5568/5900 (epoch 94.373) train_loss=66.03363800 time/batch=0.20s
5569/5900 (epoch 94.390) train_loss=626.71105957 time/batch=2.64s
5570/5900 (epoch 94.407) train_loss=134.05081177 time/batch=0.75s
5571/5900 (epoch 94.424) train_loss=83.59417725 time/batch=0.22s
5572/5900 (epoch 94.441) train_loss=110.26943970 time/batch=0.27s
5573/5900 (epoch 94.458) train_loss=99.99839783 time/batch=0.27s
5574/5900 (epoch 94.475) train_loss=140.24728394 time/batch=0.34s
5575/5900 (epoch 94.492) train_loss=73.61290741 time/batch=0.22s
5576/5900 (epoch 94.508) train_loss=129.11264038 time/batch=0.30s
5577/5900 (epoch 94.525) train_loss=150.96905518 time/batch=0.35s
5578/5900 (epoch 94.542) train_loss=165.73461914 time/batch=0.41s
5579/5900 (epoch 94.559) train_loss=175.23284912 time/batch=0.39s
5580/5900 (epoch 94.576) train_loss=71.90891266 time/batch=0.22s
5581/5900 (epoch 94.593) train_loss=132.13314819 time/batch=0.30s
5582/5900 (epoch 94.610) train_loss=66.12838745 time/batch=0.21s
5583/5900 (epoch 94.627) train_loss=113.66085052 time/batch=0.28s
5584/5900 (epoch 94.644) train_loss=154.06591797 time/batch=0.36s
5585/5900 (epoch 94.661) train_loss=97.45337677 time/batch=0.25s
5586/5900 (epoch 94.678) train_loss=70.17105865 time/batch=0.19s
5587/5900 (epoch 94.695) train_loss=109.35957336 time/batch=0.28s
5588/5900 (epoch 94.712) train_loss=64.43986511 time/batch=0.19s
5589/5900 (epoch 94.729) train_loss=70.11662292 time/batch=0.19s
5590/5900 (epoch 94.746) train_loss=58.40793610 time/batch=0.19s
5591/5900 (epoch 94.763) train_loss=148.99295044 time/batch=0.33s
5592/5900 (epoch 94.780) train_loss=67.80742645 time/batch=0.21s
5593/5900 (epoch 94.797) train_loss=157.14877319 time/batch=0.34s
5594/5900 (epoch 94.814) train_loss=72.67149353 time/batch=0.22s
5595/5900 (epoch 94.831) train_loss=130.52897644 time/batch=0.34s
5596/5900 (epoch 94.847) train_loss=62.93215179 time/batch=0.20s
5597/5900 (epoch 94.864) train_loss=65.66419983 time/batch=0.19s
5598/5900 (epoch 94.881) train_loss=66.93659973 time/batch=0.17s
5599/5900 (epoch 94.898) train_loss=61.67270660 time/batch=0.19s
5600/5900 (epoch 94.915) train_loss=60.35161209 time/batch=0.17s
5601/5900 (epoch 94.932) train_loss=70.57544708 time/batch=0.19s
5602/5900 (epoch 94.949) train_loss=70.42404175 time/batch=0.19s
5603/5900 (epoch 94.966) train_loss=69.23846436 time/batch=0.17s
5604/5900 (epoch 94.983) train_loss=70.24293518 time/batch=0.19s
5605/5900 (epoch 95.000) train_loss=67.41435242 time/batch=0.19s
setting learning rate to 0.0003149
5606/5900 (epoch 95.017) train_loss=118.43843079 time/batch=0.30s
5607/5900 (epoch 95.034) train_loss=745.59558105 time/batch=2.66s
5608/5900 (epoch 95.051) train_loss=239.58259583 time/batch=0.80s
5609/5900 (epoch 95.068) train_loss=397.42346191 time/batch=0.64s
5610/5900 (epoch 95.085) train_loss=147.02770996 time/batch=0.38s
5611/5900 (epoch 95.102) train_loss=241.90185547 time/batch=0.52s
5612/5900 (epoch 95.119) train_loss=153.12698364 time/batch=0.41s
5613/5900 (epoch 95.136) train_loss=107.99869537 time/batch=0.29s
5614/5900 (epoch 95.153) train_loss=117.38815308 time/batch=0.30s
5615/5900 (epoch 95.169) train_loss=123.45133209 time/batch=0.33s
5616/5900 (epoch 95.186) train_loss=133.00350952 time/batch=0.33s
5617/5900 (epoch 95.203) train_loss=189.25384521 time/batch=0.44s
5618/5900 (epoch 95.220) train_loss=110.87260437 time/batch=0.31s
5619/5900 (epoch 95.237) train_loss=85.73956299 time/batch=0.22s
5620/5900 (epoch 95.254) train_loss=156.29798889 time/batch=0.41s
5621/5900 (epoch 95.271) train_loss=211.07196045 time/batch=0.48s
5622/5900 (epoch 95.288) train_loss=117.02271271 time/batch=0.33s
5623/5900 (epoch 95.305) train_loss=106.72003174 time/batch=0.28s
5624/5900 (epoch 95.322) train_loss=118.86602020 time/batch=0.30s
5625/5900 (epoch 95.339) train_loss=191.02890015 time/batch=0.47s
5626/5900 (epoch 95.356) train_loss=75.96244049 time/batch=0.25s
5627/5900 (epoch 95.373) train_loss=118.55831909 time/batch=0.28s
5628/5900 (epoch 95.390) train_loss=144.62200928 time/batch=0.36s
5629/5900 (epoch 95.407) train_loss=114.72981262 time/batch=0.33s
5630/5900 (epoch 95.424) train_loss=55.47063065 time/batch=0.19s
5631/5900 (epoch 95.441) train_loss=100.29086304 time/batch=0.25s
5632/5900 (epoch 95.458) train_loss=66.77609253 time/batch=0.19s
5633/5900 (epoch 95.475) train_loss=146.47247314 time/batch=0.33s
5634/5900 (epoch 95.492) train_loss=118.78387451 time/batch=1.78s
5635/5900 (epoch 95.508) train_loss=132.08459473 time/batch=0.61s
5636/5900 (epoch 95.525) train_loss=167.66319275 time/batch=0.39s
5637/5900 (epoch 95.542) train_loss=58.72120667 time/batch=0.20s
5638/5900 (epoch 95.559) train_loss=182.29708862 time/batch=0.39s
5639/5900 (epoch 95.576) train_loss=136.06538391 time/batch=0.32s
5640/5900 (epoch 95.593) train_loss=103.49440002 time/batch=0.25s
5641/5900 (epoch 95.610) train_loss=96.08376312 time/batch=0.26s
5642/5900 (epoch 95.627) train_loss=66.44187927 time/batch=0.19s
5643/5900 (epoch 95.644) train_loss=146.62611389 time/batch=0.34s
5644/5900 (epoch 95.661) train_loss=116.72332764 time/batch=0.34s
5645/5900 (epoch 95.678) train_loss=144.68359375 time/batch=0.36s
5646/5900 (epoch 95.695) train_loss=121.90845490 time/batch=0.36s
5647/5900 (epoch 95.712) train_loss=115.47303772 time/batch=1.74s
5648/5900 (epoch 95.729) train_loss=70.34803009 time/batch=0.47s
5649/5900 (epoch 95.746) train_loss=89.38992310 time/batch=0.21s
5650/5900 (epoch 95.763) train_loss=71.86400604 time/batch=0.20s
5651/5900 (epoch 95.780) train_loss=73.46481323 time/batch=0.18s
5652/5900 (epoch 95.797) train_loss=69.14095306 time/batch=0.19s
5653/5900 (epoch 95.814) train_loss=60.66287994 time/batch=0.19s
5654/5900 (epoch 95.831) train_loss=65.63213348 time/batch=0.19s
5655/5900 (epoch 95.847) train_loss=65.85528564 time/batch=0.17s
5656/5900 (epoch 95.864) train_loss=69.76246643 time/batch=0.19s
5657/5900 (epoch 95.881) train_loss=72.45779419 time/batch=0.19s
5658/5900 (epoch 95.898) train_loss=69.44541931 time/batch=0.19s
5659/5900 (epoch 95.915) train_loss=67.70271301 time/batch=0.19s
5660/5900 (epoch 95.932) train_loss=62.63455200 time/batch=0.17s
5661/5900 (epoch 95.949) train_loss=60.74560547 time/batch=0.19s
5662/5900 (epoch 95.966) train_loss=65.67299652 time/batch=0.17s
5663/5900 (epoch 95.983) train_loss=63.11624146 time/batch=0.17s
5664/5900 (epoch 96.000) train_loss=65.10533142 time/batch=0.19s
setting learning rate to 0.0003055
5665/5900 (epoch 96.017) train_loss=200.91845703 time/batch=0.50s
5666/5900 (epoch 96.034) train_loss=168.49580383 time/batch=0.41s
5667/5900 (epoch 96.051) train_loss=227.17033386 time/batch=0.48s
5668/5900 (epoch 96.068) train_loss=182.25018311 time/batch=0.44s
5669/5900 (epoch 96.085) train_loss=166.28933716 time/batch=0.42s
5670/5900 (epoch 96.102) train_loss=196.54724121 time/batch=0.46s
5671/5900 (epoch 96.119) train_loss=106.27827454 time/batch=0.31s
5672/5900 (epoch 96.136) train_loss=118.50706482 time/batch=0.30s
5673/5900 (epoch 96.153) train_loss=104.47708130 time/batch=0.30s
5674/5900 (epoch 96.169) train_loss=86.47581482 time/batch=0.22s
5675/5900 (epoch 96.186) train_loss=436.17984009 time/batch=2.05s
5676/5900 (epoch 96.203) train_loss=592.32934570 time/batch=2.95s
5677/5900 (epoch 96.220) train_loss=157.51870728 time/batch=0.77s
5678/5900 (epoch 96.237) train_loss=151.26110840 time/batch=0.36s
5679/5900 (epoch 96.254) train_loss=182.88687134 time/batch=0.53s
5680/5900 (epoch 96.271) train_loss=90.19343567 time/batch=0.28s
5681/5900 (epoch 96.288) train_loss=137.63011169 time/batch=0.33s
5682/5900 (epoch 96.305) train_loss=61.05583954 time/batch=0.21s
5683/5900 (epoch 96.322) train_loss=93.49250793 time/batch=0.23s
5684/5900 (epoch 96.339) train_loss=125.60266113 time/batch=1.77s
5685/5900 (epoch 96.356) train_loss=116.23835754 time/batch=0.56s
5686/5900 (epoch 96.373) train_loss=152.09860229 time/batch=0.39s
5687/5900 (epoch 96.390) train_loss=112.46243286 time/batch=0.30s
5688/5900 (epoch 96.407) train_loss=56.11461639 time/batch=0.19s
5689/5900 (epoch 96.424) train_loss=66.57592773 time/batch=0.19s
5690/5900 (epoch 96.441) train_loss=103.11404419 time/batch=0.25s
5691/5900 (epoch 96.458) train_loss=80.92287445 time/batch=0.22s
5692/5900 (epoch 96.475) train_loss=118.31056976 time/batch=0.30s
5693/5900 (epoch 96.492) train_loss=147.07043457 time/batch=0.36s
5694/5900 (epoch 96.508) train_loss=97.86695862 time/batch=0.27s
5695/5900 (epoch 96.525) train_loss=83.56555176 time/batch=0.25s
5696/5900 (epoch 96.542) train_loss=65.79283142 time/batch=0.20s
5697/5900 (epoch 96.559) train_loss=97.10176086 time/batch=1.71s
5698/5900 (epoch 96.576) train_loss=139.98312378 time/batch=0.58s
5699/5900 (epoch 96.593) train_loss=62.84793854 time/batch=0.20s
5700/5900 (epoch 96.610) train_loss=133.96595764 time/batch=0.31s
5701/5900 (epoch 96.627) train_loss=149.46820068 time/batch=0.35s
5702/5900 (epoch 96.644) train_loss=130.22021484 time/batch=0.31s
5703/5900 (epoch 96.661) train_loss=112.77871704 time/batch=0.27s
5704/5900 (epoch 96.678) train_loss=69.64880371 time/batch=0.20s
5705/5900 (epoch 96.695) train_loss=151.64521790 time/batch=0.35s
5706/5900 (epoch 96.712) train_loss=68.76344299 time/batch=0.22s
5707/5900 (epoch 96.729) train_loss=65.28992462 time/batch=0.17s
5708/5900 (epoch 96.746) train_loss=110.66336060 time/batch=0.28s
5709/5900 (epoch 96.763) train_loss=62.75437164 time/batch=0.19s
5710/5900 (epoch 96.780) train_loss=70.30841827 time/batch=0.19s
5711/5900 (epoch 96.797) train_loss=109.19941711 time/batch=0.30s
5712/5900 (epoch 96.814) train_loss=157.87963867 time/batch=0.40s
5713/5900 (epoch 96.831) train_loss=142.82200623 time/batch=0.33s
5714/5900 (epoch 96.847) train_loss=86.68826294 time/batch=0.33s
5715/5900 (epoch 96.864) train_loss=65.99711609 time/batch=0.19s
5716/5900 (epoch 96.881) train_loss=65.59588623 time/batch=0.17s
5717/5900 (epoch 96.898) train_loss=64.62767792 time/batch=0.19s
5718/5900 (epoch 96.915) train_loss=68.58997345 time/batch=0.19s
5719/5900 (epoch 96.932) train_loss=61.77041626 time/batch=0.19s
5720/5900 (epoch 96.949) train_loss=68.18778229 time/batch=0.17s
5721/5900 (epoch 96.966) train_loss=69.60652924 time/batch=0.19s
5722/5900 (epoch 96.983) train_loss=69.59864807 time/batch=0.19s
5723/5900 (epoch 97.000) train_loss=70.16547394 time/batch=0.17s
setting learning rate to 0.0002963
5724/5900 (epoch 97.017) train_loss=141.46713257 time/batch=0.38s
5725/5900 (epoch 97.034) train_loss=115.06788635 time/batch=1.78s
5726/5900 (epoch 97.051) train_loss=271.41125488 time/batch=0.95s
5727/5900 (epoch 97.068) train_loss=151.00271606 time/batch=0.42s
5728/5900 (epoch 97.085) train_loss=770.28192139 time/batch=2.66s
5729/5900 (epoch 97.102) train_loss=217.96261597 time/batch=0.86s
5730/5900 (epoch 97.119) train_loss=129.80160522 time/batch=0.31s
5731/5900 (epoch 97.136) train_loss=196.02851868 time/batch=0.44s
5732/5900 (epoch 97.153) train_loss=76.60390472 time/batch=0.23s
5733/5900 (epoch 97.169) train_loss=200.28591919 time/batch=0.48s
5734/5900 (epoch 97.186) train_loss=122.50277710 time/batch=0.35s
5735/5900 (epoch 97.203) train_loss=62.70349503 time/batch=0.20s
5736/5900 (epoch 97.220) train_loss=143.02780151 time/batch=0.33s
5737/5900 (epoch 97.237) train_loss=108.19432831 time/batch=0.28s
5738/5900 (epoch 97.254) train_loss=53.55456161 time/batch=0.19s
5739/5900 (epoch 97.271) train_loss=97.89320374 time/batch=0.25s
5740/5900 (epoch 97.288) train_loss=100.17730713 time/batch=1.72s
5741/5900 (epoch 97.305) train_loss=155.44708252 time/batch=0.66s
5742/5900 (epoch 97.322) train_loss=95.12155151 time/batch=0.26s
5743/5900 (epoch 97.339) train_loss=149.40338135 time/batch=0.34s
5744/5900 (epoch 97.356) train_loss=98.71000671 time/batch=0.28s
5745/5900 (epoch 97.373) train_loss=141.63442993 time/batch=0.33s
5746/5900 (epoch 97.390) train_loss=234.45593262 time/batch=0.53s
5747/5900 (epoch 97.407) train_loss=70.89004517 time/batch=0.24s
5748/5900 (epoch 97.424) train_loss=98.23745728 time/batch=0.24s
5749/5900 (epoch 97.441) train_loss=138.65676880 time/batch=0.36s
5750/5900 (epoch 97.458) train_loss=167.57730103 time/batch=0.42s
5751/5900 (epoch 97.475) train_loss=66.06376648 time/batch=0.20s
5752/5900 (epoch 97.492) train_loss=91.50917053 time/batch=0.22s
5753/5900 (epoch 97.508) train_loss=91.72698975 time/batch=0.23s
5754/5900 (epoch 97.525) train_loss=60.69295502 time/batch=0.19s
5755/5900 (epoch 97.542) train_loss=120.67276764 time/batch=0.28s
5756/5900 (epoch 97.559) train_loss=139.90441895 time/batch=0.34s
5757/5900 (epoch 97.576) train_loss=166.08798218 time/batch=0.31s
5758/5900 (epoch 97.593) train_loss=73.61389160 time/batch=0.20s
5759/5900 (epoch 97.610) train_loss=192.29141235 time/batch=0.44s
5760/5900 (epoch 97.627) train_loss=138.11529541 time/batch=0.38s
5761/5900 (epoch 97.644) train_loss=66.85314941 time/batch=0.20s
5762/5900 (epoch 97.661) train_loss=75.13066864 time/batch=0.19s
5763/5900 (epoch 97.678) train_loss=143.09457397 time/batch=0.36s
5764/5900 (epoch 97.695) train_loss=108.56391907 time/batch=0.28s
5765/5900 (epoch 97.712) train_loss=128.56875610 time/batch=0.33s
5766/5900 (epoch 97.729) train_loss=68.69465637 time/batch=0.20s
5767/5900 (epoch 97.746) train_loss=114.22842407 time/batch=0.28s
5768/5900 (epoch 97.763) train_loss=118.31575775 time/batch=0.30s
5769/5900 (epoch 97.780) train_loss=115.11054993 time/batch=0.30s
5770/5900 (epoch 97.797) train_loss=90.18296814 time/batch=0.26s
5771/5900 (epoch 97.814) train_loss=65.12790680 time/batch=0.19s
5772/5900 (epoch 97.831) train_loss=132.48454285 time/batch=0.30s
5773/5900 (epoch 97.847) train_loss=64.49499512 time/batch=0.20s
5774/5900 (epoch 97.864) train_loss=69.47151184 time/batch=0.17s
5775/5900 (epoch 97.881) train_loss=59.96901703 time/batch=0.19s
5776/5900 (epoch 97.898) train_loss=75.27426910 time/batch=0.28s
5777/5900 (epoch 97.915) train_loss=62.94873428 time/batch=0.19s
5778/5900 (epoch 97.932) train_loss=67.26166534 time/batch=0.19s
5779/5900 (epoch 97.949) train_loss=65.63438416 time/batch=0.17s
5780/5900 (epoch 97.966) train_loss=65.83224487 time/batch=0.19s
5781/5900 (epoch 97.983) train_loss=68.56967163 time/batch=0.19s
5782/5900 (epoch 98.000) train_loss=66.87176514 time/batch=0.17s
setting learning rate to 0.0002874
5783/5900 (epoch 98.017) train_loss=630.58331299 time/batch=2.64s
5784/5900 (epoch 98.034) train_loss=92.41329956 time/batch=0.67s
5785/5900 (epoch 98.051) train_loss=86.84539795 time/batch=0.26s
5786/5900 (epoch 98.068) train_loss=112.83525085 time/batch=0.27s
5787/5900 (epoch 98.085) train_loss=137.42892456 time/batch=0.35s
5788/5900 (epoch 98.102) train_loss=77.89035797 time/batch=0.24s
5789/5900 (epoch 98.119) train_loss=366.61550903 time/batch=1.37s
5790/5900 (epoch 98.136) train_loss=129.23788452 time/batch=0.51s
5791/5900 (epoch 98.153) train_loss=154.33685303 time/batch=0.39s
5792/5900 (epoch 98.169) train_loss=127.09699249 time/batch=1.78s
5793/5900 (epoch 98.186) train_loss=118.38594818 time/batch=0.60s
5794/5900 (epoch 98.203) train_loss=77.77226257 time/batch=0.23s
5795/5900 (epoch 98.220) train_loss=97.14431000 time/batch=0.25s
5796/5900 (epoch 98.237) train_loss=122.39743805 time/batch=0.33s
5797/5900 (epoch 98.254) train_loss=186.01403809 time/batch=0.42s
5798/5900 (epoch 98.271) train_loss=100.20656586 time/batch=0.29s
5799/5900 (epoch 98.288) train_loss=133.35809326 time/batch=0.33s
5800/5900 (epoch 98.305) train_loss=224.82981873 time/batch=0.52s
5801/5900 (epoch 98.322) train_loss=105.80726624 time/batch=0.33s
5802/5900 (epoch 98.339) train_loss=108.64261627 time/batch=0.28s
5803/5900 (epoch 98.356) train_loss=123.89699554 time/batch=0.31s
5804/5900 (epoch 98.373) train_loss=151.66596985 time/batch=0.39s
5805/5900 (epoch 98.390) train_loss=114.77465057 time/batch=0.31s
5806/5900 (epoch 98.407) train_loss=59.82904053 time/batch=0.20s
5807/5900 (epoch 98.424) train_loss=113.08119965 time/batch=0.44s
5808/5900 (epoch 98.441) train_loss=140.23611450 time/batch=0.34s
5809/5900 (epoch 98.458) train_loss=113.94831848 time/batch=0.30s
5810/5900 (epoch 98.475) train_loss=199.03927612 time/batch=0.45s
5811/5900 (epoch 98.492) train_loss=172.28118896 time/batch=0.42s
5812/5900 (epoch 98.508) train_loss=173.86042786 time/batch=0.49s
5813/5900 (epoch 98.525) train_loss=169.56953430 time/batch=0.49s
5814/5900 (epoch 98.542) train_loss=120.47041321 time/batch=0.34s
5815/5900 (epoch 98.559) train_loss=145.79061890 time/batch=0.35s
5816/5900 (epoch 98.576) train_loss=84.41861725 time/batch=0.24s
5817/5900 (epoch 98.593) train_loss=166.39169312 time/batch=0.45s
5818/5900 (epoch 98.610) train_loss=66.51115417 time/batch=0.23s
5819/5900 (epoch 98.627) train_loss=65.88988495 time/batch=0.19s
5820/5900 (epoch 98.644) train_loss=134.67662048 time/batch=0.30s
5821/5900 (epoch 98.661) train_loss=147.57702637 time/batch=0.37s
5822/5900 (epoch 98.678) train_loss=142.45620728 time/batch=0.36s
5823/5900 (epoch 98.695) train_loss=98.84872437 time/batch=0.28s
5824/5900 (epoch 98.712) train_loss=58.89915466 time/batch=0.19s
5825/5900 (epoch 98.729) train_loss=66.60588837 time/batch=0.19s
5826/5900 (epoch 98.746) train_loss=79.00600433 time/batch=0.24s
5827/5900 (epoch 98.763) train_loss=97.90146637 time/batch=1.72s
5828/5900 (epoch 98.780) train_loss=70.53376770 time/batch=0.47s
5829/5900 (epoch 98.797) train_loss=65.28016663 time/batch=0.17s
5830/5900 (epoch 98.814) train_loss=71.35627747 time/batch=0.19s
5831/5900 (epoch 98.831) train_loss=61.50973892 time/batch=0.17s
5832/5900 (epoch 98.847) train_loss=67.47143555 time/batch=0.19s
5833/5900 (epoch 98.864) train_loss=62.45265198 time/batch=0.17s
5834/5900 (epoch 98.881) train_loss=62.10010910 time/batch=0.19s
5835/5900 (epoch 98.898) train_loss=69.08409119 time/batch=0.17s
5836/5900 (epoch 98.915) train_loss=69.32058716 time/batch=0.19s
5837/5900 (epoch 98.932) train_loss=66.11616516 time/batch=0.17s
5838/5900 (epoch 98.949) train_loss=68.30340576 time/batch=0.19s
5839/5900 (epoch 98.966) train_loss=72.67163086 time/batch=0.19s
5840/5900 (epoch 98.983) train_loss=66.96002960 time/batch=0.17s
5841/5900 (epoch 99.000) train_loss=68.96640015 time/batch=0.19s
setting learning rate to 0.0002788
5842/5900 (epoch 99.017) train_loss=627.65686035 time/batch=2.61s
5843/5900 (epoch 99.034) train_loss=84.01970673 time/batch=0.65s
5844/5900 (epoch 99.051) train_loss=178.74737549 time/batch=0.37s
5845/5900 (epoch 99.068) train_loss=111.08457947 time/batch=0.28s
5846/5900 (epoch 99.085) train_loss=93.94587708 time/batch=0.27s
5847/5900 (epoch 99.102) train_loss=82.93101501 time/batch=0.22s
5848/5900 (epoch 99.119) train_loss=255.18154907 time/batch=0.59s
5849/5900 (epoch 99.136) train_loss=170.95733643 time/batch=0.45s
5850/5900 (epoch 99.153) train_loss=160.14575195 time/batch=1.78s
5851/5900 (epoch 99.169) train_loss=136.72836304 time/batch=0.62s
5852/5900 (epoch 99.186) train_loss=89.23916626 time/batch=0.27s
5853/5900 (epoch 99.203) train_loss=185.69953918 time/batch=0.43s
5854/5900 (epoch 99.220) train_loss=137.06433105 time/batch=0.36s
5855/5900 (epoch 99.237) train_loss=188.76940918 time/batch=0.50s
5856/5900 (epoch 99.254) train_loss=70.40417480 time/batch=0.23s
5857/5900 (epoch 99.271) train_loss=123.57019043 time/batch=0.30s
5858/5900 (epoch 99.288) train_loss=154.12709045 time/batch=0.41s
5859/5900 (epoch 99.305) train_loss=95.24084473 time/batch=0.28s
5860/5900 (epoch 99.322) train_loss=81.06048584 time/batch=0.22s
5861/5900 (epoch 99.339) train_loss=177.30203247 time/batch=0.44s
5862/5900 (epoch 99.356) train_loss=144.44648743 time/batch=0.37s
5863/5900 (epoch 99.373) train_loss=92.89625549 time/batch=0.25s
5864/5900 (epoch 99.390) train_loss=125.90908051 time/batch=0.30s
5865/5900 (epoch 99.407) train_loss=105.71446228 time/batch=0.29s
5866/5900 (epoch 99.424) train_loss=134.93907166 time/batch=0.33s
5867/5900 (epoch 99.441) train_loss=325.12615967 time/batch=1.39s
5868/5900 (epoch 99.458) train_loss=76.41506958 time/batch=0.44s
5869/5900 (epoch 99.475) train_loss=123.32046509 time/batch=0.31s
5870/5900 (epoch 99.492) train_loss=120.90238190 time/batch=0.31s
5871/5900 (epoch 99.508) train_loss=121.11752319 time/batch=0.30s
5872/5900 (epoch 99.525) train_loss=157.16024780 time/batch=0.39s
5873/5900 (epoch 99.542) train_loss=61.11693192 time/batch=0.20s
5874/5900 (epoch 99.559) train_loss=114.06441498 time/batch=0.28s
5875/5900 (epoch 99.576) train_loss=119.33628845 time/batch=0.27s
5876/5900 (epoch 99.593) train_loss=114.55277252 time/batch=0.30s
5877/5900 (epoch 99.610) train_loss=129.51925659 time/batch=0.34s
5878/5900 (epoch 99.627) train_loss=157.05636597 time/batch=0.36s
5879/5900 (epoch 99.644) train_loss=68.19893646 time/batch=0.22s
5880/5900 (epoch 99.661) train_loss=71.00396729 time/batch=0.19s
5881/5900 (epoch 99.678) train_loss=83.91058350 time/batch=0.27s
5882/5900 (epoch 99.695) train_loss=116.38755798 time/batch=0.30s
5883/5900 (epoch 99.712) train_loss=140.05387878 time/batch=0.36s
5884/5900 (epoch 99.729) train_loss=63.70343781 time/batch=0.22s
5885/5900 (epoch 99.746) train_loss=67.71215057 time/batch=0.17s
5886/5900 (epoch 99.763) train_loss=66.48405457 time/batch=0.19s
5887/5900 (epoch 99.780) train_loss=64.67364502 time/batch=0.19s
5888/5900 (epoch 99.797) train_loss=139.08476257 time/batch=0.34s
5889/5900 (epoch 99.814) train_loss=71.12568665 time/batch=0.21s
5890/5900 (epoch 99.831) train_loss=89.37612152 time/batch=0.35s
5891/5900 (epoch 99.847) train_loss=58.58866119 time/batch=0.20s
5892/5900 (epoch 99.864) train_loss=66.15732574 time/batch=0.19s
5893/5900 (epoch 99.881) train_loss=62.21606827 time/batch=0.19s
5894/5900 (epoch 99.898) train_loss=61.98096466 time/batch=0.17s
5895/5900 (epoch 99.915) train_loss=65.09599304 time/batch=0.17s
5896/5900 (epoch 99.932) train_loss=63.84851074 time/batch=0.19s
5897/5900 (epoch 99.949) train_loss=60.43629074 time/batch=0.17s
5898/5900 (epoch 99.966) train_loss=62.31924057 time/batch=0.17s
5899/5900 (epoch 99.983) train_loss=69.02873230 time/batch=0.19s
5900/5900 (epoch 100.000) train_loss=62.34525681 time/batch=0.17s
setting learning rate to 0.0002705
  saved to metadata/config5--20190119-190634.pkl
