set([' ', '\xa7', '(', '\xab', ',', '0', '4', '8', '<', '\xc3', 'D', 'H', 'L', 'P', 'T', 'X', 'd', 'h', 'l', 'p', 't', 'x', '|', '\x80', '\x98', '\xa4', "'", '/', '3', '\xb4', '7', ';', '\xbc', '?', 'C', 'G', 'K', 'O', 'S', 'W', '[', '_', 'c', 'g', 'k', 'o', 's', 'w', '\n', '\x99', '&', '.', '2', '6', ':', '>', 'B', 'F', 'J', 'N', 'R', 'V', 'Z', '^', 'b', 'f', 'j', 'n', 'r', 'v', 'z', '!', '%', ')', '\xaa', '-', '1', '5', '\xb6', '9', '=', 'A', 'E', 'I', 'M', 'Q', 'U', 'Y', ']', 'a', '\xe2', 'e', 'i', 'm', 'q', 'u', 'y'])
['</s>', ' ', '\xa7', '(', '\xab', ',', '0', '4', '8', '<', '\xc3', 'D', 'H', 'L', 'P', 'T', 'X', 'd', 'h', 'l', 'p', 't', 'x', '|', '\x80', '\x98', '\xa4', "'", '/', '3', '\xb4', '7', ';', '\xbc', '?', 'C', 'G', 'K', 'O', 'S', 'W', '[', '_', 'c', 'g', 'k', 'o', 's', 'w', '\n', '\x99', '&', '<s>', '.', '2', '6', ':', '>', 'B', 'F', 'J', 'N', 'R', 'V', 'Z', '^', 'b', 'f', 'j', 'n', 'r', 'v', 'z', '!', '%', ')', '\xaa', '-', '1', '5', '\xb6', '9', '=', 'A', 'E', 'I', 'M', 'Q', 'U', 'Y', ']', 'a', '\xe2', 'e', 'i', 'm', 'q', 'u', 'y']
vocabulary size: 99
{'</s>': 0, ' ': 1, '\xa7': 2, '(': 3, '\xab': 4, ',': 5, '0': 6, '4': 7, '8': 8, '<': 9, '\xc3': 10, 'D': 11, 'H': 12, 'L': 13, 'P': 14, 'T': 15, 'X': 16, 'd': 17, 'h': 18, 'l': 19, 'p': 20, 't': 21, 'x': 22, '|': 23, '\x80': 24, '\x98': 25, '\xa4': 26, "'": 27, '/': 28, '3': 29, '\xb4': 30, '7': 31, ';': 32, '\xbc': 33, '?': 34, 'C': 35, 'G': 36, 'K': 37, 'O': 38, 'S': 39, 'W': 40, '[': 41, '_': 42, 'c': 43, 'g': 44, 'k': 45, 'o': 46, 's': 47, 'w': 48, '\n': 49, '\x99': 50, '&': 51, '<s>': 52, '.': 53, '2': 54, '6': 55, ':': 56, '>': 57, 'B': 58, 'F': 59, 'J': 60, 'N': 61, 'R': 62, 'V': 63, 'Z': 64, '^': 65, 'b': 66, 'f': 67, 'j': 68, 'n': 69, 'r': 70, 'v': 71, 'z': 72, '!': 73, '%': 74, ')': 75, '\xaa': 76, '-': 77, '1': 78, '5': 79, '\xb6': 80, '9': 81, '=': 82, 'A': 83, 'E': 84, 'I': 85, 'M': 86, 'Q': 87, 'U': 88, 'Y': 89, ']': 90, 'a': 91, '\xe2': 92, 'e': 93, 'i': 94, 'm': 95, 'q': 96, 'u': 97, 'y': 98}
999
n tunes: 999
n train tunes: 951
n validation tunes: 48
min, max length 367 2323
Building the model
  number of parameters: 5515436
  layer output shapes:               #params:   output shape:
    InputLayer                       0          (16, None)
    EmbeddingLayer                   9801       (16, None, 99)
    InputLayer                       0          (16, None)
    LSTMLayer                        1254400    (16, None, 512)
    DropoutLayer                     0          (16, None, 512)
    LSTMLayer                        2100224    (16, None, 512)
    DropoutLayer                     0          (16, None, 512)
    LSTMLayer                        2100224    (16, None, 512)
    DropoutLayer                     0          (16, None, 512)
    ReshapeLayer                     0          (None, 512)
    DenseLayer                       50787      (None, 99)
Train model
1/5900 (epoch 0.017) train_loss=2552.52636719 time/batch=1.57s
2/5900 (epoch 0.034) train_loss=2375.95068359 time/batch=0.65s
3/5900 (epoch 0.051) train_loss=2651.97460938 time/batch=1.45s
4/5900 (epoch 0.068) train_loss=2449.60693359 time/batch=2.54s
5/5900 (epoch 0.085) train_loss=2415.36621094 time/batch=0.86s
6/5900 (epoch 0.102) train_loss=2433.16943359 time/batch=0.78s
7/5900 (epoch 0.119) train_loss=2330.90380859 time/batch=0.77s
8/5900 (epoch 0.136) train_loss=2538.08935547 time/batch=2.17s
9/5900 (epoch 0.153) train_loss=2066.92333984 time/batch=1.39s
10/5900 (epoch 0.169) train_loss=2424.64404297 time/batch=0.85s
11/5900 (epoch 0.186) train_loss=2287.66894531 time/batch=2.50s
12/5900 (epoch 0.203) train_loss=2010.04541016 time/batch=0.79s
13/5900 (epoch 0.220) train_loss=2628.36816406 time/batch=1.52s
14/5900 (epoch 0.237) train_loss=2002.56164551 time/batch=0.72s
15/5900 (epoch 0.254) train_loss=2202.46899414 time/batch=0.77s
16/5900 (epoch 0.271) train_loss=1982.36474609 time/batch=1.31s
17/5900 (epoch 0.288) train_loss=1927.68420410 time/batch=0.69s
18/5900 (epoch 0.305) train_loss=2054.43359375 time/batch=0.69s
19/5900 (epoch 0.322) train_loss=1754.29089355 time/batch=0.70s
20/5900 (epoch 0.339) train_loss=1733.87109375 time/batch=0.59s
21/5900 (epoch 0.356) train_loss=2401.82348633 time/batch=0.84s
22/5900 (epoch 0.373) train_loss=1758.45349121 time/batch=1.20s
23/5900 (epoch 0.390) train_loss=1742.70239258 time/batch=0.63s
24/5900 (epoch 0.407) train_loss=2024.70922852 time/batch=1.28s
25/5900 (epoch 0.424) train_loss=2645.47827148 time/batch=1.60s
26/5900 (epoch 0.441) train_loss=1853.84960938 time/batch=0.69s
27/5900 (epoch 0.458) train_loss=2019.09106445 time/batch=0.70s
28/5900 (epoch 0.475) train_loss=1738.98925781 time/batch=0.60s
29/5900 (epoch 0.492) train_loss=1958.44750977 time/batch=0.67s
30/5900 (epoch 0.508) train_loss=2069.18017578 time/batch=0.71s
31/5900 (epoch 0.525) train_loss=1789.72534180 time/batch=0.63s
32/5900 (epoch 0.542) train_loss=1817.02551270 time/batch=0.61s
33/5900 (epoch 0.559) train_loss=1638.77075195 time/batch=0.57s
34/5900 (epoch 0.576) train_loss=1698.13439941 time/batch=0.62s
35/5900 (epoch 0.593) train_loss=2540.54443359 time/batch=0.94s
36/5900 (epoch 0.610) train_loss=2178.58935547 time/batch=1.82s
37/5900 (epoch 0.627) train_loss=2399.00903320 time/batch=0.83s
38/5900 (epoch 0.644) train_loss=1877.71875000 time/batch=0.66s
39/5900 (epoch 0.661) train_loss=2058.93505859 time/batch=0.71s
40/5900 (epoch 0.678) train_loss=2339.69677734 time/batch=2.36s
41/5900 (epoch 0.695) train_loss=1778.32812500 time/batch=1.32s
42/5900 (epoch 0.712) train_loss=1995.38403320 time/batch=0.72s
43/5900 (epoch 0.729) train_loss=2227.25585938 time/batch=0.78s
44/5900 (epoch 0.746) train_loss=2096.91577148 time/batch=0.76s
45/5900 (epoch 0.763) train_loss=1972.58508301 time/batch=0.70s
46/5900 (epoch 0.780) train_loss=1742.61389160 time/batch=0.61s
47/5900 (epoch 0.797) train_loss=2345.14160156 time/batch=2.97s
48/5900 (epoch 0.814) train_loss=2189.72705078 time/batch=1.50s
49/5900 (epoch 0.831) train_loss=1845.30224609 time/batch=0.70s
50/5900 (epoch 0.847) train_loss=2380.18603516 time/batch=1.00s
51/5900 (epoch 0.864) train_loss=1875.41833496 time/batch=0.67s
52/5900 (epoch 0.881) train_loss=1862.48779297 time/batch=0.67s
53/5900 (epoch 0.898) train_loss=1793.08349609 time/batch=0.65s
54/5900 (epoch 0.915) train_loss=2075.54541016 time/batch=0.73s
55/5900 (epoch 0.932) train_loss=1734.61889648 time/batch=0.61s
56/5900 (epoch 0.949) train_loss=1741.72363281 time/batch=0.64s
57/5900 (epoch 0.966) train_loss=2055.94580078 time/batch=0.76s
58/5900 (epoch 0.983) train_loss=1930.19458008 time/batch=1.00s
59/5900 (epoch 1.000) train_loss=1770.74108887 time/batch=0.77s
60/5900 (epoch 1.017) train_loss=3204.25024414 time/batch=2.90s
61/5900 (epoch 1.034) train_loss=2009.67309570 time/batch=0.77s
62/5900 (epoch 1.051) train_loss=1753.92480469 time/batch=0.59s
63/5900 (epoch 1.068) train_loss=1719.78393555 time/batch=1.22s
64/5900 (epoch 1.085) train_loss=2068.20800781 time/batch=1.39s
65/5900 (epoch 1.102) train_loss=2317.83496094 time/batch=0.88s
66/5900 (epoch 1.119) train_loss=2330.54980469 time/batch=0.84s
67/5900 (epoch 1.136) train_loss=2213.00341797 time/batch=0.81s
68/5900 (epoch 1.153) train_loss=2101.16845703 time/batch=0.77s
69/5900 (epoch 1.169) train_loss=2284.05712891 time/batch=0.80s
70/5900 (epoch 1.186) train_loss=1764.91601562 time/batch=0.63s
71/5900 (epoch 1.203) train_loss=1807.99584961 time/batch=0.65s
72/5900 (epoch 1.220) train_loss=1734.38940430 time/batch=1.21s
73/5900 (epoch 1.237) train_loss=1881.33398438 time/batch=0.72s
74/5900 (epoch 1.254) train_loss=2246.02294922 time/batch=2.47s
75/5900 (epoch 1.271) train_loss=2015.76208496 time/batch=0.79s
76/5900 (epoch 1.288) train_loss=2232.40087891 time/batch=1.13s
77/5900 (epoch 1.305) train_loss=2022.56298828 time/batch=1.81s
78/5900 (epoch 1.322) train_loss=2696.02221680 time/batch=2.53s
79/5900 (epoch 1.339) train_loss=2108.00268555 time/batch=0.84s
80/5900 (epoch 1.356) train_loss=2340.57324219 time/batch=1.57s
81/5900 (epoch 1.373) train_loss=1988.73291016 time/batch=0.78s
82/5900 (epoch 1.390) train_loss=1913.06018066 time/batch=0.73s
83/5900 (epoch 1.407) train_loss=1662.18627930 time/batch=0.61s
84/5900 (epoch 1.424) train_loss=2035.66235352 time/batch=0.72s
85/5900 (epoch 1.441) train_loss=2582.13842773 time/batch=1.50s
86/5900 (epoch 1.458) train_loss=1778.24768066 time/batch=0.66s
87/5900 (epoch 1.475) train_loss=1957.63659668 time/batch=1.19s
88/5900 (epoch 1.492) train_loss=1589.73486328 time/batch=0.60s
89/5900 (epoch 1.508) train_loss=2173.87280273 time/batch=0.79s
90/5900 (epoch 1.525) train_loss=2062.36816406 time/batch=0.78s
91/5900 (epoch 1.542) train_loss=1816.78247070 time/batch=0.68s
92/5900 (epoch 1.559) train_loss=1980.10180664 time/batch=0.72s
93/5900 (epoch 1.576) train_loss=1748.77294922 time/batch=0.65s
94/5900 (epoch 1.593) train_loss=1669.51708984 time/batch=0.60s
95/5900 (epoch 1.610) train_loss=1850.15063477 time/batch=0.67s
96/5900 (epoch 1.627) train_loss=1737.69909668 time/batch=0.64s
97/5900 (epoch 1.644) train_loss=1798.49914551 time/batch=0.69s
98/5900 (epoch 1.661) train_loss=1934.39746094 time/batch=0.68s
99/5900 (epoch 1.678) train_loss=1866.96899414 time/batch=0.68s
100/5900 (epoch 1.695) train_loss=1810.69897461 time/batch=0.69s
101/5900 (epoch 1.712) train_loss=1728.62927246 time/batch=0.67s
102/5900 (epoch 1.729) train_loss=2025.06518555 time/batch=0.76s
103/5900 (epoch 1.746) train_loss=2039.92578125 time/batch=2.17s
104/5900 (epoch 1.763) train_loss=2028.53417969 time/batch=0.87s
105/5900 (epoch 1.780) train_loss=1968.63757324 time/batch=0.74s
106/5900 (epoch 1.797) train_loss=1685.89025879 time/batch=0.63s
107/5900 (epoch 1.814) train_loss=1589.12939453 time/batch=0.60s
108/5900 (epoch 1.831) train_loss=2059.90405273 time/batch=0.70s
109/5900 (epoch 1.847) train_loss=2175.85253906 time/batch=1.41s
110/5900 (epoch 1.864) train_loss=1678.15258789 time/batch=0.67s
111/5900 (epoch 1.881) train_loss=1820.81530762 time/batch=1.26s
112/5900 (epoch 1.898) train_loss=1886.03417969 time/batch=0.75s
113/5900 (epoch 1.915) train_loss=1771.96740723 time/batch=0.67s
114/5900 (epoch 1.932) train_loss=1881.20861816 time/batch=1.32s
115/5900 (epoch 1.949) train_loss=1938.08239746 time/batch=0.80s
116/5900 (epoch 1.966) train_loss=1786.40991211 time/batch=0.68s
117/5900 (epoch 1.983) train_loss=1597.19079590 time/batch=0.64s
118/5900 (epoch 2.000) train_loss=1879.78735352 time/batch=1.30s
119/5900 (epoch 2.017) train_loss=1767.76562500 time/batch=0.71s
120/5900 (epoch 2.034) train_loss=2439.96484375 time/batch=0.94s
121/5900 (epoch 2.051) train_loss=1721.16259766 time/batch=0.68s
122/5900 (epoch 2.068) train_loss=2038.84497070 time/batch=0.71s
123/5900 (epoch 2.085) train_loss=1652.49951172 time/batch=0.64s
124/5900 (epoch 2.102) train_loss=1934.45788574 time/batch=0.72s
125/5900 (epoch 2.119) train_loss=1842.59399414 time/batch=0.65s
126/5900 (epoch 2.136) train_loss=1933.39562988 time/batch=2.53s
127/5900 (epoch 2.153) train_loss=1881.54223633 time/batch=0.80s
128/5900 (epoch 2.169) train_loss=1731.75878906 time/batch=0.62s
129/5900 (epoch 2.186) train_loss=1686.78112793 time/batch=1.19s
130/5900 (epoch 2.203) train_loss=2274.40454102 time/batch=0.86s
131/5900 (epoch 2.220) train_loss=2315.89038086 time/batch=2.34s
132/5900 (epoch 2.237) train_loss=1729.71984863 time/batch=0.81s
133/5900 (epoch 2.254) train_loss=1883.37341309 time/batch=0.65s
134/5900 (epoch 2.271) train_loss=1761.71423340 time/batch=0.67s
135/5900 (epoch 2.288) train_loss=1537.00756836 time/batch=0.58s
136/5900 (epoch 2.305) train_loss=1842.92675781 time/batch=1.31s
137/5900 (epoch 2.322) train_loss=1703.38769531 time/batch=0.66s
138/5900 (epoch 2.339) train_loss=2059.45800781 time/batch=0.77s
139/5900 (epoch 2.356) train_loss=2497.74707031 time/batch=1.55s
140/5900 (epoch 2.373) train_loss=1878.72949219 time/batch=0.81s
141/5900 (epoch 2.390) train_loss=1985.52038574 time/batch=0.74s
142/5900 (epoch 2.407) train_loss=1700.72021484 time/batch=0.57s
143/5900 (epoch 2.424) train_loss=2135.83349609 time/batch=2.48s
144/5900 (epoch 2.441) train_loss=1545.35156250 time/batch=0.70s
145/5900 (epoch 2.458) train_loss=1913.44372559 time/batch=1.29s
146/5900 (epoch 2.475) train_loss=2158.09814453 time/batch=0.85s
147/5900 (epoch 2.492) train_loss=1904.72631836 time/batch=0.69s
148/5900 (epoch 2.508) train_loss=1942.80517578 time/batch=0.77s
149/5900 (epoch 2.525) train_loss=1598.65087891 time/batch=0.62s
150/5900 (epoch 2.542) train_loss=2232.00317383 time/batch=1.41s
151/5900 (epoch 2.559) train_loss=2202.55322266 time/batch=0.91s
152/5900 (epoch 2.576) train_loss=1790.06616211 time/batch=0.70s
153/5900 (epoch 2.593) train_loss=1944.35449219 time/batch=0.73s
154/5900 (epoch 2.610) train_loss=1660.95910645 time/batch=0.62s
155/5900 (epoch 2.627) train_loss=1740.69702148 time/batch=0.62s
156/5900 (epoch 2.644) train_loss=1911.13989258 time/batch=1.00s
157/5900 (epoch 2.661) train_loss=1832.56103516 time/batch=0.75s
158/5900 (epoch 2.678) train_loss=2031.03527832 time/batch=0.81s
159/5900 (epoch 2.695) train_loss=1718.47570801 time/batch=0.65s
160/5900 (epoch 2.712) train_loss=1727.14941406 time/batch=0.66s
161/5900 (epoch 2.729) train_loss=2790.07836914 time/batch=2.99s
162/5900 (epoch 2.746) train_loss=1935.17480469 time/batch=1.47s
163/5900 (epoch 2.763) train_loss=2363.77954102 time/batch=2.24s
164/5900 (epoch 2.780) train_loss=1624.94580078 time/batch=0.73s
165/5900 (epoch 2.797) train_loss=1649.94018555 time/batch=0.86s
166/5900 (epoch 2.814) train_loss=2240.17871094 time/batch=0.76s
167/5900 (epoch 2.831) train_loss=1719.00732422 time/batch=0.60s
168/5900 (epoch 2.847) train_loss=1919.33105469 time/batch=0.75s
169/5900 (epoch 2.864) train_loss=1777.10278320 time/batch=0.69s
170/5900 (epoch 2.881) train_loss=1849.52917480 time/batch=0.69s
171/5900 (epoch 2.898) train_loss=1854.47680664 time/batch=0.70s
172/5900 (epoch 2.915) train_loss=2001.64379883 time/batch=0.79s
173/5900 (epoch 2.932) train_loss=1675.06298828 time/batch=0.67s
174/5900 (epoch 2.949) train_loss=1655.34008789 time/batch=0.68s
175/5900 (epoch 2.966) train_loss=1719.68298340 time/batch=0.85s
176/5900 (epoch 2.983) train_loss=1727.14575195 time/batch=0.69s
177/5900 (epoch 3.000) train_loss=1704.56555176 time/batch=0.80s
178/5900 (epoch 3.017) train_loss=1586.83007812 time/batch=0.61s
179/5900 (epoch 3.034) train_loss=1946.46435547 time/batch=0.73s
180/5900 (epoch 3.051) train_loss=1684.90283203 time/batch=0.66s
181/5900 (epoch 3.068) train_loss=1636.65502930 time/batch=0.64s
182/5900 (epoch 3.085) train_loss=1871.99365234 time/batch=0.73s
183/5900 (epoch 3.102) train_loss=2247.67724609 time/batch=1.58s
184/5900 (epoch 3.119) train_loss=1777.71520996 time/batch=1.35s
185/5900 (epoch 3.136) train_loss=1972.05957031 time/batch=1.35s
186/5900 (epoch 3.153) train_loss=1836.52575684 time/batch=0.76s
187/5900 (epoch 3.169) train_loss=2160.72705078 time/batch=0.85s
188/5900 (epoch 3.186) train_loss=2873.67919922 time/batch=3.02s
189/5900 (epoch 3.203) train_loss=1904.81201172 time/batch=0.81s
190/5900 (epoch 3.220) train_loss=1727.58789062 time/batch=0.69s
191/5900 (epoch 3.237) train_loss=1829.76220703 time/batch=1.80s
192/5900 (epoch 3.254) train_loss=1595.16149902 time/batch=0.68s
193/5900 (epoch 3.271) train_loss=1775.06982422 time/batch=1.33s
194/5900 (epoch 3.288) train_loss=2146.86889648 time/batch=0.83s
195/5900 (epoch 3.305) train_loss=1726.92211914 time/batch=0.65s
196/5900 (epoch 3.322) train_loss=1565.20703125 time/batch=0.69s
197/5900 (epoch 3.339) train_loss=2063.53564453 time/batch=1.40s
198/5900 (epoch 3.356) train_loss=2030.92895508 time/batch=2.52s
199/5900 (epoch 3.373) train_loss=1847.08093262 time/batch=0.79s
200/5900 (epoch 3.390) train_loss=1589.20629883 time/batch=1.23s
201/5900 (epoch 3.407) train_loss=1635.40563965 time/batch=0.64s
202/5900 (epoch 3.424) train_loss=1546.50842285 time/batch=0.61s
203/5900 (epoch 3.441) train_loss=2485.25292969 time/batch=2.21s
204/5900 (epoch 3.458) train_loss=1447.29284668 time/batch=0.67s
205/5900 (epoch 3.475) train_loss=1596.67480469 time/batch=0.64s
206/5900 (epoch 3.492) train_loss=1527.65551758 time/batch=1.21s
207/5900 (epoch 3.508) train_loss=2004.81372070 time/batch=1.15s
208/5900 (epoch 3.525) train_loss=2072.20605469 time/batch=0.76s
209/5900 (epoch 3.542) train_loss=2411.18066406 time/batch=2.51s
210/5900 (epoch 3.559) train_loss=1846.71020508 time/batch=0.78s
211/5900 (epoch 3.576) train_loss=1904.29711914 time/batch=0.75s
212/5900 (epoch 3.593) train_loss=2088.50683594 time/batch=0.95s
213/5900 (epoch 3.610) train_loss=1960.91137695 time/batch=0.78s
214/5900 (epoch 3.627) train_loss=1828.14550781 time/batch=0.71s
215/5900 (epoch 3.644) train_loss=1616.77246094 time/batch=0.64s
216/5900 (epoch 3.661) train_loss=1602.94506836 time/batch=0.64s
217/5900 (epoch 3.678) train_loss=1576.14843750 time/batch=0.62s
218/5900 (epoch 3.695) train_loss=1693.50683594 time/batch=0.68s
219/5900 (epoch 3.712) train_loss=2002.50146484 time/batch=0.79s
220/5900 (epoch 3.729) train_loss=1553.00781250 time/batch=0.69s
221/5900 (epoch 3.746) train_loss=1864.41650391 time/batch=1.32s
222/5900 (epoch 3.763) train_loss=2070.46752930 time/batch=0.79s
223/5900 (epoch 3.780) train_loss=1515.31579590 time/batch=0.62s
224/5900 (epoch 3.797) train_loss=1675.12292480 time/batch=0.66s
225/5900 (epoch 3.814) train_loss=1864.81884766 time/batch=0.96s
226/5900 (epoch 3.831) train_loss=1584.41503906 time/batch=0.67s
227/5900 (epoch 3.847) train_loss=1909.95495605 time/batch=0.70s
228/5900 (epoch 3.864) train_loss=1785.66674805 time/batch=1.23s
229/5900 (epoch 3.881) train_loss=1964.06640625 time/batch=0.82s
230/5900 (epoch 3.898) train_loss=1863.67419434 time/batch=0.69s
231/5900 (epoch 3.915) train_loss=1892.92236328 time/batch=0.76s
232/5900 (epoch 3.932) train_loss=1802.61303711 time/batch=0.70s
233/5900 (epoch 3.949) train_loss=1966.82312012 time/batch=0.78s
234/5900 (epoch 3.966) train_loss=1720.92431641 time/batch=0.79s
235/5900 (epoch 3.983) train_loss=1621.63452148 time/batch=0.69s
236/5900 (epoch 4.000) train_loss=1651.54162598 time/batch=0.69s
237/5900 (epoch 4.017) train_loss=2416.54760742 time/batch=0.97s
238/5900 (epoch 4.034) train_loss=1877.65209961 time/batch=0.71s
239/5900 (epoch 4.051) train_loss=2455.63940430 time/batch=2.17s
240/5900 (epoch 4.068) train_loss=2108.85473633 time/batch=0.93s
241/5900 (epoch 4.085) train_loss=2039.79785156 time/batch=0.94s
242/5900 (epoch 4.102) train_loss=2092.71826172 time/batch=0.82s
243/5900 (epoch 4.119) train_loss=2441.21728516 time/batch=1.60s
244/5900 (epoch 4.136) train_loss=2174.25292969 time/batch=2.57s
245/5900 (epoch 4.153) train_loss=1596.14770508 time/batch=0.75s
246/5900 (epoch 4.169) train_loss=1905.06530762 time/batch=0.77s
247/5900 (epoch 4.186) train_loss=1863.82507324 time/batch=2.53s
248/5900 (epoch 4.203) train_loss=1746.12927246 time/batch=0.76s
249/5900 (epoch 4.220) train_loss=2088.23266602 time/batch=1.41s
250/5900 (epoch 4.237) train_loss=1621.79687500 time/batch=0.66s
251/5900 (epoch 4.254) train_loss=1646.34301758 time/batch=0.66s
252/5900 (epoch 4.271) train_loss=1583.32128906 time/batch=0.65s
253/5900 (epoch 4.288) train_loss=1934.83386230 time/batch=0.76s
254/5900 (epoch 4.305) train_loss=1823.95629883 time/batch=0.71s
255/5900 (epoch 4.322) train_loss=1465.80981445 time/batch=0.58s
256/5900 (epoch 4.339) train_loss=1607.10217285 time/batch=0.62s
257/5900 (epoch 4.356) train_loss=1717.59057617 time/batch=0.69s
258/5900 (epoch 4.373) train_loss=1628.95898438 time/batch=1.19s
259/5900 (epoch 4.390) train_loss=2009.00817871 time/batch=0.83s
260/5900 (epoch 4.407) train_loss=2023.64892578 time/batch=0.79s
261/5900 (epoch 4.424) train_loss=1844.66162109 time/batch=0.72s
262/5900 (epoch 4.441) train_loss=2094.05859375 time/batch=0.86s
263/5900 (epoch 4.458) train_loss=1663.01818848 time/batch=0.65s
264/5900 (epoch 4.475) train_loss=1699.64184570 time/batch=0.67s
265/5900 (epoch 4.492) train_loss=1923.76367188 time/batch=0.77s
266/5900 (epoch 4.508) train_loss=1562.78039551 time/batch=0.61s
267/5900 (epoch 4.525) train_loss=2516.02392578 time/batch=2.93s
268/5900 (epoch 4.542) train_loss=1802.61926270 time/batch=1.47s
269/5900 (epoch 4.559) train_loss=1510.45483398 time/batch=0.65s
270/5900 (epoch 4.576) train_loss=1707.57568359 time/batch=1.79s
271/5900 (epoch 4.593) train_loss=1503.61755371 time/batch=0.83s
272/5900 (epoch 4.610) train_loss=1863.44628906 time/batch=1.36s
273/5900 (epoch 4.627) train_loss=1860.01562500 time/batch=1.36s
274/5900 (epoch 4.644) train_loss=1726.93627930 time/batch=0.71s
275/5900 (epoch 4.661) train_loss=1712.58972168 time/batch=0.66s
276/5900 (epoch 4.678) train_loss=1522.17846680 time/batch=0.60s
277/5900 (epoch 4.695) train_loss=1455.23730469 time/batch=0.57s
278/5900 (epoch 4.712) train_loss=1762.98974609 time/batch=0.70s
279/5900 (epoch 4.729) train_loss=1727.93334961 time/batch=1.31s
280/5900 (epoch 4.746) train_loss=1735.02343750 time/batch=0.67s
281/5900 (epoch 4.763) train_loss=1864.09375000 time/batch=0.72s
282/5900 (epoch 4.780) train_loss=1824.76538086 time/batch=0.74s
283/5900 (epoch 4.797) train_loss=1549.96606445 time/batch=0.62s
284/5900 (epoch 4.814) train_loss=1765.65307617 time/batch=1.06s
285/5900 (epoch 4.831) train_loss=1552.31652832 time/batch=0.62s
286/5900 (epoch 4.847) train_loss=1620.78430176 time/batch=0.63s
287/5900 (epoch 4.864) train_loss=1833.48803711 time/batch=0.72s
288/5900 (epoch 4.881) train_loss=1669.05346680 time/batch=0.67s
289/5900 (epoch 4.898) train_loss=1550.42626953 time/batch=0.62s
290/5900 (epoch 4.915) train_loss=1635.09448242 time/batch=0.68s
291/5900 (epoch 4.932) train_loss=1575.30297852 time/batch=0.63s
292/5900 (epoch 4.949) train_loss=2083.47338867 time/batch=2.35s
293/5900 (epoch 4.966) train_loss=1845.43041992 time/batch=0.83s
294/5900 (epoch 4.983) train_loss=1703.03295898 time/batch=0.70s
295/5900 (epoch 5.000) train_loss=1781.69177246 time/batch=0.72s
296/5900 (epoch 5.017) train_loss=2293.28393555 time/batch=0.99s
297/5900 (epoch 5.034) train_loss=2090.55981445 time/batch=2.49s
298/5900 (epoch 5.051) train_loss=2272.40942383 time/batch=1.69s
299/5900 (epoch 5.068) train_loss=2389.80371094 time/batch=2.24s
300/5900 (epoch 5.085) train_loss=2076.37866211 time/batch=0.91s
301/5900 (epoch 5.102) train_loss=2046.78283691 time/batch=2.38s
302/5900 (epoch 5.119) train_loss=1773.55346680 time/batch=0.81s
303/5900 (epoch 5.136) train_loss=1996.28173828 time/batch=0.79s
304/5900 (epoch 5.153) train_loss=2226.84570312 time/batch=0.84s
305/5900 (epoch 5.169) train_loss=1556.77319336 time/batch=0.60s
306/5900 (epoch 5.186) train_loss=1550.11389160 time/batch=0.71s
307/5900 (epoch 5.203) train_loss=1499.42871094 time/batch=1.18s
308/5900 (epoch 5.220) train_loss=1467.34094238 time/batch=0.64s
309/5900 (epoch 5.237) train_loss=1755.20678711 time/batch=1.32s
310/5900 (epoch 5.254) train_loss=1747.69616699 time/batch=0.74s
311/5900 (epoch 5.271) train_loss=1841.87109375 time/batch=1.33s
312/5900 (epoch 5.288) train_loss=2034.50683594 time/batch=2.57s
313/5900 (epoch 5.305) train_loss=2010.48437500 time/batch=0.90s
314/5900 (epoch 5.322) train_loss=1920.35522461 time/batch=0.79s
315/5900 (epoch 5.339) train_loss=2007.37158203 time/batch=1.43s
316/5900 (epoch 5.356) train_loss=1510.32910156 time/batch=0.65s
317/5900 (epoch 5.373) train_loss=1573.54162598 time/batch=1.22s
318/5900 (epoch 5.390) train_loss=1944.00195312 time/batch=0.79s
319/5900 (epoch 5.407) train_loss=1643.38562012 time/batch=0.62s
320/5900 (epoch 5.424) train_loss=1985.94128418 time/batch=0.74s
321/5900 (epoch 5.441) train_loss=2080.58862305 time/batch=0.83s
322/5900 (epoch 5.458) train_loss=1545.53942871 time/batch=0.62s
323/5900 (epoch 5.475) train_loss=1863.16613770 time/batch=0.74s
324/5900 (epoch 5.492) train_loss=1761.09899902 time/batch=0.71s
325/5900 (epoch 5.508) train_loss=1731.70166016 time/batch=0.69s
326/5900 (epoch 5.525) train_loss=2502.82299805 time/batch=0.72s
327/5900 (epoch 5.542) train_loss=1639.78833008 time/batch=1.23s
328/5900 (epoch 5.559) train_loss=1658.97253418 time/batch=0.70s
329/5900 (epoch 5.576) train_loss=2162.46289062 time/batch=0.98s
330/5900 (epoch 5.593) train_loss=1711.24951172 time/batch=1.33s
331/5900 (epoch 5.610) train_loss=1850.37500000 time/batch=1.39s
332/5900 (epoch 5.627) train_loss=1820.87158203 time/batch=0.77s
333/5900 (epoch 5.644) train_loss=1580.23559570 time/batch=0.62s
334/5900 (epoch 5.661) train_loss=1626.09753418 time/batch=0.62s
335/5900 (epoch 5.678) train_loss=1598.66137695 time/batch=0.64s
336/5900 (epoch 5.695) train_loss=1440.40136719 time/batch=0.58s
337/5900 (epoch 5.712) train_loss=1744.34155273 time/batch=0.72s
338/5900 (epoch 5.729) train_loss=1671.12890625 time/batch=0.68s
339/5900 (epoch 5.746) train_loss=1511.82312012 time/batch=0.60s
340/5900 (epoch 5.763) train_loss=1800.44299316 time/batch=0.66s
341/5900 (epoch 5.780) train_loss=1651.02966309 time/batch=0.61s
342/5900 (epoch 5.797) train_loss=1681.74682617 time/batch=0.66s
343/5900 (epoch 5.814) train_loss=2487.14990234 time/batch=2.97s
344/5900 (epoch 5.831) train_loss=1634.80810547 time/batch=0.78s
345/5900 (epoch 5.847) train_loss=1791.95751953 time/batch=0.74s
346/5900 (epoch 5.864) train_loss=1625.25097656 time/batch=0.68s
347/5900 (epoch 5.881) train_loss=1628.90747070 time/batch=0.63s
348/5900 (epoch 5.898) train_loss=1807.25866699 time/batch=0.68s
349/5900 (epoch 5.915) train_loss=1844.77832031 time/batch=0.73s
350/5900 (epoch 5.932) train_loss=1759.16223145 time/batch=0.73s
351/5900 (epoch 5.949) train_loss=1526.60656738 time/batch=0.65s
352/5900 (epoch 5.966) train_loss=1556.98657227 time/batch=0.64s
353/5900 (epoch 5.983) train_loss=1855.62036133 time/batch=0.71s
354/5900 (epoch 6.000) train_loss=1687.62219238 time/batch=0.68s
355/5900 (epoch 6.017) train_loss=2389.89111328 time/batch=2.97s
356/5900 (epoch 6.034) train_loss=1600.70874023 time/batch=0.77s
357/5900 (epoch 6.051) train_loss=1435.46655273 time/batch=0.60s
358/5900 (epoch 6.068) train_loss=1697.22631836 time/batch=0.68s
359/5900 (epoch 6.085) train_loss=1894.21301270 time/batch=2.51s
360/5900 (epoch 6.102) train_loss=1967.81372070 time/batch=1.40s
361/5900 (epoch 6.119) train_loss=1663.03442383 time/batch=0.69s
362/5900 (epoch 6.136) train_loss=1754.32983398 time/batch=1.79s
363/5900 (epoch 6.153) train_loss=1558.72949219 time/batch=0.69s
364/5900 (epoch 6.169) train_loss=1690.79956055 time/batch=0.67s
365/5900 (epoch 6.186) train_loss=2466.07763672 time/batch=1.58s
366/5900 (epoch 6.203) train_loss=1692.98168945 time/batch=0.69s
367/5900 (epoch 6.220) train_loss=2009.89160156 time/batch=0.91s
368/5900 (epoch 6.237) train_loss=1498.47412109 time/batch=1.24s
369/5900 (epoch 6.254) train_loss=1522.79650879 time/batch=0.64s
370/5900 (epoch 6.271) train_loss=2034.74194336 time/batch=1.45s
371/5900 (epoch 6.288) train_loss=1536.43737793 time/batch=0.64s
372/5900 (epoch 6.305) train_loss=1740.35595703 time/batch=0.67s
373/5900 (epoch 6.322) train_loss=2216.35449219 time/batch=2.51s
374/5900 (epoch 6.339) train_loss=1690.63977051 time/batch=0.78s
375/5900 (epoch 6.356) train_loss=1462.73254395 time/batch=0.60s
376/5900 (epoch 6.373) train_loss=1625.09741211 time/batch=0.64s
377/5900 (epoch 6.390) train_loss=1817.75170898 time/batch=0.73s
378/5900 (epoch 6.407) train_loss=1794.22399902 time/batch=0.72s
379/5900 (epoch 6.424) train_loss=1975.11206055 time/batch=0.76s
380/5900 (epoch 6.441) train_loss=2791.36083984 time/batch=2.37s
381/5900 (epoch 6.458) train_loss=1536.43164062 time/batch=0.74s
382/5900 (epoch 6.475) train_loss=1687.83300781 time/batch=1.30s
383/5900 (epoch 6.492) train_loss=1425.62841797 time/batch=0.63s
384/5900 (epoch 6.508) train_loss=1832.21398926 time/batch=0.72s
385/5900 (epoch 6.525) train_loss=1538.22570801 time/batch=0.63s
386/5900 (epoch 6.542) train_loss=1828.98388672 time/batch=0.70s
387/5900 (epoch 6.559) train_loss=2170.25317383 time/batch=0.83s
388/5900 (epoch 6.576) train_loss=1599.73547363 time/batch=1.24s
389/5900 (epoch 6.593) train_loss=1892.67626953 time/batch=0.82s
390/5900 (epoch 6.610) train_loss=1736.11572266 time/batch=0.70s
391/5900 (epoch 6.627) train_loss=2070.53857422 time/batch=0.87s
392/5900 (epoch 6.644) train_loss=1812.43225098 time/batch=0.76s
393/5900 (epoch 6.661) train_loss=2183.22070312 time/batch=1.50s
394/5900 (epoch 6.678) train_loss=1956.68908691 time/batch=0.84s
395/5900 (epoch 6.695) train_loss=1583.06188965 time/batch=0.60s
396/5900 (epoch 6.712) train_loss=1958.69506836 time/batch=1.21s
397/5900 (epoch 6.729) train_loss=1818.49768066 time/batch=0.75s
398/5900 (epoch 6.746) train_loss=1761.92626953 time/batch=0.74s
399/5900 (epoch 6.763) train_loss=1699.88159180 time/batch=0.70s
400/5900 (epoch 6.780) train_loss=1576.80957031 time/batch=0.64s
401/5900 (epoch 6.797) train_loss=1955.84326172 time/batch=0.78s
402/5900 (epoch 6.814) train_loss=1571.02099609 time/batch=0.61s
403/5900 (epoch 6.831) train_loss=2005.56420898 time/batch=0.78s
404/5900 (epoch 6.847) train_loss=1663.77856445 time/batch=0.70s
405/5900 (epoch 6.864) train_loss=1842.40502930 time/batch=0.80s
406/5900 (epoch 6.881) train_loss=1486.70166016 time/batch=0.62s
407/5900 (epoch 6.898) train_loss=1874.52697754 time/batch=0.73s
408/5900 (epoch 6.915) train_loss=1687.73486328 time/batch=0.69s
409/5900 (epoch 6.932) train_loss=1609.65893555 time/batch=0.67s
410/5900 (epoch 6.949) train_loss=1504.28344727 time/batch=0.64s
411/5900 (epoch 6.966) train_loss=1740.05578613 time/batch=0.72s
412/5900 (epoch 6.983) train_loss=1724.88110352 time/batch=1.30s
413/5900 (epoch 7.000) train_loss=1819.16271973 time/batch=1.37s
414/5900 (epoch 7.017) train_loss=1976.57580566 time/batch=2.54s
415/5900 (epoch 7.034) train_loss=1660.22192383 time/batch=0.77s
416/5900 (epoch 7.051) train_loss=1615.16284180 time/batch=0.65s
417/5900 (epoch 7.068) train_loss=1704.92785645 time/batch=0.68s
418/5900 (epoch 7.085) train_loss=1966.14660645 time/batch=0.80s
419/5900 (epoch 7.102) train_loss=1717.38305664 time/batch=0.68s
420/5900 (epoch 7.119) train_loss=2468.72753906 time/batch=2.22s
421/5900 (epoch 7.136) train_loss=1801.34338379 time/batch=0.78s
422/5900 (epoch 7.153) train_loss=1764.16308594 time/batch=0.73s
423/5900 (epoch 7.169) train_loss=1742.66381836 time/batch=1.76s
424/5900 (epoch 7.186) train_loss=1535.31469727 time/batch=0.69s
425/5900 (epoch 7.203) train_loss=1589.21301270 time/batch=0.62s
426/5900 (epoch 7.220) train_loss=1570.04064941 time/batch=0.62s
427/5900 (epoch 7.237) train_loss=2024.91540527 time/batch=2.51s
428/5900 (epoch 7.254) train_loss=1779.21875000 time/batch=0.82s
429/5900 (epoch 7.271) train_loss=1957.31506348 time/batch=0.77s
430/5900 (epoch 7.288) train_loss=1950.16882324 time/batch=0.81s
431/5900 (epoch 7.305) train_loss=2150.56713867 time/batch=0.84s
432/5900 (epoch 7.322) train_loss=1614.85815430 time/batch=0.65s
433/5900 (epoch 7.339) train_loss=1780.32348633 time/batch=0.71s
434/5900 (epoch 7.356) train_loss=1563.77709961 time/batch=1.18s
435/5900 (epoch 7.373) train_loss=1753.42382812 time/batch=1.37s
436/5900 (epoch 7.390) train_loss=2538.55029297 time/batch=3.01s
437/5900 (epoch 7.407) train_loss=2058.49316406 time/batch=1.56s
438/5900 (epoch 7.424) train_loss=1759.62011719 time/batch=1.37s
439/5900 (epoch 7.441) train_loss=2275.39892578 time/batch=1.03s
440/5900 (epoch 7.458) train_loss=1515.93383789 time/batch=0.62s
441/5900 (epoch 7.475) train_loss=1863.77453613 time/batch=0.73s
442/5900 (epoch 7.492) train_loss=1577.21582031 time/batch=0.63s
443/5900 (epoch 7.508) train_loss=1998.40429688 time/batch=1.01s
444/5900 (epoch 7.525) train_loss=2070.63134766 time/batch=0.85s
445/5900 (epoch 7.542) train_loss=1449.40332031 time/batch=0.59s
446/5900 (epoch 7.559) train_loss=1805.05932617 time/batch=0.73s
447/5900 (epoch 7.576) train_loss=1550.79199219 time/batch=0.66s
448/5900 (epoch 7.593) train_loss=1794.18701172 time/batch=1.29s
449/5900 (epoch 7.610) train_loss=1729.37915039 time/batch=0.69s
450/5900 (epoch 7.627) train_loss=2075.61010742 time/batch=0.94s
451/5900 (epoch 7.644) train_loss=1989.92749023 time/batch=0.85s
452/5900 (epoch 7.661) train_loss=1409.35131836 time/batch=0.60s
453/5900 (epoch 7.678) train_loss=2059.78125000 time/batch=1.59s
454/5900 (epoch 7.695) train_loss=1848.76220703 time/batch=0.78s
455/5900 (epoch 7.712) train_loss=1633.66601562 time/batch=1.24s
456/5900 (epoch 7.729) train_loss=1731.00439453 time/batch=0.73s
457/5900 (epoch 7.746) train_loss=1583.64672852 time/batch=0.65s
458/5900 (epoch 7.763) train_loss=1829.87011719 time/batch=0.75s
459/5900 (epoch 7.780) train_loss=1866.20520020 time/batch=0.78s
460/5900 (epoch 7.797) train_loss=1654.74023438 time/batch=0.69s
461/5900 (epoch 7.814) train_loss=1809.39843750 time/batch=0.76s
462/5900 (epoch 7.831) train_loss=1482.93457031 time/batch=0.59s
463/5900 (epoch 7.847) train_loss=1617.82141113 time/batch=0.72s
464/5900 (epoch 7.864) train_loss=1777.96289062 time/batch=0.69s
465/5900 (epoch 7.881) train_loss=1938.34252930 time/batch=1.31s
466/5900 (epoch 7.898) train_loss=1548.47631836 time/batch=0.68s
467/5900 (epoch 7.915) train_loss=1493.20019531 time/batch=0.60s
468/5900 (epoch 7.932) train_loss=1792.91772461 time/batch=0.73s
469/5900 (epoch 7.949) train_loss=1469.03198242 time/batch=0.64s
470/5900 (epoch 7.966) train_loss=1632.76232910 time/batch=0.67s
471/5900 (epoch 7.983) train_loss=1626.32006836 time/batch=0.65s
472/5900 (epoch 8.000) train_loss=1662.25988770 time/batch=0.73s
473/5900 (epoch 8.017) train_loss=2254.18701172 time/batch=2.20s
474/5900 (epoch 8.034) train_loss=2257.06323242 time/batch=1.07s
475/5900 (epoch 8.051) train_loss=1413.98193359 time/batch=0.59s
476/5900 (epoch 8.068) train_loss=2004.12963867 time/batch=1.42s
477/5900 (epoch 8.085) train_loss=2205.53125000 time/batch=1.56s
478/5900 (epoch 8.102) train_loss=2810.47998047 time/batch=2.99s
479/5900 (epoch 8.119) train_loss=1638.44982910 time/batch=0.78s
480/5900 (epoch 8.136) train_loss=1873.40441895 time/batch=0.75s
481/5900 (epoch 8.153) train_loss=1508.70104980 time/batch=0.62s
482/5900 (epoch 8.169) train_loss=1820.82385254 time/batch=1.35s
483/5900 (epoch 8.186) train_loss=2307.99487305 time/batch=1.64s
484/5900 (epoch 8.203) train_loss=1825.04992676 time/batch=2.55s
485/5900 (epoch 8.220) train_loss=1504.38159180 time/batch=0.69s
486/5900 (epoch 8.237) train_loss=1664.98376465 time/batch=0.69s
487/5900 (epoch 8.254) train_loss=1959.01037598 time/batch=0.79s
488/5900 (epoch 8.271) train_loss=1529.66101074 time/batch=0.69s
489/5900 (epoch 8.288) train_loss=1747.22863770 time/batch=0.71s
490/5900 (epoch 8.305) train_loss=1772.92297363 time/batch=0.71s
491/5900 (epoch 8.322) train_loss=1585.39477539 time/batch=0.59s
492/5900 (epoch 8.339) train_loss=1536.82055664 time/batch=0.70s
493/5900 (epoch 8.356) train_loss=1556.30944824 time/batch=0.65s
494/5900 (epoch 8.373) train_loss=1821.13354492 time/batch=0.76s
495/5900 (epoch 8.390) train_loss=1590.28686523 time/batch=0.66s
496/5900 (epoch 8.407) train_loss=1667.12573242 time/batch=0.70s
497/5900 (epoch 8.424) train_loss=1804.23852539 time/batch=0.72s
498/5900 (epoch 8.441) train_loss=1529.22375488 time/batch=1.21s
499/5900 (epoch 8.458) train_loss=1871.14697266 time/batch=1.85s
500/5900 (epoch 8.475) train_loss=1624.16772461 time/batch=0.73s
501/5900 (epoch 8.492) train_loss=1745.83129883 time/batch=0.73s
502/5900 (epoch 8.508) train_loss=1805.02880859 time/batch=0.73s
503/5900 (epoch 8.525) train_loss=2140.41992188 time/batch=0.83s
504/5900 (epoch 8.542) train_loss=1863.17309570 time/batch=0.75s
505/5900 (epoch 8.559) train_loss=1574.10681152 time/batch=0.64s
506/5900 (epoch 8.576) train_loss=1737.81738281 time/batch=1.30s
507/5900 (epoch 8.593) train_loss=1540.92553711 time/batch=0.66s
508/5900 (epoch 8.610) train_loss=1812.80126953 time/batch=0.72s
509/5900 (epoch 8.627) train_loss=2168.54052734 time/batch=0.99s
510/5900 (epoch 8.644) train_loss=1925.43212891 time/batch=0.80s
511/5900 (epoch 8.661) train_loss=1998.99011230 time/batch=0.78s
512/5900 (epoch 8.678) train_loss=1556.03686523 time/batch=1.19s
513/5900 (epoch 8.695) train_loss=1673.18969727 time/batch=0.73s
514/5900 (epoch 8.712) train_loss=1522.72412109 time/batch=0.62s
515/5900 (epoch 8.729) train_loss=1602.23559570 time/batch=0.64s
516/5900 (epoch 8.746) train_loss=1848.84606934 time/batch=1.12s
517/5900 (epoch 8.763) train_loss=1538.90478516 time/batch=0.63s
518/5900 (epoch 8.780) train_loss=1497.35681152 time/batch=0.61s
519/5900 (epoch 8.797) train_loss=1668.28955078 time/batch=0.68s
520/5900 (epoch 8.814) train_loss=1512.24670410 time/batch=0.61s
521/5900 (epoch 8.831) train_loss=2073.24243164 time/batch=2.47s
522/5900 (epoch 8.847) train_loss=1906.04833984 time/batch=0.85s
523/5900 (epoch 8.864) train_loss=1887.77954102 time/batch=0.80s
524/5900 (epoch 8.881) train_loss=1505.83129883 time/batch=0.64s
525/5900 (epoch 8.898) train_loss=1674.47265625 time/batch=0.73s
526/5900 (epoch 8.915) train_loss=1583.50158691 time/batch=0.67s
527/5900 (epoch 8.932) train_loss=1648.55224609 time/batch=0.64s
528/5900 (epoch 8.949) train_loss=1817.11596680 time/batch=1.32s
529/5900 (epoch 8.966) train_loss=1773.86157227 time/batch=0.80s
530/5900 (epoch 8.983) train_loss=1748.83227539 time/batch=1.34s
531/5900 (epoch 9.000) train_loss=1735.32031250 time/batch=0.77s
532/5900 (epoch 9.017) train_loss=2042.11206055 time/batch=0.81s
533/5900 (epoch 9.034) train_loss=1554.56469727 time/batch=0.63s
534/5900 (epoch 9.051) train_loss=1917.15991211 time/batch=0.77s
535/5900 (epoch 9.068) train_loss=1528.11669922 time/batch=0.64s
536/5900 (epoch 9.085) train_loss=1662.83837891 time/batch=0.67s
537/5900 (epoch 9.102) train_loss=1619.59326172 time/batch=0.62s
538/5900 (epoch 9.119) train_loss=1997.79931641 time/batch=0.80s
539/5900 (epoch 9.136) train_loss=1534.46728516 time/batch=0.63s
540/5900 (epoch 9.153) train_loss=2080.76245117 time/batch=2.45s
541/5900 (epoch 9.169) train_loss=1561.77612305 time/batch=1.34s
542/5900 (epoch 9.186) train_loss=2066.82617188 time/batch=0.89s
543/5900 (epoch 9.203) train_loss=1809.27526855 time/batch=0.74s
544/5900 (epoch 9.220) train_loss=1592.15295410 time/batch=0.64s
545/5900 (epoch 9.237) train_loss=1774.07275391 time/batch=1.08s
546/5900 (epoch 9.254) train_loss=1554.68310547 time/batch=0.63s
547/5900 (epoch 9.271) train_loss=1966.94409180 time/batch=0.72s
548/5900 (epoch 9.288) train_loss=1972.91162109 time/batch=0.80s
549/5900 (epoch 9.305) train_loss=1691.60253906 time/batch=0.70s
550/5900 (epoch 9.322) train_loss=1524.89550781 time/batch=0.63s
551/5900 (epoch 9.339) train_loss=1746.53857422 time/batch=0.72s
552/5900 (epoch 9.356) train_loss=1993.87524414 time/batch=0.80s
553/5900 (epoch 9.373) train_loss=1846.61596680 time/batch=0.76s
554/5900 (epoch 9.390) train_loss=1595.29492188 time/batch=1.20s
555/5900 (epoch 9.407) train_loss=1723.61669922 time/batch=0.73s
556/5900 (epoch 9.424) train_loss=1860.11901855 time/batch=2.52s
557/5900 (epoch 9.441) train_loss=1663.74902344 time/batch=1.40s
558/5900 (epoch 9.458) train_loss=1569.19409180 time/batch=0.72s
559/5900 (epoch 9.475) train_loss=2431.86718750 time/batch=2.18s
560/5900 (epoch 9.492) train_loss=1768.00781250 time/batch=0.78s
561/5900 (epoch 9.508) train_loss=1605.47290039 time/batch=0.67s
562/5900 (epoch 9.525) train_loss=2215.28222656 time/batch=1.42s
563/5900 (epoch 9.542) train_loss=1743.84167480 time/batch=0.82s
564/5900 (epoch 9.559) train_loss=1521.32812500 time/batch=0.68s
565/5900 (epoch 9.576) train_loss=1741.22070312 time/batch=0.72s
566/5900 (epoch 9.593) train_loss=2308.18896484 time/batch=1.02s
567/5900 (epoch 9.610) train_loss=1815.65197754 time/batch=0.78s
568/5900 (epoch 9.627) train_loss=1450.35009766 time/batch=0.59s
569/5900 (epoch 9.644) train_loss=1476.94726562 time/batch=0.62s
570/5900 (epoch 9.661) train_loss=1511.50610352 time/batch=0.63s
571/5900 (epoch 9.678) train_loss=1801.36242676 time/batch=1.31s
572/5900 (epoch 9.695) train_loss=2276.02758789 time/batch=1.59s
573/5900 (epoch 9.712) train_loss=1733.80834961 time/batch=1.35s
574/5900 (epoch 9.729) train_loss=1519.98059082 time/batch=0.64s
575/5900 (epoch 9.746) train_loss=1650.72558594 time/batch=0.69s
576/5900 (epoch 9.763) train_loss=1977.58935547 time/batch=0.95s
577/5900 (epoch 9.780) train_loss=1836.96777344 time/batch=1.37s
578/5900 (epoch 9.797) train_loss=1554.39147949 time/batch=0.71s
579/5900 (epoch 9.814) train_loss=1773.29821777 time/batch=0.67s
580/5900 (epoch 9.831) train_loss=1702.77539062 time/batch=0.70s
581/5900 (epoch 9.847) train_loss=2426.13012695 time/batch=2.98s
582/5900 (epoch 9.864) train_loss=1700.49462891 time/batch=0.84s
583/5900 (epoch 9.881) train_loss=2081.45239258 time/batch=2.35s
584/5900 (epoch 9.898) train_loss=1791.60644531 time/batch=0.84s
585/5900 (epoch 9.915) train_loss=1611.74377441 time/batch=0.66s
586/5900 (epoch 9.932) train_loss=1525.65087891 time/batch=0.58s
587/5900 (epoch 9.949) train_loss=1616.69726562 time/batch=0.59s
588/5900 (epoch 9.966) train_loss=1834.72290039 time/batch=0.74s
589/5900 (epoch 9.983) train_loss=1571.14855957 time/batch=0.72s
590/5900 (epoch 10.000) train_loss=1609.94311523 time/batch=0.68s
  saved to metadata/config5--20190119-211157.pkl
591/5900 (epoch 10.017) train_loss=1631.87866211 time/batch=0.74s
592/5900 (epoch 10.034) train_loss=1812.89160156 time/batch=1.83s
593/5900 (epoch 10.051) train_loss=2375.18603516 time/batch=1.07s
594/5900 (epoch 10.068) train_loss=1621.48950195 time/batch=0.67s
595/5900 (epoch 10.085) train_loss=1490.09680176 time/batch=0.60s
596/5900 (epoch 10.102) train_loss=1737.55737305 time/batch=0.73s
597/5900 (epoch 10.119) train_loss=1607.35400391 time/batch=1.24s
598/5900 (epoch 10.136) train_loss=2122.94897461 time/batch=0.87s
599/5900 (epoch 10.153) train_loss=2475.87109375 time/batch=2.21s
600/5900 (epoch 10.169) train_loss=1805.89965820 time/batch=0.79s
601/5900 (epoch 10.186) train_loss=1719.79968262 time/batch=1.34s
602/5900 (epoch 10.203) train_loss=1448.48266602 time/batch=0.64s
603/5900 (epoch 10.220) train_loss=1999.20800781 time/batch=0.81s
604/5900 (epoch 10.237) train_loss=1672.00207520 time/batch=0.69s
605/5900 (epoch 10.254) train_loss=1966.78710938 time/batch=0.94s
606/5900 (epoch 10.271) train_loss=1452.17163086 time/batch=0.60s
607/5900 (epoch 10.288) train_loss=2154.59301758 time/batch=0.82s
608/5900 (epoch 10.305) train_loss=1975.77294922 time/batch=0.80s
609/5900 (epoch 10.322) train_loss=1573.23889160 time/batch=0.67s
610/5900 (epoch 10.339) train_loss=1644.92272949 time/batch=0.66s
611/5900 (epoch 10.356) train_loss=1826.57543945 time/batch=2.50s
612/5900 (epoch 10.373) train_loss=1777.49633789 time/batch=2.58s
613/5900 (epoch 10.390) train_loss=1752.31225586 time/batch=0.78s
614/5900 (epoch 10.407) train_loss=1713.35839844 time/batch=1.30s
615/5900 (epoch 10.424) train_loss=1906.56152344 time/batch=0.78s
616/5900 (epoch 10.441) train_loss=1650.30175781 time/batch=0.70s
617/5900 (epoch 10.458) train_loss=1696.47875977 time/batch=0.69s
618/5900 (epoch 10.475) train_loss=1410.82250977 time/batch=0.59s
619/5900 (epoch 10.492) train_loss=2660.72607422 time/batch=2.88s
620/5900 (epoch 10.508) train_loss=2411.19165039 time/batch=1.73s
621/5900 (epoch 10.525) train_loss=1604.51049805 time/batch=0.72s
622/5900 (epoch 10.542) train_loss=1797.65930176 time/batch=1.36s
623/5900 (epoch 10.559) train_loss=1550.22192383 time/batch=0.67s
624/5900 (epoch 10.576) train_loss=1821.33081055 time/batch=0.74s
625/5900 (epoch 10.593) train_loss=1491.20898438 time/batch=0.60s
626/5900 (epoch 10.610) train_loss=1529.30932617 time/batch=1.24s
627/5900 (epoch 10.627) train_loss=1902.93188477 time/batch=0.78s
628/5900 (epoch 10.644) train_loss=1595.40686035 time/batch=0.63s
629/5900 (epoch 10.661) train_loss=2033.67724609 time/batch=1.41s
630/5900 (epoch 10.678) train_loss=1797.54174805 time/batch=0.77s
631/5900 (epoch 10.695) train_loss=1457.78515625 time/batch=0.62s
632/5900 (epoch 10.712) train_loss=1684.64794922 time/batch=0.71s
633/5900 (epoch 10.729) train_loss=1557.93920898 time/batch=0.63s
634/5900 (epoch 10.746) train_loss=1972.54956055 time/batch=0.80s
635/5900 (epoch 10.763) train_loss=1540.62255859 time/batch=0.64s
636/5900 (epoch 10.780) train_loss=1626.45520020 time/batch=0.63s
637/5900 (epoch 10.797) train_loss=1507.99047852 time/batch=0.64s
638/5900 (epoch 10.814) train_loss=1965.18212891 time/batch=1.04s
639/5900 (epoch 10.831) train_loss=1653.78051758 time/batch=0.69s
640/5900 (epoch 10.847) train_loss=1748.55773926 time/batch=0.70s
641/5900 (epoch 10.864) train_loss=1750.15002441 time/batch=1.32s
642/5900 (epoch 10.881) train_loss=1768.34875488 time/batch=0.81s
643/5900 (epoch 10.898) train_loss=1613.79846191 time/batch=0.66s
644/5900 (epoch 10.915) train_loss=1573.35473633 time/batch=0.68s
645/5900 (epoch 10.932) train_loss=1782.38867188 time/batch=0.73s
646/5900 (epoch 10.949) train_loss=1520.68054199 time/batch=0.64s
647/5900 (epoch 10.966) train_loss=1769.90832520 time/batch=0.72s
648/5900 (epoch 10.983) train_loss=1537.86523438 time/batch=0.62s
649/5900 (epoch 11.000) train_loss=1836.33300781 time/batch=0.75s
650/5900 (epoch 11.017) train_loss=1992.75634766 time/batch=0.91s
651/5900 (epoch 11.034) train_loss=2565.10815430 time/batch=2.99s
652/5900 (epoch 11.051) train_loss=1636.47229004 time/batch=0.80s
653/5900 (epoch 11.068) train_loss=1466.70849609 time/batch=0.69s
654/5900 (epoch 11.085) train_loss=1465.28100586 time/batch=0.62s
655/5900 (epoch 11.102) train_loss=1680.86059570 time/batch=0.66s
656/5900 (epoch 11.119) train_loss=1821.79345703 time/batch=0.71s
657/5900 (epoch 11.136) train_loss=1996.51806641 time/batch=0.81s
658/5900 (epoch 11.153) train_loss=1769.88867188 time/batch=0.75s
659/5900 (epoch 11.169) train_loss=1805.31311035 time/batch=0.75s
660/5900 (epoch 11.186) train_loss=2102.92871094 time/batch=2.39s
661/5900 (epoch 11.203) train_loss=1507.10485840 time/batch=1.29s
662/5900 (epoch 11.220) train_loss=1967.47570801 time/batch=1.81s
663/5900 (epoch 11.237) train_loss=2119.83154297 time/batch=0.88s
664/5900 (epoch 11.254) train_loss=1626.18115234 time/batch=0.70s
665/5900 (epoch 11.271) train_loss=1874.34497070 time/batch=2.50s
666/5900 (epoch 11.288) train_loss=2470.48388672 time/batch=2.34s
667/5900 (epoch 11.305) train_loss=1420.83056641 time/batch=0.65s
668/5900 (epoch 11.322) train_loss=1725.91003418 time/batch=1.31s
669/5900 (epoch 11.339) train_loss=1999.06762695 time/batch=0.81s
670/5900 (epoch 11.356) train_loss=1724.47802734 time/batch=0.72s
671/5900 (epoch 11.373) train_loss=1567.88928223 time/batch=0.62s
672/5900 (epoch 11.390) train_loss=2025.12963867 time/batch=0.84s
673/5900 (epoch 11.407) train_loss=1766.22912598 time/batch=0.74s
674/5900 (epoch 11.424) train_loss=1505.10107422 time/batch=0.64s
675/5900 (epoch 11.441) train_loss=1906.95288086 time/batch=0.77s
676/5900 (epoch 11.458) train_loss=2401.42919922 time/batch=1.52s
677/5900 (epoch 11.475) train_loss=1586.13208008 time/batch=0.68s
678/5900 (epoch 11.492) train_loss=1625.46972656 time/batch=0.65s
679/5900 (epoch 11.508) train_loss=2091.53271484 time/batch=1.18s
680/5900 (epoch 11.525) train_loss=1527.77050781 time/batch=1.24s
681/5900 (epoch 11.542) train_loss=1463.29016113 time/batch=0.62s
682/5900 (epoch 11.559) train_loss=1772.51098633 time/batch=0.72s
683/5900 (epoch 11.576) train_loss=1538.43652344 time/batch=0.62s
684/5900 (epoch 11.593) train_loss=1594.87438965 time/batch=0.62s
685/5900 (epoch 11.610) train_loss=1538.04309082 time/batch=0.61s
686/5900 (epoch 11.627) train_loss=1770.10583496 time/batch=1.33s
687/5900 (epoch 11.644) train_loss=1501.99121094 time/batch=0.68s
688/5900 (epoch 11.661) train_loss=1634.03247070 time/batch=0.70s
689/5900 (epoch 11.678) train_loss=1918.57946777 time/batch=0.80s
690/5900 (epoch 11.695) train_loss=1508.65429688 time/batch=0.59s
691/5900 (epoch 11.712) train_loss=2063.38281250 time/batch=1.43s
692/5900 (epoch 11.729) train_loss=1500.24804688 time/batch=0.65s
693/5900 (epoch 11.746) train_loss=1656.73364258 time/batch=0.68s
694/5900 (epoch 11.763) train_loss=1688.76538086 time/batch=0.70s
695/5900 (epoch 11.780) train_loss=1867.84020996 time/batch=0.81s
696/5900 (epoch 11.797) train_loss=1839.40332031 time/batch=0.74s
697/5900 (epoch 11.814) train_loss=1773.89208984 time/batch=0.73s
698/5900 (epoch 11.831) train_loss=1449.13256836 time/batch=0.59s
699/5900 (epoch 11.847) train_loss=1783.97070312 time/batch=1.34s
700/5900 (epoch 11.864) train_loss=1750.71032715 time/batch=0.82s
701/5900 (epoch 11.881) train_loss=1684.79882812 time/batch=0.75s
702/5900 (epoch 11.898) train_loss=1885.52001953 time/batch=2.51s
703/5900 (epoch 11.915) train_loss=1545.91821289 time/batch=0.73s
704/5900 (epoch 11.932) train_loss=1689.81787109 time/batch=0.65s
705/5900 (epoch 11.949) train_loss=1686.12817383 time/batch=0.66s
706/5900 (epoch 11.966) train_loss=1599.93725586 time/batch=1.20s
707/5900 (epoch 11.983) train_loss=1498.73571777 time/batch=0.69s
708/5900 (epoch 12.000) train_loss=1682.63781738 time/batch=1.31s
709/5900 (epoch 12.017) train_loss=1911.90356445 time/batch=0.83s
710/5900 (epoch 12.034) train_loss=2007.00341797 time/batch=0.80s
711/5900 (epoch 12.051) train_loss=1569.61889648 time/batch=0.68s
712/5900 (epoch 12.068) train_loss=2217.58105469 time/batch=1.52s
713/5900 (epoch 12.085) train_loss=1847.39208984 time/batch=0.73s
714/5900 (epoch 12.102) train_loss=1607.15649414 time/batch=0.60s
715/5900 (epoch 12.119) train_loss=1648.57019043 time/batch=0.68s
716/5900 (epoch 12.136) train_loss=1451.22595215 time/batch=0.68s
717/5900 (epoch 12.153) train_loss=1833.49365234 time/batch=1.82s
718/5900 (epoch 12.169) train_loss=2321.48315430 time/batch=1.65s
719/5900 (epoch 12.186) train_loss=1903.28198242 time/batch=0.86s
720/5900 (epoch 12.203) train_loss=1832.10034180 time/batch=0.76s
721/5900 (epoch 12.220) train_loss=1854.10986328 time/batch=2.46s
722/5900 (epoch 12.237) train_loss=1824.03466797 time/batch=0.88s
723/5900 (epoch 12.254) train_loss=1698.91674805 time/batch=0.68s
724/5900 (epoch 12.271) train_loss=2153.24023438 time/batch=0.83s
725/5900 (epoch 12.288) train_loss=2197.01708984 time/batch=2.21s
726/5900 (epoch 12.305) train_loss=1919.24682617 time/batch=0.88s
727/5900 (epoch 12.322) train_loss=1727.09631348 time/batch=1.32s
728/5900 (epoch 12.339) train_loss=2050.60839844 time/batch=1.45s
729/5900 (epoch 12.356) train_loss=1652.52917480 time/batch=0.73s
730/5900 (epoch 12.373) train_loss=1548.45971680 time/batch=0.65s
731/5900 (epoch 12.390) train_loss=1502.99316406 time/batch=0.63s
732/5900 (epoch 12.407) train_loss=1561.53833008 time/batch=0.66s
733/5900 (epoch 12.424) train_loss=2740.31494141 time/batch=3.00s
734/5900 (epoch 12.441) train_loss=1826.21044922 time/batch=0.87s
735/5900 (epoch 12.458) train_loss=1801.65844727 time/batch=0.75s
736/5900 (epoch 12.475) train_loss=1562.84741211 time/batch=1.22s
737/5900 (epoch 12.492) train_loss=1698.08508301 time/batch=0.68s
738/5900 (epoch 12.508) train_loss=1506.80908203 time/batch=0.66s
739/5900 (epoch 12.525) train_loss=1387.01916504 time/batch=0.58s
740/5900 (epoch 12.542) train_loss=1410.09887695 time/batch=0.66s
741/5900 (epoch 12.559) train_loss=1705.65039062 time/batch=0.71s
742/5900 (epoch 12.576) train_loss=1726.30615234 time/batch=1.10s
743/5900 (epoch 12.593) train_loss=1575.29809570 time/batch=0.69s
744/5900 (epoch 12.610) train_loss=1511.38061523 time/batch=1.17s
745/5900 (epoch 12.627) train_loss=1654.67114258 time/batch=0.67s
746/5900 (epoch 12.644) train_loss=1945.54003906 time/batch=0.73s
747/5900 (epoch 12.661) train_loss=1924.52148438 time/batch=0.90s
748/5900 (epoch 12.678) train_loss=1794.26025391 time/batch=0.87s
749/5900 (epoch 12.695) train_loss=1917.63000488 time/batch=2.52s
750/5900 (epoch 12.712) train_loss=1798.64257812 time/batch=0.82s
751/5900 (epoch 12.729) train_loss=1464.54833984 time/batch=0.62s
752/5900 (epoch 12.746) train_loss=1520.87414551 time/batch=0.61s
753/5900 (epoch 12.763) train_loss=2110.08056641 time/batch=0.97s
754/5900 (epoch 12.780) train_loss=1838.91467285 time/batch=1.39s
755/5900 (epoch 12.797) train_loss=1697.85986328 time/batch=1.01s
756/5900 (epoch 12.814) train_loss=1480.00231934 time/batch=0.70s
757/5900 (epoch 12.831) train_loss=1510.60961914 time/batch=0.63s
758/5900 (epoch 12.847) train_loss=1460.60205078 time/batch=0.60s
759/5900 (epoch 12.864) train_loss=1482.69238281 time/batch=0.62s
760/5900 (epoch 12.881) train_loss=1762.10119629 time/batch=0.69s
761/5900 (epoch 12.898) train_loss=1527.98852539 time/batch=0.71s
762/5900 (epoch 12.915) train_loss=1668.06677246 time/batch=1.32s
763/5900 (epoch 12.932) train_loss=1494.85058594 time/batch=0.74s
764/5900 (epoch 12.949) train_loss=1537.29931641 time/batch=0.71s
765/5900 (epoch 12.966) train_loss=1767.46215820 time/batch=1.30s
766/5900 (epoch 12.983) train_loss=1749.08630371 time/batch=0.73s
767/5900 (epoch 13.000) train_loss=1704.00488281 time/batch=0.69s
768/5900 (epoch 13.017) train_loss=1425.19970703 time/batch=0.58s
769/5900 (epoch 13.034) train_loss=1503.16210938 time/batch=0.64s
770/5900 (epoch 13.051) train_loss=1723.05712891 time/batch=0.68s
771/5900 (epoch 13.068) train_loss=1743.65734863 time/batch=1.83s
772/5900 (epoch 13.085) train_loss=2244.74755859 time/batch=1.07s
773/5900 (epoch 13.102) train_loss=1845.19848633 time/batch=0.78s
774/5900 (epoch 13.119) train_loss=2126.20043945 time/batch=1.51s
775/5900 (epoch 13.136) train_loss=1605.61523438 time/batch=0.73s
776/5900 (epoch 13.153) train_loss=2132.06372070 time/batch=0.83s
777/5900 (epoch 13.169) train_loss=2049.93334961 time/batch=0.81s
778/5900 (epoch 13.186) train_loss=1676.37573242 time/batch=0.71s
779/5900 (epoch 13.203) train_loss=1910.53930664 time/batch=2.50s
780/5900 (epoch 13.220) train_loss=1954.01977539 time/batch=0.90s
781/5900 (epoch 13.237) train_loss=1440.89697266 time/batch=0.61s
782/5900 (epoch 13.254) train_loss=1503.24084473 time/batch=0.64s
783/5900 (epoch 13.271) train_loss=1978.52661133 time/batch=1.42s
784/5900 (epoch 13.288) train_loss=1563.33715820 time/batch=0.68s
785/5900 (epoch 13.305) train_loss=1553.25805664 time/batch=1.19s
786/5900 (epoch 13.322) train_loss=1570.17431641 time/batch=0.68s
787/5900 (epoch 13.339) train_loss=2148.52612305 time/batch=2.34s
788/5900 (epoch 13.356) train_loss=1391.93872070 time/batch=0.67s
789/5900 (epoch 13.373) train_loss=1747.59619141 time/batch=0.71s
790/5900 (epoch 13.390) train_loss=1451.42797852 time/batch=1.23s
791/5900 (epoch 13.407) train_loss=1729.61218262 time/batch=0.72s
792/5900 (epoch 13.424) train_loss=1566.34179688 time/batch=0.63s
793/5900 (epoch 13.441) train_loss=1570.21057129 time/batch=0.64s
794/5900 (epoch 13.458) train_loss=1460.27832031 time/batch=0.69s
795/5900 (epoch 13.475) train_loss=1633.80834961 time/batch=1.31s
796/5900 (epoch 13.492) train_loss=1721.17993164 time/batch=0.75s
797/5900 (epoch 13.508) train_loss=1705.14343262 time/batch=1.34s
798/5900 (epoch 13.525) train_loss=1506.08557129 time/batch=0.71s
799/5900 (epoch 13.542) train_loss=1499.81713867 time/batch=0.61s
800/5900 (epoch 13.559) train_loss=1499.57434082 time/batch=0.67s
801/5900 (epoch 13.576) train_loss=1806.04553223 time/batch=0.76s
802/5900 (epoch 13.593) train_loss=1766.53881836 time/batch=0.71s
803/5900 (epoch 13.610) train_loss=1923.23046875 time/batch=2.52s
804/5900 (epoch 13.627) train_loss=1439.41333008 time/batch=0.72s
805/5900 (epoch 13.644) train_loss=1611.44628906 time/batch=0.67s
806/5900 (epoch 13.661) train_loss=1950.68713379 time/batch=0.81s
807/5900 (epoch 13.678) train_loss=1741.94384766 time/batch=0.71s
808/5900 (epoch 13.695) train_loss=1696.96215820 time/batch=0.64s
809/5900 (epoch 13.712) train_loss=1783.66162109 time/batch=0.74s
810/5900 (epoch 13.729) train_loss=1585.76000977 time/batch=0.69s
811/5900 (epoch 13.746) train_loss=1547.50573730 time/batch=0.68s
812/5900 (epoch 13.763) train_loss=2092.53295898 time/batch=2.98s
813/5900 (epoch 13.780) train_loss=1636.19018555 time/batch=0.80s
814/5900 (epoch 13.797) train_loss=1957.78930664 time/batch=0.80s
815/5900 (epoch 13.814) train_loss=1619.20117188 time/batch=0.67s
816/5900 (epoch 13.831) train_loss=2218.52490234 time/batch=2.20s
817/5900 (epoch 13.847) train_loss=1774.53015137 time/batch=1.43s
818/5900 (epoch 13.864) train_loss=1636.72851562 time/batch=1.35s
819/5900 (epoch 13.881) train_loss=1880.36987305 time/batch=0.94s
820/5900 (epoch 13.898) train_loss=1680.76123047 time/batch=0.70s
821/5900 (epoch 13.915) train_loss=2288.79980469 time/batch=1.59s
822/5900 (epoch 13.932) train_loss=1581.89501953 time/batch=0.72s
823/5900 (epoch 13.949) train_loss=1482.11914062 time/batch=0.63s
824/5900 (epoch 13.966) train_loss=1760.62646484 time/batch=0.72s
825/5900 (epoch 13.983) train_loss=1833.96044922 time/batch=0.96s
826/5900 (epoch 14.000) train_loss=1722.65087891 time/batch=0.75s
827/5900 (epoch 14.017) train_loss=1461.48388672 time/batch=0.61s
828/5900 (epoch 14.034) train_loss=1745.58386230 time/batch=1.83s
829/5900 (epoch 14.051) train_loss=1896.06542969 time/batch=0.85s
830/5900 (epoch 14.068) train_loss=2553.17285156 time/batch=2.96s
831/5900 (epoch 14.085) train_loss=1392.93383789 time/batch=1.34s
832/5900 (epoch 14.102) train_loss=2032.88134766 time/batch=0.86s
833/5900 (epoch 14.119) train_loss=1875.07592773 time/batch=0.72s
834/5900 (epoch 14.136) train_loss=2240.44628906 time/batch=1.01s
835/5900 (epoch 14.153) train_loss=1651.29663086 time/batch=0.68s
836/5900 (epoch 14.169) train_loss=2175.36669922 time/batch=2.17s
837/5900 (epoch 14.186) train_loss=1584.69165039 time/batch=0.76s
838/5900 (epoch 14.203) train_loss=1487.17919922 time/batch=0.63s
839/5900 (epoch 14.220) train_loss=1485.31298828 time/batch=0.61s
840/5900 (epoch 14.237) train_loss=2160.07348633 time/batch=2.50s
841/5900 (epoch 14.254) train_loss=1673.13610840 time/batch=0.79s
842/5900 (epoch 14.271) train_loss=1820.44848633 time/batch=0.75s
843/5900 (epoch 14.288) train_loss=2002.91259766 time/batch=0.85s
844/5900 (epoch 14.305) train_loss=1396.29638672 time/batch=0.71s
845/5900 (epoch 14.322) train_loss=2317.16552734 time/batch=1.58s
846/5900 (epoch 14.339) train_loss=1591.28479004 time/batch=0.75s
847/5900 (epoch 14.356) train_loss=1723.46704102 time/batch=1.33s
848/5900 (epoch 14.373) train_loss=1725.87341309 time/batch=0.79s
849/5900 (epoch 14.390) train_loss=1516.88867188 time/batch=0.62s
850/5900 (epoch 14.407) train_loss=2056.87597656 time/batch=0.81s
851/5900 (epoch 14.424) train_loss=1525.33569336 time/batch=1.26s
852/5900 (epoch 14.441) train_loss=1674.87207031 time/batch=1.33s
853/5900 (epoch 14.458) train_loss=1820.76965332 time/batch=0.97s
854/5900 (epoch 14.475) train_loss=1874.78613281 time/batch=0.80s
855/5900 (epoch 14.492) train_loss=1481.00561523 time/batch=0.69s
856/5900 (epoch 14.508) train_loss=1657.49291992 time/batch=0.71s
857/5900 (epoch 14.525) train_loss=1847.24658203 time/batch=0.75s
858/5900 (epoch 14.542) train_loss=1756.71350098 time/batch=0.71s
859/5900 (epoch 14.559) train_loss=1509.61791992 time/batch=0.65s
860/5900 (epoch 14.576) train_loss=1426.48730469 time/batch=0.63s
861/5900 (epoch 14.593) train_loss=1656.59130859 time/batch=1.31s
862/5900 (epoch 14.610) train_loss=1784.48828125 time/batch=0.73s
863/5900 (epoch 14.627) train_loss=1934.06005859 time/batch=2.50s
864/5900 (epoch 14.644) train_loss=2005.72167969 time/batch=0.90s
865/5900 (epoch 14.661) train_loss=1714.08630371 time/batch=0.73s
866/5900 (epoch 14.678) train_loss=1706.56811523 time/batch=1.33s
867/5900 (epoch 14.695) train_loss=1475.92749023 time/batch=0.66s
868/5900 (epoch 14.712) train_loss=1839.37902832 time/batch=0.78s
869/5900 (epoch 14.729) train_loss=1657.44104004 time/batch=0.70s
870/5900 (epoch 14.746) train_loss=1670.25610352 time/batch=0.70s
871/5900 (epoch 14.763) train_loss=1472.23022461 time/batch=0.62s
872/5900 (epoch 14.780) train_loss=1544.97851562 time/batch=0.63s
873/5900 (epoch 14.797) train_loss=1538.53210449 time/batch=0.66s
874/5900 (epoch 14.814) train_loss=1509.99023438 time/batch=0.67s
875/5900 (epoch 14.831) train_loss=1978.56994629 time/batch=1.40s
876/5900 (epoch 14.847) train_loss=1495.62841797 time/batch=0.65s
877/5900 (epoch 14.864) train_loss=1911.00036621 time/batch=0.86s
878/5900 (epoch 14.881) train_loss=1407.82373047 time/batch=0.69s
879/5900 (epoch 14.898) train_loss=1675.58593750 time/batch=0.74s
880/5900 (epoch 14.915) train_loss=1772.50952148 time/batch=0.70s
881/5900 (epoch 14.932) train_loss=1425.33276367 time/batch=0.64s
882/5900 (epoch 14.949) train_loss=1397.21289062 time/batch=0.61s
883/5900 (epoch 14.966) train_loss=1651.57128906 time/batch=0.67s
884/5900 (epoch 14.983) train_loss=1463.91333008 time/batch=0.62s
885/5900 (epoch 15.000) train_loss=1520.94531250 time/batch=0.74s
886/5900 (epoch 15.017) train_loss=1678.01904297 time/batch=0.71s
887/5900 (epoch 15.034) train_loss=1983.97070312 time/batch=0.83s
888/5900 (epoch 15.051) train_loss=1622.35803223 time/batch=0.70s
889/5900 (epoch 15.068) train_loss=1559.11035156 time/batch=0.68s
890/5900 (epoch 15.085) train_loss=1907.30859375 time/batch=0.75s
891/5900 (epoch 15.102) train_loss=1891.60327148 time/batch=2.52s
892/5900 (epoch 15.119) train_loss=2387.28784180 time/batch=2.29s
893/5900 (epoch 15.136) train_loss=1751.37719727 time/batch=2.57s
894/5900 (epoch 15.153) train_loss=1826.33471680 time/batch=0.85s
895/5900 (epoch 15.169) train_loss=1648.14416504 time/batch=1.29s
896/5900 (epoch 15.186) train_loss=1929.00952148 time/batch=0.85s
897/5900 (epoch 15.203) train_loss=1496.39135742 time/batch=0.64s
898/5900 (epoch 15.220) train_loss=1749.17675781 time/batch=0.69s
899/5900 (epoch 15.237) train_loss=2078.86328125 time/batch=0.85s
900/5900 (epoch 15.254) train_loss=1916.22875977 time/batch=0.80s
901/5900 (epoch 15.271) train_loss=1744.72253418 time/batch=1.36s
902/5900 (epoch 15.288) train_loss=2698.07739258 time/batch=2.99s
903/5900 (epoch 15.305) train_loss=1895.80969238 time/batch=0.96s
904/5900 (epoch 15.322) train_loss=1682.97131348 time/batch=0.72s
905/5900 (epoch 15.339) train_loss=1706.18127441 time/batch=1.82s
906/5900 (epoch 15.356) train_loss=1622.80468750 time/batch=0.75s
907/5900 (epoch 15.373) train_loss=1546.68420410 time/batch=0.59s
908/5900 (epoch 15.390) train_loss=1892.70605469 time/batch=0.90s
909/5900 (epoch 15.407) train_loss=2207.89941406 time/batch=0.99s
910/5900 (epoch 15.424) train_loss=1617.89086914 time/batch=0.72s
911/5900 (epoch 15.441) train_loss=2416.08471680 time/batch=1.61s
912/5900 (epoch 15.458) train_loss=1748.59252930 time/batch=0.76s
913/5900 (epoch 15.475) train_loss=1725.75732422 time/batch=1.00s
914/5900 (epoch 15.492) train_loss=1563.37023926 time/batch=0.68s
915/5900 (epoch 15.508) train_loss=1433.27465820 time/batch=0.63s
916/5900 (epoch 15.525) train_loss=1765.76501465 time/batch=0.73s
917/5900 (epoch 15.542) train_loss=1397.28222656 time/batch=0.58s
918/5900 (epoch 15.559) train_loss=1626.33911133 time/batch=1.31s
919/5900 (epoch 15.576) train_loss=1561.73217773 time/batch=0.70s
920/5900 (epoch 15.593) train_loss=1514.78857422 time/batch=0.62s
921/5900 (epoch 15.610) train_loss=1474.01110840 time/batch=0.63s
922/5900 (epoch 15.627) train_loss=1473.08056641 time/batch=1.21s
923/5900 (epoch 15.644) train_loss=1754.19750977 time/batch=0.78s
924/5900 (epoch 15.661) train_loss=1424.52026367 time/batch=0.63s
925/5900 (epoch 15.678) train_loss=1863.95007324 time/batch=1.43s
926/5900 (epoch 15.695) train_loss=1468.18579102 time/batch=0.66s
927/5900 (epoch 15.712) train_loss=1487.35363770 time/batch=0.61s
928/5900 (epoch 15.729) train_loss=1719.71618652 time/batch=1.27s
929/5900 (epoch 15.746) train_loss=1507.19946289 time/batch=0.70s
930/5900 (epoch 15.763) train_loss=1756.30541992 time/batch=0.74s
931/5900 (epoch 15.780) train_loss=1385.22192383 time/batch=0.60s
932/5900 (epoch 15.797) train_loss=1322.20532227 time/batch=0.77s
933/5900 (epoch 15.814) train_loss=1474.13940430 time/batch=0.70s
934/5900 (epoch 15.831) train_loss=1449.38110352 time/batch=0.68s
935/5900 (epoch 15.847) train_loss=1787.51635742 time/batch=0.76s
936/5900 (epoch 15.864) train_loss=1494.91674805 time/batch=0.63s
937/5900 (epoch 15.881) train_loss=1657.75585938 time/batch=0.73s
938/5900 (epoch 15.898) train_loss=1588.33007812 time/batch=0.70s
939/5900 (epoch 15.915) train_loss=1529.48120117 time/batch=0.68s
940/5900 (epoch 15.932) train_loss=1446.93603516 time/batch=0.75s
941/5900 (epoch 15.949) train_loss=1736.64880371 time/batch=0.72s
942/5900 (epoch 15.966) train_loss=1640.96057129 time/batch=0.67s
943/5900 (epoch 15.983) train_loss=1633.01989746 time/batch=0.67s
944/5900 (epoch 16.000) train_loss=1602.86535645 time/batch=0.71s
945/5900 (epoch 16.017) train_loss=1756.81335449 time/batch=0.76s
946/5900 (epoch 16.034) train_loss=1713.17919922 time/batch=0.74s
947/5900 (epoch 16.051) train_loss=1967.43981934 time/batch=1.44s
948/5900 (epoch 16.068) train_loss=1964.31665039 time/batch=0.84s
949/5900 (epoch 16.085) train_loss=1519.98681641 time/batch=0.67s
950/5900 (epoch 16.102) train_loss=1915.44555664 time/batch=0.80s
951/5900 (epoch 16.119) train_loss=1448.26342773 time/batch=0.61s
952/5900 (epoch 16.136) train_loss=1486.16503906 time/batch=1.21s
953/5900 (epoch 16.153) train_loss=1993.00646973 time/batch=0.90s
954/5900 (epoch 16.169) train_loss=1489.20202637 time/batch=0.65s
955/5900 (epoch 16.186) train_loss=2555.94750977 time/batch=2.98s
956/5900 (epoch 16.203) train_loss=2159.19140625 time/batch=1.63s
957/5900 (epoch 16.220) train_loss=1779.59228516 time/batch=0.76s
958/5900 (epoch 16.237) train_loss=1407.86584473 time/batch=0.66s
959/5900 (epoch 16.254) train_loss=1748.86181641 time/batch=1.36s
960/5900 (epoch 16.271) train_loss=1591.31970215 time/batch=0.73s
961/5900 (epoch 16.288) train_loss=1496.13256836 time/batch=0.64s
962/5900 (epoch 16.305) train_loss=1401.79870605 time/batch=0.58s
963/5900 (epoch 16.322) train_loss=1753.90747070 time/batch=0.72s
964/5900 (epoch 16.339) train_loss=1645.90087891 time/batch=1.33s
965/5900 (epoch 16.356) train_loss=2132.76416016 time/batch=2.24s
966/5900 (epoch 16.373) train_loss=1726.61840820 time/batch=0.80s
967/5900 (epoch 16.390) train_loss=1603.57055664 time/batch=0.70s
968/5900 (epoch 16.407) train_loss=2044.51269531 time/batch=2.36s
969/5900 (epoch 16.424) train_loss=2367.42138672 time/batch=1.68s
970/5900 (epoch 16.441) train_loss=1464.28930664 time/batch=0.64s
971/5900 (epoch 16.458) train_loss=2087.97094727 time/batch=0.98s
972/5900 (epoch 16.475) train_loss=1525.99511719 time/batch=0.67s
973/5900 (epoch 16.492) train_loss=1383.58483887 time/batch=1.21s
974/5900 (epoch 16.508) train_loss=1517.19213867 time/batch=0.69s
975/5900 (epoch 16.525) train_loss=1549.27099609 time/batch=1.26s
976/5900 (epoch 16.542) train_loss=1786.85839844 time/batch=0.84s
977/5900 (epoch 16.559) train_loss=1391.11352539 time/batch=0.70s
978/5900 (epoch 16.576) train_loss=1551.03771973 time/batch=0.64s
979/5900 (epoch 16.593) train_loss=1812.84106445 time/batch=2.49s
980/5900 (epoch 16.610) train_loss=1900.87341309 time/batch=0.91s
981/5900 (epoch 16.627) train_loss=1972.17041016 time/batch=1.83s
982/5900 (epoch 16.644) train_loss=1712.56567383 time/batch=0.81s
983/5900 (epoch 16.661) train_loss=1598.37194824 time/batch=0.71s
984/5900 (epoch 16.678) train_loss=1848.61755371 time/batch=2.54s
985/5900 (epoch 16.695) train_loss=1811.15686035 time/batch=0.89s
986/5900 (epoch 16.712) train_loss=1552.54418945 time/batch=0.69s
987/5900 (epoch 16.729) train_loss=1716.63452148 time/batch=0.76s
988/5900 (epoch 16.746) train_loss=1377.14526367 time/batch=1.18s
989/5900 (epoch 16.763) train_loss=1542.41577148 time/batch=1.20s
990/5900 (epoch 16.780) train_loss=1710.78076172 time/batch=0.75s
991/5900 (epoch 16.797) train_loss=1456.81115723 time/batch=0.75s
992/5900 (epoch 16.814) train_loss=1543.94433594 time/batch=0.66s
993/5900 (epoch 16.831) train_loss=1476.92382812 time/batch=1.00s
994/5900 (epoch 16.847) train_loss=1451.52612305 time/batch=0.63s
995/5900 (epoch 16.864) train_loss=1565.63598633 time/batch=0.72s
996/5900 (epoch 16.881) train_loss=1487.98034668 time/batch=0.73s
997/5900 (epoch 16.898) train_loss=1486.46093750 time/batch=0.73s
998/5900 (epoch 16.915) train_loss=1522.64257812 time/batch=0.67s
999/5900 (epoch 16.932) train_loss=1591.82958984 time/batch=0.68s
Validating
    loss:	1625.553467

1000/5900 (epoch 16.949) train_loss=1593.18823242 time/batch=1.36s
1001/5900 (epoch 16.966) train_loss=1640.94189453 time/batch=1.31s
1002/5900 (epoch 16.983) train_loss=1580.38159180 time/batch=0.73s
1003/5900 (epoch 17.000) train_loss=1604.66113281 time/batch=0.70s
1004/5900 (epoch 17.017) train_loss=1290.92871094 time/batch=0.58s
1005/5900 (epoch 17.034) train_loss=1738.27893066 time/batch=2.40s
1006/5900 (epoch 17.051) train_loss=1877.11010742 time/batch=0.91s
1007/5900 (epoch 17.068) train_loss=1699.59472656 time/batch=1.37s
1008/5900 (epoch 17.085) train_loss=1567.17663574 time/batch=1.35s
1009/5900 (epoch 17.102) train_loss=1746.86755371 time/batch=0.77s
1010/5900 (epoch 17.119) train_loss=1505.48937988 time/batch=0.66s
1011/5900 (epoch 17.136) train_loss=1966.08593750 time/batch=1.44s
1012/5900 (epoch 17.153) train_loss=1320.29614258 time/batch=0.62s
1013/5900 (epoch 17.169) train_loss=1525.75830078 time/batch=0.64s
1014/5900 (epoch 17.186) train_loss=1746.39062500 time/batch=1.82s
1015/5900 (epoch 17.203) train_loss=2030.03491211 time/batch=0.89s
1016/5900 (epoch 17.220) train_loss=1442.07568359 time/batch=0.62s
1017/5900 (epoch 17.237) train_loss=1711.85522461 time/batch=0.74s
1018/5900 (epoch 17.254) train_loss=1739.57592773 time/batch=0.75s
1019/5900 (epoch 17.271) train_loss=1871.31347656 time/batch=0.80s
1020/5900 (epoch 17.288) train_loss=1483.02636719 time/batch=1.18s
1021/5900 (epoch 17.305) train_loss=1856.25329590 time/batch=0.85s
1022/5900 (epoch 17.322) train_loss=2323.05664062 time/batch=2.37s
1023/5900 (epoch 17.339) train_loss=1792.71545410 time/batch=0.83s
1024/5900 (epoch 17.356) train_loss=2367.10815430 time/batch=1.59s
1025/5900 (epoch 17.373) train_loss=1802.62158203 time/batch=0.81s
1026/5900 (epoch 17.390) train_loss=1866.76757812 time/batch=0.80s
1027/5900 (epoch 17.407) train_loss=2062.45898438 time/batch=1.52s
1028/5900 (epoch 17.424) train_loss=1386.72314453 time/batch=0.67s
1029/5900 (epoch 17.441) train_loss=1564.60119629 time/batch=0.66s
1030/5900 (epoch 17.458) train_loss=2225.30664062 time/batch=2.20s
1031/5900 (epoch 17.475) train_loss=1953.29077148 time/batch=1.02s
1032/5900 (epoch 17.492) train_loss=2142.57958984 time/batch=1.04s
1033/5900 (epoch 17.508) train_loss=1780.81188965 time/batch=0.75s
1034/5900 (epoch 17.525) train_loss=1522.98352051 time/batch=0.70s
1035/5900 (epoch 17.542) train_loss=1665.79858398 time/batch=1.31s
1036/5900 (epoch 17.559) train_loss=1489.34863281 time/batch=0.68s
1037/5900 (epoch 17.576) train_loss=1374.44213867 time/batch=0.59s
1038/5900 (epoch 17.593) train_loss=1488.20129395 time/batch=0.66s
1039/5900 (epoch 17.610) train_loss=1728.88281250 time/batch=0.72s
1040/5900 (epoch 17.627) train_loss=1616.22265625 time/batch=0.70s
1041/5900 (epoch 17.644) train_loss=1561.06384277 time/batch=1.21s
1042/5900 (epoch 17.661) train_loss=1754.04711914 time/batch=0.84s
1043/5900 (epoch 17.678) train_loss=1388.80224609 time/batch=0.61s
1044/5900 (epoch 17.695) train_loss=1612.98510742 time/batch=2.52s
1045/5900 (epoch 17.712) train_loss=1605.92004395 time/batch=0.79s
1046/5900 (epoch 17.729) train_loss=1349.85375977 time/batch=0.65s
1047/5900 (epoch 17.746) train_loss=1557.56958008 time/batch=0.69s
1048/5900 (epoch 17.763) train_loss=2404.74536133 time/batch=2.91s
1049/5900 (epoch 17.780) train_loss=1561.79577637 time/batch=0.78s
1050/5900 (epoch 17.797) train_loss=1465.02563477 time/batch=0.60s
1051/5900 (epoch 17.814) train_loss=1569.06445312 time/batch=0.71s
1052/5900 (epoch 17.831) train_loss=1535.29760742 time/batch=0.67s
1053/5900 (epoch 17.847) train_loss=1659.13085938 time/batch=0.71s
1054/5900 (epoch 17.864) train_loss=1578.90930176 time/batch=1.30s
1055/5900 (epoch 17.881) train_loss=1462.89697266 time/batch=0.70s
1056/5900 (epoch 17.898) train_loss=1466.97338867 time/batch=0.65s
1057/5900 (epoch 17.915) train_loss=1658.46191406 time/batch=0.70s
1058/5900 (epoch 17.932) train_loss=1482.29248047 time/batch=0.67s
1059/5900 (epoch 17.949) train_loss=1388.26269531 time/batch=0.62s
1060/5900 (epoch 17.966) train_loss=1442.15844727 time/batch=0.64s
1061/5900 (epoch 17.983) train_loss=1413.63940430 time/batch=0.62s
1062/5900 (epoch 18.000) train_loss=1553.87377930 time/batch=0.70s
1063/5900 (epoch 18.017) train_loss=1430.98937988 time/batch=0.63s
1064/5900 (epoch 18.034) train_loss=2016.97509766 time/batch=0.80s
1065/5900 (epoch 18.051) train_loss=1634.09826660 time/batch=1.28s
1066/5900 (epoch 18.068) train_loss=1999.28869629 time/batch=0.89s
1067/5900 (epoch 18.085) train_loss=1373.79943848 time/batch=0.60s
1068/5900 (epoch 18.102) train_loss=1719.04931641 time/batch=0.73s
1069/5900 (epoch 18.119) train_loss=1566.54162598 time/batch=0.71s
1070/5900 (epoch 18.136) train_loss=1950.04956055 time/batch=1.45s
1071/5900 (epoch 18.153) train_loss=1490.55151367 time/batch=0.67s
1072/5900 (epoch 18.169) train_loss=1806.75354004 time/batch=2.47s
1073/5900 (epoch 18.186) train_loss=1439.03540039 time/batch=0.70s
1074/5900 (epoch 18.203) train_loss=1704.94702148 time/batch=0.70s
1075/5900 (epoch 18.220) train_loss=1727.75805664 time/batch=0.75s
1076/5900 (epoch 18.237) train_loss=1756.48510742 time/batch=0.75s
1077/5900 (epoch 18.254) train_loss=1990.86328125 time/batch=0.84s
1078/5900 (epoch 18.271) train_loss=1714.96875000 time/batch=1.37s
1079/5900 (epoch 18.288) train_loss=1844.10144043 time/batch=0.84s
1080/5900 (epoch 18.305) train_loss=1649.04772949 time/batch=0.70s
1081/5900 (epoch 18.322) train_loss=2264.69726562 time/batch=2.88s
1082/5900 (epoch 18.339) train_loss=1405.14587402 time/batch=0.73s
1083/5900 (epoch 18.356) train_loss=1412.44482422 time/batch=0.63s
1084/5900 (epoch 18.373) train_loss=1320.50585938 time/batch=0.66s
1085/5900 (epoch 18.390) train_loss=1384.90258789 time/batch=1.24s
1086/5900 (epoch 18.407) train_loss=1843.15478516 time/batch=0.75s
1087/5900 (epoch 18.424) train_loss=1597.40942383 time/batch=0.69s
1088/5900 (epoch 18.441) train_loss=1465.15954590 time/batch=0.62s
1089/5900 (epoch 18.458) train_loss=2348.24340820 time/batch=1.69s
1090/5900 (epoch 18.475) train_loss=1833.71948242 time/batch=0.86s
1091/5900 (epoch 18.492) train_loss=1503.94555664 time/batch=0.69s
1092/5900 (epoch 18.508) train_loss=1695.43286133 time/batch=0.73s
1093/5900 (epoch 18.525) train_loss=2310.61230469 time/batch=2.19s
1094/5900 (epoch 18.542) train_loss=1435.21118164 time/batch=1.29s
1095/5900 (epoch 18.559) train_loss=1635.14245605 time/batch=1.76s
1096/5900 (epoch 18.576) train_loss=1526.46875000 time/batch=0.73s
1097/5900 (epoch 18.593) train_loss=1465.56787109 time/batch=0.63s
1098/5900 (epoch 18.610) train_loss=1842.14892578 time/batch=0.77s
1099/5900 (epoch 18.627) train_loss=1656.64550781 time/batch=0.68s
1100/5900 (epoch 18.644) train_loss=1554.65771484 time/batch=0.67s
1101/5900 (epoch 18.661) train_loss=1752.16894531 time/batch=0.85s
1102/5900 (epoch 18.678) train_loss=1814.10278320 time/batch=2.52s
1103/5900 (epoch 18.695) train_loss=2624.48852539 time/batch=2.47s
1104/5900 (epoch 18.712) train_loss=1726.88085938 time/batch=0.87s
1105/5900 (epoch 18.729) train_loss=1922.58886719 time/batch=1.25s
1106/5900 (epoch 18.746) train_loss=1611.50476074 time/batch=0.71s
1107/5900 (epoch 18.763) train_loss=1640.14013672 time/batch=1.31s
1108/5900 (epoch 18.780) train_loss=1453.37890625 time/batch=0.68s
1109/5900 (epoch 18.797) train_loss=1615.69128418 time/batch=0.70s
1110/5900 (epoch 18.814) train_loss=1407.01586914 time/batch=0.62s
1111/5900 (epoch 18.831) train_loss=1724.17407227 time/batch=1.31s
1112/5900 (epoch 18.847) train_loss=1718.95312500 time/batch=0.77s
1113/5900 (epoch 18.864) train_loss=1359.45971680 time/batch=0.59s
1114/5900 (epoch 18.881) train_loss=1366.82702637 time/batch=0.70s
1115/5900 (epoch 18.898) train_loss=1312.67187500 time/batch=0.59s
1116/5900 (epoch 18.915) train_loss=1494.28283691 time/batch=0.74s
1117/5900 (epoch 18.932) train_loss=1500.98583984 time/batch=0.66s
1118/5900 (epoch 18.949) train_loss=1468.88330078 time/batch=0.69s
1119/5900 (epoch 18.966) train_loss=1543.08068848 time/batch=0.70s
1120/5900 (epoch 18.983) train_loss=1492.11157227 time/batch=0.67s
1121/5900 (epoch 19.000) train_loss=1378.57153320 time/batch=0.63s
1122/5900 (epoch 19.017) train_loss=1556.16137695 time/batch=0.68s
1123/5900 (epoch 19.034) train_loss=2240.96655273 time/batch=1.01s
1124/5900 (epoch 19.051) train_loss=1713.93139648 time/batch=0.76s
1125/5900 (epoch 19.068) train_loss=1859.48291016 time/batch=0.81s
1126/5900 (epoch 19.085) train_loss=1471.93627930 time/batch=0.64s
1127/5900 (epoch 19.102) train_loss=1653.89733887 time/batch=2.45s
1128/5900 (epoch 19.119) train_loss=1477.49768066 time/batch=0.77s
1129/5900 (epoch 19.136) train_loss=2352.51806641 time/batch=2.18s
1130/5900 (epoch 19.153) train_loss=1969.49206543 time/batch=0.89s
1131/5900 (epoch 19.169) train_loss=2312.64501953 time/batch=1.60s
1132/5900 (epoch 19.186) train_loss=1388.94824219 time/batch=0.66s
1133/5900 (epoch 19.203) train_loss=1527.43872070 time/batch=0.67s
1134/5900 (epoch 19.220) train_loss=2061.03125000 time/batch=2.99s
1135/5900 (epoch 19.237) train_loss=1619.48779297 time/batch=1.46s
1136/5900 (epoch 19.254) train_loss=1551.85656738 time/batch=0.74s
1137/5900 (epoch 19.271) train_loss=1643.23559570 time/batch=0.72s
1138/5900 (epoch 19.288) train_loss=1443.08764648 time/batch=0.65s
1139/5900 (epoch 19.305) train_loss=1966.90551758 time/batch=1.42s
1140/5900 (epoch 19.322) train_loss=1490.71105957 time/batch=1.29s
1141/5900 (epoch 19.339) train_loss=1865.08398438 time/batch=1.85s
1142/5900 (epoch 19.356) train_loss=1568.04809570 time/batch=0.74s
1143/5900 (epoch 19.373) train_loss=1432.56689453 time/batch=0.60s
1144/5900 (epoch 19.390) train_loss=1395.10961914 time/batch=0.61s
1145/5900 (epoch 19.407) train_loss=1510.52124023 time/batch=0.68s
1146/5900 (epoch 19.424) train_loss=1432.04345703 time/batch=0.62s
1147/5900 (epoch 19.441) train_loss=1672.73413086 time/batch=0.71s
1148/5900 (epoch 19.458) train_loss=1684.71044922 time/batch=0.75s
1149/5900 (epoch 19.475) train_loss=1668.72045898 time/batch=1.38s
1150/5900 (epoch 19.492) train_loss=1555.48864746 time/batch=1.32s
1151/5900 (epoch 19.508) train_loss=1569.27172852 time/batch=0.74s
1152/5900 (epoch 19.525) train_loss=1919.85107422 time/batch=0.82s
1153/5900 (epoch 19.542) train_loss=1380.81958008 time/batch=0.70s
1154/5900 (epoch 19.559) train_loss=1376.07666016 time/batch=0.60s
1155/5900 (epoch 19.576) train_loss=1488.13684082 time/batch=0.63s
1156/5900 (epoch 19.593) train_loss=1457.69152832 time/batch=0.67s
1157/5900 (epoch 19.610) train_loss=1452.92187500 time/batch=1.19s
1158/5900 (epoch 19.627) train_loss=1426.46643066 time/batch=0.62s
1159/5900 (epoch 19.644) train_loss=2024.10620117 time/batch=1.02s
1160/5900 (epoch 19.661) train_loss=1692.59423828 time/batch=0.74s
1161/5900 (epoch 19.678) train_loss=1833.23339844 time/batch=0.76s
1162/5900 (epoch 19.695) train_loss=1681.02563477 time/batch=0.73s
1163/5900 (epoch 19.712) train_loss=1342.38281250 time/batch=0.59s
1164/5900 (epoch 19.729) train_loss=1380.60571289 time/batch=0.64s
1165/5900 (epoch 19.746) train_loss=1818.44628906 time/batch=0.82s
1166/5900 (epoch 19.763) train_loss=1712.46826172 time/batch=0.76s
1167/5900 (epoch 19.780) train_loss=1696.80114746 time/batch=0.75s
1168/5900 (epoch 19.797) train_loss=1601.23071289 time/batch=1.31s
1169/5900 (epoch 19.814) train_loss=1681.45996094 time/batch=0.77s
1170/5900 (epoch 19.831) train_loss=1912.68896484 time/batch=0.83s
1171/5900 (epoch 19.847) train_loss=1787.94458008 time/batch=0.83s
1172/5900 (epoch 19.864) train_loss=1461.85766602 time/batch=0.66s
1173/5900 (epoch 19.881) train_loss=1992.67614746 time/batch=2.34s
1174/5900 (epoch 19.898) train_loss=2028.37890625 time/batch=2.61s
1175/5900 (epoch 19.915) train_loss=1525.70532227 time/batch=0.79s
1176/5900 (epoch 19.932) train_loss=1269.10131836 time/batch=0.61s
1177/5900 (epoch 19.949) train_loss=1446.39062500 time/batch=0.69s
1178/5900 (epoch 19.966) train_loss=1525.91833496 time/batch=0.62s
1179/5900 (epoch 19.983) train_loss=1492.14624023 time/batch=0.68s
1180/5900 (epoch 20.000) train_loss=1501.58190918 time/batch=0.68s
  saved to metadata/config5--20190119-211157.pkl
1181/5900 (epoch 20.017) train_loss=1826.45898438 time/batch=0.83s
1182/5900 (epoch 20.034) train_loss=1401.24194336 time/batch=0.62s
1183/5900 (epoch 20.051) train_loss=1775.21850586 time/batch=1.80s
1184/5900 (epoch 20.068) train_loss=2167.59228516 time/batch=2.43s
1185/5900 (epoch 20.085) train_loss=1848.13671875 time/batch=0.91s
1186/5900 (epoch 20.102) train_loss=2112.63012695 time/batch=2.10s
1187/5900 (epoch 20.119) train_loss=2049.89550781 time/batch=1.11s
1188/5900 (epoch 20.136) train_loss=1311.04833984 time/batch=0.59s
1189/5900 (epoch 20.153) train_loss=2263.72412109 time/batch=1.56s
1190/5900 (epoch 20.169) train_loss=1438.35058594 time/batch=1.28s
1191/5900 (epoch 20.186) train_loss=1977.91088867 time/batch=0.88s
1192/5900 (epoch 20.203) train_loss=1445.98266602 time/batch=0.64s
1193/5900 (epoch 20.220) train_loss=1665.61352539 time/batch=0.71s
1194/5900 (epoch 20.237) train_loss=1377.34924316 time/batch=1.20s
1195/5900 (epoch 20.254) train_loss=1564.08679199 time/batch=1.32s
1196/5900 (epoch 20.271) train_loss=1571.03051758 time/batch=0.72s
1197/5900 (epoch 20.288) train_loss=1323.66296387 time/batch=0.61s
1198/5900 (epoch 20.305) train_loss=1544.87243652 time/batch=0.68s
1199/5900 (epoch 20.322) train_loss=1458.73242188 time/batch=0.64s
1200/5900 (epoch 20.339) train_loss=1852.36791992 time/batch=0.76s
1201/5900 (epoch 20.356) train_loss=2053.27758789 time/batch=1.53s
1202/5900 (epoch 20.373) train_loss=1402.68261719 time/batch=0.67s
1203/5900 (epoch 20.390) train_loss=1473.66967773 time/batch=0.69s
1204/5900 (epoch 20.407) train_loss=1699.58911133 time/batch=0.73s
1205/5900 (epoch 20.424) train_loss=1561.89428711 time/batch=0.69s
1206/5900 (epoch 20.441) train_loss=1724.55810547 time/batch=0.75s
1207/5900 (epoch 20.458) train_loss=2439.99340820 time/batch=2.99s
1208/5900 (epoch 20.475) train_loss=1972.39868164 time/batch=0.94s
1209/5900 (epoch 20.492) train_loss=1681.86437988 time/batch=0.76s
1210/5900 (epoch 20.508) train_loss=1645.52221680 time/batch=0.74s
1211/5900 (epoch 20.525) train_loss=1805.02746582 time/batch=0.82s
1212/5900 (epoch 20.542) train_loss=1738.94360352 time/batch=0.75s
1213/5900 (epoch 20.559) train_loss=1536.49584961 time/batch=0.66s
1214/5900 (epoch 20.576) train_loss=1577.02368164 time/batch=0.67s
1215/5900 (epoch 20.593) train_loss=1801.53808594 time/batch=0.76s
1216/5900 (epoch 20.610) train_loss=1514.29345703 time/batch=0.65s
1217/5900 (epoch 20.627) train_loss=1288.56506348 time/batch=0.60s
1218/5900 (epoch 20.644) train_loss=1315.79125977 time/batch=0.61s
1219/5900 (epoch 20.661) train_loss=1647.87182617 time/batch=0.71s
1220/5900 (epoch 20.678) train_loss=1606.71606445 time/batch=1.31s
1221/5900 (epoch 20.695) train_loss=1681.45642090 time/batch=0.76s
1222/5900 (epoch 20.712) train_loss=1549.93566895 time/batch=0.69s
1223/5900 (epoch 20.729) train_loss=1934.28393555 time/batch=2.49s
1224/5900 (epoch 20.746) train_loss=1450.66430664 time/batch=0.81s
1225/5900 (epoch 20.763) train_loss=1343.37072754 time/batch=0.61s
1226/5900 (epoch 20.780) train_loss=1746.15136719 time/batch=1.40s
1227/5900 (epoch 20.797) train_loss=1553.23461914 time/batch=0.73s
1228/5900 (epoch 20.814) train_loss=1573.56689453 time/batch=1.32s
1229/5900 (epoch 20.831) train_loss=1353.46166992 time/batch=0.65s
1230/5900 (epoch 20.847) train_loss=1718.15515137 time/batch=0.73s
1231/5900 (epoch 20.864) train_loss=1460.46826172 time/batch=0.64s
1232/5900 (epoch 20.881) train_loss=1529.32531738 time/batch=0.64s
1233/5900 (epoch 20.898) train_loss=1555.15417480 time/batch=0.77s
1234/5900 (epoch 20.915) train_loss=1613.58007812 time/batch=1.35s
1235/5900 (epoch 20.932) train_loss=1424.66064453 time/batch=0.69s
1236/5900 (epoch 20.949) train_loss=1484.40527344 time/batch=0.70s
1237/5900 (epoch 20.966) train_loss=1436.31835938 time/batch=0.61s
1238/5900 (epoch 20.983) train_loss=1399.10534668 time/batch=0.60s
1239/5900 (epoch 21.000) train_loss=1427.62365723 time/batch=0.68s
1240/5900 (epoch 21.017) train_loss=1708.42456055 time/batch=0.74s
1241/5900 (epoch 21.034) train_loss=1399.30566406 time/batch=1.22s
1242/5900 (epoch 21.051) train_loss=1821.48706055 time/batch=0.84s
1243/5900 (epoch 21.068) train_loss=1293.10156250 time/batch=0.59s
1244/5900 (epoch 21.085) train_loss=1683.55957031 time/batch=0.71s
1245/5900 (epoch 21.102) train_loss=1497.29785156 time/batch=1.31s
1246/5900 (epoch 21.119) train_loss=2265.12402344 time/batch=2.21s
1247/5900 (epoch 21.136) train_loss=1964.76147461 time/batch=0.89s
1248/5900 (epoch 21.153) train_loss=1923.00683594 time/batch=2.38s
1249/5900 (epoch 21.169) train_loss=1630.92028809 time/batch=0.81s
1250/5900 (epoch 21.186) train_loss=1321.75378418 time/batch=1.19s
1251/5900 (epoch 21.203) train_loss=2311.74975586 time/batch=3.06s
1252/5900 (epoch 21.220) train_loss=1412.80078125 time/batch=0.75s
1253/5900 (epoch 21.237) train_loss=1419.91455078 time/batch=0.64s
1254/5900 (epoch 21.254) train_loss=1480.51855469 time/batch=0.67s
1255/5900 (epoch 21.271) train_loss=1649.05700684 time/batch=0.71s
1256/5900 (epoch 21.288) train_loss=1518.27087402 time/batch=0.69s
1257/5900 (epoch 21.305) train_loss=2263.00000000 time/batch=1.80s
1258/5900 (epoch 21.322) train_loss=2311.59838867 time/batch=1.65s
1259/5900 (epoch 21.339) train_loss=1892.31884766 time/batch=1.25s
1260/5900 (epoch 21.356) train_loss=1525.84106445 time/batch=0.72s
1261/5900 (epoch 21.373) train_loss=1646.85400391 time/batch=1.36s
1262/5900 (epoch 21.390) train_loss=1672.00903320 time/batch=1.33s
1263/5900 (epoch 21.407) train_loss=1632.88415527 time/batch=0.79s
1264/5900 (epoch 21.424) train_loss=1438.78833008 time/batch=0.63s
1265/5900 (epoch 21.441) train_loss=1969.10668945 time/batch=1.43s
1266/5900 (epoch 21.458) train_loss=1683.87329102 time/batch=0.78s
1267/5900 (epoch 21.475) train_loss=1674.99938965 time/batch=0.75s
1268/5900 (epoch 21.492) train_loss=2013.07739258 time/batch=0.91s
1269/5900 (epoch 21.508) train_loss=1853.80651855 time/batch=0.81s
1270/5900 (epoch 21.525) train_loss=1740.81677246 time/batch=2.50s
1271/5900 (epoch 21.542) train_loss=1342.21704102 time/batch=0.71s
1272/5900 (epoch 21.559) train_loss=1732.33447266 time/batch=0.73s
1273/5900 (epoch 21.576) train_loss=1788.95922852 time/batch=2.52s
1274/5900 (epoch 21.593) train_loss=1780.77050781 time/batch=0.85s
1275/5900 (epoch 21.610) train_loss=1371.89355469 time/batch=0.64s
1276/5900 (epoch 21.627) train_loss=1828.76977539 time/batch=0.77s
1277/5900 (epoch 21.644) train_loss=1335.23608398 time/batch=0.64s
1278/5900 (epoch 21.661) train_loss=1431.00964355 time/batch=0.64s
1279/5900 (epoch 21.678) train_loss=1705.48559570 time/batch=0.76s
1280/5900 (epoch 21.695) train_loss=1319.87744141 time/batch=0.58s
1281/5900 (epoch 21.712) train_loss=1364.74609375 time/batch=0.62s
1282/5900 (epoch 21.729) train_loss=1246.57727051 time/batch=0.60s
1283/5900 (epoch 21.746) train_loss=1912.99365234 time/batch=1.22s
1284/5900 (epoch 21.763) train_loss=1488.57568359 time/batch=0.69s
1285/5900 (epoch 21.780) train_loss=1532.82446289 time/batch=0.71s
1286/5900 (epoch 21.797) train_loss=1372.83374023 time/batch=0.62s
1287/5900 (epoch 21.814) train_loss=1566.29309082 time/batch=0.70s
1288/5900 (epoch 21.831) train_loss=1469.86328125 time/batch=0.66s
1289/5900 (epoch 21.847) train_loss=1372.28393555 time/batch=0.67s
1290/5900 (epoch 21.864) train_loss=1429.46704102 time/batch=0.68s
1291/5900 (epoch 21.881) train_loss=1545.72009277 time/batch=0.69s
1292/5900 (epoch 21.898) train_loss=1469.50170898 time/batch=0.68s
1293/5900 (epoch 21.915) train_loss=1508.04992676 time/batch=0.68s
1294/5900 (epoch 21.932) train_loss=1437.83544922 time/batch=0.68s
1295/5900 (epoch 21.949) train_loss=1504.30004883 time/batch=0.67s
1296/5900 (epoch 21.966) train_loss=1469.97497559 time/batch=0.67s
1297/5900 (epoch 21.983) train_loss=1440.29541016 time/batch=0.67s
1298/5900 (epoch 22.000) train_loss=1392.62963867 time/batch=0.61s
setting learning rate to 0.0029100
1299/5900 (epoch 22.017) train_loss=2073.84765625 time/batch=1.51s
1300/5900 (epoch 22.034) train_loss=1485.07910156 time/batch=1.34s
1301/5900 (epoch 22.051) train_loss=1251.53454590 time/batch=0.62s
1302/5900 (epoch 22.068) train_loss=1275.49511719 time/batch=0.59s
1303/5900 (epoch 22.085) train_loss=1947.54687500 time/batch=1.43s
1304/5900 (epoch 22.102) train_loss=1458.49572754 time/batch=0.74s
1305/5900 (epoch 22.119) train_loss=1780.25512695 time/batch=2.54s
1306/5900 (epoch 22.136) train_loss=1641.54455566 time/batch=1.43s
1307/5900 (epoch 22.153) train_loss=2144.36230469 time/batch=2.23s
1308/5900 (epoch 22.169) train_loss=1685.03747559 time/batch=2.49s
1309/5900 (epoch 22.186) train_loss=2202.67919922 time/batch=1.12s
1310/5900 (epoch 22.203) train_loss=1493.93823242 time/batch=1.21s
1311/5900 (epoch 22.220) train_loss=1620.49536133 time/batch=0.74s
1312/5900 (epoch 22.237) train_loss=1281.62377930 time/batch=0.59s
1313/5900 (epoch 22.254) train_loss=1213.59851074 time/batch=0.60s
1314/5900 (epoch 22.271) train_loss=1410.59692383 time/batch=1.20s
1315/5900 (epoch 22.288) train_loss=1862.55371094 time/batch=0.83s
1316/5900 (epoch 22.305) train_loss=1825.33874512 time/batch=0.77s
1317/5900 (epoch 22.322) train_loss=2331.17065430 time/batch=1.58s
1318/5900 (epoch 22.339) train_loss=1514.00146484 time/batch=0.74s
1319/5900 (epoch 22.356) train_loss=1561.68530273 time/batch=0.71s
1320/5900 (epoch 22.373) train_loss=1360.05517578 time/batch=0.62s
1321/5900 (epoch 22.390) train_loss=1347.99072266 time/batch=0.61s
1322/5900 (epoch 22.407) train_loss=1506.04028320 time/batch=0.69s
1323/5900 (epoch 22.424) train_loss=1383.60241699 time/batch=0.65s
1324/5900 (epoch 22.441) train_loss=1617.24511719 time/batch=0.72s
1325/5900 (epoch 22.458) train_loss=1326.66796875 time/batch=0.63s
1326/5900 (epoch 22.475) train_loss=2252.58569336 time/batch=2.96s
1327/5900 (epoch 22.492) train_loss=1674.59472656 time/batch=0.90s
1328/5900 (epoch 22.508) train_loss=1679.24255371 time/batch=0.72s
1329/5900 (epoch 22.525) train_loss=1702.01025391 time/batch=0.74s
1330/5900 (epoch 22.542) train_loss=1470.50268555 time/batch=0.66s
1331/5900 (epoch 22.559) train_loss=1348.89831543 time/batch=0.61s
1332/5900 (epoch 22.576) train_loss=1400.95751953 time/batch=0.63s
1333/5900 (epoch 22.593) train_loss=1820.41174316 time/batch=0.79s
1334/5900 (epoch 22.610) train_loss=1262.81640625 time/batch=0.59s
1335/5900 (epoch 22.627) train_loss=1648.12792969 time/batch=0.74s
1336/5900 (epoch 22.644) train_loss=1678.05871582 time/batch=0.71s
1337/5900 (epoch 22.661) train_loss=1489.43920898 time/batch=0.69s
1338/5900 (epoch 22.678) train_loss=1902.06298828 time/batch=0.81s
1339/5900 (epoch 22.695) train_loss=1476.30090332 time/batch=0.68s
1340/5900 (epoch 22.712) train_loss=2238.58300781 time/batch=2.36s
1341/5900 (epoch 22.729) train_loss=1454.94775391 time/batch=0.75s
1342/5900 (epoch 22.746) train_loss=1334.96630859 time/batch=0.60s
1343/5900 (epoch 22.763) train_loss=1337.40551758 time/batch=1.21s
1344/5900 (epoch 22.780) train_loss=1955.50415039 time/batch=0.93s
1345/5900 (epoch 22.797) train_loss=1439.21057129 time/batch=0.67s
1346/5900 (epoch 22.814) train_loss=1624.78833008 time/batch=0.76s
1347/5900 (epoch 22.831) train_loss=1586.02221680 time/batch=0.72s
1348/5900 (epoch 22.847) train_loss=1533.22900391 time/batch=0.76s
1349/5900 (epoch 22.864) train_loss=1751.21704102 time/batch=0.78s
1350/5900 (epoch 22.881) train_loss=1488.67431641 time/batch=1.76s
1351/5900 (epoch 22.898) train_loss=1510.47753906 time/batch=0.71s
1352/5900 (epoch 22.915) train_loss=1564.20178223 time/batch=0.69s
1353/5900 (epoch 22.932) train_loss=1718.30322266 time/batch=0.91s
1354/5900 (epoch 22.949) train_loss=1535.73632812 time/batch=1.34s
1355/5900 (epoch 22.966) train_loss=1487.18762207 time/batch=0.72s
1356/5900 (epoch 22.983) train_loss=1590.69104004 time/batch=1.33s
1357/5900 (epoch 23.000) train_loss=1462.31323242 time/batch=0.71s
setting learning rate to 0.0028227
1358/5900 (epoch 23.017) train_loss=2323.73486328 time/batch=2.21s
1359/5900 (epoch 23.034) train_loss=1629.89123535 time/batch=2.55s
1360/5900 (epoch 23.051) train_loss=1310.11840820 time/batch=0.73s
1361/5900 (epoch 23.068) train_loss=2067.66186523 time/batch=2.33s
1362/5900 (epoch 23.085) train_loss=1799.11169434 time/batch=1.00s
1363/5900 (epoch 23.102) train_loss=1250.48095703 time/batch=1.25s
1364/5900 (epoch 23.119) train_loss=1631.48632812 time/batch=0.74s
1365/5900 (epoch 23.136) train_loss=2010.97412109 time/batch=2.97s
1366/5900 (epoch 23.153) train_loss=1298.35668945 time/batch=0.73s
1367/5900 (epoch 23.169) train_loss=1468.59143066 time/batch=1.21s
1368/5900 (epoch 23.186) train_loss=1868.17785645 time/batch=0.82s
1369/5900 (epoch 23.203) train_loss=1652.52087402 time/batch=0.74s
1370/5900 (epoch 23.220) train_loss=1586.17260742 time/batch=1.32s
1371/5900 (epoch 23.237) train_loss=1339.57446289 time/batch=0.65s
1372/5900 (epoch 23.254) train_loss=1638.87585449 time/batch=0.71s
1373/5900 (epoch 23.271) train_loss=1426.72497559 time/batch=0.67s
1374/5900 (epoch 23.288) train_loss=1958.16040039 time/batch=0.93s
1375/5900 (epoch 23.305) train_loss=1911.92590332 time/batch=0.85s
1376/5900 (epoch 23.322) train_loss=1673.47302246 time/batch=0.74s
1377/5900 (epoch 23.339) train_loss=1827.44836426 time/batch=0.79s
1378/5900 (epoch 23.356) train_loss=1420.24841309 time/batch=0.64s
1379/5900 (epoch 23.373) train_loss=1628.85986328 time/batch=0.73s
1380/5900 (epoch 23.390) train_loss=1350.57983398 time/batch=0.60s
1381/5900 (epoch 23.407) train_loss=1260.83703613 time/batch=0.58s
1382/5900 (epoch 23.424) train_loss=2098.86254883 time/batch=2.52s
1383/5900 (epoch 23.441) train_loss=1680.12866211 time/batch=0.83s
1384/5900 (epoch 23.458) train_loss=1515.09057617 time/batch=0.71s
1385/5900 (epoch 23.475) train_loss=1547.69921875 time/batch=1.33s
1386/5900 (epoch 23.492) train_loss=1450.97070312 time/batch=1.25s
1387/5900 (epoch 23.508) train_loss=1554.60192871 time/batch=0.73s
1388/5900 (epoch 23.525) train_loss=2182.72656250 time/batch=1.60s
1389/5900 (epoch 23.542) train_loss=1862.27197266 time/batch=1.47s
1390/5900 (epoch 23.559) train_loss=1393.53564453 time/batch=0.71s
1391/5900 (epoch 23.576) train_loss=1794.47216797 time/batch=0.98s
1392/5900 (epoch 23.593) train_loss=1576.39624023 time/batch=0.70s
1393/5900 (epoch 23.610) train_loss=1722.99560547 time/batch=0.76s
1394/5900 (epoch 23.627) train_loss=1661.46667480 time/batch=1.36s
1395/5900 (epoch 23.644) train_loss=1491.93872070 time/batch=0.73s
1396/5900 (epoch 23.661) train_loss=1308.13269043 time/batch=0.60s
1397/5900 (epoch 23.678) train_loss=1399.59228516 time/batch=0.65s
1398/5900 (epoch 23.695) train_loss=1853.80737305 time/batch=0.94s
1399/5900 (epoch 23.712) train_loss=1298.80883789 time/batch=0.63s
1400/5900 (epoch 23.729) train_loss=1532.49877930 time/batch=1.26s
1401/5900 (epoch 23.746) train_loss=1669.97644043 time/batch=1.03s
1402/5900 (epoch 23.763) train_loss=1405.19482422 time/batch=0.69s
1403/5900 (epoch 23.780) train_loss=1421.12548828 time/batch=0.67s
1404/5900 (epoch 23.797) train_loss=1383.41210938 time/batch=0.61s
1405/5900 (epoch 23.814) train_loss=1455.96582031 time/batch=0.69s
1406/5900 (epoch 23.831) train_loss=1435.73168945 time/batch=0.67s
1407/5900 (epoch 23.847) train_loss=1776.69799805 time/batch=0.79s
1408/5900 (epoch 23.864) train_loss=1642.77832031 time/batch=0.76s
1409/5900 (epoch 23.881) train_loss=1655.24694824 time/batch=0.74s
1410/5900 (epoch 23.898) train_loss=1407.27355957 time/batch=0.62s
1411/5900 (epoch 23.915) train_loss=1270.00048828 time/batch=0.68s
1412/5900 (epoch 23.932) train_loss=1395.45800781 time/batch=0.63s
1413/5900 (epoch 23.949) train_loss=1334.91748047 time/batch=0.64s
1414/5900 (epoch 23.966) train_loss=1693.23925781 time/batch=0.95s
1415/5900 (epoch 23.983) train_loss=1375.21350098 time/batch=0.70s
1416/5900 (epoch 24.000) train_loss=1622.60400391 time/batch=0.77s
setting learning rate to 0.0027380
1417/5900 (epoch 24.017) train_loss=1516.53747559 time/batch=1.30s
1418/5900 (epoch 24.034) train_loss=2110.93017578 time/batch=1.02s
1419/5900 (epoch 24.051) train_loss=1879.61279297 time/batch=0.84s
1420/5900 (epoch 24.068) train_loss=1286.55310059 time/batch=0.63s
1421/5900 (epoch 24.085) train_loss=1494.02172852 time/batch=0.68s
1422/5900 (epoch 24.102) train_loss=1416.09899902 time/batch=0.65s
1423/5900 (epoch 24.119) train_loss=1286.16162109 time/batch=0.58s
1424/5900 (epoch 24.136) train_loss=1410.15490723 time/batch=0.70s
1425/5900 (epoch 24.153) train_loss=1923.47729492 time/batch=0.82s
1426/5900 (epoch 24.169) train_loss=1638.71118164 time/batch=0.72s
1427/5900 (epoch 24.186) train_loss=1786.36401367 time/batch=0.77s
1428/5900 (epoch 24.203) train_loss=1265.83801270 time/batch=1.21s
1429/5900 (epoch 24.220) train_loss=1257.09277344 time/batch=0.68s
1430/5900 (epoch 24.237) train_loss=1340.68395996 time/batch=0.66s
1431/5900 (epoch 24.254) train_loss=1679.48291016 time/batch=0.75s
1432/5900 (epoch 24.271) train_loss=1749.44177246 time/batch=0.79s
1433/5900 (epoch 24.288) train_loss=2258.76904297 time/batch=3.00s
1434/5900 (epoch 24.305) train_loss=1744.71044922 time/batch=0.89s
1435/5900 (epoch 24.322) train_loss=1911.85998535 time/batch=0.85s
1436/5900 (epoch 24.339) train_loss=1661.64282227 time/batch=1.36s
1437/5900 (epoch 24.356) train_loss=2006.14379883 time/batch=1.48s
1438/5900 (epoch 24.373) train_loss=1694.09204102 time/batch=0.80s
1439/5900 (epoch 24.390) train_loss=1682.50964355 time/batch=2.51s
1440/5900 (epoch 24.407) train_loss=1737.75878906 time/batch=1.90s
1441/5900 (epoch 24.424) train_loss=1625.00244141 time/batch=0.79s
1442/5900 (epoch 24.441) train_loss=1366.47631836 time/batch=1.23s
1443/5900 (epoch 24.458) train_loss=1450.28637695 time/batch=0.71s
1444/5900 (epoch 24.475) train_loss=1629.81933594 time/batch=0.71s
1445/5900 (epoch 24.492) train_loss=2774.94946289 time/batch=2.35s
1446/5900 (epoch 24.508) train_loss=1515.97216797 time/batch=1.40s
1447/5900 (epoch 24.525) train_loss=1347.64404297 time/batch=0.69s
1448/5900 (epoch 24.542) train_loss=2009.23950195 time/batch=2.20s
1449/5900 (epoch 24.559) train_loss=1300.34313965 time/batch=0.72s
1450/5900 (epoch 24.576) train_loss=1920.05615234 time/batch=1.51s
1451/5900 (epoch 24.593) train_loss=1594.96801758 time/batch=0.77s
1452/5900 (epoch 24.610) train_loss=1498.67712402 time/batch=0.68s
1453/5900 (epoch 24.627) train_loss=1807.04174805 time/batch=2.54s
1454/5900 (epoch 24.644) train_loss=1515.16882324 time/batch=0.79s
1455/5900 (epoch 24.661) train_loss=1264.99096680 time/batch=0.61s
1456/5900 (epoch 24.678) train_loss=1395.40722656 time/batch=0.67s
1457/5900 (epoch 24.695) train_loss=1350.91162109 time/batch=0.62s
1458/5900 (epoch 24.712) train_loss=1636.18261719 time/batch=0.72s
1459/5900 (epoch 24.729) train_loss=1684.12194824 time/batch=0.85s
1460/5900 (epoch 24.746) train_loss=1661.72509766 time/batch=1.09s
1461/5900 (epoch 24.763) train_loss=1600.23828125 time/batch=1.30s
1462/5900 (epoch 24.780) train_loss=1302.56787109 time/batch=0.67s
1463/5900 (epoch 24.797) train_loss=1295.14648438 time/batch=0.62s
1464/5900 (epoch 24.814) train_loss=1346.59375000 time/batch=0.64s
1465/5900 (epoch 24.831) train_loss=1698.98461914 time/batch=0.72s
1466/5900 (epoch 24.847) train_loss=1450.52001953 time/batch=0.65s
1467/5900 (epoch 24.864) train_loss=1553.45336914 time/batch=0.71s
1468/5900 (epoch 24.881) train_loss=1279.41625977 time/batch=0.72s
1469/5900 (epoch 24.898) train_loss=1366.51147461 time/batch=0.64s
1470/5900 (epoch 24.915) train_loss=1430.91601562 time/batch=0.72s
1471/5900 (epoch 24.932) train_loss=1366.12426758 time/batch=0.68s
1472/5900 (epoch 24.949) train_loss=1415.87402344 time/batch=0.70s
1473/5900 (epoch 24.966) train_loss=1365.03674316 time/batch=0.68s
1474/5900 (epoch 24.983) train_loss=1446.42407227 time/batch=0.69s
1475/5900 (epoch 25.000) train_loss=1533.11987305 time/batch=0.67s
setting learning rate to 0.0026559
1476/5900 (epoch 25.017) train_loss=2126.16625977 time/batch=1.60s
1477/5900 (epoch 25.034) train_loss=1807.87475586 time/batch=0.84s
1478/5900 (epoch 25.051) train_loss=1848.92993164 time/batch=0.80s
1479/5900 (epoch 25.068) train_loss=1258.29309082 time/batch=0.60s
1480/5900 (epoch 25.085) train_loss=1312.41857910 time/batch=0.60s
1481/5900 (epoch 25.102) train_loss=2323.33178711 time/batch=2.20s
1482/5900 (epoch 25.119) train_loss=1445.66381836 time/batch=0.74s
1483/5900 (epoch 25.136) train_loss=1763.02465820 time/batch=0.71s
1484/5900 (epoch 25.153) train_loss=1385.19555664 time/batch=0.62s
1485/5900 (epoch 25.169) train_loss=1618.75268555 time/batch=0.73s
1486/5900 (epoch 25.186) train_loss=1432.61474609 time/batch=0.70s
1487/5900 (epoch 25.203) train_loss=1291.54760742 time/batch=0.61s
1488/5900 (epoch 25.220) train_loss=1751.24536133 time/batch=2.49s
1489/5900 (epoch 25.237) train_loss=2189.00585938 time/batch=1.11s
1490/5900 (epoch 25.254) train_loss=1555.22375488 time/batch=0.72s
1491/5900 (epoch 25.271) train_loss=1355.96228027 time/batch=1.25s
1492/5900 (epoch 25.288) train_loss=1302.07177734 time/batch=0.71s
1493/5900 (epoch 25.305) train_loss=1837.57360840 time/batch=0.83s
1494/5900 (epoch 25.322) train_loss=1333.07299805 time/batch=0.65s
1495/5900 (epoch 25.339) train_loss=1541.54760742 time/batch=1.31s
1496/5900 (epoch 25.356) train_loss=1532.84106445 time/batch=0.70s
1497/5900 (epoch 25.373) train_loss=1503.48974609 time/batch=0.69s
1498/5900 (epoch 25.390) train_loss=1991.37365723 time/batch=0.95s
1499/5900 (epoch 25.407) train_loss=1635.49450684 time/batch=2.50s
1500/5900 (epoch 25.424) train_loss=1771.99719238 time/batch=0.89s
1501/5900 (epoch 25.441) train_loss=1581.84191895 time/batch=0.74s
1502/5900 (epoch 25.458) train_loss=1491.62475586 time/batch=0.70s
1503/5900 (epoch 25.475) train_loss=2623.14990234 time/batch=2.96s
1504/5900 (epoch 25.492) train_loss=1541.09277344 time/batch=1.44s
1505/5900 (epoch 25.508) train_loss=1383.30004883 time/batch=0.66s
1506/5900 (epoch 25.525) train_loss=1918.46362305 time/batch=0.83s
1507/5900 (epoch 25.542) train_loss=1750.04492188 time/batch=1.12s
1508/5900 (epoch 25.559) train_loss=1535.35192871 time/batch=1.22s
1509/5900 (epoch 25.576) train_loss=1327.66711426 time/batch=0.67s
1510/5900 (epoch 25.593) train_loss=1535.93090820 time/batch=1.31s
1511/5900 (epoch 25.610) train_loss=1618.98608398 time/batch=1.39s
1512/5900 (epoch 25.627) train_loss=1654.69689941 time/batch=0.79s
1513/5900 (epoch 25.644) train_loss=1873.74658203 time/batch=1.44s
1514/5900 (epoch 25.661) train_loss=1657.29260254 time/batch=0.79s
1515/5900 (epoch 25.678) train_loss=1610.69970703 time/batch=0.71s
1516/5900 (epoch 25.695) train_loss=1369.33374023 time/batch=1.83s
1517/5900 (epoch 25.712) train_loss=1375.32067871 time/batch=0.67s
1518/5900 (epoch 25.729) train_loss=1541.86230469 time/batch=0.68s
1519/5900 (epoch 25.746) train_loss=1660.86035156 time/batch=0.76s
1520/5900 (epoch 25.763) train_loss=1419.44274902 time/batch=0.67s
1521/5900 (epoch 25.780) train_loss=1615.71899414 time/batch=0.74s
1522/5900 (epoch 25.797) train_loss=1316.80249023 time/batch=0.63s
1523/5900 (epoch 25.814) train_loss=1241.88391113 time/batch=0.59s
1524/5900 (epoch 25.831) train_loss=1365.30957031 time/batch=0.65s
1525/5900 (epoch 25.847) train_loss=1396.09411621 time/batch=0.66s
1526/5900 (epoch 25.864) train_loss=1493.39880371 time/batch=0.79s
1527/5900 (epoch 25.881) train_loss=1640.51647949 time/batch=0.77s
1528/5900 (epoch 25.898) train_loss=1345.46484375 time/batch=0.62s
1529/5900 (epoch 25.915) train_loss=1246.97473145 time/batch=0.62s
1530/5900 (epoch 25.932) train_loss=1289.76184082 time/batch=0.62s
1531/5900 (epoch 25.949) train_loss=1374.83898926 time/batch=0.67s
1532/5900 (epoch 25.966) train_loss=1335.51477051 time/batch=0.70s
1533/5900 (epoch 25.983) train_loss=1388.03039551 time/batch=0.68s
1534/5900 (epoch 26.000) train_loss=1485.92565918 time/batch=0.75s
setting learning rate to 0.0025762
1535/5900 (epoch 26.017) train_loss=1933.90246582 time/batch=2.33s
1536/5900 (epoch 26.034) train_loss=1252.38818359 time/batch=0.69s
1537/5900 (epoch 26.051) train_loss=2127.05419922 time/batch=0.98s
1538/5900 (epoch 26.068) train_loss=1896.68359375 time/batch=0.83s
1539/5900 (epoch 26.085) train_loss=1795.78466797 time/batch=0.82s
1540/5900 (epoch 26.102) train_loss=1401.41979980 time/batch=1.25s
1541/5900 (epoch 26.119) train_loss=1371.14916992 time/batch=0.71s
1542/5900 (epoch 26.136) train_loss=1599.68457031 time/batch=0.71s
1543/5900 (epoch 26.153) train_loss=1245.41210938 time/batch=0.69s
1544/5900 (epoch 26.169) train_loss=1964.78552246 time/batch=1.53s
1545/5900 (epoch 26.186) train_loss=1441.71813965 time/batch=0.72s
1546/5900 (epoch 26.203) train_loss=1354.87402344 time/batch=0.65s
1547/5900 (epoch 26.220) train_loss=1443.22900391 time/batch=1.22s
1548/5900 (epoch 26.237) train_loss=1990.13671875 time/batch=0.97s
1549/5900 (epoch 26.254) train_loss=1495.81787109 time/batch=0.70s
1550/5900 (epoch 26.271) train_loss=1532.83471680 time/batch=0.70s
1551/5900 (epoch 26.288) train_loss=1583.65100098 time/batch=0.72s
1552/5900 (epoch 26.305) train_loss=1365.25073242 time/batch=0.67s
1553/5900 (epoch 26.322) train_loss=1545.07629395 time/batch=1.32s
1554/5900 (epoch 26.339) train_loss=1417.07446289 time/batch=0.68s
1555/5900 (epoch 26.356) train_loss=1452.09936523 time/batch=0.69s
1556/5900 (epoch 26.373) train_loss=1138.51135254 time/batch=0.67s
1557/5900 (epoch 26.390) train_loss=2365.89013672 time/batch=1.57s
1558/5900 (epoch 26.407) train_loss=1917.28417969 time/batch=2.46s
1559/5900 (epoch 26.424) train_loss=1354.86816406 time/batch=0.74s
1560/5900 (epoch 26.441) train_loss=1838.50878906 time/batch=2.96s
1561/5900 (epoch 26.458) train_loss=1642.90808105 time/batch=0.88s
1562/5900 (epoch 26.475) train_loss=1381.03479004 time/batch=0.69s
1563/5900 (epoch 26.492) train_loss=1858.94787598 time/batch=0.83s
1564/5900 (epoch 26.508) train_loss=1226.51953125 time/batch=0.69s
1565/5900 (epoch 26.525) train_loss=1820.41845703 time/batch=0.78s
1566/5900 (epoch 26.542) train_loss=1421.13696289 time/batch=0.64s
1567/5900 (epoch 26.559) train_loss=1704.71630859 time/batch=0.75s
1568/5900 (epoch 26.576) train_loss=1595.52563477 time/batch=0.78s
1569/5900 (epoch 26.593) train_loss=1323.91821289 time/batch=0.61s
1570/5900 (epoch 26.610) train_loss=1386.37097168 time/batch=0.69s
1571/5900 (epoch 26.627) train_loss=1503.51818848 time/batch=1.32s
1572/5900 (epoch 26.644) train_loss=1773.50512695 time/batch=0.82s
1573/5900 (epoch 26.661) train_loss=1646.37597656 time/batch=0.78s
1574/5900 (epoch 26.678) train_loss=1834.63635254 time/batch=1.43s
1575/5900 (epoch 26.695) train_loss=1460.38671875 time/batch=0.73s
1576/5900 (epoch 26.712) train_loss=1337.89282227 time/batch=0.64s
1577/5900 (epoch 26.729) train_loss=1607.05187988 time/batch=1.35s
1578/5900 (epoch 26.746) train_loss=1259.41406250 time/batch=0.65s
1579/5900 (epoch 26.763) train_loss=2269.70898438 time/batch=2.48s
1580/5900 (epoch 26.780) train_loss=1593.87072754 time/batch=0.83s
1581/5900 (epoch 26.797) train_loss=1586.58837891 time/batch=0.72s
1582/5900 (epoch 26.814) train_loss=1215.72521973 time/batch=0.64s
1583/5900 (epoch 26.831) train_loss=1536.49902344 time/batch=0.80s
1584/5900 (epoch 26.847) train_loss=1316.92431641 time/batch=0.62s
1585/5900 (epoch 26.864) train_loss=1414.14599609 time/batch=0.66s
1586/5900 (epoch 26.881) train_loss=1426.80761719 time/batch=0.75s
1587/5900 (epoch 26.898) train_loss=1303.16235352 time/batch=0.63s
1588/5900 (epoch 26.915) train_loss=1244.99584961 time/batch=0.76s
1589/5900 (epoch 26.932) train_loss=1630.34802246 time/batch=0.73s
1590/5900 (epoch 26.949) train_loss=1366.69311523 time/batch=0.68s
1591/5900 (epoch 26.966) train_loss=1501.66259766 time/batch=1.31s
1592/5900 (epoch 26.983) train_loss=1294.47314453 time/batch=0.67s
1593/5900 (epoch 27.000) train_loss=1509.83593750 time/batch=0.77s
setting learning rate to 0.0024989
1594/5900 (epoch 27.017) train_loss=1731.45812988 time/batch=0.82s
1595/5900 (epoch 27.034) train_loss=1592.85034180 time/batch=1.36s
1596/5900 (epoch 27.051) train_loss=1939.86206055 time/batch=0.97s
1597/5900 (epoch 27.068) train_loss=1739.39599609 time/batch=0.81s
1598/5900 (epoch 27.085) train_loss=1230.50268555 time/batch=0.61s
1599/5900 (epoch 27.102) train_loss=1275.31909180 time/batch=0.70s
1600/5900 (epoch 27.119) train_loss=1957.67626953 time/batch=0.80s
1601/5900 (epoch 27.136) train_loss=1450.50463867 time/batch=0.68s
1602/5900 (epoch 27.153) train_loss=2196.29418945 time/batch=1.04s
1603/5900 (epoch 27.169) train_loss=1865.80297852 time/batch=1.45s
1604/5900 (epoch 27.186) train_loss=1684.75122070 time/batch=2.52s
1605/5900 (epoch 27.203) train_loss=1414.96191406 time/batch=1.35s
1606/5900 (epoch 27.220) train_loss=1437.03063965 time/batch=0.75s
1607/5900 (epoch 27.237) train_loss=1813.95141602 time/batch=0.80s
1608/5900 (epoch 27.254) train_loss=1448.37524414 time/batch=0.69s
1609/5900 (epoch 27.271) train_loss=1312.47216797 time/batch=0.65s
1610/5900 (epoch 27.288) train_loss=1172.59521484 time/batch=1.22s
1611/5900 (epoch 27.305) train_loss=2626.63989258 time/batch=3.00s
1612/5900 (epoch 27.322) train_loss=1797.64392090 time/batch=0.94s
1613/5900 (epoch 27.339) train_loss=1975.85974121 time/batch=1.52s
1614/5900 (epoch 27.356) train_loss=1345.08105469 time/batch=1.25s
1615/5900 (epoch 27.373) train_loss=1326.10900879 time/batch=0.65s
1616/5900 (epoch 27.390) train_loss=1340.00354004 time/batch=1.18s
1617/5900 (epoch 27.407) train_loss=1203.77685547 time/batch=0.62s
1618/5900 (epoch 27.424) train_loss=1589.84912109 time/batch=2.51s
1619/5900 (epoch 27.441) train_loss=1447.68676758 time/batch=0.75s
1620/5900 (epoch 27.458) train_loss=2206.97558594 time/batch=2.17s
1621/5900 (epoch 27.475) train_loss=1431.99218750 time/batch=0.75s
1622/5900 (epoch 27.492) train_loss=1613.39550781 time/batch=0.71s
1623/5900 (epoch 27.508) train_loss=2056.78271484 time/batch=1.57s
1624/5900 (epoch 27.525) train_loss=1261.31005859 time/batch=0.66s
1625/5900 (epoch 27.542) train_loss=1367.91296387 time/batch=0.67s
1626/5900 (epoch 27.559) train_loss=1535.49609375 time/batch=0.71s
1627/5900 (epoch 27.576) train_loss=1457.14086914 time/batch=0.70s
1628/5900 (epoch 27.593) train_loss=1445.67602539 time/batch=1.16s
1629/5900 (epoch 27.610) train_loss=1493.70410156 time/batch=1.33s
1630/5900 (epoch 27.627) train_loss=1633.86889648 time/batch=0.79s
1631/5900 (epoch 27.644) train_loss=1666.00134277 time/batch=1.76s
1632/5900 (epoch 27.661) train_loss=1602.27954102 time/batch=0.84s
1633/5900 (epoch 27.678) train_loss=1577.50781250 time/batch=0.75s
1634/5900 (epoch 27.695) train_loss=1428.15991211 time/batch=0.73s
1635/5900 (epoch 27.712) train_loss=1186.18603516 time/batch=0.60s
1636/5900 (epoch 27.729) train_loss=1582.65893555 time/batch=0.70s
1637/5900 (epoch 27.746) train_loss=1578.75097656 time/batch=0.68s
1638/5900 (epoch 27.763) train_loss=1454.38085938 time/batch=0.63s
1639/5900 (epoch 27.780) train_loss=1639.37084961 time/batch=0.74s
1640/5900 (epoch 27.797) train_loss=1481.00732422 time/batch=0.74s
1641/5900 (epoch 27.814) train_loss=1591.21606445 time/batch=0.72s
1642/5900 (epoch 27.831) train_loss=1289.20898438 time/batch=0.62s
1643/5900 (epoch 27.847) train_loss=1313.44677734 time/batch=0.68s
1644/5900 (epoch 27.864) train_loss=1332.94055176 time/batch=0.62s
1645/5900 (epoch 27.881) train_loss=1578.71752930 time/batch=0.72s
1646/5900 (epoch 27.898) train_loss=1622.41296387 time/batch=0.79s
1647/5900 (epoch 27.915) train_loss=1483.51220703 time/batch=0.75s
1648/5900 (epoch 27.932) train_loss=1456.47021484 time/batch=1.32s
1649/5900 (epoch 27.949) train_loss=1322.08679199 time/batch=0.70s
1650/5900 (epoch 27.966) train_loss=1240.77856445 time/batch=0.58s
1651/5900 (epoch 27.983) train_loss=1218.99316406 time/batch=0.63s
1652/5900 (epoch 28.000) train_loss=1308.64135742 time/batch=0.59s
setting learning rate to 0.0024239
1653/5900 (epoch 28.017) train_loss=1334.92541504 time/batch=0.65s
1654/5900 (epoch 28.034) train_loss=1689.55212402 time/batch=0.76s
1655/5900 (epoch 28.051) train_loss=1603.97021484 time/batch=1.76s
1656/5900 (epoch 28.068) train_loss=2435.66552734 time/batch=3.03s
1657/5900 (epoch 28.085) train_loss=1195.88208008 time/batch=1.36s
1658/5900 (epoch 28.102) train_loss=1412.40319824 time/batch=0.72s
1659/5900 (epoch 28.119) train_loss=1651.09179688 time/batch=0.74s
1660/5900 (epoch 28.136) train_loss=1494.97900391 time/batch=0.72s
1661/5900 (epoch 28.153) train_loss=1370.29638672 time/batch=0.68s
1662/5900 (epoch 28.169) train_loss=2294.52758789 time/batch=2.49s
1663/5900 (epoch 28.186) train_loss=1715.79406738 time/batch=0.88s
1664/5900 (epoch 28.203) train_loss=1287.37231445 time/batch=0.64s
1665/5900 (epoch 28.220) train_loss=1295.85998535 time/batch=0.63s
1666/5900 (epoch 28.237) train_loss=1733.63391113 time/batch=0.81s
1667/5900 (epoch 28.254) train_loss=1826.23974609 time/batch=0.86s
1668/5900 (epoch 28.271) train_loss=1233.31079102 time/batch=0.60s
1669/5900 (epoch 28.288) train_loss=1558.24267578 time/batch=0.71s
1670/5900 (epoch 28.305) train_loss=1755.89709473 time/batch=2.52s
1671/5900 (epoch 28.322) train_loss=1595.67309570 time/batch=0.82s
1672/5900 (epoch 28.339) train_loss=1600.27380371 time/batch=0.77s
1673/5900 (epoch 28.356) train_loss=1464.02270508 time/batch=0.69s
1674/5900 (epoch 28.373) train_loss=1414.47741699 time/batch=0.69s
1675/5900 (epoch 28.390) train_loss=1403.72521973 time/batch=0.98s
1676/5900 (epoch 28.407) train_loss=1953.30554199 time/batch=0.84s
1677/5900 (epoch 28.424) train_loss=2054.87939453 time/batch=2.17s
1678/5900 (epoch 28.441) train_loss=1887.55493164 time/batch=0.95s
1679/5900 (epoch 28.458) train_loss=1248.68652344 time/batch=0.61s
1680/5900 (epoch 28.475) train_loss=1416.36425781 time/batch=0.69s
1681/5900 (epoch 28.492) train_loss=1213.47314453 time/batch=0.60s
1682/5900 (epoch 28.508) train_loss=1296.09216309 time/batch=0.66s
1683/5900 (epoch 28.525) train_loss=1682.12963867 time/batch=0.74s
1684/5900 (epoch 28.542) train_loss=1224.71423340 time/batch=0.59s
1685/5900 (epoch 28.559) train_loss=1281.66406250 time/batch=0.60s
1686/5900 (epoch 28.576) train_loss=1372.96459961 time/batch=0.63s
1687/5900 (epoch 28.593) train_loss=1498.42456055 time/batch=1.30s
1688/5900 (epoch 28.610) train_loss=1419.05908203 time/batch=0.71s
1689/5900 (epoch 28.627) train_loss=1616.44262695 time/batch=0.73s
1690/5900 (epoch 28.644) train_loss=1308.08862305 time/batch=0.68s
1691/5900 (epoch 28.661) train_loss=2213.87500000 time/batch=1.58s
1692/5900 (epoch 28.678) train_loss=1222.15942383 time/batch=0.66s
1693/5900 (epoch 28.695) train_loss=1278.94567871 time/batch=0.60s
1694/5900 (epoch 28.712) train_loss=1353.39062500 time/batch=0.68s
1695/5900 (epoch 28.729) train_loss=1526.53515625 time/batch=1.35s
1696/5900 (epoch 28.746) train_loss=1304.84887695 time/batch=0.63s
1697/5900 (epoch 28.763) train_loss=1799.22167969 time/batch=1.42s
1698/5900 (epoch 28.780) train_loss=1296.02038574 time/batch=0.73s
1699/5900 (epoch 28.797) train_loss=1977.02172852 time/batch=1.00s
1700/5900 (epoch 28.814) train_loss=1324.86181641 time/batch=0.65s
1701/5900 (epoch 28.831) train_loss=1153.19897461 time/batch=0.60s
1702/5900 (epoch 28.847) train_loss=1312.91845703 time/batch=0.60s
1703/5900 (epoch 28.864) train_loss=1610.16857910 time/batch=1.33s
1704/5900 (epoch 28.881) train_loss=1343.72436523 time/batch=0.72s
1705/5900 (epoch 28.898) train_loss=1545.12768555 time/batch=0.72s
1706/5900 (epoch 28.915) train_loss=1843.55200195 time/batch=0.78s
1707/5900 (epoch 28.932) train_loss=1374.18176270 time/batch=1.22s
1708/5900 (epoch 28.949) train_loss=1871.75610352 time/batch=0.98s
1709/5900 (epoch 28.966) train_loss=1464.85156250 time/batch=0.75s
1710/5900 (epoch 28.983) train_loss=1464.82519531 time/batch=0.68s
1711/5900 (epoch 29.000) train_loss=1389.38623047 time/batch=0.70s
setting learning rate to 0.0023512
1712/5900 (epoch 29.017) train_loss=1704.05810547 time/batch=0.78s
1713/5900 (epoch 29.034) train_loss=1295.09704590 time/batch=0.65s
1714/5900 (epoch 29.051) train_loss=2048.24658203 time/batch=0.99s
1715/5900 (epoch 29.068) train_loss=1198.25244141 time/batch=0.62s
1716/5900 (epoch 29.085) train_loss=2082.89941406 time/batch=1.53s
1717/5900 (epoch 29.102) train_loss=1372.00500488 time/batch=0.72s
1718/5900 (epoch 29.119) train_loss=1779.00354004 time/batch=0.81s
1719/5900 (epoch 29.136) train_loss=1608.39672852 time/batch=0.76s
1720/5900 (epoch 29.153) train_loss=1773.02624512 time/batch=2.52s
1721/5900 (epoch 29.169) train_loss=1754.54101562 time/batch=0.89s
1722/5900 (epoch 29.186) train_loss=1433.99169922 time/batch=0.69s
1723/5900 (epoch 29.203) train_loss=1240.39270020 time/batch=0.60s
1724/5900 (epoch 29.220) train_loss=1370.04785156 time/batch=0.69s
1725/5900 (epoch 29.237) train_loss=1719.34680176 time/batch=2.52s
1726/5900 (epoch 29.254) train_loss=2441.14746094 time/batch=3.02s
1727/5900 (epoch 29.271) train_loss=2201.41552734 time/batch=2.25s
1728/5900 (epoch 29.288) train_loss=1153.48193359 time/batch=1.28s
1729/5900 (epoch 29.305) train_loss=1468.69238281 time/batch=1.36s
1730/5900 (epoch 29.322) train_loss=1862.54077148 time/batch=1.48s
1731/5900 (epoch 29.339) train_loss=1517.01611328 time/batch=1.84s
1732/5900 (epoch 29.356) train_loss=1210.14916992 time/batch=0.65s
1733/5900 (epoch 29.373) train_loss=1264.61486816 time/batch=0.71s
1734/5900 (epoch 29.390) train_loss=1663.81567383 time/batch=0.72s
1735/5900 (epoch 29.407) train_loss=1764.91821289 time/batch=1.01s
1736/5900 (epoch 29.424) train_loss=1304.14501953 time/batch=0.68s
1737/5900 (epoch 29.441) train_loss=1318.12353516 time/batch=0.61s
1738/5900 (epoch 29.458) train_loss=1754.71594238 time/batch=0.80s
1739/5900 (epoch 29.475) train_loss=1742.44824219 time/batch=0.82s
1740/5900 (epoch 29.492) train_loss=1217.33544922 time/batch=0.65s
1741/5900 (epoch 29.508) train_loss=1450.46240234 time/batch=1.22s
1742/5900 (epoch 29.525) train_loss=1731.38171387 time/batch=0.92s
1743/5900 (epoch 29.542) train_loss=1444.64880371 time/batch=1.33s
1744/5900 (epoch 29.559) train_loss=1666.77465820 time/batch=0.76s
1745/5900 (epoch 29.576) train_loss=1820.45385742 time/batch=0.83s
1746/5900 (epoch 29.593) train_loss=1523.77270508 time/batch=0.74s
1747/5900 (epoch 29.610) train_loss=1596.21618652 time/batch=0.76s
1748/5900 (epoch 29.627) train_loss=1584.33374023 time/batch=0.76s
1749/5900 (epoch 29.644) train_loss=1404.42553711 time/batch=0.65s
1750/5900 (epoch 29.661) train_loss=1534.14843750 time/batch=0.71s
1751/5900 (epoch 29.678) train_loss=1252.20849609 time/batch=0.60s
1752/5900 (epoch 29.695) train_loss=1252.81567383 time/batch=0.63s
1753/5900 (epoch 29.712) train_loss=1458.17236328 time/batch=0.68s
1754/5900 (epoch 29.729) train_loss=1392.09643555 time/batch=0.62s
1755/5900 (epoch 29.746) train_loss=1567.33520508 time/batch=0.83s
1756/5900 (epoch 29.763) train_loss=1579.06591797 time/batch=0.70s
1757/5900 (epoch 29.780) train_loss=1374.70288086 time/batch=0.73s
1758/5900 (epoch 29.797) train_loss=1562.10620117 time/batch=1.35s
1759/5900 (epoch 29.814) train_loss=1457.43261719 time/batch=0.77s
1760/5900 (epoch 29.831) train_loss=1493.92944336 time/batch=1.27s
1761/5900 (epoch 29.847) train_loss=1370.67089844 time/batch=0.72s
1762/5900 (epoch 29.864) train_loss=1221.28405762 time/batch=0.64s
1763/5900 (epoch 29.881) train_loss=1514.04150391 time/batch=0.71s
1764/5900 (epoch 29.898) train_loss=1469.58776855 time/batch=0.75s
1765/5900 (epoch 29.915) train_loss=1259.70788574 time/batch=0.76s
1766/5900 (epoch 29.932) train_loss=1240.25170898 time/batch=0.65s
1767/5900 (epoch 29.949) train_loss=1350.07043457 time/batch=0.69s
1768/5900 (epoch 29.966) train_loss=1323.68481445 time/batch=0.63s
1769/5900 (epoch 29.983) train_loss=1193.94799805 time/batch=0.65s
1770/5900 (epoch 30.000) train_loss=1413.00585938 time/batch=0.67s
setting learning rate to 0.0022807
  saved to metadata/config5--20190119-211157.pkl
1771/5900 (epoch 30.017) train_loss=1783.12341309 time/batch=0.82s
1772/5900 (epoch 30.034) train_loss=1225.09912109 time/batch=1.20s
1773/5900 (epoch 30.051) train_loss=1391.81884766 time/batch=0.73s
1774/5900 (epoch 30.068) train_loss=1579.46716309 time/batch=2.51s
1775/5900 (epoch 30.085) train_loss=1588.30627441 time/batch=0.84s
1776/5900 (epoch 30.102) train_loss=1209.66772461 time/batch=0.61s
1777/5900 (epoch 30.119) train_loss=1330.79443359 time/batch=0.68s
1778/5900 (epoch 30.136) train_loss=1809.50024414 time/batch=0.83s
1779/5900 (epoch 30.153) train_loss=1243.30493164 time/batch=0.63s
1780/5900 (epoch 30.169) train_loss=1104.38085938 time/batch=0.61s
1781/5900 (epoch 30.186) train_loss=1290.57910156 time/batch=0.62s
1782/5900 (epoch 30.203) train_loss=2162.12231445 time/batch=2.18s
1783/5900 (epoch 30.220) train_loss=2639.04052734 time/batch=3.08s
1784/5900 (epoch 30.237) train_loss=1540.88427734 time/batch=0.87s
1785/5900 (epoch 30.254) train_loss=1673.95361328 time/batch=0.80s
1786/5900 (epoch 30.271) train_loss=1203.35937500 time/batch=0.63s
1787/5900 (epoch 30.288) train_loss=1816.67907715 time/batch=0.79s
1788/5900 (epoch 30.305) train_loss=1862.81506348 time/batch=1.43s
1789/5900 (epoch 30.322) train_loss=1682.23388672 time/batch=1.16s
1790/5900 (epoch 30.339) train_loss=1771.50146484 time/batch=0.94s
1791/5900 (epoch 30.356) train_loss=2187.64941406 time/batch=8.88s
1792/5900 (epoch 30.373) train_loss=1353.07702637 time/batch=2.10s
1793/5900 (epoch 30.390) train_loss=1689.84155273 time/batch=2.34s
1794/5900 (epoch 30.407) train_loss=2054.07714844 time/batch=5.84s
1795/5900 (epoch 30.424) train_loss=1558.59582520 time/batch=1.99s
1796/5900 (epoch 30.441) train_loss=1726.30432129 time/batch=0.85s
1797/5900 (epoch 30.458) train_loss=1163.02575684 time/batch=0.63s
1798/5900 (epoch 30.475) train_loss=1373.35717773 time/batch=0.73s
1799/5900 (epoch 30.492) train_loss=1463.59997559 time/batch=1.37s
1800/5900 (epoch 30.508) train_loss=1560.91235352 time/batch=0.81s
1801/5900 (epoch 30.525) train_loss=1611.32189941 time/batch=0.74s
1802/5900 (epoch 30.542) train_loss=1662.75488281 time/batch=1.26s
1803/5900 (epoch 30.559) train_loss=1608.35229492 time/batch=0.74s
1804/5900 (epoch 30.576) train_loss=1262.82836914 time/batch=0.64s
1805/5900 (epoch 30.593) train_loss=1233.58227539 time/batch=0.60s
1806/5900 (epoch 30.610) train_loss=1139.98083496 time/batch=0.60s
1807/5900 (epoch 30.627) train_loss=1598.92065430 time/batch=0.72s
1808/5900 (epoch 30.644) train_loss=1931.60546875 time/batch=2.52s
1809/5900 (epoch 30.661) train_loss=1255.12939453 time/batch=0.75s
1810/5900 (epoch 30.678) train_loss=1332.37451172 time/batch=0.81s
1811/5900 (epoch 30.695) train_loss=1200.90002441 time/batch=0.60s
1812/5900 (epoch 30.712) train_loss=1273.46069336 time/batch=0.59s
1813/5900 (epoch 30.729) train_loss=1418.29040527 time/batch=1.36s
1814/5900 (epoch 30.746) train_loss=1196.80810547 time/batch=0.70s
1815/5900 (epoch 30.763) train_loss=1402.65966797 time/batch=0.67s
1816/5900 (epoch 30.780) train_loss=1376.46179199 time/batch=0.69s
1817/5900 (epoch 30.797) train_loss=1364.56811523 time/batch=0.62s
1818/5900 (epoch 30.814) train_loss=1322.38940430 time/batch=0.69s
1819/5900 (epoch 30.831) train_loss=1275.96704102 time/batch=0.69s
1820/5900 (epoch 30.847) train_loss=1513.35253906 time/batch=0.72s
1821/5900 (epoch 30.864) train_loss=1567.78955078 time/batch=0.74s
1822/5900 (epoch 30.881) train_loss=1419.84130859 time/batch=0.70s
1823/5900 (epoch 30.898) train_loss=1329.19555664 time/batch=0.74s
1824/5900 (epoch 30.915) train_loss=1446.66845703 time/batch=1.32s
1825/5900 (epoch 30.932) train_loss=1241.69238281 time/batch=0.65s
1826/5900 (epoch 30.949) train_loss=1464.86621094 time/batch=1.36s
1827/5900 (epoch 30.966) train_loss=1322.88964844 time/batch=0.78s
1828/5900 (epoch 30.983) train_loss=1188.86242676 time/batch=0.69s
1829/5900 (epoch 31.000) train_loss=1398.85876465 time/batch=0.67s
setting learning rate to 0.0022123
1830/5900 (epoch 31.017) train_loss=1221.98461914 time/batch=0.61s
1831/5900 (epoch 31.034) train_loss=1581.95971680 time/batch=0.73s
1832/5900 (epoch 31.051) train_loss=1877.78015137 time/batch=0.85s
1833/5900 (epoch 31.068) train_loss=2163.87402344 time/batch=1.01s
1834/5900 (epoch 31.085) train_loss=1975.49145508 time/batch=2.36s
1835/5900 (epoch 31.102) train_loss=1929.47253418 time/batch=2.60s
1836/5900 (epoch 31.119) train_loss=1626.53198242 time/batch=2.59s
1837/5900 (epoch 31.136) train_loss=2094.90405273 time/batch=1.71s
1838/5900 (epoch 31.153) train_loss=1701.86926270 time/batch=0.82s
1839/5900 (epoch 31.169) train_loss=1304.15393066 time/batch=0.64s
1840/5900 (epoch 31.186) train_loss=1374.05786133 time/batch=0.70s
1841/5900 (epoch 31.203) train_loss=1132.75292969 time/batch=0.62s
1842/5900 (epoch 31.220) train_loss=1437.63476562 time/batch=1.32s
1843/5900 (epoch 31.237) train_loss=1395.26171875 time/batch=0.69s
1844/5900 (epoch 31.254) train_loss=1565.51757812 time/batch=0.73s
1845/5900 (epoch 31.271) train_loss=1175.76367188 time/batch=0.61s
1846/5900 (epoch 31.288) train_loss=1899.03344727 time/batch=1.50s
1847/5900 (epoch 31.305) train_loss=1647.94299316 time/batch=0.80s
1848/5900 (epoch 31.322) train_loss=1136.61450195 time/batch=0.60s
1849/5900 (epoch 31.339) train_loss=1435.18652344 time/batch=1.27s
1850/5900 (epoch 31.356) train_loss=1801.96813965 time/batch=0.86s
1851/5900 (epoch 31.373) train_loss=1843.32446289 time/batch=2.91s
1852/5900 (epoch 31.390) train_loss=1748.10693359 time/batch=0.98s
1853/5900 (epoch 31.407) train_loss=1143.40222168 time/batch=0.60s
1854/5900 (epoch 31.424) train_loss=1437.06542969 time/batch=0.69s
1855/5900 (epoch 31.441) train_loss=1622.78332520 time/batch=0.72s
1856/5900 (epoch 31.458) train_loss=1190.39965820 time/batch=0.65s
1857/5900 (epoch 31.475) train_loss=2057.37182617 time/batch=2.18s
1858/5900 (epoch 31.492) train_loss=1688.06518555 time/batch=1.04s
1859/5900 (epoch 31.508) train_loss=1524.66674805 time/batch=1.37s
1860/5900 (epoch 31.525) train_loss=1631.39880371 time/batch=0.83s
1861/5900 (epoch 31.542) train_loss=1324.38256836 time/batch=1.21s
1862/5900 (epoch 31.559) train_loss=1370.26684570 time/batch=0.70s
1863/5900 (epoch 31.576) train_loss=1343.69812012 time/batch=0.69s
1864/5900 (epoch 31.593) train_loss=1189.03344727 time/batch=0.61s
1865/5900 (epoch 31.610) train_loss=1277.56323242 time/batch=0.60s
1866/5900 (epoch 31.627) train_loss=1406.49670410 time/batch=0.69s
1867/5900 (epoch 31.644) train_loss=1697.76684570 time/batch=0.76s
1868/5900 (epoch 31.661) train_loss=1377.22460938 time/batch=0.64s
1869/5900 (epoch 31.678) train_loss=1881.63256836 time/batch=1.42s
1870/5900 (epoch 31.695) train_loss=1275.31347656 time/batch=0.71s
1871/5900 (epoch 31.712) train_loss=1327.14416504 time/batch=0.70s
1872/5900 (epoch 31.729) train_loss=1175.65454102 time/batch=0.69s
1873/5900 (epoch 31.746) train_loss=1197.65478516 time/batch=0.62s
1874/5900 (epoch 31.763) train_loss=1282.68823242 time/batch=0.63s
1875/5900 (epoch 31.780) train_loss=1470.87719727 time/batch=0.71s
1876/5900 (epoch 31.797) train_loss=1206.76147461 time/batch=0.62s
1877/5900 (epoch 31.814) train_loss=1233.24755859 time/batch=0.65s
1878/5900 (epoch 31.831) train_loss=1535.22192383 time/batch=0.73s
1879/5900 (epoch 31.847) train_loss=1453.51416016 time/batch=1.32s
1880/5900 (epoch 31.864) train_loss=1617.20666504 time/batch=0.76s
1881/5900 (epoch 31.881) train_loss=1245.71289062 time/batch=0.68s
1882/5900 (epoch 31.898) train_loss=1129.90454102 time/batch=1.20s
1883/5900 (epoch 31.915) train_loss=1511.77392578 time/batch=0.75s
1884/5900 (epoch 31.932) train_loss=1565.25598145 time/batch=0.75s
1885/5900 (epoch 31.949) train_loss=1497.66259766 time/batch=0.73s
1886/5900 (epoch 31.966) train_loss=1451.69384766 time/batch=0.77s
1887/5900 (epoch 31.983) train_loss=1282.83813477 time/batch=0.66s
1888/5900 (epoch 32.000) train_loss=1354.47399902 time/batch=0.69s
setting learning rate to 0.0021459
1889/5900 (epoch 32.017) train_loss=1967.92016602 time/batch=2.48s
1890/5900 (epoch 32.034) train_loss=1018.64691162 time/batch=0.67s
1891/5900 (epoch 32.051) train_loss=1782.62207031 time/batch=0.82s
1892/5900 (epoch 32.068) train_loss=2439.06445312 time/batch=2.90s
1893/5900 (epoch 32.085) train_loss=1773.04345703 time/batch=0.99s
1894/5900 (epoch 32.102) train_loss=1252.25158691 time/batch=1.21s
1895/5900 (epoch 32.119) train_loss=1677.97631836 time/batch=0.84s
1896/5900 (epoch 32.136) train_loss=1816.01416016 time/batch=1.42s
1897/5900 (epoch 32.153) train_loss=1521.65319824 time/batch=0.77s
1898/5900 (epoch 32.169) train_loss=1689.96240234 time/batch=1.11s
1899/5900 (epoch 32.186) train_loss=1513.63159180 time/batch=0.73s
1900/5900 (epoch 32.203) train_loss=1535.42602539 time/batch=0.75s
1901/5900 (epoch 32.220) train_loss=1438.08984375 time/batch=0.71s
1902/5900 (epoch 32.237) train_loss=1925.06079102 time/batch=0.93s
1903/5900 (epoch 32.254) train_loss=1681.21801758 time/batch=0.80s
1904/5900 (epoch 32.271) train_loss=1269.52343750 time/batch=0.65s
1905/5900 (epoch 32.288) train_loss=1332.24316406 time/batch=0.66s
1906/5900 (epoch 32.305) train_loss=1719.93786621 time/batch=2.49s
1907/5900 (epoch 32.322) train_loss=1201.30517578 time/batch=0.80s
1908/5900 (epoch 32.339) train_loss=1370.43872070 time/batch=0.66s
1909/5900 (epoch 32.356) train_loss=1415.28442383 time/batch=1.20s
1910/5900 (epoch 32.373) train_loss=1882.82641602 time/batch=0.89s
1911/5900 (epoch 32.390) train_loss=1477.39135742 time/batch=0.72s
1912/5900 (epoch 32.407) train_loss=1630.09179688 time/batch=0.99s
1913/5900 (epoch 32.424) train_loss=1573.04125977 time/batch=1.34s
1914/5900 (epoch 32.441) train_loss=1848.75341797 time/batch=1.00s
1915/5900 (epoch 32.458) train_loss=1256.53369141 time/batch=0.62s
1916/5900 (epoch 32.475) train_loss=1198.41809082 time/batch=0.61s
1917/5900 (epoch 32.492) train_loss=1271.41430664 time/batch=0.66s
1918/5900 (epoch 32.508) train_loss=1939.38183594 time/batch=2.19s
1919/5900 (epoch 32.525) train_loss=1722.85437012 time/batch=0.94s
1920/5900 (epoch 32.542) train_loss=1300.56384277 time/batch=0.69s
1921/5900 (epoch 32.559) train_loss=1402.04687500 time/batch=0.72s
1922/5900 (epoch 32.576) train_loss=1368.11901855 time/batch=0.70s
1923/5900 (epoch 32.593) train_loss=1162.95971680 time/batch=0.67s
1924/5900 (epoch 32.610) train_loss=1609.04711914 time/batch=0.71s
1925/5900 (epoch 32.627) train_loss=1092.25781250 time/batch=0.64s
1926/5900 (epoch 32.644) train_loss=1420.00561523 time/batch=0.68s
1927/5900 (epoch 32.661) train_loss=1242.44555664 time/batch=0.61s
1928/5900 (epoch 32.678) train_loss=1646.19104004 time/batch=0.72s
1929/5900 (epoch 32.695) train_loss=1818.83056641 time/batch=1.48s
1930/5900 (epoch 32.712) train_loss=1102.78564453 time/batch=0.64s
1931/5900 (epoch 32.729) train_loss=1209.24536133 time/batch=0.58s
1932/5900 (epoch 32.746) train_loss=1322.87060547 time/batch=0.64s
1933/5900 (epoch 32.763) train_loss=1370.34350586 time/batch=1.25s
1934/5900 (epoch 32.780) train_loss=1281.99096680 time/batch=0.66s
1935/5900 (epoch 32.797) train_loss=1319.45043945 time/batch=0.66s
1936/5900 (epoch 32.814) train_loss=1566.98791504 time/batch=0.76s
1937/5900 (epoch 32.831) train_loss=1263.86987305 time/batch=0.68s
1938/5900 (epoch 32.847) train_loss=1503.28234863 time/batch=0.72s
1939/5900 (epoch 32.864) train_loss=1192.43151855 time/batch=0.77s
1940/5900 (epoch 32.881) train_loss=1617.05224609 time/batch=1.38s
1941/5900 (epoch 32.898) train_loss=1390.37756348 time/batch=0.71s
1942/5900 (epoch 32.915) train_loss=1499.46533203 time/batch=0.76s
1943/5900 (epoch 32.932) train_loss=1247.31640625 time/batch=0.69s
1944/5900 (epoch 32.949) train_loss=1393.17077637 time/batch=0.69s
1945/5900 (epoch 32.966) train_loss=1150.67651367 time/batch=0.64s
1946/5900 (epoch 32.983) train_loss=1184.57946777 time/batch=0.68s
1947/5900 (epoch 33.000) train_loss=1293.32373047 time/batch=0.69s
setting learning rate to 0.0020815
1948/5900 (epoch 33.017) train_loss=1232.77197266 time/batch=0.65s
1949/5900 (epoch 33.034) train_loss=1639.94897461 time/batch=0.74s
1950/5900 (epoch 33.051) train_loss=1111.12902832 time/batch=0.63s
1951/5900 (epoch 33.068) train_loss=1361.05712891 time/batch=0.68s
1952/5900 (epoch 33.085) train_loss=1520.00830078 time/batch=0.73s
1953/5900 (epoch 33.102) train_loss=1421.66149902 time/batch=1.26s
1954/5900 (epoch 33.119) train_loss=1553.03857422 time/batch=0.76s
1955/5900 (epoch 33.136) train_loss=2025.80285645 time/batch=1.00s
1956/5900 (epoch 33.153) train_loss=2034.75732422 time/batch=2.23s
1957/5900 (epoch 33.169) train_loss=1547.56372070 time/batch=1.89s
1958/5900 (epoch 33.186) train_loss=1310.58911133 time/batch=1.27s
1959/5900 (epoch 33.203) train_loss=2377.27270508 time/batch=3.02s
1960/5900 (epoch 33.220) train_loss=1735.73034668 time/batch=0.95s
1961/5900 (epoch 33.237) train_loss=1538.53051758 time/batch=0.77s
1962/5900 (epoch 33.254) train_loss=1469.24487305 time/batch=1.31s
1963/5900 (epoch 33.271) train_loss=1616.72509766 time/batch=0.75s
1964/5900 (epoch 33.288) train_loss=1542.02343750 time/batch=2.50s
1965/5900 (epoch 33.305) train_loss=1575.34350586 time/batch=0.83s
1966/5900 (epoch 33.322) train_loss=1238.53588867 time/batch=0.62s
1967/5900 (epoch 33.339) train_loss=1639.68762207 time/batch=1.32s
1968/5900 (epoch 33.356) train_loss=1437.51110840 time/batch=0.72s
1969/5900 (epoch 33.373) train_loss=1368.08789062 time/batch=0.69s
1970/5900 (epoch 33.390) train_loss=1987.65063477 time/batch=1.51s
1971/5900 (epoch 33.407) train_loss=1770.23779297 time/batch=1.46s
1972/5900 (epoch 33.424) train_loss=1224.94628906 time/batch=0.72s
1973/5900 (epoch 33.441) train_loss=1170.23168945 time/batch=0.68s
1974/5900 (epoch 33.458) train_loss=1356.56567383 time/batch=0.68s
1975/5900 (epoch 33.475) train_loss=1622.50659180 time/batch=0.79s
1976/5900 (epoch 33.492) train_loss=1824.32666016 time/batch=0.94s
1977/5900 (epoch 33.508) train_loss=1783.57543945 time/batch=0.80s
1978/5900 (epoch 33.525) train_loss=1125.44091797 time/batch=1.22s
1979/5900 (epoch 33.542) train_loss=1946.24755859 time/batch=2.42s
1980/5900 (epoch 33.559) train_loss=1073.52612305 time/batch=0.70s
1981/5900 (epoch 33.576) train_loss=1352.84082031 time/batch=0.68s
1982/5900 (epoch 33.593) train_loss=1315.27441406 time/batch=0.65s
1983/5900 (epoch 33.610) train_loss=1550.94042969 time/batch=0.80s
1984/5900 (epoch 33.627) train_loss=1578.65576172 time/batch=2.46s
1985/5900 (epoch 33.644) train_loss=1229.22863770 time/batch=0.72s
1986/5900 (epoch 33.661) train_loss=1281.74804688 time/batch=0.66s
1987/5900 (epoch 33.678) train_loss=1545.44604492 time/batch=0.80s
1988/5900 (epoch 33.695) train_loss=1160.75659180 time/batch=0.63s
1989/5900 (epoch 33.712) train_loss=1333.94250488 time/batch=0.69s
1990/5900 (epoch 33.729) train_loss=1495.97863770 time/batch=0.73s
1991/5900 (epoch 33.746) train_loss=1297.78686523 time/batch=0.65s
1992/5900 (epoch 33.763) train_loss=1245.21166992 time/batch=0.59s
1993/5900 (epoch 33.780) train_loss=1057.17944336 time/batch=0.57s
1994/5900 (epoch 33.797) train_loss=1372.70703125 time/batch=1.31s
1995/5900 (epoch 33.814) train_loss=1927.13488770 time/batch=1.65s
1996/5900 (epoch 33.831) train_loss=1287.76831055 time/batch=0.73s
1997/5900 (epoch 33.847) train_loss=1753.64135742 time/batch=0.94s
1998/5900 (epoch 33.864) train_loss=1458.04980469 time/batch=0.73s
1999/5900 (epoch 33.881) train_loss=1358.85375977 time/batch=0.68s
Validating
    loss:	1283.091268

2000/5900 (epoch 33.898) train_loss=1462.62060547 time/batch=1.38s
2001/5900 (epoch 33.915) train_loss=1124.02905273 time/batch=0.59s
2002/5900 (epoch 33.932) train_loss=1254.80371094 time/batch=0.64s
2003/5900 (epoch 33.949) train_loss=1333.74853516 time/batch=0.64s
2004/5900 (epoch 33.966) train_loss=1258.75256348 time/batch=0.64s
2005/5900 (epoch 33.983) train_loss=1268.86596680 time/batch=0.68s
2006/5900 (epoch 34.000) train_loss=1224.39660645 time/batch=0.62s
setting learning rate to 0.0020191
2007/5900 (epoch 34.017) train_loss=1833.03759766 time/batch=0.83s
2008/5900 (epoch 34.034) train_loss=1885.20507812 time/batch=1.43s
2009/5900 (epoch 34.051) train_loss=2238.73144531 time/batch=1.62s
2010/5900 (epoch 34.068) train_loss=1320.74182129 time/batch=0.75s
2011/5900 (epoch 34.085) train_loss=1113.88696289 time/batch=0.59s
2012/5900 (epoch 34.102) train_loss=1144.01733398 time/batch=0.57s
2013/5900 (epoch 34.119) train_loss=1501.19946289 time/batch=0.72s
2014/5900 (epoch 34.136) train_loss=1142.18139648 time/batch=0.70s
2015/5900 (epoch 34.153) train_loss=1672.71374512 time/batch=2.47s
2016/5900 (epoch 34.169) train_loss=1658.52856445 time/batch=0.88s
2017/5900 (epoch 34.186) train_loss=1101.62451172 time/batch=1.23s
2018/5900 (epoch 34.203) train_loss=1641.98242188 time/batch=0.82s
2019/5900 (epoch 34.220) train_loss=1524.10229492 time/batch=1.81s
2020/5900 (epoch 34.237) train_loss=1293.28747559 time/batch=0.74s
2021/5900 (epoch 34.254) train_loss=2046.92761230 time/batch=2.17s
2022/5900 (epoch 34.271) train_loss=1908.28247070 time/batch=1.57s
2023/5900 (epoch 34.288) train_loss=1591.23730469 time/batch=0.76s
2024/5900 (epoch 34.305) train_loss=1776.58605957 time/batch=0.83s
2025/5900 (epoch 34.322) train_loss=1109.34948730 time/batch=0.70s
2026/5900 (epoch 34.339) train_loss=2464.12792969 time/batch=2.99s
2027/5900 (epoch 34.356) train_loss=1921.17431641 time/batch=1.09s
2028/5900 (epoch 34.373) train_loss=1408.15161133 time/batch=1.31s
2029/5900 (epoch 34.390) train_loss=1510.74096680 time/batch=0.76s
2030/5900 (epoch 34.407) train_loss=1499.57067871 time/batch=1.35s
2031/5900 (epoch 34.424) train_loss=1314.34094238 time/batch=1.26s
2032/5900 (epoch 34.441) train_loss=1273.97595215 time/batch=0.71s
2033/5900 (epoch 34.458) train_loss=1169.77026367 time/batch=1.19s
2034/5900 (epoch 34.475) train_loss=1249.28857422 time/batch=0.72s
2035/5900 (epoch 34.492) train_loss=1168.84741211 time/batch=0.62s
2036/5900 (epoch 34.508) train_loss=1315.18298340 time/batch=0.67s
2037/5900 (epoch 34.525) train_loss=1210.39428711 time/batch=0.62s
2038/5900 (epoch 34.542) train_loss=1314.88403320 time/batch=0.66s
2039/5900 (epoch 34.559) train_loss=1247.50219727 time/batch=0.62s
2040/5900 (epoch 34.576) train_loss=1530.16357422 time/batch=0.77s
2041/5900 (epoch 34.593) train_loss=1364.85693359 time/batch=0.69s
2042/5900 (epoch 34.610) train_loss=1652.61499023 time/batch=0.80s
2043/5900 (epoch 34.627) train_loss=1490.18090820 time/batch=0.76s
2044/5900 (epoch 34.644) train_loss=1682.91381836 time/batch=0.78s
2045/5900 (epoch 34.661) train_loss=1585.60766602 time/batch=0.72s
2046/5900 (epoch 34.678) train_loss=1380.37145996 time/batch=0.67s
2047/5900 (epoch 34.695) train_loss=1309.53491211 time/batch=0.70s
2048/5900 (epoch 34.712) train_loss=1417.84045410 time/batch=0.74s
2049/5900 (epoch 34.729) train_loss=1964.44189453 time/batch=2.34s
2050/5900 (epoch 34.746) train_loss=1472.01159668 time/batch=0.84s
2051/5900 (epoch 34.763) train_loss=1439.38549805 time/batch=1.10s
2052/5900 (epoch 34.780) train_loss=1215.06652832 time/batch=0.68s
2053/5900 (epoch 34.797) train_loss=1275.94458008 time/batch=0.62s
2054/5900 (epoch 34.814) train_loss=1209.43103027 time/batch=0.61s
2055/5900 (epoch 34.831) train_loss=1337.99548340 time/batch=0.64s
2056/5900 (epoch 34.847) train_loss=1305.80346680 time/batch=0.67s
2057/5900 (epoch 34.864) train_loss=1172.28747559 time/batch=0.64s
2058/5900 (epoch 34.881) train_loss=1362.30688477 time/batch=1.33s
2059/5900 (epoch 34.898) train_loss=1144.75390625 time/batch=0.65s
2060/5900 (epoch 34.915) train_loss=1815.38354492 time/batch=2.48s
2061/5900 (epoch 34.932) train_loss=1105.22412109 time/batch=0.71s
2062/5900 (epoch 34.949) train_loss=1114.33581543 time/batch=0.64s
2063/5900 (epoch 34.966) train_loss=1492.85473633 time/batch=1.30s
2064/5900 (epoch 34.983) train_loss=1493.42749023 time/batch=0.71s
2065/5900 (epoch 35.000) train_loss=1257.57861328 time/batch=0.62s
setting learning rate to 0.0019585
2066/5900 (epoch 35.017) train_loss=1129.14770508 time/batch=0.60s
2067/5900 (epoch 35.034) train_loss=1931.74731445 time/batch=0.92s
2068/5900 (epoch 35.051) train_loss=1189.01879883 time/batch=0.64s
2069/5900 (epoch 35.068) train_loss=1584.23681641 time/batch=0.77s
2070/5900 (epoch 35.085) train_loss=2155.65136719 time/batch=1.60s
2071/5900 (epoch 35.102) train_loss=1721.85278320 time/batch=0.86s
2072/5900 (epoch 35.119) train_loss=1301.12194824 time/batch=1.20s
2073/5900 (epoch 35.136) train_loss=2232.39794922 time/batch=2.24s
2074/5900 (epoch 35.153) train_loss=1508.79565430 time/batch=0.82s
2075/5900 (epoch 35.169) train_loss=1155.20788574 time/batch=0.59s
2076/5900 (epoch 35.186) train_loss=1079.91979980 time/batch=0.58s
2077/5900 (epoch 35.203) train_loss=1217.03015137 time/batch=0.68s
2078/5900 (epoch 35.220) train_loss=1469.04711914 time/batch=0.77s
2079/5900 (epoch 35.237) train_loss=1799.76538086 time/batch=0.82s
2080/5900 (epoch 35.254) train_loss=1506.72241211 time/batch=0.74s
2081/5900 (epoch 35.271) train_loss=1631.59936523 time/batch=2.53s
2082/5900 (epoch 35.288) train_loss=2015.52026367 time/batch=1.12s
2083/5900 (epoch 35.305) train_loss=1652.85034180 time/batch=0.79s
2084/5900 (epoch 35.322) train_loss=1367.38513184 time/batch=1.32s
2085/5900 (epoch 35.339) train_loss=1402.76086426 time/batch=1.41s
2086/5900 (epoch 35.356) train_loss=1518.22509766 time/batch=1.17s
2087/5900 (epoch 35.373) train_loss=1658.07543945 time/batch=0.74s
2088/5900 (epoch 35.390) train_loss=1772.48388672 time/batch=1.42s
2089/5900 (epoch 35.407) train_loss=1256.46228027 time/batch=0.66s
2090/5900 (epoch 35.424) train_loss=2097.44042969 time/batch=2.93s
2091/5900 (epoch 35.441) train_loss=1865.38891602 time/batch=2.60s
2092/5900 (epoch 35.458) train_loss=1493.01269531 time/batch=0.83s
2093/5900 (epoch 35.475) train_loss=1638.83203125 time/batch=0.79s
2094/5900 (epoch 35.492) train_loss=1626.69067383 time/batch=0.83s
2095/5900 (epoch 35.508) train_loss=1342.61645508 time/batch=0.70s
2096/5900 (epoch 35.525) train_loss=1343.54418945 time/batch=0.68s
2097/5900 (epoch 35.542) train_loss=1601.64111328 time/batch=0.70s
2098/5900 (epoch 35.559) train_loss=1631.78808594 time/batch=2.36s
2099/5900 (epoch 35.576) train_loss=1416.80761719 time/batch=1.42s
2100/5900 (epoch 35.593) train_loss=1490.11987305 time/batch=0.78s
2101/5900 (epoch 35.610) train_loss=1321.29797363 time/batch=0.69s
2102/5900 (epoch 35.627) train_loss=1416.76074219 time/batch=0.73s
2103/5900 (epoch 35.644) train_loss=1281.45458984 time/batch=0.62s
2104/5900 (epoch 35.661) train_loss=1160.34167480 time/batch=0.64s
2105/5900 (epoch 35.678) train_loss=1659.65246582 time/batch=0.83s
2106/5900 (epoch 35.695) train_loss=1287.39294434 time/batch=0.67s
2107/5900 (epoch 35.712) train_loss=1219.04772949 time/batch=0.68s
2108/5900 (epoch 35.729) train_loss=1447.25671387 time/batch=0.72s
2109/5900 (epoch 35.746) train_loss=1117.45947266 time/batch=0.62s
2110/5900 (epoch 35.763) train_loss=1201.00256348 time/batch=0.70s
2111/5900 (epoch 35.780) train_loss=1372.62109375 time/batch=1.29s
2112/5900 (epoch 35.797) train_loss=1276.05834961 time/batch=0.71s
2113/5900 (epoch 35.814) train_loss=1079.98925781 time/batch=0.60s
2114/5900 (epoch 35.831) train_loss=1412.08862305 time/batch=0.74s
2115/5900 (epoch 35.847) train_loss=1130.18188477 time/batch=1.21s
2116/5900 (epoch 35.864) train_loss=1258.30700684 time/batch=0.65s
2117/5900 (epoch 35.881) train_loss=1340.97753906 time/batch=0.70s
2118/5900 (epoch 35.898) train_loss=1245.91210938 time/batch=0.64s
2119/5900 (epoch 35.915) train_loss=1196.94775391 time/batch=0.67s
2120/5900 (epoch 35.932) train_loss=1165.23645020 time/batch=0.69s
2121/5900 (epoch 35.949) train_loss=1275.17980957 time/batch=0.62s
2122/5900 (epoch 35.966) train_loss=1296.75634766 time/batch=0.68s
2123/5900 (epoch 35.983) train_loss=1073.78271484 time/batch=0.60s
2124/5900 (epoch 36.000) train_loss=1179.84375000 time/batch=0.65s
setting learning rate to 0.0018998
2125/5900 (epoch 36.017) train_loss=1175.36425781 time/batch=0.66s
2126/5900 (epoch 36.034) train_loss=1807.74877930 time/batch=0.81s
2127/5900 (epoch 36.051) train_loss=956.18884277 time/batch=0.58s
2128/5900 (epoch 36.068) train_loss=1450.19360352 time/batch=0.71s
2129/5900 (epoch 36.085) train_loss=1774.12084961 time/batch=0.86s
2130/5900 (epoch 36.102) train_loss=1442.55297852 time/batch=0.71s
2131/5900 (epoch 36.119) train_loss=1699.03613281 time/batch=0.81s
2132/5900 (epoch 36.136) train_loss=1386.08984375 time/batch=0.66s
2133/5900 (epoch 36.153) train_loss=2077.13281250 time/batch=1.01s
2134/5900 (epoch 36.169) train_loss=1182.84509277 time/batch=0.61s
2135/5900 (epoch 36.186) train_loss=1508.49963379 time/batch=2.41s
2136/5900 (epoch 36.203) train_loss=1330.30273438 time/batch=1.42s
2137/5900 (epoch 36.220) train_loss=1559.95141602 time/batch=1.84s
2138/5900 (epoch 36.237) train_loss=2189.38256836 time/batch=2.55s
2139/5900 (epoch 36.254) train_loss=1206.35217285 time/batch=0.74s
2140/5900 (epoch 36.271) train_loss=1856.08129883 time/batch=1.53s
2141/5900 (epoch 36.288) train_loss=1285.58471680 time/batch=0.70s
2142/5900 (epoch 36.305) train_loss=2037.52709961 time/batch=2.98s
2143/5900 (epoch 36.322) train_loss=1094.73535156 time/batch=0.72s
2144/5900 (epoch 36.339) train_loss=1814.13208008 time/batch=1.40s
2145/5900 (epoch 36.356) train_loss=1939.44653320 time/batch=2.18s
2146/5900 (epoch 36.373) train_loss=1176.06103516 time/batch=0.68s
2147/5900 (epoch 36.390) train_loss=1723.21203613 time/batch=0.93s
2148/5900 (epoch 36.407) train_loss=1075.94897461 time/batch=0.62s
2149/5900 (epoch 36.424) train_loss=1246.86621094 time/batch=0.62s
2150/5900 (epoch 36.441) train_loss=1298.56091309 time/batch=0.67s
2151/5900 (epoch 36.458) train_loss=1361.53308105 time/batch=1.31s
2152/5900 (epoch 36.475) train_loss=1282.87390137 time/batch=0.74s
2153/5900 (epoch 36.492) train_loss=1464.10278320 time/batch=0.76s
2154/5900 (epoch 36.508) train_loss=1106.86401367 time/batch=0.61s
2155/5900 (epoch 36.525) train_loss=1139.12280273 time/batch=0.64s
2156/5900 (epoch 36.542) train_loss=1633.62402344 time/batch=0.92s
2157/5900 (epoch 36.559) train_loss=2095.83691406 time/batch=1.60s
2158/5900 (epoch 36.576) train_loss=1637.96679688 time/batch=0.77s
2159/5900 (epoch 36.593) train_loss=1222.96667480 time/batch=0.70s
2160/5900 (epoch 36.610) train_loss=1492.77038574 time/batch=0.74s
2161/5900 (epoch 36.627) train_loss=1599.90270996 time/batch=0.79s
2162/5900 (epoch 36.644) train_loss=1448.23950195 time/batch=0.71s
2163/5900 (epoch 36.661) train_loss=1397.17138672 time/batch=1.24s
2164/5900 (epoch 36.678) train_loss=1500.54150391 time/batch=0.77s
2165/5900 (epoch 36.695) train_loss=1208.78942871 time/batch=0.64s
2166/5900 (epoch 36.712) train_loss=1422.67126465 time/batch=1.28s
2167/5900 (epoch 36.729) train_loss=1320.10827637 time/batch=0.72s
2168/5900 (epoch 36.746) train_loss=1160.50683594 time/batch=0.62s
2169/5900 (epoch 36.763) train_loss=1217.15356445 time/batch=0.70s
2170/5900 (epoch 36.780) train_loss=1529.16186523 time/batch=0.73s
2171/5900 (epoch 36.797) train_loss=1622.69958496 time/batch=0.77s
2172/5900 (epoch 36.814) train_loss=1531.09655762 time/batch=0.73s
2173/5900 (epoch 36.831) train_loss=1192.70385742 time/batch=0.68s
2174/5900 (epoch 36.847) train_loss=1430.21118164 time/batch=1.33s
2175/5900 (epoch 36.864) train_loss=1200.15917969 time/batch=0.66s
2176/5900 (epoch 36.881) train_loss=1271.48120117 time/batch=0.68s
2177/5900 (epoch 36.898) train_loss=1257.43041992 time/batch=0.68s
2178/5900 (epoch 36.915) train_loss=1142.87878418 time/batch=0.60s
2179/5900 (epoch 36.932) train_loss=1071.69726562 time/batch=0.61s
2180/5900 (epoch 36.949) train_loss=1280.49707031 time/batch=0.64s
2181/5900 (epoch 36.966) train_loss=1348.19360352 time/batch=0.67s
2182/5900 (epoch 36.983) train_loss=1550.76953125 time/batch=0.79s
2183/5900 (epoch 37.000) train_loss=1372.03442383 time/batch=1.22s
setting learning rate to 0.0018428
2184/5900 (epoch 37.017) train_loss=1113.19445801 time/batch=0.62s
2185/5900 (epoch 37.034) train_loss=1729.18811035 time/batch=0.84s
2186/5900 (epoch 37.051) train_loss=1028.11718750 time/batch=0.63s
2187/5900 (epoch 37.068) train_loss=1306.44677734 time/batch=0.66s
2188/5900 (epoch 37.085) train_loss=1155.71545410 time/batch=0.61s
2189/5900 (epoch 37.102) train_loss=2042.12902832 time/batch=2.17s
2190/5900 (epoch 37.119) train_loss=1422.23083496 time/batch=1.39s
2191/5900 (epoch 37.136) train_loss=1196.99340820 time/batch=0.66s
2192/5900 (epoch 37.153) train_loss=1264.30908203 time/batch=0.66s
2193/5900 (epoch 37.169) train_loss=2274.14013672 time/batch=1.56s
2194/5900 (epoch 37.186) train_loss=1522.14648438 time/batch=1.83s
2195/5900 (epoch 37.203) train_loss=1211.91870117 time/batch=0.76s
2196/5900 (epoch 37.220) train_loss=1263.23864746 time/batch=0.66s
2197/5900 (epoch 37.237) train_loss=1766.77941895 time/batch=0.84s
2198/5900 (epoch 37.254) train_loss=1734.69189453 time/batch=1.44s
2199/5900 (epoch 37.271) train_loss=1097.11267090 time/batch=1.26s
2200/5900 (epoch 37.288) train_loss=1426.48168945 time/batch=1.36s
2201/5900 (epoch 37.305) train_loss=1537.54089355 time/batch=2.51s
2202/5900 (epoch 37.322) train_loss=1746.70312500 time/batch=0.85s
2203/5900 (epoch 37.339) train_loss=1623.36987305 time/batch=0.74s
2204/5900 (epoch 37.356) train_loss=1595.81713867 time/batch=0.74s
2205/5900 (epoch 37.373) train_loss=1228.49365234 time/batch=1.22s
2206/5900 (epoch 37.390) train_loss=1588.19921875 time/batch=0.74s
2207/5900 (epoch 37.407) train_loss=1529.24914551 time/batch=0.75s
2208/5900 (epoch 37.424) train_loss=1210.68359375 time/batch=0.68s
2209/5900 (epoch 37.441) train_loss=1500.17163086 time/batch=0.70s
2210/5900 (epoch 37.458) train_loss=1036.91870117 time/batch=0.67s
2211/5900 (epoch 37.475) train_loss=1832.93127441 time/batch=2.35s
2212/5900 (epoch 37.492) train_loss=1032.50341797 time/batch=0.69s
2213/5900 (epoch 37.508) train_loss=1424.17492676 time/batch=1.34s
2214/5900 (epoch 37.525) train_loss=1115.87536621 time/batch=0.63s
2215/5900 (epoch 37.542) train_loss=1271.99084473 time/batch=0.62s
2216/5900 (epoch 37.559) train_loss=2311.26708984 time/batch=2.98s
2217/5900 (epoch 37.576) train_loss=1606.96240234 time/batch=0.95s
2218/5900 (epoch 37.593) train_loss=1052.02685547 time/batch=0.62s
2219/5900 (epoch 37.610) train_loss=2015.52844238 time/batch=1.50s
2220/5900 (epoch 37.627) train_loss=1263.55139160 time/batch=0.73s
2221/5900 (epoch 37.644) train_loss=1392.18286133 time/batch=1.29s
2222/5900 (epoch 37.661) train_loss=1407.85839844 time/batch=0.77s
2223/5900 (epoch 37.678) train_loss=1251.85327148 time/batch=0.62s
2224/5900 (epoch 37.695) train_loss=1753.65930176 time/batch=0.81s
2225/5900 (epoch 37.712) train_loss=1155.66259766 time/batch=0.61s
2226/5900 (epoch 37.729) train_loss=1239.84448242 time/batch=0.67s
2227/5900 (epoch 37.746) train_loss=1497.61279297 time/batch=0.74s
2228/5900 (epoch 37.763) train_loss=1660.39245605 time/batch=1.20s
2229/5900 (epoch 37.780) train_loss=1592.57324219 time/batch=0.81s
2230/5900 (epoch 37.797) train_loss=1563.78894043 time/batch=0.78s
2231/5900 (epoch 37.814) train_loss=1121.41467285 time/batch=0.64s
2232/5900 (epoch 37.831) train_loss=1229.45288086 time/batch=0.68s
2233/5900 (epoch 37.847) train_loss=1222.50195312 time/batch=0.62s
2234/5900 (epoch 37.864) train_loss=1525.50756836 time/batch=0.78s
2235/5900 (epoch 37.881) train_loss=1405.31274414 time/batch=0.99s
2236/5900 (epoch 37.898) train_loss=1240.08996582 time/batch=0.67s
2237/5900 (epoch 37.915) train_loss=1430.25329590 time/batch=0.73s
2238/5900 (epoch 37.932) train_loss=1297.38488770 time/batch=0.69s
2239/5900 (epoch 37.949) train_loss=1465.31811523 time/batch=0.78s
2240/5900 (epoch 37.966) train_loss=1158.14868164 time/batch=0.69s
2241/5900 (epoch 37.983) train_loss=1284.02160645 time/batch=0.70s
2242/5900 (epoch 38.000) train_loss=1330.81335449 time/batch=0.74s
setting learning rate to 0.0017875
2243/5900 (epoch 38.017) train_loss=1882.81848145 time/batch=0.90s
2244/5900 (epoch 38.034) train_loss=1476.31958008 time/batch=0.75s
2245/5900 (epoch 38.051) train_loss=2587.26318359 time/batch=2.98s
2246/5900 (epoch 38.068) train_loss=1984.36352539 time/batch=1.13s
2247/5900 (epoch 38.085) train_loss=1165.15661621 time/batch=0.63s
2248/5900 (epoch 38.102) train_loss=1716.67163086 time/batch=0.81s
2249/5900 (epoch 38.119) train_loss=1554.37292480 time/batch=0.72s
2250/5900 (epoch 38.136) train_loss=1090.01538086 time/batch=0.59s
2251/5900 (epoch 38.153) train_loss=1172.04663086 time/batch=0.62s
2252/5900 (epoch 38.169) train_loss=2549.00927734 time/batch=2.18s
2253/5900 (epoch 38.186) train_loss=1401.85278320 time/batch=0.80s
2254/5900 (epoch 38.203) train_loss=1049.74353027 time/batch=1.22s
2255/5900 (epoch 38.220) train_loss=1479.97924805 time/batch=1.39s
2256/5900 (epoch 38.237) train_loss=1308.75830078 time/batch=0.73s
2257/5900 (epoch 38.254) train_loss=1032.08996582 time/batch=0.59s
2258/5900 (epoch 38.271) train_loss=1529.27575684 time/batch=2.51s
2259/5900 (epoch 38.288) train_loss=1191.98437500 time/batch=0.74s
2260/5900 (epoch 38.305) train_loss=1510.88134766 time/batch=0.70s
2261/5900 (epoch 38.322) train_loss=1347.31689453 time/batch=0.66s
2262/5900 (epoch 38.339) train_loss=1150.35400391 time/batch=0.61s
2263/5900 (epoch 38.356) train_loss=1179.44250488 time/batch=0.67s
2264/5900 (epoch 38.373) train_loss=1601.88549805 time/batch=0.65s
2265/5900 (epoch 38.390) train_loss=1509.28735352 time/batch=0.72s
2266/5900 (epoch 38.407) train_loss=1302.56030273 time/batch=0.64s
2267/5900 (epoch 38.424) train_loss=2362.42431641 time/batch=1.30s
2268/5900 (epoch 38.441) train_loss=2759.86181641 time/batch=0.76s
2269/5900 (epoch 38.458) train_loss=2374.77709961 time/batch=0.77s
2270/5900 (epoch 38.475) train_loss=2043.83789062 time/batch=0.59s
2271/5900 (epoch 38.492) train_loss=2116.34912109 time/batch=0.74s
2272/5900 (epoch 38.508) train_loss=2306.23339844 time/batch=0.83s
2273/5900 (epoch 38.525) train_loss=1969.18127441 time/batch=1.20s
2274/5900 (epoch 38.542) train_loss=2258.06518555 time/batch=1.41s
2275/5900 (epoch 38.559) train_loss=1893.33422852 time/batch=1.38s
2276/5900 (epoch 38.576) train_loss=1964.26782227 time/batch=2.54s
2277/5900 (epoch 38.593) train_loss=2169.38891602 time/batch=1.61s
2278/5900 (epoch 38.610) train_loss=2046.46130371 time/batch=0.71s
2279/5900 (epoch 38.627) train_loss=1888.78991699 time/batch=0.68s
2280/5900 (epoch 38.644) train_loss=2001.47326660 time/batch=0.74s
2281/5900 (epoch 38.661) train_loss=1699.02368164 time/batch=0.59s
2282/5900 (epoch 38.678) train_loss=2234.73925781 time/batch=0.83s
2283/5900 (epoch 38.695) train_loss=1918.52526855 time/batch=1.79s
2284/5900 (epoch 38.712) train_loss=2067.18261719 time/batch=0.82s
2285/5900 (epoch 38.729) train_loss=1653.21887207 time/batch=0.62s
2286/5900 (epoch 38.746) train_loss=1657.65161133 time/batch=0.64s
2287/5900 (epoch 38.763) train_loss=1846.12280273 time/batch=1.28s
2288/5900 (epoch 38.780) train_loss=1691.88842773 time/batch=0.67s
2289/5900 (epoch 38.797) train_loss=1593.63525391 time/batch=0.60s
2290/5900 (epoch 38.814) train_loss=1863.31542969 time/batch=0.74s
2291/5900 (epoch 38.831) train_loss=1675.61669922 time/batch=0.84s
2292/5900 (epoch 38.847) train_loss=1774.33093262 time/batch=0.69s
2293/5900 (epoch 38.864) train_loss=1705.71020508 time/batch=0.69s
2294/5900 (epoch 38.881) train_loss=1869.35058594 time/batch=0.84s
2295/5900 (epoch 38.898) train_loss=2030.12841797 time/batch=0.78s
2296/5900 (epoch 38.915) train_loss=1664.97021484 time/batch=0.68s
2297/5900 (epoch 38.932) train_loss=2011.23205566 time/batch=0.82s
2298/5900 (epoch 38.949) train_loss=1736.92724609 time/batch=0.83s
2299/5900 (epoch 38.966) train_loss=1763.42626953 time/batch=0.72s
2300/5900 (epoch 38.983) train_loss=1919.11181641 time/batch=0.83s
2301/5900 (epoch 39.000) train_loss=1843.81103516 time/batch=0.76s
setting learning rate to 0.0017339
2302/5900 (epoch 39.017) train_loss=1840.69873047 time/batch=1.32s
2303/5900 (epoch 39.034) train_loss=1599.06323242 time/batch=0.63s
2304/5900 (epoch 39.051) train_loss=1728.81982422 time/batch=0.68s
2305/5900 (epoch 39.068) train_loss=1920.42236328 time/batch=1.81s
2306/5900 (epoch 39.085) train_loss=1711.40869141 time/batch=1.39s
2307/5900 (epoch 39.102) train_loss=2096.58520508 time/batch=0.87s
2308/5900 (epoch 39.119) train_loss=1602.59716797 time/batch=0.63s
2309/5900 (epoch 39.136) train_loss=2078.60205078 time/batch=0.74s
2310/5900 (epoch 39.153) train_loss=2037.77185059 time/batch=0.77s
2311/5900 (epoch 39.169) train_loss=2071.49560547 time/batch=0.83s
2312/5900 (epoch 39.186) train_loss=1666.81274414 time/batch=0.69s
2313/5900 (epoch 39.203) train_loss=1833.25097656 time/batch=2.47s
2314/5900 (epoch 39.220) train_loss=1816.53540039 time/batch=0.83s
2315/5900 (epoch 39.237) train_loss=1441.22290039 time/batch=0.58s
2316/5900 (epoch 39.254) train_loss=1915.08251953 time/batch=0.74s
2317/5900 (epoch 39.271) train_loss=2505.47509766 time/batch=1.60s
2318/5900 (epoch 39.288) train_loss=2506.64062500 time/batch=3.01s
2319/5900 (epoch 39.305) train_loss=2206.71166992 time/batch=1.34s
2320/5900 (epoch 39.322) train_loss=1794.99902344 time/batch=0.74s
2321/5900 (epoch 39.339) train_loss=1922.17309570 time/batch=0.80s
2322/5900 (epoch 39.356) train_loss=2201.67358398 time/batch=1.55s
2323/5900 (epoch 39.373) train_loss=2003.09875488 time/batch=0.87s
2324/5900 (epoch 39.390) train_loss=1828.87182617 time/batch=0.74s
2325/5900 (epoch 39.407) train_loss=1791.43920898 time/batch=0.72s
2326/5900 (epoch 39.424) train_loss=2093.79565430 time/batch=0.98s
2327/5900 (epoch 39.441) train_loss=1845.75805664 time/batch=1.40s
2328/5900 (epoch 39.458) train_loss=1708.88598633 time/batch=0.72s
2329/5900 (epoch 39.475) train_loss=1443.38757324 time/batch=0.58s
2330/5900 (epoch 39.492) train_loss=1867.55712891 time/batch=0.74s
2331/5900 (epoch 39.508) train_loss=1451.55444336 time/batch=0.58s
2332/5900 (epoch 39.525) train_loss=1865.62194824 time/batch=0.74s
2333/5900 (epoch 39.542) train_loss=1511.67675781 time/batch=0.70s
2334/5900 (epoch 39.559) train_loss=2026.62927246 time/batch=1.40s
2335/5900 (epoch 39.576) train_loss=1895.63330078 time/batch=0.81s
2336/5900 (epoch 39.593) train_loss=1551.17773438 time/batch=1.25s
2337/5900 (epoch 39.610) train_loss=1618.67675781 time/batch=0.70s
2338/5900 (epoch 39.627) train_loss=1574.95263672 time/batch=0.60s
2339/5900 (epoch 39.644) train_loss=2341.15380859 time/batch=2.18s
2340/5900 (epoch 39.661) train_loss=1557.27490234 time/batch=0.72s
2341/5900 (epoch 39.678) train_loss=1534.16772461 time/batch=0.62s
2342/5900 (epoch 39.695) train_loss=1526.63659668 time/batch=1.21s
2343/5900 (epoch 39.712) train_loss=1800.89990234 time/batch=0.79s
2344/5900 (epoch 39.729) train_loss=1762.81542969 time/batch=0.70s
2345/5900 (epoch 39.746) train_loss=1914.42895508 time/batch=2.51s
2346/5900 (epoch 39.763) train_loss=1658.74340820 time/batch=0.79s
2347/5900 (epoch 39.780) train_loss=1679.70288086 time/batch=0.67s
2348/5900 (epoch 39.797) train_loss=1839.54467773 time/batch=0.97s
2349/5900 (epoch 39.814) train_loss=1555.91845703 time/batch=0.64s
2350/5900 (epoch 39.831) train_loss=1482.07519531 time/batch=0.60s
2351/5900 (epoch 39.847) train_loss=1544.59204102 time/batch=0.64s
2352/5900 (epoch 39.864) train_loss=1548.39172363 time/batch=0.62s
2353/5900 (epoch 39.881) train_loss=1491.40356445 time/batch=0.60s
2354/5900 (epoch 39.898) train_loss=1535.80273438 time/batch=0.61s
2355/5900 (epoch 39.915) train_loss=1515.42358398 time/batch=0.64s
2356/5900 (epoch 39.932) train_loss=1612.60278320 time/batch=0.66s
2357/5900 (epoch 39.949) train_loss=1604.45849609 time/batch=0.66s
2358/5900 (epoch 39.966) train_loss=1746.21630859 time/batch=1.34s
2359/5900 (epoch 39.983) train_loss=1666.97497559 time/batch=0.72s
2360/5900 (epoch 40.000) train_loss=1670.59399414 time/batch=0.70s
setting learning rate to 0.0016818
  saved to metadata/config5--20190119-211157.pkl
2361/5900 (epoch 40.017) train_loss=1789.45043945 time/batch=0.76s
2362/5900 (epoch 40.034) train_loss=2118.64843750 time/batch=0.85s
2363/5900 (epoch 40.051) train_loss=1811.82495117 time/batch=1.37s
2364/5900 (epoch 40.068) train_loss=1539.10595703 time/batch=0.67s
2365/5900 (epoch 40.085) train_loss=1647.26928711 time/batch=0.70s
2366/5900 (epoch 40.102) train_loss=1508.35070801 time/batch=0.64s
2367/5900 (epoch 40.119) train_loss=2005.91528320 time/batch=2.49s
2368/5900 (epoch 40.136) train_loss=1711.67126465 time/batch=0.78s
2369/5900 (epoch 40.153) train_loss=2211.63476562 time/batch=1.60s
2370/5900 (epoch 40.169) train_loss=2041.98693848 time/batch=0.88s
2371/5900 (epoch 40.186) train_loss=1926.48510742 time/batch=0.78s
2372/5900 (epoch 40.203) train_loss=1795.26318359 time/batch=0.74s
2373/5900 (epoch 40.220) train_loss=1824.41674805 time/batch=0.74s
2374/5900 (epoch 40.237) train_loss=1581.65600586 time/batch=1.20s
2375/5900 (epoch 40.254) train_loss=1445.56665039 time/batch=0.63s
2376/5900 (epoch 40.271) train_loss=1966.39501953 time/batch=0.83s
2377/5900 (epoch 40.288) train_loss=2427.14428711 time/batch=2.20s
2378/5900 (epoch 40.305) train_loss=1921.66699219 time/batch=2.61s
2379/5900 (epoch 40.322) train_loss=1758.76525879 time/batch=0.82s
2380/5900 (epoch 40.339) train_loss=1782.12353516 time/batch=0.77s
2381/5900 (epoch 40.356) train_loss=1660.42810059 time/batch=0.69s
2382/5900 (epoch 40.373) train_loss=1690.63793945 time/batch=1.33s
2383/5900 (epoch 40.390) train_loss=1332.29052734 time/batch=0.70s
2384/5900 (epoch 40.407) train_loss=1583.34228516 time/batch=0.67s
2385/5900 (epoch 40.424) train_loss=1861.71728516 time/batch=0.73s
2386/5900 (epoch 40.441) train_loss=1709.23095703 time/batch=1.29s
2387/5900 (epoch 40.458) train_loss=1493.55395508 time/batch=1.26s
2388/5900 (epoch 40.475) train_loss=1499.32800293 time/batch=0.64s
2389/5900 (epoch 40.492) train_loss=1882.40905762 time/batch=0.79s
2390/5900 (epoch 40.508) train_loss=1494.77307129 time/batch=0.65s
2391/5900 (epoch 40.525) train_loss=2599.51367188 time/batch=2.97s
2392/5900 (epoch 40.542) train_loss=1714.43688965 time/batch=1.45s
2393/5900 (epoch 40.559) train_loss=1968.14062500 time/batch=0.87s
2394/5900 (epoch 40.576) train_loss=1626.80859375 time/batch=0.70s
2395/5900 (epoch 40.593) train_loss=1434.19238281 time/batch=0.68s
2396/5900 (epoch 40.610) train_loss=1496.21435547 time/batch=0.64s
2397/5900 (epoch 40.627) train_loss=2234.65917969 time/batch=0.98s
2398/5900 (epoch 40.644) train_loss=1617.86669922 time/batch=0.68s
2399/5900 (epoch 40.661) train_loss=1426.93371582 time/batch=0.60s
2400/5900 (epoch 40.678) train_loss=1848.14160156 time/batch=0.77s
2401/5900 (epoch 40.695) train_loss=1723.76672363 time/batch=1.13s
2402/5900 (epoch 40.712) train_loss=1601.68481445 time/batch=0.72s
2403/5900 (epoch 40.729) train_loss=1711.55224609 time/batch=0.71s
2404/5900 (epoch 40.746) train_loss=1628.10083008 time/batch=0.66s
2405/5900 (epoch 40.763) train_loss=1538.95288086 time/batch=0.67s
2406/5900 (epoch 40.780) train_loss=1946.63574219 time/batch=1.44s
2407/5900 (epoch 40.797) train_loss=1612.16345215 time/batch=0.72s
2408/5900 (epoch 40.814) train_loss=1702.69506836 time/batch=0.72s
2409/5900 (epoch 40.831) train_loss=2017.16613770 time/batch=2.36s
2410/5900 (epoch 40.847) train_loss=1498.28332520 time/batch=0.75s
2411/5900 (epoch 40.864) train_loss=1542.28198242 time/batch=0.85s
2412/5900 (epoch 40.881) train_loss=1775.71582031 time/batch=0.72s
2413/5900 (epoch 40.898) train_loss=1641.65783691 time/batch=0.67s
2414/5900 (epoch 40.915) train_loss=1656.04492188 time/batch=0.64s
2415/5900 (epoch 40.932) train_loss=1613.38061523 time/batch=0.78s
2416/5900 (epoch 40.949) train_loss=1486.22485352 time/batch=0.61s
2417/5900 (epoch 40.966) train_loss=1545.13110352 time/batch=0.63s
2418/5900 (epoch 40.983) train_loss=1462.46264648 time/batch=0.61s
2419/5900 (epoch 41.000) train_loss=1432.81298828 time/batch=0.61s
setting learning rate to 0.0016314
2420/5900 (epoch 41.017) train_loss=1514.36157227 time/batch=1.22s
2421/5900 (epoch 41.034) train_loss=1749.46325684 time/batch=0.76s
2422/5900 (epoch 41.051) train_loss=1476.50048828 time/batch=0.66s
2423/5900 (epoch 41.068) train_loss=1773.51855469 time/batch=2.52s
2424/5900 (epoch 41.085) train_loss=1640.06286621 time/batch=0.79s
2425/5900 (epoch 41.102) train_loss=1937.93457031 time/batch=0.81s
2426/5900 (epoch 41.119) train_loss=1559.07104492 time/batch=0.67s
2427/5900 (epoch 41.136) train_loss=1431.75354004 time/batch=0.60s
2428/5900 (epoch 41.153) train_loss=1774.02465820 time/batch=0.72s
2429/5900 (epoch 41.169) train_loss=1600.08361816 time/batch=0.70s
2430/5900 (epoch 41.186) train_loss=1486.60498047 time/batch=0.65s
2431/5900 (epoch 41.203) train_loss=1566.53491211 time/batch=0.66s
2432/5900 (epoch 41.220) train_loss=1372.06567383 time/batch=0.69s
2433/5900 (epoch 41.237) train_loss=1978.18530273 time/batch=0.83s
2434/5900 (epoch 41.254) train_loss=2199.03466797 time/batch=2.17s
2435/5900 (epoch 41.271) train_loss=1481.55480957 time/batch=0.72s
2436/5900 (epoch 41.288) train_loss=2007.37670898 time/batch=0.82s
2437/5900 (epoch 41.305) train_loss=1911.29541016 time/batch=0.82s
2438/5900 (epoch 41.322) train_loss=1599.00195312 time/batch=1.32s
2439/5900 (epoch 41.339) train_loss=1450.09802246 time/batch=0.69s
2440/5900 (epoch 41.356) train_loss=1529.96411133 time/batch=0.67s
2441/5900 (epoch 41.373) train_loss=1763.48413086 time/batch=1.82s
2442/5900 (epoch 41.390) train_loss=1812.43286133 time/batch=0.83s
2443/5900 (epoch 41.407) train_loss=1817.02954102 time/batch=0.74s
2444/5900 (epoch 41.424) train_loss=1714.71777344 time/batch=1.32s
2445/5900 (epoch 41.441) train_loss=1512.68627930 time/batch=0.69s
2446/5900 (epoch 41.458) train_loss=2223.46289062 time/batch=0.98s
2447/5900 (epoch 41.475) train_loss=1449.74755859 time/batch=0.66s
2448/5900 (epoch 41.492) train_loss=1621.33581543 time/batch=2.46s
2449/5900 (epoch 41.508) train_loss=2348.04296875 time/batch=1.68s
2450/5900 (epoch 41.525) train_loss=1989.22607422 time/batch=1.01s
2451/5900 (epoch 41.542) train_loss=1537.44506836 time/batch=1.15s
2452/5900 (epoch 41.559) train_loss=1918.84460449 time/batch=0.86s
2453/5900 (epoch 41.576) train_loss=2729.08862305 time/batch=3.02s
2454/5900 (epoch 41.593) train_loss=1531.41931152 time/batch=0.81s
2455/5900 (epoch 41.610) train_loss=1390.95361328 time/batch=0.70s
2456/5900 (epoch 41.627) train_loss=1428.98852539 time/batch=0.63s
2457/5900 (epoch 41.644) train_loss=1847.04772949 time/batch=0.75s
2458/5900 (epoch 41.661) train_loss=1401.73876953 time/batch=0.62s
2459/5900 (epoch 41.678) train_loss=1585.51171875 time/batch=1.25s
2460/5900 (epoch 41.695) train_loss=1390.85571289 time/batch=0.66s
2461/5900 (epoch 41.712) train_loss=1414.04321289 time/batch=0.64s
2462/5900 (epoch 41.729) train_loss=1677.31518555 time/batch=1.31s
2463/5900 (epoch 41.746) train_loss=1746.64208984 time/batch=0.77s
2464/5900 (epoch 41.763) train_loss=1411.81152344 time/batch=0.59s
2465/5900 (epoch 41.780) train_loss=1814.89123535 time/batch=0.76s
2466/5900 (epoch 41.797) train_loss=1781.25122070 time/batch=1.37s
2467/5900 (epoch 41.814) train_loss=1731.38513184 time/batch=0.76s
2468/5900 (epoch 41.831) train_loss=1508.37561035 time/batch=0.68s
2469/5900 (epoch 41.847) train_loss=1565.34545898 time/batch=0.68s
2470/5900 (epoch 41.864) train_loss=1701.34802246 time/batch=0.74s
2471/5900 (epoch 41.881) train_loss=1475.47509766 time/batch=0.66s
2472/5900 (epoch 41.898) train_loss=1759.38671875 time/batch=0.74s
2473/5900 (epoch 41.915) train_loss=1693.29748535 time/batch=0.75s
2474/5900 (epoch 41.932) train_loss=1979.37182617 time/batch=1.40s
2475/5900 (epoch 41.949) train_loss=1628.65698242 time/batch=0.74s
2476/5900 (epoch 41.966) train_loss=1550.42333984 time/batch=0.68s
2477/5900 (epoch 41.983) train_loss=1529.65673828 time/batch=0.66s
2478/5900 (epoch 42.000) train_loss=1384.38476562 time/batch=0.61s
setting learning rate to 0.0015824
2479/5900 (epoch 42.017) train_loss=1668.95642090 time/batch=1.36s
2480/5900 (epoch 42.034) train_loss=1254.25805664 time/batch=0.61s
2481/5900 (epoch 42.051) train_loss=1641.06872559 time/batch=1.28s
2482/5900 (epoch 42.068) train_loss=1916.96325684 time/batch=0.82s
2483/5900 (epoch 42.085) train_loss=1569.09350586 time/batch=0.67s
2484/5900 (epoch 42.102) train_loss=2141.11035156 time/batch=1.52s
2485/5900 (epoch 42.119) train_loss=1618.65161133 time/batch=0.74s
2486/5900 (epoch 42.136) train_loss=2215.50048828 time/batch=1.60s
2487/5900 (epoch 42.153) train_loss=2272.60473633 time/batch=1.09s
2488/5900 (epoch 42.169) train_loss=1674.17175293 time/batch=1.82s
2489/5900 (epoch 42.186) train_loss=1536.51318359 time/batch=0.74s
2490/5900 (epoch 42.203) train_loss=1630.71240234 time/batch=0.71s
2491/5900 (epoch 42.220) train_loss=1459.50915527 time/batch=1.18s
2492/5900 (epoch 42.237) train_loss=1683.47814941 time/batch=0.79s
2493/5900 (epoch 42.254) train_loss=1501.31958008 time/batch=0.70s
2494/5900 (epoch 42.271) train_loss=1685.48461914 time/batch=0.71s
2495/5900 (epoch 42.288) train_loss=1680.13696289 time/batch=0.69s
2496/5900 (epoch 42.305) train_loss=1965.61230469 time/batch=0.83s
2497/5900 (epoch 42.322) train_loss=1480.26904297 time/batch=0.67s
2498/5900 (epoch 42.339) train_loss=1965.19116211 time/batch=0.97s
2499/5900 (epoch 42.356) train_loss=2956.80859375 time/batch=3.02s
2500/5900 (epoch 42.373) train_loss=1800.59423828 time/batch=1.23s
2501/5900 (epoch 42.390) train_loss=1853.46862793 time/batch=0.85s
2502/5900 (epoch 42.407) train_loss=1400.38342285 time/batch=0.65s
2503/5900 (epoch 42.424) train_loss=1828.80468750 time/batch=0.77s
2504/5900 (epoch 42.441) train_loss=1304.34497070 time/batch=0.61s
2505/5900 (epoch 42.458) train_loss=1714.03356934 time/batch=0.71s
2506/5900 (epoch 42.475) train_loss=1619.82568359 time/batch=1.30s
2507/5900 (epoch 42.492) train_loss=1464.92431641 time/batch=1.28s
2508/5900 (epoch 42.508) train_loss=1383.85778809 time/batch=0.65s
2509/5900 (epoch 42.525) train_loss=1447.91516113 time/batch=0.62s
2510/5900 (epoch 42.542) train_loss=1815.50561523 time/batch=0.75s
2511/5900 (epoch 42.559) train_loss=1600.19201660 time/batch=0.71s
2512/5900 (epoch 42.576) train_loss=1468.62756348 time/batch=0.65s
2513/5900 (epoch 42.593) train_loss=1542.44775391 time/batch=0.67s
2514/5900 (epoch 42.610) train_loss=1509.16040039 time/batch=0.62s
2515/5900 (epoch 42.627) train_loss=1757.56591797 time/batch=0.75s
2516/5900 (epoch 42.644) train_loss=1623.53576660 time/batch=1.33s
2517/5900 (epoch 42.661) train_loss=1883.65502930 time/batch=2.50s
2518/5900 (epoch 42.678) train_loss=1563.64819336 time/batch=0.81s
2519/5900 (epoch 42.695) train_loss=1494.52148438 time/batch=0.69s
2520/5900 (epoch 42.712) train_loss=1955.99584961 time/batch=1.43s
2521/5900 (epoch 42.729) train_loss=1728.63671875 time/batch=0.79s
2522/5900 (epoch 42.746) train_loss=1389.82336426 time/batch=0.61s
2523/5900 (epoch 42.763) train_loss=1720.09838867 time/batch=0.72s
2524/5900 (epoch 42.780) train_loss=1869.90307617 time/batch=0.83s
2525/5900 (epoch 42.797) train_loss=1819.85742188 time/batch=0.80s
2526/5900 (epoch 42.814) train_loss=1478.82592773 time/batch=1.22s
2527/5900 (epoch 42.831) train_loss=1444.69677734 time/batch=0.67s
2528/5900 (epoch 42.847) train_loss=1961.12585449 time/batch=2.51s
2529/5900 (epoch 42.864) train_loss=1362.69287109 time/batch=0.71s
2530/5900 (epoch 42.881) train_loss=1410.00390625 time/batch=0.65s
2531/5900 (epoch 42.898) train_loss=1377.71740723 time/batch=0.62s
2532/5900 (epoch 42.915) train_loss=1559.04614258 time/batch=0.68s
2533/5900 (epoch 42.932) train_loss=1383.80053711 time/batch=0.63s
2534/5900 (epoch 42.949) train_loss=1390.37402344 time/batch=0.63s
2535/5900 (epoch 42.966) train_loss=1376.73242188 time/batch=0.60s
2536/5900 (epoch 42.983) train_loss=1626.99145508 time/batch=0.72s
2537/5900 (epoch 43.000) train_loss=1510.08105469 time/batch=0.71s
setting learning rate to 0.0015350
2538/5900 (epoch 43.017) train_loss=1950.04931641 time/batch=0.85s
2539/5900 (epoch 43.034) train_loss=1275.02307129 time/batch=0.60s
2540/5900 (epoch 43.051) train_loss=1798.36767578 time/batch=0.77s
2541/5900 (epoch 43.068) train_loss=1970.81860352 time/batch=0.92s
2542/5900 (epoch 43.085) train_loss=1664.11730957 time/batch=0.74s
2543/5900 (epoch 43.102) train_loss=1361.72973633 time/batch=0.70s
2544/5900 (epoch 43.119) train_loss=1745.64038086 time/batch=0.71s
2545/5900 (epoch 43.136) train_loss=1382.95153809 time/batch=1.21s
2546/5900 (epoch 43.153) train_loss=1560.13891602 time/batch=0.70s
2547/5900 (epoch 43.169) train_loss=1530.22753906 time/batch=1.29s
2548/5900 (epoch 43.186) train_loss=1444.32324219 time/batch=0.67s
2549/5900 (epoch 43.203) train_loss=1386.23095703 time/batch=0.60s
2550/5900 (epoch 43.220) train_loss=1803.83105469 time/batch=0.80s
2551/5900 (epoch 43.237) train_loss=2116.76733398 time/batch=1.03s
2552/5900 (epoch 43.254) train_loss=1581.96875000 time/batch=0.70s
2553/5900 (epoch 43.271) train_loss=1453.09631348 time/batch=0.64s
2554/5900 (epoch 43.288) train_loss=2324.13378906 time/batch=1.59s
2555/5900 (epoch 43.305) train_loss=1929.89086914 time/batch=0.86s
2556/5900 (epoch 43.322) train_loss=1469.90856934 time/batch=0.69s
2557/5900 (epoch 43.339) train_loss=1396.18041992 time/batch=0.63s
2558/5900 (epoch 43.356) train_loss=1757.46618652 time/batch=2.51s
2559/5900 (epoch 43.373) train_loss=1541.38317871 time/batch=0.81s
2560/5900 (epoch 43.390) train_loss=1301.09399414 time/batch=0.60s
2561/5900 (epoch 43.407) train_loss=1796.65698242 time/batch=1.76s
2562/5900 (epoch 43.424) train_loss=1811.58276367 time/batch=2.58s
2563/5900 (epoch 43.441) train_loss=2088.47363281 time/batch=1.63s
2564/5900 (epoch 43.458) train_loss=1892.65185547 time/batch=0.83s
2565/5900 (epoch 43.475) train_loss=1774.05346680 time/batch=0.78s
2566/5900 (epoch 43.492) train_loss=2716.50976562 time/batch=2.97s
2567/5900 (epoch 43.508) train_loss=1858.84008789 time/batch=1.03s
2568/5900 (epoch 43.525) train_loss=1487.40832520 time/batch=0.76s
2569/5900 (epoch 43.542) train_loss=1480.05749512 time/batch=0.69s
2570/5900 (epoch 43.559) train_loss=1462.61254883 time/batch=0.66s
2571/5900 (epoch 43.576) train_loss=1430.40283203 time/batch=0.65s
2572/5900 (epoch 43.593) train_loss=1467.15185547 time/batch=0.65s
2573/5900 (epoch 43.610) train_loss=1468.57373047 time/batch=0.68s
2574/5900 (epoch 43.627) train_loss=1833.13110352 time/batch=0.76s
2575/5900 (epoch 43.644) train_loss=1634.82641602 time/batch=0.68s
2576/5900 (epoch 43.661) train_loss=1748.51342773 time/batch=0.73s
2577/5900 (epoch 43.678) train_loss=1959.24243164 time/batch=1.40s
2578/5900 (epoch 43.695) train_loss=1729.26330566 time/batch=0.79s
2579/5900 (epoch 43.712) train_loss=1391.92993164 time/batch=0.63s
2580/5900 (epoch 43.729) train_loss=1336.74597168 time/batch=0.63s
2581/5900 (epoch 43.746) train_loss=1626.53442383 time/batch=0.72s
2582/5900 (epoch 43.763) train_loss=1593.57409668 time/batch=1.31s
2583/5900 (epoch 43.780) train_loss=1369.93432617 time/batch=0.64s
2584/5900 (epoch 43.797) train_loss=1516.42089844 time/batch=0.70s
2585/5900 (epoch 43.814) train_loss=1489.13183594 time/batch=0.64s
2586/5900 (epoch 43.831) train_loss=1374.58447266 time/batch=0.61s
2587/5900 (epoch 43.847) train_loss=1456.96704102 time/batch=0.67s
2588/5900 (epoch 43.864) train_loss=1511.77807617 time/batch=0.69s
2589/5900 (epoch 43.881) train_loss=1465.55688477 time/batch=1.27s
2590/5900 (epoch 43.898) train_loss=1692.15234375 time/batch=0.76s
2591/5900 (epoch 43.915) train_loss=1575.31994629 time/batch=1.34s
2592/5900 (epoch 43.932) train_loss=1588.61328125 time/batch=0.79s
2593/5900 (epoch 43.949) train_loss=1636.90502930 time/batch=0.74s
2594/5900 (epoch 43.966) train_loss=1757.42333984 time/batch=1.36s
2595/5900 (epoch 43.983) train_loss=1334.46630859 time/batch=0.66s
2596/5900 (epoch 44.000) train_loss=1442.20605469 time/batch=0.71s
setting learning rate to 0.0014889
2597/5900 (epoch 44.017) train_loss=1814.42260742 time/batch=0.80s
2598/5900 (epoch 44.034) train_loss=2170.15039062 time/batch=1.01s
2599/5900 (epoch 44.051) train_loss=1446.12768555 time/batch=0.71s
2600/5900 (epoch 44.068) train_loss=1318.29980469 time/batch=0.63s
2601/5900 (epoch 44.085) train_loss=1963.68884277 time/batch=0.83s
2602/5900 (epoch 44.102) train_loss=1432.05810547 time/batch=0.63s
2603/5900 (epoch 44.119) train_loss=1508.68188477 time/batch=0.67s
2604/5900 (epoch 44.136) train_loss=1557.70336914 time/batch=1.29s
2605/5900 (epoch 44.153) train_loss=1818.44311523 time/batch=0.82s
2606/5900 (epoch 44.169) train_loss=1931.72363281 time/batch=1.43s
2607/5900 (epoch 44.186) train_loss=1418.43981934 time/batch=1.27s
2608/5900 (epoch 44.203) train_loss=1650.29357910 time/batch=0.76s
2609/5900 (epoch 44.220) train_loss=1922.95605469 time/batch=0.84s
2610/5900 (epoch 44.237) train_loss=1561.90429688 time/batch=1.34s
2611/5900 (epoch 44.254) train_loss=1810.57104492 time/batch=2.53s
2612/5900 (epoch 44.271) train_loss=1957.75000000 time/batch=1.01s
2613/5900 (epoch 44.288) train_loss=1334.20654297 time/batch=0.60s
2614/5900 (epoch 44.305) train_loss=1574.03295898 time/batch=0.67s
2615/5900 (epoch 44.322) train_loss=1924.42285156 time/batch=0.81s
2616/5900 (epoch 44.339) train_loss=1576.97070312 time/batch=1.32s
2617/5900 (epoch 44.356) train_loss=1693.41992188 time/batch=0.77s
2618/5900 (epoch 44.373) train_loss=1378.97460938 time/batch=0.63s
2619/5900 (epoch 44.390) train_loss=1736.42651367 time/batch=1.31s
2620/5900 (epoch 44.407) train_loss=1423.73974609 time/batch=0.66s
2621/5900 (epoch 44.424) train_loss=1767.77148438 time/batch=2.49s
2622/5900 (epoch 44.441) train_loss=2202.25122070 time/batch=1.69s
2623/5900 (epoch 44.458) train_loss=2594.08081055 time/batch=3.00s
2624/5900 (epoch 44.475) train_loss=1489.76477051 time/batch=0.81s
2625/5900 (epoch 44.492) train_loss=1729.64355469 time/batch=0.74s
2626/5900 (epoch 44.508) train_loss=1682.67651367 time/batch=1.82s
2627/5900 (epoch 44.525) train_loss=1423.21862793 time/batch=1.28s
2628/5900 (epoch 44.542) train_loss=1291.31518555 time/batch=0.65s
2629/5900 (epoch 44.559) train_loss=1468.19726562 time/batch=0.64s
2630/5900 (epoch 44.576) train_loss=1544.99487305 time/batch=0.66s
2631/5900 (epoch 44.593) train_loss=1848.85559082 time/batch=2.23s
2632/5900 (epoch 44.610) train_loss=1426.85693359 time/batch=0.73s
2633/5900 (epoch 44.627) train_loss=1655.70129395 time/batch=0.72s
2634/5900 (epoch 44.644) train_loss=1678.42578125 time/batch=1.53s
2635/5900 (epoch 44.661) train_loss=1353.78149414 time/batch=0.68s
2636/5900 (epoch 44.678) train_loss=1531.14050293 time/batch=0.69s
2637/5900 (epoch 44.695) train_loss=1611.13342285 time/batch=0.74s
2638/5900 (epoch 44.712) train_loss=1637.88610840 time/batch=0.72s
2639/5900 (epoch 44.729) train_loss=1688.45239258 time/batch=0.72s
2640/5900 (epoch 44.746) train_loss=1435.85668945 time/batch=0.68s
2641/5900 (epoch 44.763) train_loss=1384.62951660 time/batch=0.64s
2642/5900 (epoch 44.780) train_loss=1308.38903809 time/batch=0.60s
2643/5900 (epoch 44.797) train_loss=1614.75805664 time/batch=0.78s
2644/5900 (epoch 44.814) train_loss=1477.32421875 time/batch=0.72s
2645/5900 (epoch 44.831) train_loss=1738.89196777 time/batch=0.74s
2646/5900 (epoch 44.847) train_loss=1382.39648438 time/batch=0.70s
2647/5900 (epoch 44.864) train_loss=1448.69091797 time/batch=0.68s
2648/5900 (epoch 44.881) train_loss=1648.23608398 time/batch=0.70s
2649/5900 (epoch 44.898) train_loss=1648.89440918 time/batch=0.75s
2650/5900 (epoch 44.915) train_loss=1709.06323242 time/batch=0.79s
2651/5900 (epoch 44.932) train_loss=1357.21435547 time/batch=0.68s
2652/5900 (epoch 44.949) train_loss=1310.64489746 time/batch=0.64s
2653/5900 (epoch 44.966) train_loss=1416.73815918 time/batch=0.64s
2654/5900 (epoch 44.983) train_loss=1408.97216797 time/batch=0.61s
2655/5900 (epoch 45.000) train_loss=1522.55175781 time/batch=0.68s
setting learning rate to 0.0014443
2656/5900 (epoch 45.017) train_loss=2279.27221680 time/batch=1.60s
2657/5900 (epoch 45.034) train_loss=1668.35546875 time/batch=0.75s
2658/5900 (epoch 45.051) train_loss=1245.46704102 time/batch=0.59s
2659/5900 (epoch 45.068) train_loss=1963.90930176 time/batch=0.99s
2660/5900 (epoch 45.085) train_loss=1550.49243164 time/batch=0.69s
2661/5900 (epoch 45.102) train_loss=1332.31640625 time/batch=0.58s
2662/5900 (epoch 45.119) train_loss=1850.66918945 time/batch=0.79s
2663/5900 (epoch 45.136) train_loss=1321.22998047 time/batch=0.61s
2664/5900 (epoch 45.153) train_loss=1830.05883789 time/batch=2.54s
2665/5900 (epoch 45.169) train_loss=2684.60693359 time/batch=3.06s
2666/5900 (epoch 45.186) train_loss=2232.32763672 time/batch=2.33s
2667/5900 (epoch 45.203) train_loss=1524.33447266 time/batch=1.38s
2668/5900 (epoch 45.220) train_loss=1955.99047852 time/batch=1.02s
2669/5900 (epoch 45.237) train_loss=1536.17724609 time/batch=1.31s
2670/5900 (epoch 45.254) train_loss=1686.72644043 time/batch=2.54s
2671/5900 (epoch 45.271) train_loss=1489.36523438 time/batch=0.76s
2672/5900 (epoch 45.288) train_loss=1697.55395508 time/batch=0.75s
2673/5900 (epoch 45.305) train_loss=1926.00903320 time/batch=1.13s
2674/5900 (epoch 45.322) train_loss=1905.04846191 time/batch=0.85s
2675/5900 (epoch 45.339) train_loss=1468.55322266 time/batch=0.71s
2676/5900 (epoch 45.356) train_loss=1763.61547852 time/batch=0.77s
2677/5900 (epoch 45.373) train_loss=1385.85253906 time/batch=0.68s
2678/5900 (epoch 45.390) train_loss=1435.08959961 time/batch=0.62s
2679/5900 (epoch 45.407) train_loss=1629.62817383 time/batch=1.35s
2680/5900 (epoch 45.424) train_loss=1666.41259766 time/batch=0.76s
2681/5900 (epoch 45.441) train_loss=1551.69799805 time/batch=0.69s
2682/5900 (epoch 45.458) train_loss=1474.99389648 time/batch=1.21s
2683/5900 (epoch 45.475) train_loss=1603.90405273 time/batch=0.77s
2684/5900 (epoch 45.492) train_loss=1489.80700684 time/batch=0.64s
2685/5900 (epoch 45.508) train_loss=1663.90893555 time/batch=0.76s
2686/5900 (epoch 45.525) train_loss=1441.20959473 time/batch=1.80s
2687/5900 (epoch 45.542) train_loss=1704.41906738 time/batch=0.83s
2688/5900 (epoch 45.559) train_loss=1360.35644531 time/batch=1.24s
2689/5900 (epoch 45.576) train_loss=1766.33715820 time/batch=0.84s
2690/5900 (epoch 45.593) train_loss=1809.60766602 time/batch=0.80s
2691/5900 (epoch 45.610) train_loss=1567.17797852 time/batch=0.76s
2692/5900 (epoch 45.627) train_loss=1333.38537598 time/batch=0.64s
2693/5900 (epoch 45.644) train_loss=1457.72875977 time/batch=0.69s
2694/5900 (epoch 45.661) train_loss=1875.63696289 time/batch=1.41s
2695/5900 (epoch 45.678) train_loss=1720.90673828 time/batch=0.89s
2696/5900 (epoch 45.695) train_loss=1361.68212891 time/batch=0.63s
2697/5900 (epoch 45.712) train_loss=1518.15454102 time/batch=0.82s
2698/5900 (epoch 45.729) train_loss=1327.59082031 time/batch=0.61s
2699/5900 (epoch 45.746) train_loss=1637.71801758 time/batch=0.68s
2700/5900 (epoch 45.763) train_loss=1253.88037109 time/batch=0.61s
2701/5900 (epoch 45.780) train_loss=1313.99560547 time/batch=0.62s
2702/5900 (epoch 45.797) train_loss=1313.19616699 time/batch=0.66s
2703/5900 (epoch 45.814) train_loss=1353.25524902 time/batch=0.65s
2704/5900 (epoch 45.831) train_loss=1546.35473633 time/batch=1.33s
2705/5900 (epoch 45.847) train_loss=1199.94384766 time/batch=0.64s
2706/5900 (epoch 45.864) train_loss=1501.39160156 time/batch=0.70s
2707/5900 (epoch 45.881) train_loss=1386.31262207 time/batch=0.73s
2708/5900 (epoch 45.898) train_loss=1466.58654785 time/batch=0.69s
2709/5900 (epoch 45.915) train_loss=1264.86755371 time/batch=0.68s
2710/5900 (epoch 45.932) train_loss=1450.40222168 time/batch=0.69s
2711/5900 (epoch 45.949) train_loss=1348.98046875 time/batch=0.66s
2712/5900 (epoch 45.966) train_loss=1278.52978516 time/batch=0.60s
2713/5900 (epoch 45.983) train_loss=1377.68310547 time/batch=0.65s
2714/5900 (epoch 46.000) train_loss=1283.57312012 time/batch=0.70s
setting learning rate to 0.0014009
2715/5900 (epoch 46.017) train_loss=1562.99414062 time/batch=0.74s
2716/5900 (epoch 46.034) train_loss=1709.45056152 time/batch=0.78s
2717/5900 (epoch 46.051) train_loss=1450.94921875 time/batch=1.29s
2718/5900 (epoch 46.068) train_loss=1372.86840820 time/batch=0.66s
2719/5900 (epoch 46.085) train_loss=1623.44604492 time/batch=0.73s
2720/5900 (epoch 46.102) train_loss=1724.00805664 time/batch=0.81s
2721/5900 (epoch 46.119) train_loss=1573.91723633 time/batch=0.74s
2722/5900 (epoch 46.136) train_loss=1435.70996094 time/batch=1.92s
2723/5900 (epoch 46.153) train_loss=1461.48193359 time/batch=1.13s
2724/5900 (epoch 46.169) train_loss=1222.55786133 time/batch=0.65s
2725/5900 (epoch 46.186) train_loss=2459.88452148 time/batch=2.94s
2726/5900 (epoch 46.203) train_loss=1382.82397461 time/batch=0.79s
2727/5900 (epoch 46.220) train_loss=1410.31811523 time/batch=0.65s
2728/5900 (epoch 46.237) train_loss=1604.16406250 time/batch=2.52s
2729/5900 (epoch 46.254) train_loss=1771.96044922 time/batch=0.90s
2730/5900 (epoch 46.271) train_loss=1228.63037109 time/batch=0.58s
2731/5900 (epoch 46.288) train_loss=1781.01513672 time/batch=0.83s
2732/5900 (epoch 46.305) train_loss=1663.85278320 time/batch=2.51s
2733/5900 (epoch 46.322) train_loss=1464.59814453 time/batch=0.84s
2734/5900 (epoch 46.339) train_loss=1618.71459961 time/batch=0.81s
2735/5900 (epoch 46.356) train_loss=1146.50964355 time/batch=0.70s
2736/5900 (epoch 46.373) train_loss=1180.05969238 time/batch=0.60s
2737/5900 (epoch 46.390) train_loss=1563.57519531 time/batch=0.74s
2738/5900 (epoch 46.407) train_loss=1802.81835938 time/batch=0.94s
2739/5900 (epoch 46.424) train_loss=2000.69909668 time/batch=1.08s
2740/5900 (epoch 46.441) train_loss=1137.34570312 time/batch=0.62s
2741/5900 (epoch 46.458) train_loss=1709.21862793 time/batch=0.86s
2742/5900 (epoch 46.475) train_loss=1179.23254395 time/batch=0.61s
2743/5900 (epoch 46.492) train_loss=1362.21093750 time/batch=0.71s
2744/5900 (epoch 46.508) train_loss=1258.07641602 time/batch=0.70s
2745/5900 (epoch 46.525) train_loss=2293.54418945 time/batch=2.38s
2746/5900 (epoch 46.542) train_loss=1222.60058594 time/batch=1.31s
2747/5900 (epoch 46.559) train_loss=1285.32275391 time/batch=0.70s
2748/5900 (epoch 46.576) train_loss=1291.81542969 time/batch=0.61s
2749/5900 (epoch 46.593) train_loss=1385.90161133 time/batch=0.66s
2750/5900 (epoch 46.610) train_loss=1105.92724609 time/batch=0.56s
2751/5900 (epoch 46.627) train_loss=1316.94140625 time/batch=0.68s
2752/5900 (epoch 46.644) train_loss=1143.53320312 time/batch=1.21s
2753/5900 (epoch 46.661) train_loss=1270.79663086 time/batch=0.71s
2754/5900 (epoch 46.678) train_loss=1783.92285156 time/batch=1.51s
2755/5900 (epoch 46.695) train_loss=1215.33410645 time/batch=0.72s
2756/5900 (epoch 46.712) train_loss=1444.60693359 time/batch=1.22s
2757/5900 (epoch 46.729) train_loss=1357.63110352 time/batch=0.76s
2758/5900 (epoch 46.746) train_loss=1127.83447266 time/batch=0.63s
2759/5900 (epoch 46.763) train_loss=1302.97656250 time/batch=0.69s
2760/5900 (epoch 46.780) train_loss=1376.83410645 time/batch=0.74s
2761/5900 (epoch 46.797) train_loss=1418.00817871 time/batch=1.42s
2762/5900 (epoch 46.814) train_loss=1388.46948242 time/batch=1.36s
2763/5900 (epoch 46.831) train_loss=1184.85461426 time/batch=0.67s
2764/5900 (epoch 46.847) train_loss=1333.16503906 time/batch=0.69s
2765/5900 (epoch 46.864) train_loss=1436.53222656 time/batch=0.77s
2766/5900 (epoch 46.881) train_loss=1394.80053711 time/batch=1.36s
2767/5900 (epoch 46.898) train_loss=1342.48681641 time/batch=0.78s
2768/5900 (epoch 46.915) train_loss=1153.76806641 time/batch=0.69s
2769/5900 (epoch 46.932) train_loss=1032.79504395 time/batch=0.62s
2770/5900 (epoch 46.949) train_loss=1021.73742676 time/batch=0.61s
2771/5900 (epoch 46.966) train_loss=1036.24707031 time/batch=0.62s
2772/5900 (epoch 46.983) train_loss=1286.35949707 time/batch=0.73s
2773/5900 (epoch 47.000) train_loss=1085.49475098 time/batch=0.70s
setting learning rate to 0.0013589
2774/5900 (epoch 47.017) train_loss=1737.91784668 time/batch=0.94s
2775/5900 (epoch 47.034) train_loss=1873.25805664 time/batch=0.97s
2776/5900 (epoch 47.051) train_loss=1453.70031738 time/batch=0.68s
2777/5900 (epoch 47.068) train_loss=1068.90197754 time/batch=0.59s
2778/5900 (epoch 47.085) train_loss=1201.67700195 time/batch=0.65s
2779/5900 (epoch 47.102) train_loss=1590.87207031 time/batch=0.86s
2780/5900 (epoch 47.119) train_loss=1264.05664062 time/batch=0.71s
2781/5900 (epoch 47.136) train_loss=1141.31774902 time/batch=1.22s
2782/5900 (epoch 47.153) train_loss=1290.57299805 time/batch=1.39s
2783/5900 (epoch 47.169) train_loss=1614.27075195 time/batch=1.56s
2784/5900 (epoch 47.186) train_loss=1342.44946289 time/batch=0.77s
2785/5900 (epoch 47.203) train_loss=1999.56005859 time/batch=2.96s
2786/5900 (epoch 47.220) train_loss=1191.25231934 time/batch=0.76s
2787/5900 (epoch 47.237) train_loss=1268.22595215 time/batch=0.71s
2788/5900 (epoch 47.254) train_loss=1379.52722168 time/batch=0.73s
2789/5900 (epoch 47.271) train_loss=1368.06958008 time/batch=0.73s
2790/5900 (epoch 47.288) train_loss=1164.41748047 time/batch=0.64s
2791/5900 (epoch 47.305) train_loss=1412.32739258 time/batch=0.75s
2792/5900 (epoch 47.322) train_loss=1273.75695801 time/batch=1.81s
2793/5900 (epoch 47.339) train_loss=1256.78112793 time/batch=0.80s
2794/5900 (epoch 47.356) train_loss=1371.87377930 time/batch=0.80s
2795/5900 (epoch 47.373) train_loss=1515.71984863 time/batch=0.83s
2796/5900 (epoch 47.390) train_loss=1010.43884277 time/batch=1.26s
2797/5900 (epoch 47.407) train_loss=1013.72436523 time/batch=0.65s
2798/5900 (epoch 47.424) train_loss=1450.71899414 time/batch=1.39s
2799/5900 (epoch 47.441) train_loss=1108.47534180 time/batch=0.71s
2800/5900 (epoch 47.458) train_loss=1810.57885742 time/batch=2.21s
2801/5900 (epoch 47.475) train_loss=965.50860596 time/batch=0.70s
2802/5900 (epoch 47.492) train_loss=1251.33642578 time/batch=0.76s
2803/5900 (epoch 47.508) train_loss=1170.93725586 time/batch=0.71s
2804/5900 (epoch 47.525) train_loss=1036.84301758 time/batch=0.63s
2805/5900 (epoch 47.542) train_loss=1633.09692383 time/batch=0.78s
2806/5900 (epoch 47.559) train_loss=1196.25463867 time/batch=0.61s
2807/5900 (epoch 47.576) train_loss=1347.42163086 time/batch=0.71s
2808/5900 (epoch 47.593) train_loss=1484.24218750 time/batch=2.48s
2809/5900 (epoch 47.610) train_loss=1072.31372070 time/batch=0.80s
2810/5900 (epoch 47.627) train_loss=1616.00744629 time/batch=2.40s
2811/5900 (epoch 47.644) train_loss=899.14001465 time/batch=0.69s
2812/5900 (epoch 47.661) train_loss=1053.47277832 time/batch=0.68s
2813/5900 (epoch 47.678) train_loss=1021.51843262 time/batch=0.70s
2814/5900 (epoch 47.695) train_loss=932.74279785 time/batch=0.64s
2815/5900 (epoch 47.712) train_loss=1128.04309082 time/batch=1.32s
2816/5900 (epoch 47.729) train_loss=871.74548340 time/batch=0.64s
2817/5900 (epoch 47.746) train_loss=1450.64550781 time/batch=2.51s
2818/5900 (epoch 47.763) train_loss=1333.43530273 time/batch=0.79s
2819/5900 (epoch 47.780) train_loss=1188.80322266 time/batch=1.26s
2820/5900 (epoch 47.797) train_loss=1106.26562500 time/batch=0.65s
2821/5900 (epoch 47.814) train_loss=1313.19604492 time/batch=0.78s
2822/5900 (epoch 47.831) train_loss=886.87152100 time/batch=0.59s
2823/5900 (epoch 47.847) train_loss=856.80773926 time/batch=0.57s
2824/5900 (epoch 47.864) train_loss=1288.08459473 time/batch=0.79s
2825/5900 (epoch 47.881) train_loss=989.20288086 time/batch=0.69s
2826/5900 (epoch 47.898) train_loss=946.86108398 time/batch=0.67s
2827/5900 (epoch 47.915) train_loss=983.02636719 time/batch=0.68s
2828/5900 (epoch 47.932) train_loss=879.84313965 time/batch=0.62s
2829/5900 (epoch 47.949) train_loss=1159.12231445 time/batch=0.75s
2830/5900 (epoch 47.966) train_loss=1049.44738770 time/batch=1.32s
2831/5900 (epoch 47.983) train_loss=909.44274902 time/batch=0.68s
2832/5900 (epoch 48.000) train_loss=920.16772461 time/batch=0.71s
setting learning rate to 0.0013181
2833/5900 (epoch 48.017) train_loss=1168.65209961 time/batch=0.73s
2834/5900 (epoch 48.034) train_loss=1001.61743164 time/batch=0.65s
2835/5900 (epoch 48.051) train_loss=1176.73730469 time/batch=1.31s
2836/5900 (epoch 48.068) train_loss=2108.94409180 time/batch=2.92s
2837/5900 (epoch 48.085) train_loss=1270.19763184 time/batch=0.87s
2838/5900 (epoch 48.102) train_loss=1498.63232422 time/batch=0.81s
2839/5900 (epoch 48.119) train_loss=1688.29138184 time/batch=2.19s
2840/5900 (epoch 48.136) train_loss=1189.89575195 time/batch=2.58s
2841/5900 (epoch 48.153) train_loss=1455.33312988 time/batch=0.92s
2842/5900 (epoch 48.169) train_loss=1336.90039062 time/batch=0.76s
2843/5900 (epoch 48.186) train_loss=1447.03955078 time/batch=1.15s
2844/5900 (epoch 48.203) train_loss=853.91174316 time/batch=0.63s
2845/5900 (epoch 48.220) train_loss=1089.36474609 time/batch=0.72s
2846/5900 (epoch 48.237) train_loss=1191.33471680 time/batch=0.77s
2847/5900 (epoch 48.254) train_loss=828.36376953 time/batch=0.62s
2848/5900 (epoch 48.271) train_loss=1296.96459961 time/batch=1.42s
2849/5900 (epoch 48.288) train_loss=854.33044434 time/batch=1.23s
2850/5900 (epoch 48.305) train_loss=944.76208496 time/batch=1.36s
2851/5900 (epoch 48.322) train_loss=1484.63305664 time/batch=1.01s
2852/5900 (epoch 48.339) train_loss=857.16931152 time/batch=0.62s
2853/5900 (epoch 48.356) train_loss=1350.15295410 time/batch=1.60s
2854/5900 (epoch 48.373) train_loss=1103.98339844 time/batch=1.41s
2855/5900 (epoch 48.390) train_loss=1044.62182617 time/batch=1.36s
2856/5900 (epoch 48.407) train_loss=1165.61108398 time/batch=1.86s
2857/5900 (epoch 48.424) train_loss=862.25305176 time/batch=1.25s
2858/5900 (epoch 48.441) train_loss=779.81738281 time/batch=0.62s
2859/5900 (epoch 48.458) train_loss=1130.43298340 time/batch=0.78s
2860/5900 (epoch 48.475) train_loss=930.99926758 time/batch=0.69s
2861/5900 (epoch 48.492) train_loss=1048.79199219 time/batch=0.74s
2862/5900 (epoch 48.508) train_loss=817.92687988 time/batch=0.60s
2863/5900 (epoch 48.525) train_loss=1318.71325684 time/batch=0.83s
2864/5900 (epoch 48.542) train_loss=1246.05151367 time/batch=2.52s
2865/5900 (epoch 48.559) train_loss=821.70574951 time/batch=0.73s
2866/5900 (epoch 48.576) train_loss=870.28186035 time/batch=0.68s
2867/5900 (epoch 48.593) train_loss=968.56390381 time/batch=0.70s
2868/5900 (epoch 48.610) train_loss=1056.42846680 time/batch=0.70s
2869/5900 (epoch 48.627) train_loss=1146.88391113 time/batch=0.74s
2870/5900 (epoch 48.644) train_loss=904.88610840 time/batch=0.66s
2871/5900 (epoch 48.661) train_loss=998.84844971 time/batch=0.71s
2872/5900 (epoch 48.678) train_loss=940.96081543 time/batch=0.71s
2873/5900 (epoch 48.695) train_loss=902.70996094 time/batch=0.69s
2874/5900 (epoch 48.712) train_loss=775.10424805 time/batch=0.70s
2875/5900 (epoch 48.729) train_loss=1011.68206787 time/batch=0.75s
2876/5900 (epoch 48.746) train_loss=1200.24633789 time/batch=0.80s
2877/5900 (epoch 48.763) train_loss=768.78222656 time/batch=0.63s
2878/5900 (epoch 48.780) train_loss=759.85003662 time/batch=0.80s
2879/5900 (epoch 48.797) train_loss=844.25177002 time/batch=0.69s
2880/5900 (epoch 48.814) train_loss=736.41546631 time/batch=0.60s
2881/5900 (epoch 48.831) train_loss=691.03936768 time/batch=0.58s
2882/5900 (epoch 48.847) train_loss=778.94958496 time/batch=0.62s
2883/5900 (epoch 48.864) train_loss=747.05456543 time/batch=0.63s
2884/5900 (epoch 48.881) train_loss=1218.21166992 time/batch=0.77s
2885/5900 (epoch 48.898) train_loss=1179.48608398 time/batch=0.61s
2886/5900 (epoch 48.915) train_loss=1470.86340332 time/batch=0.61s
2887/5900 (epoch 48.932) train_loss=1179.28857422 time/batch=0.80s
2888/5900 (epoch 48.949) train_loss=851.00866699 time/batch=0.69s
2889/5900 (epoch 48.966) train_loss=1021.60968018 time/batch=0.77s
2890/5900 (epoch 48.983) train_loss=791.11987305 time/batch=0.70s
2891/5900 (epoch 49.000) train_loss=852.89086914 time/batch=0.68s
setting learning rate to 0.0012786
2892/5900 (epoch 49.017) train_loss=1378.24157715 time/batch=1.60s
2893/5900 (epoch 49.034) train_loss=980.91998291 time/batch=0.78s
2894/5900 (epoch 49.051) train_loss=946.68212891 time/batch=0.74s
2895/5900 (epoch 49.068) train_loss=1209.67761230 time/batch=0.84s
2896/5900 (epoch 49.085) train_loss=881.52661133 time/batch=1.32s
2897/5900 (epoch 49.102) train_loss=700.88354492 time/batch=0.66s
2898/5900 (epoch 49.119) train_loss=902.76831055 time/batch=0.72s
2899/5900 (epoch 49.136) train_loss=1154.80761719 time/batch=1.42s
2900/5900 (epoch 49.153) train_loss=1016.23394775 time/batch=1.84s
2901/5900 (epoch 49.169) train_loss=660.67382812 time/batch=0.65s
2902/5900 (epoch 49.186) train_loss=910.10754395 time/batch=0.71s
2903/5900 (epoch 49.203) train_loss=1679.43139648 time/batch=2.98s
2904/5900 (epoch 49.220) train_loss=1149.57397461 time/batch=0.94s
2905/5900 (epoch 49.237) train_loss=603.91253662 time/batch=0.62s
2906/5900 (epoch 49.254) train_loss=1154.04992676 time/batch=0.98s
2907/5900 (epoch 49.271) train_loss=1275.94799805 time/batch=1.00s
2908/5900 (epoch 49.288) train_loss=1149.67480469 time/batch=0.88s
2909/5900 (epoch 49.305) train_loss=961.93395996 time/batch=2.49s
2910/5900 (epoch 49.322) train_loss=932.06860352 time/batch=0.84s
2911/5900 (epoch 49.339) train_loss=986.80895996 time/batch=0.76s
2912/5900 (epoch 49.356) train_loss=697.77050781 time/batch=0.64s
2913/5900 (epoch 49.373) train_loss=631.14147949 time/batch=0.60s
2914/5900 (epoch 49.390) train_loss=1089.85595703 time/batch=2.50s
2915/5900 (epoch 49.407) train_loss=688.98510742 time/batch=0.76s
2916/5900 (epoch 49.424) train_loss=1174.71142578 time/batch=2.14s
2917/5900 (epoch 49.441) train_loss=667.16278076 time/batch=0.73s
2918/5900 (epoch 49.458) train_loss=603.52239990 time/batch=1.22s
2919/5900 (epoch 49.475) train_loss=814.44274902 time/batch=0.75s
2920/5900 (epoch 49.492) train_loss=979.87371826 time/batch=0.79s
2921/5900 (epoch 49.508) train_loss=925.31530762 time/batch=1.35s
2922/5900 (epoch 49.525) train_loss=1039.72229004 time/batch=0.81s
2923/5900 (epoch 49.542) train_loss=954.79748535 time/batch=0.70s
2924/5900 (epoch 49.559) train_loss=949.72717285 time/batch=0.63s
2925/5900 (epoch 49.576) train_loss=972.97656250 time/batch=0.69s
2926/5900 (epoch 49.593) train_loss=1154.80114746 time/batch=0.69s
2927/5900 (epoch 49.610) train_loss=901.89074707 time/batch=0.73s
2928/5900 (epoch 49.627) train_loss=1028.14404297 time/batch=0.77s
2929/5900 (epoch 49.644) train_loss=742.90673828 time/batch=0.69s
2930/5900 (epoch 49.661) train_loss=711.28881836 time/batch=0.66s
2931/5900 (epoch 49.678) train_loss=739.38140869 time/batch=0.68s
2932/5900 (epoch 49.695) train_loss=620.80664062 time/batch=0.61s
2933/5900 (epoch 49.712) train_loss=554.32470703 time/batch=0.59s
2934/5900 (epoch 49.729) train_loss=609.56835938 time/batch=0.61s
2935/5900 (epoch 49.746) train_loss=656.47448730 time/batch=0.68s
2936/5900 (epoch 49.763) train_loss=716.86383057 time/batch=0.69s
2937/5900 (epoch 49.780) train_loss=885.38208008 time/batch=0.79s
2938/5900 (epoch 49.797) train_loss=617.49938965 time/batch=0.67s
2939/5900 (epoch 49.814) train_loss=702.60821533 time/batch=0.66s
2940/5900 (epoch 49.831) train_loss=532.91027832 time/batch=0.59s
2941/5900 (epoch 49.847) train_loss=831.84228516 time/batch=0.79s
2942/5900 (epoch 49.864) train_loss=705.18713379 time/batch=1.25s
2943/5900 (epoch 49.881) train_loss=719.15368652 time/batch=0.71s
2944/5900 (epoch 49.898) train_loss=758.73626709 time/batch=1.32s
2945/5900 (epoch 49.915) train_loss=757.77947998 time/batch=0.78s
2946/5900 (epoch 49.932) train_loss=661.26855469 time/batch=0.67s
2947/5900 (epoch 49.949) train_loss=576.53649902 time/batch=0.62s
2948/5900 (epoch 49.966) train_loss=671.92614746 time/batch=0.77s
2949/5900 (epoch 49.983) train_loss=734.06018066 time/batch=1.34s
2950/5900 (epoch 50.000) train_loss=685.25231934 time/batch=0.78s
setting learning rate to 0.0012402
  saved to metadata/config5--20190119-211157.pkl
2951/5900 (epoch 50.017) train_loss=692.12493896 time/batch=0.75s
2952/5900 (epoch 50.034) train_loss=1417.57873535 time/batch=2.16s
2953/5900 (epoch 50.051) train_loss=1131.06982422 time/batch=0.80s
2954/5900 (epoch 50.068) train_loss=1316.11596680 time/batch=0.77s
2955/5900 (epoch 50.085) train_loss=851.67309570 time/batch=1.32s
2956/5900 (epoch 50.102) train_loss=932.19464111 time/batch=0.77s
2957/5900 (epoch 50.119) train_loss=1027.34594727 time/batch=0.85s
2958/5900 (epoch 50.136) train_loss=905.79675293 time/batch=0.93s
2959/5900 (epoch 50.153) train_loss=777.22070312 time/batch=0.74s
2960/5900 (epoch 50.169) train_loss=565.50292969 time/batch=0.63s
2961/5900 (epoch 50.186) train_loss=605.36035156 time/batch=1.24s
2962/5900 (epoch 50.203) train_loss=669.63610840 time/batch=0.67s
2963/5900 (epoch 50.220) train_loss=641.24829102 time/batch=0.66s
2964/5900 (epoch 50.237) train_loss=666.11242676 time/batch=0.64s
2965/5900 (epoch 50.254) train_loss=587.09008789 time/batch=0.64s
2966/5900 (epoch 50.271) train_loss=1588.77380371 time/batch=2.96s
2967/5900 (epoch 50.288) train_loss=1087.67053223 time/batch=0.98s
2968/5900 (epoch 50.305) train_loss=525.87219238 time/batch=0.60s
2969/5900 (epoch 50.322) train_loss=1152.66015625 time/batch=0.98s
2970/5900 (epoch 50.339) train_loss=519.60766602 time/batch=1.24s
2971/5900 (epoch 50.356) train_loss=670.42340088 time/batch=0.71s
2972/5900 (epoch 50.373) train_loss=542.35998535 time/batch=0.61s
2973/5900 (epoch 50.390) train_loss=535.79180908 time/batch=0.61s
2974/5900 (epoch 50.407) train_loss=1090.85815430 time/batch=0.94s
2975/5900 (epoch 50.424) train_loss=699.23803711 time/batch=0.68s
2976/5900 (epoch 50.441) train_loss=885.12292480 time/batch=0.75s
2977/5900 (epoch 50.458) train_loss=1093.89160156 time/batch=1.59s
2978/5900 (epoch 50.475) train_loss=953.14807129 time/batch=0.83s
2979/5900 (epoch 50.492) train_loss=1032.80859375 time/batch=2.53s
2980/5900 (epoch 50.508) train_loss=884.71386719 time/batch=1.46s
2981/5900 (epoch 50.525) train_loss=700.72540283 time/batch=0.71s
2982/5900 (epoch 50.542) train_loss=787.33972168 time/batch=2.51s
2983/5900 (epoch 50.559) train_loss=867.47161865 time/batch=0.87s
2984/5900 (epoch 50.576) train_loss=864.23510742 time/batch=1.13s
2985/5900 (epoch 50.593) train_loss=634.71191406 time/batch=1.35s
2986/5900 (epoch 50.610) train_loss=771.10107422 time/batch=0.79s
2987/5900 (epoch 50.627) train_loss=970.58813477 time/batch=1.40s
2988/5900 (epoch 50.644) train_loss=694.68872070 time/batch=1.35s
2989/5900 (epoch 50.661) train_loss=517.00433350 time/batch=0.73s
2990/5900 (epoch 50.678) train_loss=720.94549561 time/batch=0.72s
2991/5900 (epoch 50.695) train_loss=522.70178223 time/batch=1.20s
2992/5900 (epoch 50.712) train_loss=476.29351807 time/batch=0.63s
2993/5900 (epoch 50.729) train_loss=715.22589111 time/batch=0.72s
2994/5900 (epoch 50.746) train_loss=720.74700928 time/batch=0.74s
2995/5900 (epoch 50.763) train_loss=543.33300781 time/batch=0.65s
2996/5900 (epoch 50.780) train_loss=874.43151855 time/batch=1.81s
2997/5900 (epoch 50.797) train_loss=514.51031494 time/batch=0.66s
2998/5900 (epoch 50.814) train_loss=552.89050293 time/batch=0.63s
2999/5900 (epoch 50.831) train_loss=726.55505371 time/batch=1.16s
Validating
    loss:	583.763611

3000/5900 (epoch 50.847) train_loss=586.96337891 time/batch=1.37s
3001/5900 (epoch 50.864) train_loss=549.79724121 time/batch=0.63s
3002/5900 (epoch 50.881) train_loss=629.81286621 time/batch=0.68s
3003/5900 (epoch 50.898) train_loss=736.03778076 time/batch=0.68s
3004/5900 (epoch 50.915) train_loss=779.98315430 time/batch=0.70s
3005/5900 (epoch 50.932) train_loss=580.45452881 time/batch=0.68s
3006/5900 (epoch 50.949) train_loss=565.04602051 time/batch=0.67s
3007/5900 (epoch 50.966) train_loss=488.93273926 time/batch=0.70s
3008/5900 (epoch 50.983) train_loss=625.38262939 time/batch=0.66s
3009/5900 (epoch 51.000) train_loss=584.91076660 time/batch=0.68s
setting learning rate to 0.0012030
3010/5900 (epoch 51.017) train_loss=591.06018066 time/batch=0.69s
3011/5900 (epoch 51.034) train_loss=506.45343018 time/batch=0.60s
3012/5900 (epoch 51.051) train_loss=932.49682617 time/batch=0.82s
3013/5900 (epoch 51.068) train_loss=1189.94018555 time/batch=2.96s
3014/5900 (epoch 51.085) train_loss=1011.54760742 time/batch=1.57s
3015/5900 (epoch 51.102) train_loss=993.44036865 time/batch=0.88s
3016/5900 (epoch 51.119) train_loss=945.12237549 time/batch=2.47s
3017/5900 (epoch 51.136) train_loss=577.71075439 time/batch=1.32s
3018/5900 (epoch 51.153) train_loss=735.30578613 time/batch=0.77s
3019/5900 (epoch 51.169) train_loss=847.33435059 time/batch=0.80s
3020/5900 (epoch 51.186) train_loss=700.48114014 time/batch=0.72s
3021/5900 (epoch 51.203) train_loss=514.26293945 time/batch=0.59s
3022/5900 (epoch 51.220) train_loss=587.41156006 time/batch=0.64s
3023/5900 (epoch 51.237) train_loss=610.43481445 time/batch=1.22s
3024/5900 (epoch 51.254) train_loss=703.66040039 time/batch=1.38s
3025/5900 (epoch 51.271) train_loss=576.72473145 time/batch=0.73s
3026/5900 (epoch 51.288) train_loss=507.01541138 time/batch=0.61s
3027/5900 (epoch 51.305) train_loss=415.34252930 time/batch=0.59s
3028/5900 (epoch 51.322) train_loss=720.37194824 time/batch=0.74s
3029/5900 (epoch 51.339) train_loss=764.11608887 time/batch=0.76s
3030/5900 (epoch 51.356) train_loss=823.05279541 time/batch=0.79s
3031/5900 (epoch 51.373) train_loss=568.66760254 time/batch=1.22s
3032/5900 (epoch 51.390) train_loss=662.04040527 time/batch=0.73s
3033/5900 (epoch 51.407) train_loss=756.00128174 time/batch=0.73s
3034/5900 (epoch 51.424) train_loss=590.02343750 time/batch=0.62s
3035/5900 (epoch 51.441) train_loss=820.91296387 time/batch=0.66s
3036/5900 (epoch 51.458) train_loss=592.02124023 time/batch=0.62s
3037/5900 (epoch 51.475) train_loss=412.60400391 time/batch=0.60s
3038/5900 (epoch 51.492) train_loss=1275.07666016 time/batch=2.38s
3039/5900 (epoch 51.508) train_loss=493.82034302 time/batch=0.71s
3040/5900 (epoch 51.525) train_loss=898.91265869 time/batch=0.95s
3041/5900 (epoch 51.542) train_loss=1246.44848633 time/batch=2.21s
3042/5900 (epoch 51.559) train_loss=659.51745605 time/batch=0.79s
3043/5900 (epoch 51.576) train_loss=467.62280273 time/batch=0.60s
3044/5900 (epoch 51.593) train_loss=493.22253418 time/batch=0.65s
3045/5900 (epoch 51.610) train_loss=729.51464844 time/batch=2.51s
3046/5900 (epoch 51.627) train_loss=588.06140137 time/batch=0.79s
3047/5900 (epoch 51.644) train_loss=692.96130371 time/batch=1.14s
3048/5900 (epoch 51.661) train_loss=731.94665527 time/batch=0.78s
3049/5900 (epoch 51.678) train_loss=679.55865479 time/batch=0.95s
3050/5900 (epoch 51.695) train_loss=843.34143066 time/batch=0.83s
3051/5900 (epoch 51.712) train_loss=483.39071655 time/batch=0.59s
3052/5900 (epoch 51.729) train_loss=676.45819092 time/batch=0.73s
3053/5900 (epoch 51.746) train_loss=787.25720215 time/batch=0.85s
3054/5900 (epoch 51.763) train_loss=547.75671387 time/batch=0.84s
3055/5900 (epoch 51.780) train_loss=578.63146973 time/batch=0.71s
3056/5900 (epoch 51.797) train_loss=601.87609863 time/batch=1.28s
3057/5900 (epoch 51.814) train_loss=804.82580566 time/batch=0.86s
3058/5900 (epoch 51.831) train_loss=654.02575684 time/batch=0.74s
3059/5900 (epoch 51.847) train_loss=554.77893066 time/batch=0.82s
3060/5900 (epoch 51.864) train_loss=740.19567871 time/batch=0.80s
3061/5900 (epoch 51.881) train_loss=779.36767578 time/batch=1.34s
3062/5900 (epoch 51.898) train_loss=663.25225830 time/batch=0.73s
3063/5900 (epoch 51.915) train_loss=497.06143188 time/batch=0.63s
3064/5900 (epoch 51.932) train_loss=590.79498291 time/batch=0.81s
3065/5900 (epoch 51.949) train_loss=595.99737549 time/batch=0.70s
3066/5900 (epoch 51.966) train_loss=583.87915039 time/batch=0.71s
3067/5900 (epoch 51.983) train_loss=596.61633301 time/batch=1.32s
3068/5900 (epoch 52.000) train_loss=530.07153320 time/batch=0.70s
setting learning rate to 0.0011669
3069/5900 (epoch 52.017) train_loss=1113.84741211 time/batch=1.61s
3070/5900 (epoch 52.034) train_loss=879.29644775 time/batch=0.85s
3071/5900 (epoch 52.051) train_loss=1320.47167969 time/batch=2.98s
3072/5900 (epoch 52.068) train_loss=559.97607422 time/batch=0.80s
3073/5900 (epoch 52.085) train_loss=411.31274414 time/batch=0.58s
3074/5900 (epoch 52.102) train_loss=680.92120361 time/batch=0.74s
3075/5900 (epoch 52.119) train_loss=487.52856445 time/batch=1.21s
3076/5900 (epoch 52.136) train_loss=567.20581055 time/batch=0.72s
3077/5900 (epoch 52.153) train_loss=460.61511230 time/batch=0.61s
3078/5900 (epoch 52.169) train_loss=414.59094238 time/batch=0.58s
3079/5900 (epoch 52.186) train_loss=718.01361084 time/batch=0.75s
3080/5900 (epoch 52.203) train_loss=821.99108887 time/batch=1.42s
3081/5900 (epoch 52.220) train_loss=519.66577148 time/batch=0.72s
3082/5900 (epoch 52.237) train_loss=475.10357666 time/batch=0.61s
3083/5900 (epoch 52.254) train_loss=506.31982422 time/batch=1.20s
3084/5900 (epoch 52.271) train_loss=1070.79113770 time/batch=2.16s
3085/5900 (epoch 52.288) train_loss=630.09008789 time/batch=0.77s
3086/5900 (epoch 52.305) train_loss=607.21789551 time/batch=1.27s
3087/5900 (epoch 52.322) train_loss=600.79064941 time/batch=1.34s
3088/5900 (epoch 52.339) train_loss=878.18194580 time/batch=2.56s
3089/5900 (epoch 52.356) train_loss=675.88031006 time/batch=0.83s
3090/5900 (epoch 52.373) train_loss=574.67224121 time/batch=0.68s
3091/5900 (epoch 52.390) train_loss=819.00030518 time/batch=2.48s
3092/5900 (epoch 52.407) train_loss=605.65747070 time/batch=1.43s
3093/5900 (epoch 52.424) train_loss=473.79608154 time/batch=0.74s
3094/5900 (epoch 52.441) train_loss=552.40600586 time/batch=0.69s
3095/5900 (epoch 52.458) train_loss=478.77178955 time/batch=0.65s
3096/5900 (epoch 52.475) train_loss=800.20489502 time/batch=0.80s
3097/5900 (epoch 52.492) train_loss=650.86328125 time/batch=0.73s
3098/5900 (epoch 52.508) train_loss=668.37927246 time/batch=1.38s
3099/5900 (epoch 52.525) train_loss=440.18035889 time/batch=0.71s
3100/5900 (epoch 52.542) train_loss=440.10635376 time/batch=0.59s
3101/5900 (epoch 52.559) train_loss=588.16076660 time/batch=0.70s
3102/5900 (epoch 52.576) train_loss=620.17199707 time/batch=0.72s
3103/5900 (epoch 52.593) train_loss=778.81567383 time/batch=0.92s
3104/5900 (epoch 52.610) train_loss=771.57128906 time/batch=0.81s
3105/5900 (epoch 52.627) train_loss=540.35949707 time/batch=0.67s
3106/5900 (epoch 52.644) train_loss=460.68164062 time/batch=0.61s
3107/5900 (epoch 52.661) train_loss=818.24145508 time/batch=0.84s
3108/5900 (epoch 52.678) train_loss=618.53308105 time/batch=0.72s
3109/5900 (epoch 52.695) train_loss=485.34167480 time/batch=0.65s
3110/5900 (epoch 52.712) train_loss=533.97192383 time/batch=0.70s
3111/5900 (epoch 52.729) train_loss=1155.61303711 time/batch=2.34s
3112/5900 (epoch 52.746) train_loss=497.48629761 time/batch=0.73s
3113/5900 (epoch 52.763) train_loss=638.69775391 time/batch=1.11s
3114/5900 (epoch 52.780) train_loss=549.99963379 time/batch=0.69s
3115/5900 (epoch 52.797) train_loss=696.06494141 time/batch=0.76s
3116/5900 (epoch 52.814) train_loss=686.48413086 time/batch=0.79s
3117/5900 (epoch 52.831) train_loss=538.36297607 time/batch=0.70s
3118/5900 (epoch 52.847) train_loss=465.50195312 time/batch=0.62s
3119/5900 (epoch 52.864) train_loss=376.60778809 time/batch=0.61s
3120/5900 (epoch 52.881) train_loss=647.13195801 time/batch=0.72s
3121/5900 (epoch 52.898) train_loss=641.16156006 time/batch=0.73s
3122/5900 (epoch 52.915) train_loss=650.34716797 time/batch=0.72s
3123/5900 (epoch 52.932) train_loss=722.97619629 time/batch=0.79s
3124/5900 (epoch 52.949) train_loss=629.52270508 time/batch=0.74s
3125/5900 (epoch 52.966) train_loss=449.62011719 time/batch=0.64s
3126/5900 (epoch 52.983) train_loss=461.43984985 time/batch=0.63s
3127/5900 (epoch 53.000) train_loss=451.05786133 time/batch=0.68s
setting learning rate to 0.0011319
3128/5900 (epoch 53.017) train_loss=450.58764648 time/batch=0.69s
3129/5900 (epoch 53.034) train_loss=646.15399170 time/batch=0.74s
3130/5900 (epoch 53.051) train_loss=820.56988525 time/batch=0.86s
3131/5900 (epoch 53.068) train_loss=549.12817383 time/batch=1.22s
3132/5900 (epoch 53.085) train_loss=563.55151367 time/batch=1.35s
3133/5900 (epoch 53.102) train_loss=434.20468140 time/batch=0.67s
3134/5900 (epoch 53.119) train_loss=599.59326172 time/batch=1.13s
3135/5900 (epoch 53.136) train_loss=503.46905518 time/batch=0.67s
3136/5900 (epoch 53.153) train_loss=462.40722656 time/batch=0.64s
3137/5900 (epoch 53.169) train_loss=586.20422363 time/batch=0.71s
3138/5900 (epoch 53.186) train_loss=1009.01788330 time/batch=2.19s
3139/5900 (epoch 53.203) train_loss=991.86083984 time/batch=0.91s
3140/5900 (epoch 53.220) train_loss=673.59082031 time/batch=0.69s
3141/5900 (epoch 53.237) train_loss=795.94421387 time/batch=0.80s
3142/5900 (epoch 53.254) train_loss=410.11175537 time/batch=0.59s
3143/5900 (epoch 53.271) train_loss=452.17214966 time/batch=0.62s
3144/5900 (epoch 53.288) train_loss=986.05596924 time/batch=2.99s
3145/5900 (epoch 53.305) train_loss=528.05200195 time/batch=0.82s
3146/5900 (epoch 53.322) train_loss=666.62371826 time/batch=0.76s
3147/5900 (epoch 53.339) train_loss=1002.26818848 time/batch=1.58s
3148/5900 (epoch 53.356) train_loss=499.54107666 time/batch=0.70s
3149/5900 (epoch 53.373) train_loss=644.83288574 time/batch=1.33s
3150/5900 (epoch 53.390) train_loss=481.48458862 time/batch=1.25s
3151/5900 (epoch 53.407) train_loss=781.61218262 time/batch=1.44s
3152/5900 (epoch 53.424) train_loss=415.65490723 time/batch=0.65s
3153/5900 (epoch 53.441) train_loss=527.95471191 time/batch=0.68s
3154/5900 (epoch 53.458) train_loss=579.25976562 time/batch=0.72s
3155/5900 (epoch 53.475) train_loss=581.90191650 time/batch=1.30s
3156/5900 (epoch 53.492) train_loss=690.09295654 time/batch=0.79s
3157/5900 (epoch 53.508) train_loss=440.39227295 time/batch=0.63s
3158/5900 (epoch 53.525) train_loss=467.24575806 time/batch=1.21s
3159/5900 (epoch 53.542) train_loss=420.47399902 time/batch=0.65s
3160/5900 (epoch 53.559) train_loss=699.92285156 time/batch=0.79s
3161/5900 (epoch 53.576) train_loss=912.53735352 time/batch=2.47s
3162/5900 (epoch 53.593) train_loss=847.82818604 time/batch=1.00s
3163/5900 (epoch 53.610) train_loss=678.74798584 time/batch=2.56s
3164/5900 (epoch 53.627) train_loss=390.59973145 time/batch=0.70s
3165/5900 (epoch 53.644) train_loss=552.17993164 time/batch=1.27s
3166/5900 (epoch 53.661) train_loss=511.78631592 time/batch=0.73s
3167/5900 (epoch 53.678) train_loss=594.24719238 time/batch=0.71s
3168/5900 (epoch 53.695) train_loss=875.27307129 time/batch=0.99s
3169/5900 (epoch 53.712) train_loss=411.56805420 time/batch=0.63s
3170/5900 (epoch 53.729) train_loss=749.86456299 time/batch=1.65s
3171/5900 (epoch 53.746) train_loss=427.11474609 time/batch=0.71s
3172/5900 (epoch 53.763) train_loss=509.76922607 time/batch=0.69s
3173/5900 (epoch 53.780) train_loss=571.67364502 time/batch=0.71s
3174/5900 (epoch 53.797) train_loss=478.94281006 time/batch=0.64s
3175/5900 (epoch 53.814) train_loss=686.13592529 time/batch=0.79s
3176/5900 (epoch 53.831) train_loss=595.19128418 time/batch=0.74s
3177/5900 (epoch 53.847) train_loss=609.20507812 time/batch=0.74s
3178/5900 (epoch 53.864) train_loss=441.54797363 time/batch=0.62s
3179/5900 (epoch 53.881) train_loss=428.18701172 time/batch=0.64s
3180/5900 (epoch 53.898) train_loss=583.65173340 time/batch=0.73s
3181/5900 (epoch 53.915) train_loss=479.27069092 time/batch=0.69s
3182/5900 (epoch 53.932) train_loss=591.00451660 time/batch=0.73s
3183/5900 (epoch 53.949) train_loss=430.85440063 time/batch=0.64s
3184/5900 (epoch 53.966) train_loss=504.46374512 time/batch=0.74s
3185/5900 (epoch 53.983) train_loss=510.84838867 time/batch=0.75s
3186/5900 (epoch 54.000) train_loss=437.55572510 time/batch=0.65s
setting learning rate to 0.0010980
3187/5900 (epoch 54.017) train_loss=747.70477295 time/batch=2.51s
3188/5900 (epoch 54.034) train_loss=502.67907715 time/batch=0.77s
3189/5900 (epoch 54.051) train_loss=699.23931885 time/batch=2.46s
3190/5900 (epoch 54.068) train_loss=922.90637207 time/batch=1.69s
3191/5900 (epoch 54.085) train_loss=923.93896484 time/batch=0.89s
3192/5900 (epoch 54.102) train_loss=522.24145508 time/batch=0.69s
3193/5900 (epoch 54.119) train_loss=504.83239746 time/batch=1.22s
3194/5900 (epoch 54.136) train_loss=1398.40356445 time/batch=2.21s
3195/5900 (epoch 54.153) train_loss=1133.49963379 time/batch=0.82s
3196/5900 (epoch 54.169) train_loss=1186.06872559 time/batch=0.73s
3197/5900 (epoch 54.186) train_loss=748.75354004 time/batch=0.62s
3198/5900 (epoch 54.203) train_loss=972.18627930 time/batch=0.82s
3199/5900 (epoch 54.220) train_loss=670.06854248 time/batch=0.74s
3200/5900 (epoch 54.237) train_loss=822.18127441 time/batch=1.43s
3201/5900 (epoch 54.254) train_loss=427.38830566 time/batch=0.71s
3202/5900 (epoch 54.271) train_loss=436.52917480 time/batch=0.62s
3203/5900 (epoch 54.288) train_loss=408.76281738 time/batch=0.60s
3204/5900 (epoch 54.305) train_loss=544.17395020 time/batch=1.26s
3205/5900 (epoch 54.322) train_loss=691.20635986 time/batch=0.84s
3206/5900 (epoch 54.339) train_loss=422.12530518 time/batch=0.67s
3207/5900 (epoch 54.356) train_loss=520.94812012 time/batch=0.69s
3208/5900 (epoch 54.373) train_loss=678.63525391 time/batch=0.78s
3209/5900 (epoch 54.390) train_loss=922.85742188 time/batch=0.97s
3210/5900 (epoch 54.407) train_loss=449.56695557 time/batch=0.66s
3211/5900 (epoch 54.424) train_loss=442.12512207 time/batch=1.22s
3212/5900 (epoch 54.441) train_loss=711.75744629 time/batch=0.81s
3213/5900 (epoch 54.458) train_loss=401.80685425 time/batch=0.62s
3214/5900 (epoch 54.475) train_loss=808.27416992 time/batch=0.88s
3215/5900 (epoch 54.492) train_loss=578.09729004 time/batch=0.73s
3216/5900 (epoch 54.508) train_loss=623.04980469 time/batch=1.35s
3217/5900 (epoch 54.525) train_loss=474.32537842 time/batch=0.73s
3218/5900 (epoch 54.542) train_loss=781.05822754 time/batch=1.00s
3219/5900 (epoch 54.559) train_loss=585.20239258 time/batch=0.72s
3220/5900 (epoch 54.576) train_loss=424.42636108 time/batch=1.20s
3221/5900 (epoch 54.593) train_loss=528.42102051 time/batch=0.72s
3222/5900 (epoch 54.610) train_loss=491.73883057 time/batch=1.12s
3223/5900 (epoch 54.627) train_loss=469.97521973 time/batch=0.70s
3224/5900 (epoch 54.644) train_loss=586.06884766 time/batch=0.71s
3225/5900 (epoch 54.661) train_loss=507.36099243 time/batch=0.69s
3226/5900 (epoch 54.678) train_loss=425.56680298 time/batch=1.06s
3227/5900 (epoch 54.695) train_loss=430.71984863 time/batch=0.68s
3228/5900 (epoch 54.712) train_loss=415.87881470 time/batch=0.63s
3229/5900 (epoch 54.729) train_loss=552.89410400 time/batch=0.71s
3230/5900 (epoch 54.746) train_loss=468.00372314 time/batch=0.69s
3231/5900 (epoch 54.763) train_loss=489.71670532 time/batch=0.69s
3232/5900 (epoch 54.780) train_loss=418.49737549 time/batch=0.61s
3233/5900 (epoch 54.797) train_loss=557.15960693 time/batch=1.30s
3234/5900 (epoch 54.814) train_loss=602.51171875 time/batch=0.78s
3235/5900 (epoch 54.831) train_loss=509.20462036 time/batch=0.70s
3236/5900 (epoch 54.847) train_loss=565.42095947 time/batch=0.74s
3237/5900 (epoch 54.864) train_loss=616.24835205 time/batch=0.76s
3238/5900 (epoch 54.881) train_loss=454.81427002 time/batch=0.70s
3239/5900 (epoch 54.898) train_loss=1219.17626953 time/batch=2.98s
3240/5900 (epoch 54.915) train_loss=633.46936035 time/batch=1.44s
3241/5900 (epoch 54.932) train_loss=715.14379883 time/batch=1.08s
3242/5900 (epoch 54.949) train_loss=426.55630493 time/batch=0.64s
3243/5900 (epoch 54.966) train_loss=474.39111328 time/batch=0.68s
3244/5900 (epoch 54.983) train_loss=415.87182617 time/batch=0.61s
3245/5900 (epoch 55.000) train_loss=414.38513184 time/batch=0.62s
setting learning rate to 0.0010650
3246/5900 (epoch 55.017) train_loss=418.89419556 time/batch=0.62s
3247/5900 (epoch 55.034) train_loss=841.34136963 time/batch=1.02s
3248/5900 (epoch 55.051) train_loss=476.64538574 time/batch=0.67s
3249/5900 (epoch 55.068) train_loss=935.56152344 time/batch=2.18s
3250/5900 (epoch 55.085) train_loss=711.54589844 time/batch=2.54s
3251/5900 (epoch 55.102) train_loss=436.15527344 time/batch=0.73s
3252/5900 (epoch 55.119) train_loss=500.05157471 time/batch=1.30s
3253/5900 (epoch 55.136) train_loss=1243.50927734 time/batch=3.01s
3254/5900 (epoch 55.153) train_loss=424.98217773 time/batch=0.79s
3255/5900 (epoch 55.169) train_loss=429.81039429 time/batch=0.63s
3256/5900 (epoch 55.186) train_loss=588.19415283 time/batch=0.73s
3257/5900 (epoch 55.203) train_loss=396.65411377 time/batch=0.70s
3258/5900 (epoch 55.220) train_loss=370.41381836 time/batch=0.58s
3259/5900 (epoch 55.237) train_loss=614.18847656 time/batch=0.73s
3260/5900 (epoch 55.254) train_loss=589.06323242 time/batch=0.76s
3261/5900 (epoch 55.271) train_loss=776.24023438 time/batch=0.84s
3262/5900 (epoch 55.288) train_loss=686.78247070 time/batch=0.79s
3263/5900 (epoch 55.305) train_loss=487.38601685 time/batch=0.66s
3264/5900 (epoch 55.322) train_loss=629.67895508 time/batch=2.52s
3265/5900 (epoch 55.339) train_loss=756.27355957 time/batch=1.52s
3266/5900 (epoch 55.356) train_loss=581.37646484 time/batch=0.77s
3267/5900 (epoch 55.373) train_loss=734.65966797 time/batch=0.82s
3268/5900 (epoch 55.390) train_loss=485.61825562 time/batch=0.66s
3269/5900 (epoch 55.407) train_loss=385.60226440 time/batch=0.59s
3270/5900 (epoch 55.424) train_loss=476.12854004 time/batch=0.66s
3271/5900 (epoch 55.441) train_loss=409.32843018 time/batch=0.65s
3272/5900 (epoch 55.458) train_loss=469.01626587 time/batch=0.68s
3273/5900 (epoch 55.475) train_loss=530.06463623 time/batch=1.79s
3274/5900 (epoch 55.492) train_loss=488.27954102 time/batch=0.77s
3275/5900 (epoch 55.508) train_loss=561.28100586 time/batch=1.12s
3276/5900 (epoch 55.525) train_loss=697.22949219 time/batch=0.95s
3277/5900 (epoch 55.542) train_loss=418.48495483 time/batch=0.62s
3278/5900 (epoch 55.559) train_loss=568.43286133 time/batch=1.32s
3279/5900 (epoch 55.576) train_loss=572.48895264 time/batch=0.78s
3280/5900 (epoch 55.593) train_loss=608.52783203 time/batch=0.76s
3281/5900 (epoch 55.610) train_loss=421.58117676 time/batch=0.64s
3282/5900 (epoch 55.627) train_loss=537.67687988 time/batch=0.70s
3283/5900 (epoch 55.644) train_loss=575.07482910 time/batch=0.73s
3284/5900 (epoch 55.661) train_loss=648.82031250 time/batch=1.35s
3285/5900 (epoch 55.678) train_loss=532.66247559 time/batch=0.67s
3286/5900 (epoch 55.695) train_loss=932.87860107 time/batch=0.93s
3287/5900 (epoch 55.712) train_loss=1129.48937988 time/batch=1.57s
3288/5900 (epoch 55.729) train_loss=1400.29528809 time/batch=0.73s
3289/5900 (epoch 55.746) train_loss=1403.99243164 time/batch=0.78s
3290/5900 (epoch 55.763) train_loss=955.58758545 time/batch=0.68s
3291/5900 (epoch 55.780) train_loss=602.71643066 time/batch=0.63s
3292/5900 (epoch 55.797) train_loss=632.70550537 time/batch=0.69s
3293/5900 (epoch 55.814) train_loss=527.01147461 time/batch=0.62s
3294/5900 (epoch 55.831) train_loss=803.01757812 time/batch=1.23s
3295/5900 (epoch 55.847) train_loss=666.51794434 time/batch=0.76s
3296/5900 (epoch 55.864) train_loss=686.97991943 time/batch=0.78s
3297/5900 (epoch 55.881) train_loss=510.95104980 time/batch=0.70s
3298/5900 (epoch 55.898) train_loss=450.60720825 time/batch=0.61s
3299/5900 (epoch 55.915) train_loss=436.44943237 time/batch=0.62s
3300/5900 (epoch 55.932) train_loss=479.35845947 time/batch=1.23s
3301/5900 (epoch 55.949) train_loss=562.99291992 time/batch=0.73s
3302/5900 (epoch 55.966) train_loss=501.29479980 time/batch=0.68s
3303/5900 (epoch 55.983) train_loss=390.77557373 time/batch=0.79s
3304/5900 (epoch 56.000) train_loss=517.69104004 time/batch=0.75s
setting learning rate to 0.0010331
3305/5900 (epoch 56.017) train_loss=703.53967285 time/batch=2.28s
3306/5900 (epoch 56.034) train_loss=421.03683472 time/batch=0.75s
3307/5900 (epoch 56.051) train_loss=825.89514160 time/batch=1.59s
3308/5900 (epoch 56.068) train_loss=807.10650635 time/batch=1.54s
3309/5900 (epoch 56.085) train_loss=837.46728516 time/batch=1.00s
3310/5900 (epoch 56.102) train_loss=781.21423340 time/batch=0.85s
3311/5900 (epoch 56.119) train_loss=468.39312744 time/batch=0.68s
3312/5900 (epoch 56.136) train_loss=381.93334961 time/batch=0.58s
3313/5900 (epoch 56.153) train_loss=410.79016113 time/batch=0.62s
3314/5900 (epoch 56.169) train_loss=728.61657715 time/batch=0.81s
3315/5900 (epoch 56.186) train_loss=466.60949707 time/batch=0.70s
3316/5900 (epoch 56.203) train_loss=583.39398193 time/batch=1.31s
3317/5900 (epoch 56.220) train_loss=608.71228027 time/batch=2.53s
3318/5900 (epoch 56.237) train_loss=508.79693604 time/batch=2.57s
3319/5900 (epoch 56.254) train_loss=505.34014893 time/batch=1.39s
3320/5900 (epoch 56.271) train_loss=422.24200439 time/batch=1.26s
3321/5900 (epoch 56.288) train_loss=560.38189697 time/batch=0.76s
3322/5900 (epoch 56.305) train_loss=478.43859863 time/batch=0.69s
3323/5900 (epoch 56.322) train_loss=564.26208496 time/batch=0.70s
3324/5900 (epoch 56.339) train_loss=953.75524902 time/batch=2.22s
3325/5900 (epoch 56.356) train_loss=513.50366211 time/batch=1.26s
3326/5900 (epoch 56.373) train_loss=453.59890747 time/batch=0.68s
3327/5900 (epoch 56.390) train_loss=404.26782227 time/batch=0.61s
3328/5900 (epoch 56.407) train_loss=465.11181641 time/batch=0.68s
3329/5900 (epoch 56.424) train_loss=592.69042969 time/batch=1.35s
3330/5900 (epoch 56.441) train_loss=399.25378418 time/batch=0.65s
3331/5900 (epoch 56.458) train_loss=489.28820801 time/batch=0.66s
3332/5900 (epoch 56.475) train_loss=566.38671875 time/batch=0.73s
3333/5900 (epoch 56.492) train_loss=638.79467773 time/batch=0.76s
3334/5900 (epoch 56.508) train_loss=437.76153564 time/batch=1.26s
3335/5900 (epoch 56.525) train_loss=716.08673096 time/batch=1.43s
3336/5900 (epoch 56.542) train_loss=395.04425049 time/batch=0.73s
3337/5900 (epoch 56.559) train_loss=652.15734863 time/batch=0.80s
3338/5900 (epoch 56.576) train_loss=559.99853516 time/batch=0.73s
3339/5900 (epoch 56.593) train_loss=395.07916260 time/batch=0.63s
3340/5900 (epoch 56.610) train_loss=372.06704712 time/batch=0.62s
3341/5900 (epoch 56.627) train_loss=592.99597168 time/batch=0.76s
3342/5900 (epoch 56.644) train_loss=445.30718994 time/batch=0.68s
3343/5900 (epoch 56.661) train_loss=535.10589600 time/batch=0.71s
3344/5900 (epoch 56.678) train_loss=891.94433594 time/batch=3.01s
3345/5900 (epoch 56.695) train_loss=431.96923828 time/batch=0.75s
3346/5900 (epoch 56.712) train_loss=413.57046509 time/batch=0.61s
3347/5900 (epoch 56.729) train_loss=393.01571655 time/batch=0.61s
3348/5900 (epoch 56.746) train_loss=556.74755859 time/batch=0.73s
3349/5900 (epoch 56.763) train_loss=528.71667480 time/batch=0.71s
3350/5900 (epoch 56.780) train_loss=432.45855713 time/batch=0.69s
3351/5900 (epoch 56.797) train_loss=589.89416504 time/batch=0.74s
3352/5900 (epoch 56.814) train_loss=605.41455078 time/batch=0.79s
3353/5900 (epoch 56.831) train_loss=503.74932861 time/batch=0.69s
3354/5900 (epoch 56.847) train_loss=496.61761475 time/batch=0.69s
3355/5900 (epoch 56.864) train_loss=509.73468018 time/batch=0.70s
3356/5900 (epoch 56.881) train_loss=417.75451660 time/batch=0.62s
3357/5900 (epoch 56.898) train_loss=593.85144043 time/batch=0.77s
3358/5900 (epoch 56.915) train_loss=361.82482910 time/batch=0.59s
3359/5900 (epoch 56.932) train_loss=599.08300781 time/batch=0.78s
3360/5900 (epoch 56.949) train_loss=512.73016357 time/batch=0.99s
3361/5900 (epoch 56.966) train_loss=447.81848145 time/batch=0.72s
3362/5900 (epoch 56.983) train_loss=489.37557983 time/batch=0.84s
3363/5900 (epoch 57.000) train_loss=625.50646973 time/batch=0.85s
setting learning rate to 0.0010021
3364/5900 (epoch 57.017) train_loss=542.74694824 time/batch=1.80s
3365/5900 (epoch 57.034) train_loss=816.64208984 time/batch=2.27s
3366/5900 (epoch 57.051) train_loss=655.83044434 time/batch=0.83s
3367/5900 (epoch 57.068) train_loss=986.76306152 time/batch=1.61s
3368/5900 (epoch 57.085) train_loss=1119.91979980 time/batch=3.02s
3369/5900 (epoch 57.102) train_loss=442.64874268 time/batch=0.76s
3370/5900 (epoch 57.119) train_loss=722.86932373 time/batch=0.82s
3371/5900 (epoch 57.136) train_loss=471.63714600 time/batch=0.67s
3372/5900 (epoch 57.153) train_loss=416.34252930 time/batch=0.61s
3373/5900 (epoch 57.169) train_loss=551.42248535 time/batch=0.72s
3374/5900 (epoch 57.186) train_loss=690.18792725 time/batch=0.83s
3375/5900 (epoch 57.203) train_loss=813.22967529 time/batch=2.49s
3376/5900 (epoch 57.220) train_loss=659.00067139 time/batch=0.92s
3377/5900 (epoch 57.237) train_loss=729.95904541 time/batch=1.43s
3378/5900 (epoch 57.254) train_loss=474.37994385 time/batch=0.68s
3379/5900 (epoch 57.271) train_loss=732.17181396 time/batch=0.86s
3380/5900 (epoch 57.288) train_loss=358.04522705 time/batch=0.59s
3381/5900 (epoch 57.305) train_loss=468.50527954 time/batch=1.21s
3382/5900 (epoch 57.322) train_loss=610.43035889 time/batch=0.79s
3383/5900 (epoch 57.339) train_loss=633.08764648 time/batch=0.80s
3384/5900 (epoch 57.356) train_loss=414.67736816 time/batch=0.66s
3385/5900 (epoch 57.373) train_loss=452.54724121 time/batch=0.68s
3386/5900 (epoch 57.390) train_loss=471.76538086 time/batch=0.69s
3387/5900 (epoch 57.407) train_loss=385.54608154 time/batch=1.24s
3388/5900 (epoch 57.424) train_loss=375.40841675 time/batch=0.64s
3389/5900 (epoch 57.441) train_loss=945.87170410 time/batch=2.47s
3390/5900 (epoch 57.458) train_loss=482.71417236 time/batch=0.80s
3391/5900 (epoch 57.475) train_loss=552.84667969 time/batch=0.74s
3392/5900 (epoch 57.492) train_loss=507.24578857 time/batch=1.31s
3393/5900 (epoch 57.508) train_loss=465.03155518 time/batch=0.70s
3394/5900 (epoch 57.525) train_loss=340.75830078 time/batch=0.59s
3395/5900 (epoch 57.542) train_loss=447.42456055 time/batch=0.66s
3396/5900 (epoch 57.559) train_loss=394.77630615 time/batch=0.70s
3397/5900 (epoch 57.576) train_loss=549.01184082 time/batch=0.70s
3398/5900 (epoch 57.593) train_loss=467.34362793 time/batch=0.68s
3399/5900 (epoch 57.610) train_loss=539.76354980 time/batch=1.50s
3400/5900 (epoch 57.627) train_loss=584.55163574 time/batch=0.84s
3401/5900 (epoch 57.644) train_loss=541.55053711 time/batch=0.71s
3402/5900 (epoch 57.661) train_loss=396.78637695 time/batch=0.63s
3403/5900 (epoch 57.678) train_loss=374.22204590 time/batch=0.59s
3404/5900 (epoch 57.695) train_loss=599.93444824 time/batch=0.79s
3405/5900 (epoch 57.712) train_loss=556.21832275 time/batch=1.34s
3406/5900 (epoch 57.729) train_loss=400.17443848 time/batch=0.66s
3407/5900 (epoch 57.746) train_loss=520.16137695 time/batch=1.31s
3408/5900 (epoch 57.763) train_loss=425.69976807 time/batch=0.66s
3409/5900 (epoch 57.780) train_loss=391.28186035 time/batch=1.22s
3410/5900 (epoch 57.797) train_loss=381.37225342 time/batch=0.66s
3411/5900 (epoch 57.814) train_loss=418.77023315 time/batch=0.66s
3412/5900 (epoch 57.831) train_loss=514.92767334 time/batch=0.67s
3413/5900 (epoch 57.847) train_loss=400.54760742 time/batch=0.65s
3414/5900 (epoch 57.864) train_loss=487.14938354 time/batch=1.32s
3415/5900 (epoch 57.881) train_loss=539.37976074 time/batch=0.76s
3416/5900 (epoch 57.898) train_loss=389.77520752 time/batch=0.64s
3417/5900 (epoch 57.915) train_loss=554.15905762 time/batch=0.73s
3418/5900 (epoch 57.932) train_loss=537.32678223 time/batch=0.76s
3419/5900 (epoch 57.949) train_loss=468.72238159 time/batch=0.70s
3420/5900 (epoch 57.966) train_loss=613.67901611 time/batch=0.85s
3421/5900 (epoch 57.983) train_loss=393.51892090 time/batch=0.65s
3422/5900 (epoch 58.000) train_loss=408.58895874 time/batch=0.65s
setting learning rate to 0.0009720
3423/5900 (epoch 58.017) train_loss=377.78546143 time/batch=1.22s
3424/5900 (epoch 58.034) train_loss=550.73547363 time/batch=2.49s
3425/5900 (epoch 58.051) train_loss=462.11010742 time/batch=0.75s
3426/5900 (epoch 58.068) train_loss=543.15069580 time/batch=0.71s
3427/5900 (epoch 58.085) train_loss=747.63745117 time/batch=1.53s
3428/5900 (epoch 58.102) train_loss=482.01095581 time/batch=0.71s
3429/5900 (epoch 58.119) train_loss=613.21026611 time/batch=0.81s
3430/5900 (epoch 58.136) train_loss=795.94848633 time/batch=2.55s
3431/5900 (epoch 58.153) train_loss=432.64108276 time/batch=1.30s
3432/5900 (epoch 58.169) train_loss=701.64721680 time/batch=0.85s
3433/5900 (epoch 58.186) train_loss=434.76422119 time/batch=0.69s
3434/5900 (epoch 58.203) train_loss=712.74291992 time/batch=1.42s
3435/5900 (epoch 58.220) train_loss=429.65863037 time/batch=0.68s
3436/5900 (epoch 58.237) train_loss=364.02496338 time/batch=0.63s
3437/5900 (epoch 58.254) train_loss=830.66046143 time/batch=1.00s
3438/5900 (epoch 58.271) train_loss=507.61557007 time/batch=0.72s
3439/5900 (epoch 58.288) train_loss=354.85873413 time/batch=0.59s
3440/5900 (epoch 58.305) train_loss=444.10552979 time/batch=0.69s
3441/5900 (epoch 58.322) train_loss=940.55895996 time/batch=2.94s
3442/5900 (epoch 58.339) train_loss=675.48730469 time/batch=0.93s
3443/5900 (epoch 58.356) train_loss=366.35375977 time/batch=0.61s
3444/5900 (epoch 58.373) train_loss=390.94604492 time/batch=0.63s
3445/5900 (epoch 58.390) train_loss=435.18249512 time/batch=1.21s
3446/5900 (epoch 58.407) train_loss=724.66247559 time/batch=0.87s
3447/5900 (epoch 58.424) train_loss=649.35266113 time/batch=0.83s
3448/5900 (epoch 58.441) train_loss=795.52453613 time/batch=1.56s
3449/5900 (epoch 58.458) train_loss=438.12319946 time/batch=0.69s
3450/5900 (epoch 58.475) train_loss=634.17871094 time/batch=0.82s
3451/5900 (epoch 58.492) train_loss=778.69189453 time/batch=2.21s
3452/5900 (epoch 58.508) train_loss=530.96453857 time/batch=0.83s
3453/5900 (epoch 58.525) train_loss=440.66467285 time/batch=0.69s
3454/5900 (epoch 58.542) train_loss=729.14941406 time/batch=2.36s
3455/5900 (epoch 58.559) train_loss=355.21704102 time/batch=0.73s
3456/5900 (epoch 58.576) train_loss=395.45312500 time/batch=0.60s
3457/5900 (epoch 58.593) train_loss=360.42898560 time/batch=0.66s
3458/5900 (epoch 58.610) train_loss=496.14981079 time/batch=1.08s
3459/5900 (epoch 58.627) train_loss=378.25152588 time/batch=0.69s
3460/5900 (epoch 58.644) train_loss=565.97888184 time/batch=0.75s
3461/5900 (epoch 58.661) train_loss=477.84124756 time/batch=0.68s
3462/5900 (epoch 58.678) train_loss=358.28341675 time/batch=0.64s
3463/5900 (epoch 58.695) train_loss=511.72387695 time/batch=0.71s
3464/5900 (epoch 58.712) train_loss=526.51525879 time/batch=0.73s
3465/5900 (epoch 58.729) train_loss=528.94915771 time/batch=1.31s
3466/5900 (epoch 58.746) train_loss=531.03619385 time/batch=0.77s
3467/5900 (epoch 58.763) train_loss=471.56497192 time/batch=0.77s
3468/5900 (epoch 58.780) train_loss=553.93072510 time/batch=1.38s
3469/5900 (epoch 58.797) train_loss=389.23867798 time/batch=0.66s
3470/5900 (epoch 58.814) train_loss=470.85260010 time/batch=1.32s
3471/5900 (epoch 58.831) train_loss=410.34588623 time/batch=0.78s
3472/5900 (epoch 58.847) train_loss=451.22702026 time/batch=0.67s
3473/5900 (epoch 58.864) train_loss=459.91003418 time/batch=1.26s
3474/5900 (epoch 58.881) train_loss=457.32427979 time/batch=0.74s
3475/5900 (epoch 58.898) train_loss=515.92126465 time/batch=0.73s
3476/5900 (epoch 58.915) train_loss=463.91937256 time/batch=0.69s
3477/5900 (epoch 58.932) train_loss=388.46362305 time/batch=0.64s
3478/5900 (epoch 58.949) train_loss=437.25070190 time/batch=0.65s
3479/5900 (epoch 58.966) train_loss=378.17932129 time/batch=0.61s
3480/5900 (epoch 58.983) train_loss=476.38110352 time/batch=0.75s
3481/5900 (epoch 59.000) train_loss=387.63836670 time/batch=0.63s
setting learning rate to 0.0009429
3482/5900 (epoch 59.017) train_loss=676.09399414 time/batch=0.84s
3483/5900 (epoch 59.034) train_loss=641.75756836 time/batch=2.51s
3484/5900 (epoch 59.051) train_loss=449.85229492 time/batch=0.76s
3485/5900 (epoch 59.068) train_loss=641.25286865 time/batch=2.53s
3486/5900 (epoch 59.085) train_loss=555.30517578 time/batch=1.24s
3487/5900 (epoch 59.102) train_loss=725.17187500 time/batch=0.83s
3488/5900 (epoch 59.119) train_loss=866.01184082 time/batch=1.58s
3489/5900 (epoch 59.136) train_loss=563.05694580 time/batch=0.82s
3490/5900 (epoch 59.153) train_loss=819.88635254 time/batch=0.99s
3491/5900 (epoch 59.169) train_loss=922.41235352 time/batch=2.21s
3492/5900 (epoch 59.186) train_loss=327.86889648 time/batch=0.65s
3493/5900 (epoch 59.203) train_loss=619.85827637 time/batch=0.80s
3494/5900 (epoch 59.220) train_loss=577.56030273 time/batch=0.77s
3495/5900 (epoch 59.237) train_loss=662.43481445 time/batch=1.45s
3496/5900 (epoch 59.254) train_loss=373.75085449 time/batch=0.72s
3497/5900 (epoch 59.271) train_loss=524.40600586 time/batch=0.71s
3498/5900 (epoch 59.288) train_loss=559.04211426 time/batch=0.79s
3499/5900 (epoch 59.305) train_loss=462.00247192 time/batch=1.22s
3500/5900 (epoch 59.322) train_loss=342.96743774 time/batch=0.60s
3501/5900 (epoch 59.339) train_loss=506.47485352 time/batch=0.72s
3502/5900 (epoch 59.356) train_loss=373.55297852 time/batch=0.62s
3503/5900 (epoch 59.373) train_loss=489.49011230 time/batch=0.68s
3504/5900 (epoch 59.390) train_loss=542.74218750 time/batch=1.37s
3505/5900 (epoch 59.407) train_loss=397.72314453 time/batch=0.74s
3506/5900 (epoch 59.424) train_loss=553.48767090 time/batch=0.79s
3507/5900 (epoch 59.441) train_loss=322.76947021 time/batch=0.59s
3508/5900 (epoch 59.458) train_loss=985.61071777 time/batch=2.91s
3509/5900 (epoch 59.475) train_loss=712.68115234 time/batch=1.04s
3510/5900 (epoch 59.492) train_loss=387.41815186 time/batch=0.63s
3511/5900 (epoch 59.508) train_loss=458.49230957 time/batch=0.68s
3512/5900 (epoch 59.525) train_loss=441.92889404 time/batch=0.69s
3513/5900 (epoch 59.542) train_loss=415.24514771 time/batch=0.69s
3514/5900 (epoch 59.559) train_loss=474.34289551 time/batch=1.31s
3515/5900 (epoch 59.576) train_loss=596.93798828 time/batch=0.83s
3516/5900 (epoch 59.593) train_loss=520.21478271 time/batch=1.32s
3517/5900 (epoch 59.610) train_loss=479.53634644 time/batch=0.74s
3518/5900 (epoch 59.627) train_loss=432.04971313 time/batch=0.66s
3519/5900 (epoch 59.644) train_loss=373.99719238 time/batch=0.61s
3520/5900 (epoch 59.661) train_loss=391.89666748 time/batch=0.66s
3521/5900 (epoch 59.678) train_loss=371.06689453 time/batch=0.69s
3522/5900 (epoch 59.695) train_loss=445.82623291 time/batch=0.68s
3523/5900 (epoch 59.712) train_loss=538.14123535 time/batch=0.73s
3524/5900 (epoch 59.729) train_loss=360.76473999 time/batch=0.65s
3525/5900 (epoch 59.746) train_loss=396.67443848 time/batch=0.64s
3526/5900 (epoch 59.763) train_loss=379.54119873 time/batch=0.62s
3527/5900 (epoch 59.780) train_loss=359.19323730 time/batch=0.66s
3528/5900 (epoch 59.797) train_loss=433.38107300 time/batch=0.69s
3529/5900 (epoch 59.814) train_loss=508.26367188 time/batch=0.73s
3530/5900 (epoch 59.831) train_loss=516.53137207 time/batch=1.30s
3531/5900 (epoch 59.847) train_loss=399.82723999 time/batch=0.66s
3532/5900 (epoch 59.864) train_loss=571.84246826 time/batch=0.81s
3533/5900 (epoch 59.881) train_loss=489.70727539 time/batch=0.73s
3534/5900 (epoch 59.898) train_loss=382.70861816 time/batch=0.62s
3535/5900 (epoch 59.915) train_loss=409.72268677 time/batch=0.69s
3536/5900 (epoch 59.932) train_loss=487.59704590 time/batch=0.74s
3537/5900 (epoch 59.949) train_loss=347.33312988 time/batch=0.61s
3538/5900 (epoch 59.966) train_loss=473.12826538 time/batch=0.73s
3539/5900 (epoch 59.983) train_loss=351.12918091 time/batch=0.63s
3540/5900 (epoch 60.000) train_loss=378.26138306 time/batch=0.66s
setting learning rate to 0.0009146
  saved to metadata/config5--20190119-211157.pkl
3541/5900 (epoch 60.017) train_loss=690.02203369 time/batch=0.90s
3542/5900 (epoch 60.034) train_loss=524.48571777 time/batch=2.48s
3543/5900 (epoch 60.051) train_loss=396.19488525 time/batch=0.74s
3544/5900 (epoch 60.068) train_loss=1053.16162109 time/batch=3.00s
3545/5900 (epoch 60.085) train_loss=528.24841309 time/batch=1.44s
3546/5900 (epoch 60.102) train_loss=435.15759277 time/batch=0.72s
3547/5900 (epoch 60.119) train_loss=641.36236572 time/batch=0.80s
3548/5900 (epoch 60.136) train_loss=598.65454102 time/batch=0.80s
3549/5900 (epoch 60.153) train_loss=848.86779785 time/batch=1.61s
3550/5900 (epoch 60.169) train_loss=696.58703613 time/batch=0.91s
3551/5900 (epoch 60.186) train_loss=674.93798828 time/batch=1.10s
3552/5900 (epoch 60.203) train_loss=389.14846802 time/batch=0.63s
3553/5900 (epoch 60.220) train_loss=360.72296143 time/batch=0.60s
3554/5900 (epoch 60.237) train_loss=372.79574585 time/batch=0.65s
3555/5900 (epoch 60.254) train_loss=629.81066895 time/batch=0.83s
3556/5900 (epoch 60.271) train_loss=607.18530273 time/batch=1.83s
3557/5900 (epoch 60.288) train_loss=521.62304688 time/batch=0.78s
3558/5900 (epoch 60.305) train_loss=592.98114014 time/batch=0.85s
3559/5900 (epoch 60.322) train_loss=550.99163818 time/batch=2.52s
3560/5900 (epoch 60.339) train_loss=539.85156250 time/batch=0.85s
3561/5900 (epoch 60.356) train_loss=339.21426392 time/batch=0.58s
3562/5900 (epoch 60.373) train_loss=485.43914795 time/batch=0.72s
3563/5900 (epoch 60.390) train_loss=385.43081665 time/batch=0.64s
3564/5900 (epoch 60.407) train_loss=476.76501465 time/batch=0.70s
3565/5900 (epoch 60.424) train_loss=398.18988037 time/batch=0.70s
3566/5900 (epoch 60.441) train_loss=420.67108154 time/batch=0.68s
3567/5900 (epoch 60.458) train_loss=419.63635254 time/batch=0.66s
3568/5900 (epoch 60.475) train_loss=490.64691162 time/batch=0.71s
3569/5900 (epoch 60.492) train_loss=440.01770020 time/batch=0.69s
3570/5900 (epoch 60.508) train_loss=458.79028320 time/batch=0.72s
3571/5900 (epoch 60.525) train_loss=520.27478027 time/batch=1.36s
3572/5900 (epoch 60.542) train_loss=821.61657715 time/batch=2.21s
3573/5900 (epoch 60.559) train_loss=616.55651855 time/batch=1.00s
3574/5900 (epoch 60.576) train_loss=438.17498779 time/batch=0.66s
3575/5900 (epoch 60.593) train_loss=509.45214844 time/batch=0.75s
3576/5900 (epoch 60.610) train_loss=505.58660889 time/batch=0.71s
3577/5900 (epoch 60.627) train_loss=616.74957275 time/batch=1.44s
3578/5900 (epoch 60.644) train_loss=477.88128662 time/batch=0.76s
3579/5900 (epoch 60.661) train_loss=500.82470703 time/batch=1.22s
3580/5900 (epoch 60.678) train_loss=530.88049316 time/batch=1.27s
3581/5900 (epoch 60.695) train_loss=431.21939087 time/batch=0.72s
3582/5900 (epoch 60.712) train_loss=385.30487061 time/batch=0.65s
3583/5900 (epoch 60.729) train_loss=361.73364258 time/batch=0.69s
3584/5900 (epoch 60.746) train_loss=438.33251953 time/batch=1.31s
3585/5900 (epoch 60.763) train_loss=362.42028809 time/batch=0.64s
3586/5900 (epoch 60.780) train_loss=353.65789795 time/batch=0.61s
3587/5900 (epoch 60.797) train_loss=429.36053467 time/batch=0.68s
3588/5900 (epoch 60.814) train_loss=366.52270508 time/batch=0.62s
3589/5900 (epoch 60.831) train_loss=383.15917969 time/batch=0.66s
3590/5900 (epoch 60.847) train_loss=482.39852905 time/batch=1.30s
3591/5900 (epoch 60.864) train_loss=316.88671875 time/batch=0.64s
3592/5900 (epoch 60.881) train_loss=393.10198975 time/batch=1.21s
3593/5900 (epoch 60.898) train_loss=359.31851196 time/batch=0.67s
3594/5900 (epoch 60.915) train_loss=356.20190430 time/batch=0.60s
3595/5900 (epoch 60.932) train_loss=354.22833252 time/batch=0.60s
3596/5900 (epoch 60.949) train_loss=450.43548584 time/batch=0.76s
3597/5900 (epoch 60.966) train_loss=327.12005615 time/batch=0.63s
3598/5900 (epoch 60.983) train_loss=493.45184326 time/batch=0.72s
3599/5900 (epoch 61.000) train_loss=441.12063599 time/batch=0.75s
setting learning rate to 0.0008871
3600/5900 (epoch 61.017) train_loss=565.77539062 time/batch=0.79s
3601/5900 (epoch 61.034) train_loss=382.69689941 time/batch=0.62s
3602/5900 (epoch 61.051) train_loss=636.56976318 time/batch=0.81s
3603/5900 (epoch 61.068) train_loss=360.80554199 time/batch=0.61s
3604/5900 (epoch 61.085) train_loss=753.48559570 time/batch=0.96s
3605/5900 (epoch 61.102) train_loss=744.60974121 time/batch=0.87s
3606/5900 (epoch 61.119) train_loss=623.08587646 time/batch=2.46s
3607/5900 (epoch 61.136) train_loss=696.13000488 time/batch=1.05s
3608/5900 (epoch 61.153) train_loss=469.84838867 time/batch=1.31s
3609/5900 (epoch 61.169) train_loss=380.29876709 time/batch=0.67s
3610/5900 (epoch 61.186) train_loss=365.63525391 time/batch=1.21s
3611/5900 (epoch 61.203) train_loss=490.54058838 time/batch=0.76s
3612/5900 (epoch 61.220) train_loss=528.43682861 time/batch=0.77s
3613/5900 (epoch 61.237) train_loss=620.15277100 time/batch=0.82s
3614/5900 (epoch 61.254) train_loss=372.03543091 time/batch=1.13s
3615/5900 (epoch 61.271) train_loss=472.70077515 time/batch=0.73s
3616/5900 (epoch 61.288) train_loss=372.26037598 time/batch=0.64s
3617/5900 (epoch 61.305) train_loss=410.90982056 time/batch=0.68s
3618/5900 (epoch 61.322) train_loss=511.84274292 time/batch=0.73s
3619/5900 (epoch 61.339) train_loss=354.20745850 time/batch=0.71s
3620/5900 (epoch 61.356) train_loss=649.56512451 time/batch=1.44s
3621/5900 (epoch 61.373) train_loss=977.00299072 time/batch=2.98s
3622/5900 (epoch 61.390) train_loss=504.18975830 time/batch=0.81s
3623/5900 (epoch 61.407) train_loss=588.12652588 time/batch=0.67s
3624/5900 (epoch 61.424) train_loss=441.49707031 time/batch=0.70s
3625/5900 (epoch 61.441) train_loss=452.00936890 time/batch=0.67s
3626/5900 (epoch 61.458) train_loss=808.81079102 time/batch=2.15s
3627/5900 (epoch 61.475) train_loss=581.97045898 time/batch=0.86s
3628/5900 (epoch 61.492) train_loss=347.85131836 time/batch=0.62s
3629/5900 (epoch 61.508) train_loss=478.35760498 time/batch=1.28s
3630/5900 (epoch 61.525) train_loss=411.04656982 time/batch=0.69s
3631/5900 (epoch 61.542) train_loss=487.82012939 time/batch=0.70s
3632/5900 (epoch 61.559) train_loss=397.07214355 time/batch=1.19s
3633/5900 (epoch 61.576) train_loss=344.70935059 time/batch=0.63s
3634/5900 (epoch 61.593) train_loss=441.58657837 time/batch=1.29s
3635/5900 (epoch 61.610) train_loss=828.72607422 time/batch=1.61s
3636/5900 (epoch 61.627) train_loss=413.40979004 time/batch=0.74s
3637/5900 (epoch 61.644) train_loss=483.74353027 time/batch=0.72s
3638/5900 (epoch 61.661) train_loss=306.28863525 time/batch=0.60s
3639/5900 (epoch 61.678) train_loss=524.34826660 time/batch=1.35s
3640/5900 (epoch 61.695) train_loss=468.88439941 time/batch=0.77s
3641/5900 (epoch 61.712) train_loss=614.67419434 time/batch=0.82s
3642/5900 (epoch 61.729) train_loss=539.98760986 time/batch=0.75s
3643/5900 (epoch 61.746) train_loss=340.97479248 time/batch=0.62s
3644/5900 (epoch 61.763) train_loss=495.39892578 time/batch=2.51s
3645/5900 (epoch 61.780) train_loss=346.80004883 time/batch=0.72s
3646/5900 (epoch 61.797) train_loss=417.16467285 time/batch=0.68s
3647/5900 (epoch 61.814) train_loss=419.25988770 time/batch=0.69s
3648/5900 (epoch 61.831) train_loss=400.21636963 time/batch=0.69s
3649/5900 (epoch 61.847) train_loss=397.58593750 time/batch=0.70s
3650/5900 (epoch 61.864) train_loss=482.97061157 time/batch=0.73s
3651/5900 (epoch 61.881) train_loss=373.33770752 time/batch=0.62s
3652/5900 (epoch 61.898) train_loss=504.14965820 time/batch=0.77s
3653/5900 (epoch 61.915) train_loss=397.73745728 time/batch=0.68s
3654/5900 (epoch 61.932) train_loss=518.66723633 time/batch=0.76s
3655/5900 (epoch 61.949) train_loss=388.49774170 time/batch=0.68s
3656/5900 (epoch 61.966) train_loss=486.13433838 time/batch=1.20s
3657/5900 (epoch 61.983) train_loss=362.09985352 time/batch=0.68s
3658/5900 (epoch 62.000) train_loss=333.90054321 time/batch=0.64s
setting learning rate to 0.0008605
3659/5900 (epoch 62.017) train_loss=491.60916138 time/batch=0.72s
3660/5900 (epoch 62.034) train_loss=349.43469238 time/batch=0.70s
3661/5900 (epoch 62.051) train_loss=510.61502075 time/batch=0.77s
3662/5900 (epoch 62.068) train_loss=526.56640625 time/batch=0.77s
3663/5900 (epoch 62.085) train_loss=469.95404053 time/batch=0.68s
3664/5900 (epoch 62.102) train_loss=672.34423828 time/batch=0.84s
3665/5900 (epoch 62.119) train_loss=391.93927002 time/batch=1.24s
3666/5900 (epoch 62.136) train_loss=492.78466797 time/batch=0.76s
3667/5900 (epoch 62.153) train_loss=368.68353271 time/batch=0.62s
3668/5900 (epoch 62.169) train_loss=733.38989258 time/batch=1.01s
3669/5900 (epoch 62.186) train_loss=459.55285645 time/batch=1.32s
3670/5900 (epoch 62.203) train_loss=467.01779175 time/batch=0.73s
3671/5900 (epoch 62.220) train_loss=427.41955566 time/batch=1.19s
3672/5900 (epoch 62.237) train_loss=563.49206543 time/batch=0.81s
3673/5900 (epoch 62.254) train_loss=465.11871338 time/batch=1.33s
3674/5900 (epoch 62.271) train_loss=433.67590332 time/batch=1.36s
3675/5900 (epoch 62.288) train_loss=478.77972412 time/batch=1.16s
3676/5900 (epoch 62.305) train_loss=651.10638428 time/batch=0.96s
3677/5900 (epoch 62.322) train_loss=982.09033203 time/batch=2.99s
3678/5900 (epoch 62.339) train_loss=673.54650879 time/batch=0.94s
3679/5900 (epoch 62.356) train_loss=323.92773438 time/batch=0.59s
3680/5900 (epoch 62.373) train_loss=658.88806152 time/batch=0.81s
3681/5900 (epoch 62.390) train_loss=641.82739258 time/batch=2.53s
3682/5900 (epoch 62.407) train_loss=491.75195312 time/batch=0.85s
3683/5900 (epoch 62.424) train_loss=485.40142822 time/batch=0.74s
3684/5900 (epoch 62.441) train_loss=543.33612061 time/batch=0.77s
3685/5900 (epoch 62.458) train_loss=333.02416992 time/batch=0.61s
3686/5900 (epoch 62.475) train_loss=352.29598999 time/batch=0.63s
3687/5900 (epoch 62.492) train_loss=752.44171143 time/batch=1.59s
3688/5900 (epoch 62.508) train_loss=368.16534424 time/batch=0.72s
3689/5900 (epoch 62.525) train_loss=464.23278809 time/batch=0.74s
3690/5900 (epoch 62.542) train_loss=704.37768555 time/batch=2.20s
3691/5900 (epoch 62.559) train_loss=533.16021729 time/batch=0.82s
3692/5900 (epoch 62.576) train_loss=616.96386719 time/batch=0.86s
3693/5900 (epoch 62.593) train_loss=461.71917725 time/batch=1.33s
3694/5900 (epoch 62.610) train_loss=598.85375977 time/batch=1.47s
3695/5900 (epoch 62.627) train_loss=342.06597900 time/batch=0.69s
3696/5900 (epoch 62.644) train_loss=406.71734619 time/batch=1.24s
3697/5900 (epoch 62.661) train_loss=502.36328125 time/batch=0.77s
3698/5900 (epoch 62.678) train_loss=350.91940308 time/batch=0.62s
3699/5900 (epoch 62.695) train_loss=480.26568604 time/batch=0.79s
3700/5900 (epoch 62.712) train_loss=357.79324341 time/batch=0.64s
3701/5900 (epoch 62.729) train_loss=392.79406738 time/batch=0.69s
3702/5900 (epoch 62.746) train_loss=374.26507568 time/batch=0.64s
3703/5900 (epoch 62.763) train_loss=406.98889160 time/batch=0.68s
3704/5900 (epoch 62.780) train_loss=328.58245850 time/batch=0.59s
3705/5900 (epoch 62.797) train_loss=335.54602051 time/batch=0.61s
3706/5900 (epoch 62.814) train_loss=409.45971680 time/batch=0.67s
3707/5900 (epoch 62.831) train_loss=413.55017090 time/batch=0.68s
3708/5900 (epoch 62.847) train_loss=364.87866211 time/batch=0.66s
3709/5900 (epoch 62.864) train_loss=400.08477783 time/batch=0.67s
3710/5900 (epoch 62.881) train_loss=411.17184448 time/batch=0.68s
3711/5900 (epoch 62.898) train_loss=444.63336182 time/batch=0.73s
3712/5900 (epoch 62.915) train_loss=450.31744385 time/batch=0.69s
3713/5900 (epoch 62.932) train_loss=350.61444092 time/batch=0.63s
3714/5900 (epoch 62.949) train_loss=413.98617554 time/batch=0.68s
3715/5900 (epoch 62.966) train_loss=341.22262573 time/batch=0.61s
3716/5900 (epoch 62.983) train_loss=359.87371826 time/batch=0.64s
3717/5900 (epoch 63.000) train_loss=407.74377441 time/batch=0.68s
setting learning rate to 0.0008347
3718/5900 (epoch 63.017) train_loss=325.39376831 time/batch=0.60s
3719/5900 (epoch 63.034) train_loss=317.98980713 time/batch=1.21s
3720/5900 (epoch 63.051) train_loss=665.60876465 time/batch=1.53s
3721/5900 (epoch 63.068) train_loss=415.17388916 time/batch=0.73s
3722/5900 (epoch 63.085) train_loss=588.80541992 time/batch=2.47s
3723/5900 (epoch 63.102) train_loss=840.01312256 time/batch=3.09s
3724/5900 (epoch 63.119) train_loss=386.11456299 time/batch=0.83s
3725/5900 (epoch 63.136) train_loss=490.74987793 time/batch=2.50s
3726/5900 (epoch 63.153) train_loss=482.01055908 time/batch=0.82s
3727/5900 (epoch 63.169) train_loss=354.12292480 time/batch=0.66s
3728/5900 (epoch 63.186) train_loss=370.27984619 time/batch=0.63s
3729/5900 (epoch 63.203) train_loss=594.38488770 time/batch=0.80s
3730/5900 (epoch 63.220) train_loss=390.52740479 time/batch=0.68s
3731/5900 (epoch 63.237) train_loss=508.41741943 time/batch=1.77s
3732/5900 (epoch 63.254) train_loss=619.91943359 time/batch=0.88s
3733/5900 (epoch 63.271) train_loss=475.54797363 time/batch=0.75s
3734/5900 (epoch 63.288) train_loss=407.78277588 time/batch=0.69s
3735/5900 (epoch 63.305) train_loss=424.41510010 time/batch=1.33s
3736/5900 (epoch 63.322) train_loss=422.29925537 time/batch=0.73s
3737/5900 (epoch 63.339) train_loss=654.28839111 time/batch=0.84s
3738/5900 (epoch 63.356) train_loss=453.82070923 time/batch=1.34s
3739/5900 (epoch 63.373) train_loss=312.33663940 time/batch=0.64s
3740/5900 (epoch 63.390) train_loss=528.07000732 time/batch=0.76s
3741/5900 (epoch 63.407) train_loss=355.25573730 time/batch=1.23s
3742/5900 (epoch 63.424) train_loss=535.44018555 time/batch=0.80s
3743/5900 (epoch 63.441) train_loss=625.31274414 time/batch=1.46s
3744/5900 (epoch 63.458) train_loss=535.46826172 time/batch=0.80s
3745/5900 (epoch 63.475) train_loss=497.29522705 time/batch=0.72s
3746/5900 (epoch 63.492) train_loss=461.45758057 time/batch=0.69s
3747/5900 (epoch 63.508) train_loss=392.53994751 time/batch=0.66s
3748/5900 (epoch 63.525) train_loss=929.58636475 time/batch=2.36s
3749/5900 (epoch 63.542) train_loss=361.50085449 time/batch=0.73s
3750/5900 (epoch 63.559) train_loss=327.17156982 time/batch=0.59s
3751/5900 (epoch 63.576) train_loss=390.32824707 time/batch=0.69s
3752/5900 (epoch 63.593) train_loss=720.96496582 time/batch=2.17s
3753/5900 (epoch 63.610) train_loss=352.39184570 time/batch=0.73s
3754/5900 (epoch 63.627) train_loss=468.56842041 time/batch=0.75s
3755/5900 (epoch 63.644) train_loss=335.32998657 time/batch=0.61s
3756/5900 (epoch 63.661) train_loss=782.29010010 time/batch=1.56s
3757/5900 (epoch 63.678) train_loss=366.48773193 time/batch=0.71s
3758/5900 (epoch 63.695) train_loss=367.76406860 time/batch=0.66s
3759/5900 (epoch 63.712) train_loss=346.22436523 time/batch=0.62s
3760/5900 (epoch 63.729) train_loss=340.47174072 time/batch=0.59s
3761/5900 (epoch 63.746) train_loss=436.35342407 time/batch=1.36s
3762/5900 (epoch 63.763) train_loss=486.66921997 time/batch=0.76s
3763/5900 (epoch 63.780) train_loss=359.23315430 time/batch=0.63s
3764/5900 (epoch 63.797) train_loss=359.78094482 time/batch=0.60s
3765/5900 (epoch 63.814) train_loss=402.98065186 time/batch=0.63s
3766/5900 (epoch 63.831) train_loss=419.04257202 time/batch=1.31s
3767/5900 (epoch 63.847) train_loss=425.25677490 time/batch=0.72s
3768/5900 (epoch 63.864) train_loss=548.46643066 time/batch=0.79s
3769/5900 (epoch 63.881) train_loss=504.22998047 time/batch=0.78s
3770/5900 (epoch 63.898) train_loss=515.70660400 time/batch=0.81s
3771/5900 (epoch 63.915) train_loss=411.20309448 time/batch=0.69s
3772/5900 (epoch 63.932) train_loss=365.15661621 time/batch=1.09s
3773/5900 (epoch 63.949) train_loss=453.43249512 time/batch=0.74s
3774/5900 (epoch 63.966) train_loss=452.85266113 time/batch=0.72s
3775/5900 (epoch 63.983) train_loss=352.41403198 time/batch=0.66s
3776/5900 (epoch 64.000) train_loss=447.19476318 time/batch=0.71s
setting learning rate to 0.0008097
3777/5900 (epoch 64.017) train_loss=430.30374146 time/batch=1.34s
3778/5900 (epoch 64.034) train_loss=404.24526978 time/batch=0.69s
3779/5900 (epoch 64.051) train_loss=741.65179443 time/batch=1.04s
3780/5900 (epoch 64.068) train_loss=347.44030762 time/batch=0.65s
3781/5900 (epoch 64.085) train_loss=475.97747803 time/batch=0.70s
3782/5900 (epoch 64.102) train_loss=600.35424805 time/batch=1.45s
3783/5900 (epoch 64.119) train_loss=821.20013428 time/batch=2.22s
3784/5900 (epoch 64.136) train_loss=341.15374756 time/batch=0.69s
3785/5900 (epoch 64.153) train_loss=557.41577148 time/batch=0.78s
3786/5900 (epoch 64.169) train_loss=638.73297119 time/batch=0.82s
3787/5900 (epoch 64.186) train_loss=957.82202148 time/batch=3.00s
3788/5900 (epoch 64.203) train_loss=578.71948242 time/batch=0.91s
3789/5900 (epoch 64.220) train_loss=461.13372803 time/batch=1.83s
3790/5900 (epoch 64.237) train_loss=423.33816528 time/batch=0.77s
3791/5900 (epoch 64.254) train_loss=500.15686035 time/batch=1.14s
3792/5900 (epoch 64.271) train_loss=344.63479614 time/batch=0.66s
3793/5900 (epoch 64.288) train_loss=509.07690430 time/batch=0.73s
3794/5900 (epoch 64.305) train_loss=453.24865723 time/batch=0.74s
3795/5900 (epoch 64.322) train_loss=471.41857910 time/batch=0.73s
3796/5900 (epoch 64.339) train_loss=583.42938232 time/batch=0.82s
3797/5900 (epoch 64.356) train_loss=638.32556152 time/batch=0.85s
3798/5900 (epoch 64.373) train_loss=347.52764893 time/batch=0.63s
3799/5900 (epoch 64.390) train_loss=380.11538696 time/batch=1.22s
3800/5900 (epoch 64.407) train_loss=316.26895142 time/batch=0.62s
3801/5900 (epoch 64.424) train_loss=393.46166992 time/batch=0.68s
3802/5900 (epoch 64.441) train_loss=329.32818604 time/batch=0.61s
3803/5900 (epoch 64.458) train_loss=328.03710938 time/batch=0.63s
3804/5900 (epoch 64.475) train_loss=388.16040039 time/batch=0.66s
3805/5900 (epoch 64.492) train_loss=526.43585205 time/batch=0.90s
3806/5900 (epoch 64.508) train_loss=424.87188721 time/batch=1.21s
3807/5900 (epoch 64.525) train_loss=610.67919922 time/batch=0.99s
3808/5900 (epoch 64.542) train_loss=466.42871094 time/batch=1.34s
3809/5900 (epoch 64.559) train_loss=371.72573853 time/batch=0.67s
3810/5900 (epoch 64.576) train_loss=471.66574097 time/batch=0.73s
3811/5900 (epoch 64.593) train_loss=366.21264648 time/batch=1.22s
3812/5900 (epoch 64.610) train_loss=490.82910156 time/batch=0.78s
3813/5900 (epoch 64.627) train_loss=361.24615479 time/batch=0.62s
3814/5900 (epoch 64.644) train_loss=297.39291382 time/batch=0.61s
3815/5900 (epoch 64.661) train_loss=462.86114502 time/batch=1.33s
3816/5900 (epoch 64.678) train_loss=647.16296387 time/batch=1.63s
3817/5900 (epoch 64.695) train_loss=713.39831543 time/batch=2.56s
3818/5900 (epoch 64.712) train_loss=355.92340088 time/batch=0.72s
3819/5900 (epoch 64.729) train_loss=358.12130737 time/batch=0.67s
3820/5900 (epoch 64.746) train_loss=354.75262451 time/batch=0.63s
3821/5900 (epoch 64.763) train_loss=343.17556763 time/batch=0.68s
3822/5900 (epoch 64.780) train_loss=384.60342407 time/batch=0.65s
3823/5900 (epoch 64.797) train_loss=294.84292603 time/batch=0.61s
3824/5900 (epoch 64.814) train_loss=467.24151611 time/batch=0.74s
3825/5900 (epoch 64.831) train_loss=378.63500977 time/batch=0.66s
3826/5900 (epoch 64.847) train_loss=397.72607422 time/batch=0.67s
3827/5900 (epoch 64.864) train_loss=417.14166260 time/batch=1.29s
3828/5900 (epoch 64.881) train_loss=415.53552246 time/batch=0.72s
3829/5900 (epoch 64.898) train_loss=347.91961670 time/batch=0.67s
3830/5900 (epoch 64.915) train_loss=405.76049805 time/batch=0.69s
3831/5900 (epoch 64.932) train_loss=413.24398804 time/batch=0.76s
3832/5900 (epoch 64.949) train_loss=444.11242676 time/batch=0.70s
3833/5900 (epoch 64.966) train_loss=452.49859619 time/batch=0.70s
3834/5900 (epoch 64.983) train_loss=418.22802734 time/batch=0.70s
3835/5900 (epoch 65.000) train_loss=402.10989380 time/batch=0.70s
setting learning rate to 0.0007854
3836/5900 (epoch 65.017) train_loss=523.10797119 time/batch=0.75s
3837/5900 (epoch 65.034) train_loss=640.85699463 time/batch=0.84s
3838/5900 (epoch 65.051) train_loss=595.59460449 time/batch=2.47s
3839/5900 (epoch 65.068) train_loss=647.64721680 time/batch=0.94s
3840/5900 (epoch 65.085) train_loss=346.35876465 time/batch=0.65s
3841/5900 (epoch 65.102) train_loss=379.63360596 time/batch=0.64s
3842/5900 (epoch 65.119) train_loss=313.29681396 time/batch=0.57s
3843/5900 (epoch 65.136) train_loss=453.71176147 time/batch=0.72s
3844/5900 (epoch 65.153) train_loss=677.94470215 time/batch=1.57s
3845/5900 (epoch 65.169) train_loss=575.17333984 time/batch=0.85s
3846/5900 (epoch 65.186) train_loss=419.35848999 time/batch=0.69s
3847/5900 (epoch 65.203) train_loss=349.75567627 time/batch=0.62s
3848/5900 (epoch 65.220) train_loss=526.24072266 time/batch=0.78s
3849/5900 (epoch 65.237) train_loss=493.27670288 time/batch=0.77s
3850/5900 (epoch 65.254) train_loss=322.37597656 time/batch=1.22s
3851/5900 (epoch 65.271) train_loss=391.32583618 time/batch=0.72s
3852/5900 (epoch 65.288) train_loss=846.26300049 time/batch=2.97s
3853/5900 (epoch 65.305) train_loss=390.39276123 time/batch=0.82s
3854/5900 (epoch 65.322) train_loss=445.25604248 time/batch=1.28s
3855/5900 (epoch 65.339) train_loss=337.72244263 time/batch=0.67s
3856/5900 (epoch 65.356) train_loss=490.01544189 time/batch=0.74s
3857/5900 (epoch 65.373) train_loss=424.64691162 time/batch=1.32s
3858/5900 (epoch 65.390) train_loss=337.04486084 time/batch=0.64s
3859/5900 (epoch 65.407) train_loss=736.80346680 time/batch=2.19s
3860/5900 (epoch 65.424) train_loss=415.68347168 time/batch=0.77s
3861/5900 (epoch 65.441) train_loss=339.28738403 time/batch=0.63s
3862/5900 (epoch 65.458) train_loss=532.76403809 time/batch=2.52s
3863/5900 (epoch 65.475) train_loss=324.00000000 time/batch=0.71s
3864/5900 (epoch 65.492) train_loss=554.85559082 time/batch=1.43s
3865/5900 (epoch 65.508) train_loss=391.85974121 time/batch=0.70s
3866/5900 (epoch 65.525) train_loss=718.79162598 time/batch=0.99s
3867/5900 (epoch 65.542) train_loss=435.86026001 time/batch=0.73s
3868/5900 (epoch 65.559) train_loss=334.89758301 time/batch=0.64s
3869/5900 (epoch 65.576) train_loss=333.08148193 time/batch=0.61s
3870/5900 (epoch 65.593) train_loss=607.67504883 time/batch=1.13s
3871/5900 (epoch 65.610) train_loss=453.87231445 time/batch=0.78s
3872/5900 (epoch 65.627) train_loss=374.03851318 time/batch=0.75s
3873/5900 (epoch 65.644) train_loss=523.97314453 time/batch=0.91s
3874/5900 (epoch 65.661) train_loss=539.58599854 time/batch=0.82s
3875/5900 (epoch 65.678) train_loss=374.86572266 time/batch=0.65s
3876/5900 (epoch 65.695) train_loss=388.94641113 time/batch=1.22s
3877/5900 (epoch 65.712) train_loss=418.54730225 time/batch=1.33s
3878/5900 (epoch 65.729) train_loss=486.30664062 time/batch=1.38s
3879/5900 (epoch 65.746) train_loss=444.74429321 time/batch=0.76s
3880/5900 (epoch 65.763) train_loss=407.79718018 time/batch=0.69s
3881/5900 (epoch 65.780) train_loss=307.06243896 time/batch=0.59s
3882/5900 (epoch 65.797) train_loss=496.77108765 time/batch=0.77s
3883/5900 (epoch 65.814) train_loss=388.78613281 time/batch=0.70s
3884/5900 (epoch 65.831) train_loss=373.62655640 time/batch=0.70s
3885/5900 (epoch 65.847) train_loss=460.49163818 time/batch=0.74s
3886/5900 (epoch 65.864) train_loss=476.27941895 time/batch=0.76s
3887/5900 (epoch 65.881) train_loss=325.09921265 time/batch=0.69s
3888/5900 (epoch 65.898) train_loss=387.19705200 time/batch=0.67s
3889/5900 (epoch 65.915) train_loss=346.91326904 time/batch=0.76s
3890/5900 (epoch 65.932) train_loss=371.44323730 time/batch=0.73s
3891/5900 (epoch 65.949) train_loss=427.18307495 time/batch=0.74s
3892/5900 (epoch 65.966) train_loss=406.00802612 time/batch=0.72s
3893/5900 (epoch 65.983) train_loss=372.78222656 time/batch=0.66s
3894/5900 (epoch 66.000) train_loss=358.83959961 time/batch=0.68s
setting learning rate to 0.0007618
3895/5900 (epoch 66.017) train_loss=556.27581787 time/batch=2.51s
3896/5900 (epoch 66.034) train_loss=650.33300781 time/batch=1.59s
3897/5900 (epoch 66.051) train_loss=907.91839600 time/batch=3.00s
3898/5900 (epoch 66.068) train_loss=572.82019043 time/batch=1.44s
3899/5900 (epoch 66.085) train_loss=836.04437256 time/batch=0.81s
3900/5900 (epoch 66.102) train_loss=994.40393066 time/batch=1.38s
3901/5900 (epoch 66.119) train_loss=490.09533691 time/batch=0.74s
3902/5900 (epoch 66.136) train_loss=462.35296631 time/batch=1.21s
3903/5900 (epoch 66.153) train_loss=394.01525879 time/batch=0.67s
3904/5900 (epoch 66.169) train_loss=599.07098389 time/batch=0.80s
3905/5900 (epoch 66.186) train_loss=501.75823975 time/batch=1.82s
3906/5900 (epoch 66.203) train_loss=498.87738037 time/batch=0.80s
3907/5900 (epoch 66.220) train_loss=340.86907959 time/batch=0.63s
3908/5900 (epoch 66.237) train_loss=604.61309814 time/batch=0.81s
3909/5900 (epoch 66.254) train_loss=339.36401367 time/batch=0.65s
3910/5900 (epoch 66.271) train_loss=664.04632568 time/batch=1.57s
3911/5900 (epoch 66.288) train_loss=743.01171875 time/batch=2.43s
3912/5900 (epoch 66.305) train_loss=400.80883789 time/batch=0.77s
3913/5900 (epoch 66.322) train_loss=378.42095947 time/batch=0.68s
3914/5900 (epoch 66.339) train_loss=454.27853394 time/batch=0.75s
3915/5900 (epoch 66.356) train_loss=595.66613770 time/batch=1.41s
3916/5900 (epoch 66.373) train_loss=356.78076172 time/batch=0.70s
3917/5900 (epoch 66.390) train_loss=473.94793701 time/batch=0.74s
3918/5900 (epoch 66.407) train_loss=509.18124390 time/batch=0.78s
3919/5900 (epoch 66.424) train_loss=344.86914062 time/batch=0.69s
3920/5900 (epoch 66.441) train_loss=701.22045898 time/batch=2.18s
3921/5900 (epoch 66.458) train_loss=418.72381592 time/batch=0.78s
3922/5900 (epoch 66.475) train_loss=441.97872925 time/batch=0.75s
3923/5900 (epoch 66.492) train_loss=461.66467285 time/batch=0.73s
3924/5900 (epoch 66.508) train_loss=405.61300659 time/batch=0.71s
3925/5900 (epoch 66.525) train_loss=435.57919312 time/batch=2.45s
3926/5900 (epoch 66.542) train_loss=412.63497925 time/batch=1.40s
3927/5900 (epoch 66.559) train_loss=605.15063477 time/batch=0.95s
3928/5900 (epoch 66.576) train_loss=523.56298828 time/batch=0.83s
3929/5900 (epoch 66.593) train_loss=457.50430298 time/batch=0.71s
3930/5900 (epoch 66.610) train_loss=321.86727905 time/batch=0.68s
3931/5900 (epoch 66.627) train_loss=386.28729248 time/batch=0.71s
3932/5900 (epoch 66.644) train_loss=310.43920898 time/batch=0.61s
3933/5900 (epoch 66.661) train_loss=385.00607300 time/batch=0.64s
3934/5900 (epoch 66.678) train_loss=421.11581421 time/batch=1.31s
3935/5900 (epoch 66.695) train_loss=431.30761719 time/batch=0.76s
3936/5900 (epoch 66.712) train_loss=360.35461426 time/batch=1.22s
3937/5900 (epoch 66.729) train_loss=322.57901001 time/batch=0.65s
3938/5900 (epoch 66.746) train_loss=340.33374023 time/batch=0.61s
3939/5900 (epoch 66.763) train_loss=294.94552612 time/batch=0.58s
3940/5900 (epoch 66.780) train_loss=366.16696167 time/batch=0.65s
3941/5900 (epoch 66.797) train_loss=340.79785156 time/batch=0.65s
3942/5900 (epoch 66.814) train_loss=313.93402100 time/batch=0.61s
3943/5900 (epoch 66.831) train_loss=336.45379639 time/batch=0.62s
3944/5900 (epoch 66.847) train_loss=341.30004883 time/batch=0.61s
3945/5900 (epoch 66.864) train_loss=397.06866455 time/batch=0.67s
3946/5900 (epoch 66.881) train_loss=453.62921143 time/batch=0.73s
3947/5900 (epoch 66.898) train_loss=474.31909180 time/batch=0.76s
3948/5900 (epoch 66.915) train_loss=474.33984375 time/batch=0.81s
3949/5900 (epoch 66.932) train_loss=519.82037354 time/batch=1.13s
3950/5900 (epoch 66.949) train_loss=426.53442383 time/batch=0.71s
3951/5900 (epoch 66.966) train_loss=312.47052002 time/batch=0.62s
3952/5900 (epoch 66.983) train_loss=369.28204346 time/batch=0.66s
3953/5900 (epoch 67.000) train_loss=369.76538086 time/batch=0.67s
setting learning rate to 0.0007390
3954/5900 (epoch 67.017) train_loss=679.27337646 time/batch=1.02s
3955/5900 (epoch 67.034) train_loss=325.99578857 time/batch=0.71s
3956/5900 (epoch 67.051) train_loss=361.94403076 time/batch=0.66s
3957/5900 (epoch 67.068) train_loss=431.87414551 time/batch=0.70s
3958/5900 (epoch 67.085) train_loss=541.89916992 time/batch=0.79s
3959/5900 (epoch 67.102) train_loss=455.24612427 time/batch=0.72s
3960/5900 (epoch 67.119) train_loss=604.17681885 time/batch=0.85s
3961/5900 (epoch 67.136) train_loss=609.67980957 time/batch=0.95s
3962/5900 (epoch 67.153) train_loss=330.95214844 time/batch=0.63s
3963/5900 (epoch 67.169) train_loss=554.10217285 time/batch=2.49s
3964/5900 (epoch 67.186) train_loss=627.26562500 time/batch=1.02s
3965/5900 (epoch 67.203) train_loss=574.44616699 time/batch=2.37s
3966/5900 (epoch 67.220) train_loss=493.51889038 time/batch=0.85s
3967/5900 (epoch 67.237) train_loss=596.12341309 time/batch=0.83s
3968/5900 (epoch 67.254) train_loss=405.72515869 time/batch=1.28s
3969/5900 (epoch 67.271) train_loss=638.46368408 time/batch=1.54s
3970/5900 (epoch 67.288) train_loss=579.15686035 time/batch=1.44s
3971/5900 (epoch 67.305) train_loss=388.01147461 time/batch=0.70s
3972/5900 (epoch 67.322) train_loss=485.70465088 time/batch=0.77s
3973/5900 (epoch 67.339) train_loss=449.45693970 time/batch=2.47s
3974/5900 (epoch 67.356) train_loss=448.88037109 time/batch=0.83s
3975/5900 (epoch 67.373) train_loss=445.60736084 time/batch=0.73s
3976/5900 (epoch 67.390) train_loss=356.77539062 time/batch=1.21s
3977/5900 (epoch 67.407) train_loss=385.67501831 time/batch=0.70s
3978/5900 (epoch 67.424) train_loss=508.61422729 time/batch=0.82s
3979/5900 (epoch 67.441) train_loss=467.00341797 time/batch=0.74s
3980/5900 (epoch 67.458) train_loss=329.16000366 time/batch=0.68s
3981/5900 (epoch 67.475) train_loss=339.00952148 time/batch=0.63s
3982/5900 (epoch 67.492) train_loss=400.65814209 time/batch=1.31s
3983/5900 (epoch 67.508) train_loss=994.63775635 time/batch=3.02s
3984/5900 (epoch 67.525) train_loss=364.36901855 time/batch=0.78s
3985/5900 (epoch 67.542) train_loss=391.27404785 time/batch=0.68s
3986/5900 (epoch 67.559) train_loss=446.56878662 time/batch=0.74s
3987/5900 (epoch 67.576) train_loss=327.99102783 time/batch=0.65s
3988/5900 (epoch 67.593) train_loss=427.36929321 time/batch=1.31s
3989/5900 (epoch 67.610) train_loss=371.44384766 time/batch=0.70s
3990/5900 (epoch 67.627) train_loss=446.32635498 time/batch=0.72s
3991/5900 (epoch 67.644) train_loss=471.55130005 time/batch=1.35s
3992/5900 (epoch 67.661) train_loss=344.92739868 time/batch=0.65s
3993/5900 (epoch 67.678) train_loss=290.30621338 time/batch=0.60s
3994/5900 (epoch 67.695) train_loss=369.39190674 time/batch=0.69s
3995/5900 (epoch 67.712) train_loss=302.85061646 time/batch=0.70s
3996/5900 (epoch 67.729) train_loss=323.09844971 time/batch=0.63s
3997/5900 (epoch 67.746) train_loss=399.22534180 time/batch=0.68s
3998/5900 (epoch 67.763) train_loss=517.31304932 time/batch=0.77s
3999/5900 (epoch 67.780) train_loss=336.55035400 time/batch=1.22s
Validating
    loss:	372.039551

4000/5900 (epoch 67.797) train_loss=390.08541870 time/batch=1.39s
4001/5900 (epoch 67.814) train_loss=301.92736816 time/batch=0.62s
4002/5900 (epoch 67.831) train_loss=323.98944092 time/batch=0.61s
4003/5900 (epoch 67.847) train_loss=477.93792725 time/batch=1.81s
4004/5900 (epoch 67.864) train_loss=340.65069580 time/batch=0.68s
4005/5900 (epoch 67.881) train_loss=374.36975098 time/batch=0.67s
4006/5900 (epoch 67.898) train_loss=317.22564697 time/batch=0.61s
4007/5900 (epoch 67.915) train_loss=398.25555420 time/batch=0.67s
4008/5900 (epoch 67.932) train_loss=472.34576416 time/batch=0.75s
4009/5900 (epoch 67.949) train_loss=464.33288574 time/batch=0.82s
4010/5900 (epoch 67.966) train_loss=448.91064453 time/batch=0.70s
4011/5900 (epoch 67.983) train_loss=370.14517212 time/batch=0.68s
4012/5900 (epoch 68.000) train_loss=331.20574951 time/batch=0.70s
setting learning rate to 0.0007168
4013/5900 (epoch 68.017) train_loss=432.37445068 time/batch=0.72s
4014/5900 (epoch 68.034) train_loss=372.63684082 time/batch=0.69s
4015/5900 (epoch 68.051) train_loss=336.24270630 time/batch=0.70s
4016/5900 (epoch 68.068) train_loss=585.50769043 time/batch=2.34s
4017/5900 (epoch 68.085) train_loss=435.69427490 time/batch=0.80s
4018/5900 (epoch 68.102) train_loss=587.35302734 time/batch=1.43s
4019/5900 (epoch 68.119) train_loss=353.83001709 time/batch=0.69s
4020/5900 (epoch 68.136) train_loss=294.02911377 time/batch=0.61s
4021/5900 (epoch 68.153) train_loss=630.04901123 time/batch=1.49s
4022/5900 (epoch 68.169) train_loss=752.27618408 time/batch=1.64s
4023/5900 (epoch 68.186) train_loss=331.16067505 time/batch=0.67s
4024/5900 (epoch 68.203) train_loss=491.73406982 time/batch=0.76s
4025/5900 (epoch 68.220) train_loss=534.67626953 time/batch=0.81s
4026/5900 (epoch 68.237) train_loss=336.53436279 time/batch=0.61s
4027/5900 (epoch 68.254) train_loss=350.62820435 time/batch=0.66s
4028/5900 (epoch 68.271) train_loss=315.63610840 time/batch=0.64s
4029/5900 (epoch 68.288) train_loss=371.52633667 time/batch=0.66s
4030/5900 (epoch 68.305) train_loss=460.90905762 time/batch=0.74s
4031/5900 (epoch 68.322) train_loss=392.08251953 time/batch=1.19s
4032/5900 (epoch 68.339) train_loss=588.84729004 time/batch=1.01s
4033/5900 (epoch 68.356) train_loss=326.30847168 time/batch=0.69s
4034/5900 (epoch 68.373) train_loss=608.47564697 time/batch=0.83s
4035/5900 (epoch 68.390) train_loss=342.30691528 time/batch=1.22s
4036/5900 (epoch 68.407) train_loss=520.26672363 time/batch=0.83s
4037/5900 (epoch 68.424) train_loss=627.14123535 time/batch=1.02s
4038/5900 (epoch 68.441) train_loss=450.12408447 time/batch=0.77s
4039/5900 (epoch 68.458) train_loss=493.67947388 time/batch=0.78s
4040/5900 (epoch 68.475) train_loss=440.86886597 time/batch=1.32s
4041/5900 (epoch 68.492) train_loss=391.80102539 time/batch=0.73s
4042/5900 (epoch 68.508) train_loss=274.09042358 time/batch=0.58s
4043/5900 (epoch 68.525) train_loss=678.76715088 time/batch=2.50s
4044/5900 (epoch 68.542) train_loss=424.57965088 time/batch=1.38s
4045/5900 (epoch 68.559) train_loss=788.60516357 time/batch=3.02s
4046/5900 (epoch 68.576) train_loss=528.33917236 time/batch=1.48s
4047/5900 (epoch 68.593) train_loss=474.87771606 time/batch=0.78s
4048/5900 (epoch 68.610) train_loss=476.80117798 time/batch=0.77s
4049/5900 (epoch 68.627) train_loss=381.41558838 time/batch=0.66s
4050/5900 (epoch 68.644) train_loss=316.80194092 time/batch=0.61s
4051/5900 (epoch 68.661) train_loss=315.44793701 time/batch=0.59s
4052/5900 (epoch 68.678) train_loss=438.04806519 time/batch=0.72s
4053/5900 (epoch 68.695) train_loss=330.79986572 time/batch=0.63s
4054/5900 (epoch 68.712) train_loss=350.68542480 time/batch=0.69s
4055/5900 (epoch 68.729) train_loss=319.06213379 time/batch=0.63s
4056/5900 (epoch 68.746) train_loss=354.04895020 time/batch=1.20s
4057/5900 (epoch 68.763) train_loss=388.32989502 time/batch=1.25s
4058/5900 (epoch 68.780) train_loss=438.01593018 time/batch=0.75s
4059/5900 (epoch 68.797) train_loss=327.37670898 time/batch=0.65s
4060/5900 (epoch 68.814) train_loss=451.55868530 time/batch=0.71s
4061/5900 (epoch 68.831) train_loss=512.51373291 time/batch=0.80s
4062/5900 (epoch 68.847) train_loss=388.35229492 time/batch=0.68s
4063/5900 (epoch 68.864) train_loss=487.33374023 time/batch=0.81s
4064/5900 (epoch 68.881) train_loss=449.70227051 time/batch=0.83s
4065/5900 (epoch 68.898) train_loss=407.90509033 time/batch=0.70s
4066/5900 (epoch 68.915) train_loss=328.00646973 time/batch=0.63s
4067/5900 (epoch 68.932) train_loss=425.82238770 time/batch=0.86s
4068/5900 (epoch 68.949) train_loss=360.15408325 time/batch=0.71s
4069/5900 (epoch 68.966) train_loss=399.16152954 time/batch=1.32s
4070/5900 (epoch 68.983) train_loss=400.94104004 time/batch=0.85s
4071/5900 (epoch 69.000) train_loss=367.34014893 time/batch=0.65s
setting learning rate to 0.0006953
4072/5900 (epoch 69.017) train_loss=588.41198730 time/batch=0.94s
4073/5900 (epoch 69.034) train_loss=318.64184570 time/batch=0.68s
4074/5900 (epoch 69.051) train_loss=528.56005859 time/batch=2.46s
4075/5900 (epoch 69.068) train_loss=558.77410889 time/batch=2.45s
4076/5900 (epoch 69.085) train_loss=334.17602539 time/batch=0.72s
4077/5900 (epoch 69.102) train_loss=275.21942139 time/batch=0.59s
4078/5900 (epoch 69.119) train_loss=533.29589844 time/batch=0.78s
4079/5900 (epoch 69.136) train_loss=505.12713623 time/batch=0.81s
4080/5900 (epoch 69.153) train_loss=698.49822998 time/batch=1.60s
4081/5900 (epoch 69.169) train_loss=349.97253418 time/batch=0.76s
4082/5900 (epoch 69.186) train_loss=585.87817383 time/batch=1.81s
4083/5900 (epoch 69.203) train_loss=302.76129150 time/batch=0.66s
4084/5900 (epoch 69.220) train_loss=432.62890625 time/batch=0.73s
4085/5900 (epoch 69.237) train_loss=763.99700928 time/batch=2.18s
4086/5900 (epoch 69.254) train_loss=359.57131958 time/batch=0.74s
4087/5900 (epoch 69.271) train_loss=511.92575073 time/batch=0.78s
4088/5900 (epoch 69.288) train_loss=346.66586304 time/batch=0.66s
4089/5900 (epoch 69.305) train_loss=392.78302002 time/batch=0.70s
4090/5900 (epoch 69.322) train_loss=343.31420898 time/batch=0.79s
4091/5900 (epoch 69.339) train_loss=573.45623779 time/batch=0.82s
4092/5900 (epoch 69.356) train_loss=426.39160156 time/batch=0.72s
4093/5900 (epoch 69.373) train_loss=325.05480957 time/batch=0.62s
4094/5900 (epoch 69.390) train_loss=344.84625244 time/batch=0.63s
4095/5900 (epoch 69.407) train_loss=494.94296265 time/batch=0.81s
4096/5900 (epoch 69.424) train_loss=366.02532959 time/batch=0.71s
4097/5900 (epoch 69.441) train_loss=385.65295410 time/batch=1.23s
4098/5900 (epoch 69.458) train_loss=466.10131836 time/batch=0.79s
4099/5900 (epoch 69.475) train_loss=497.34860229 time/batch=0.76s
4100/5900 (epoch 69.492) train_loss=385.57986450 time/batch=0.69s
4101/5900 (epoch 69.508) train_loss=396.07568359 time/batch=2.45s
4102/5900 (epoch 69.525) train_loss=328.99591064 time/batch=0.72s
4103/5900 (epoch 69.542) train_loss=587.25830078 time/batch=0.85s
4104/5900 (epoch 69.559) train_loss=333.13705444 time/batch=0.63s
4105/5900 (epoch 69.576) train_loss=450.90060425 time/batch=0.74s
4106/5900 (epoch 69.593) train_loss=375.80691528 time/batch=0.69s
4107/5900 (epoch 69.610) train_loss=373.78100586 time/batch=0.66s
4108/5900 (epoch 69.627) train_loss=372.41375732 time/batch=0.67s
4109/5900 (epoch 69.644) train_loss=316.15075684 time/batch=0.60s
4110/5900 (epoch 69.661) train_loss=310.44992065 time/batch=0.62s
4111/5900 (epoch 69.678) train_loss=374.93511963 time/batch=0.68s
4112/5900 (epoch 69.695) train_loss=462.15054321 time/batch=0.74s
4113/5900 (epoch 69.712) train_loss=655.83624268 time/batch=1.43s
4114/5900 (epoch 69.729) train_loss=384.55786133 time/batch=0.70s
4115/5900 (epoch 69.746) train_loss=445.39355469 time/batch=0.71s
4116/5900 (epoch 69.763) train_loss=305.41101074 time/batch=0.61s
4117/5900 (epoch 69.780) train_loss=468.80010986 time/batch=0.85s
4118/5900 (epoch 69.797) train_loss=705.70605469 time/batch=2.99s
4119/5900 (epoch 69.814) train_loss=409.91052246 time/batch=1.00s
4120/5900 (epoch 69.831) train_loss=443.41217041 time/batch=0.75s
4121/5900 (epoch 69.847) train_loss=389.69976807 time/batch=0.70s
4122/5900 (epoch 69.864) train_loss=456.56884766 time/batch=1.37s
4123/5900 (epoch 69.881) train_loss=419.08169556 time/batch=1.37s
4124/5900 (epoch 69.898) train_loss=367.58282471 time/batch=0.74s
4125/5900 (epoch 69.915) train_loss=303.76522827 time/batch=0.59s
4126/5900 (epoch 69.932) train_loss=420.39251709 time/batch=0.70s
4127/5900 (epoch 69.949) train_loss=318.44946289 time/batch=0.62s
4128/5900 (epoch 69.966) train_loss=368.33969116 time/batch=0.69s
4129/5900 (epoch 69.983) train_loss=380.59561157 time/batch=1.31s
4130/5900 (epoch 70.000) train_loss=422.83612061 time/batch=1.34s
setting learning rate to 0.0006744
  saved to metadata/config5--20190119-211157.pkl
4131/5900 (epoch 70.017) train_loss=376.10565186 time/batch=0.73s
4132/5900 (epoch 70.034) train_loss=353.04357910 time/batch=0.65s
4133/5900 (epoch 70.051) train_loss=618.97570801 time/batch=1.58s
4134/5900 (epoch 70.068) train_loss=555.18688965 time/batch=2.54s
4135/5900 (epoch 70.085) train_loss=348.79711914 time/batch=0.72s
4136/5900 (epoch 70.102) train_loss=562.52636719 time/batch=0.86s
4137/5900 (epoch 70.119) train_loss=585.29327393 time/batch=0.84s
4138/5900 (epoch 70.136) train_loss=328.17303467 time/batch=0.62s
4139/5900 (epoch 70.153) train_loss=527.90222168 time/batch=0.81s
4140/5900 (epoch 70.169) train_loss=700.81762695 time/batch=2.21s
4141/5900 (epoch 70.186) train_loss=477.37960815 time/batch=2.58s
4142/5900 (epoch 70.203) train_loss=431.60296631 time/batch=0.82s
4143/5900 (epoch 70.220) train_loss=490.36260986 time/batch=0.79s
4144/5900 (epoch 70.237) train_loss=427.08660889 time/batch=1.30s
4145/5900 (epoch 70.254) train_loss=324.41116333 time/batch=0.63s
4146/5900 (epoch 70.271) train_loss=873.06689453 time/batch=2.95s
4147/5900 (epoch 70.288) train_loss=273.43237305 time/batch=0.70s
4148/5900 (epoch 70.305) train_loss=303.60162354 time/batch=0.62s
4149/5900 (epoch 70.322) train_loss=332.94241333 time/batch=0.67s
4150/5900 (epoch 70.339) train_loss=370.39001465 time/batch=0.68s
4151/5900 (epoch 70.356) train_loss=438.01477051 time/batch=0.73s
4152/5900 (epoch 70.373) train_loss=314.73120117 time/batch=0.62s
4153/5900 (epoch 70.390) train_loss=662.71539307 time/batch=1.49s
4154/5900 (epoch 70.407) train_loss=512.39007568 time/batch=1.19s
4155/5900 (epoch 70.424) train_loss=372.68664551 time/batch=0.69s
4156/5900 (epoch 70.441) train_loss=434.03161621 time/batch=1.29s
4157/5900 (epoch 70.458) train_loss=345.02947998 time/batch=0.80s
4158/5900 (epoch 70.475) train_loss=389.51669312 time/batch=0.70s
4159/5900 (epoch 70.492) train_loss=411.01464844 time/batch=0.73s
4160/5900 (epoch 70.508) train_loss=487.86605835 time/batch=1.22s
4161/5900 (epoch 70.525) train_loss=308.22662354 time/batch=0.65s
4162/5900 (epoch 70.542) train_loss=317.64950562 time/batch=0.62s
4163/5900 (epoch 70.559) train_loss=453.80993652 time/batch=0.74s
4164/5900 (epoch 70.576) train_loss=421.33126831 time/batch=0.70s
4165/5900 (epoch 70.593) train_loss=460.68908691 time/batch=0.73s
4166/5900 (epoch 70.610) train_loss=389.28720093 time/batch=0.69s
4167/5900 (epoch 70.627) train_loss=305.46142578 time/batch=0.58s
4168/5900 (epoch 70.644) train_loss=330.69137573 time/batch=0.64s
4169/5900 (epoch 70.661) train_loss=363.77130127 time/batch=0.68s
4170/5900 (epoch 70.678) train_loss=453.51046753 time/batch=0.72s
4171/5900 (epoch 70.695) train_loss=318.33847046 time/batch=0.64s
4172/5900 (epoch 70.712) train_loss=544.47015381 time/batch=1.42s
4173/5900 (epoch 70.729) train_loss=373.65667725 time/batch=0.74s
4174/5900 (epoch 70.746) train_loss=346.05566406 time/batch=0.63s
4175/5900 (epoch 70.763) train_loss=323.46551514 time/batch=0.62s
4176/5900 (epoch 70.780) train_loss=309.36911011 time/batch=0.70s
4177/5900 (epoch 70.797) train_loss=430.85144043 time/batch=0.75s
4178/5900 (epoch 70.814) train_loss=533.40722656 time/batch=0.82s
4179/5900 (epoch 70.831) train_loss=425.09167480 time/batch=0.76s
4180/5900 (epoch 70.847) train_loss=346.96307373 time/batch=0.97s
4181/5900 (epoch 70.864) train_loss=479.31018066 time/batch=0.83s
4182/5900 (epoch 70.881) train_loss=469.07598877 time/batch=0.72s
4183/5900 (epoch 70.898) train_loss=464.82287598 time/batch=0.75s
4184/5900 (epoch 70.915) train_loss=388.12896729 time/batch=0.70s
4185/5900 (epoch 70.932) train_loss=358.32489014 time/batch=0.73s
4186/5900 (epoch 70.949) train_loss=335.01995850 time/batch=0.72s
4187/5900 (epoch 70.966) train_loss=365.43914795 time/batch=0.68s
4188/5900 (epoch 70.983) train_loss=451.41729736 time/batch=1.35s
4189/5900 (epoch 71.000) train_loss=332.77520752 time/batch=0.75s
setting learning rate to 0.0006542
4190/5900 (epoch 71.017) train_loss=323.47677612 time/batch=0.61s
4191/5900 (epoch 71.034) train_loss=522.64178467 time/batch=2.50s
4192/5900 (epoch 71.051) train_loss=769.63281250 time/batch=1.71s
4193/5900 (epoch 71.068) train_loss=757.86108398 time/batch=2.25s
4194/5900 (epoch 71.085) train_loss=474.85766602 time/batch=0.82s
4195/5900 (epoch 71.102) train_loss=303.49127197 time/batch=0.62s
4196/5900 (epoch 71.119) train_loss=371.21017456 time/batch=0.68s
4197/5900 (epoch 71.136) train_loss=382.55725098 time/batch=0.69s
4198/5900 (epoch 71.153) train_loss=572.97015381 time/batch=0.83s
4199/5900 (epoch 71.169) train_loss=410.74710083 time/batch=0.71s
4200/5900 (epoch 71.186) train_loss=576.53955078 time/batch=0.87s
4201/5900 (epoch 71.203) train_loss=786.60913086 time/batch=2.98s
4202/5900 (epoch 71.220) train_loss=353.35226440 time/batch=1.26s
4203/5900 (epoch 71.237) train_loss=476.68063354 time/batch=0.80s
4204/5900 (epoch 71.254) train_loss=310.01327515 time/batch=0.61s
4205/5900 (epoch 71.271) train_loss=334.45184326 time/batch=1.20s
4206/5900 (epoch 71.288) train_loss=563.61560059 time/batch=0.98s
4207/5900 (epoch 71.305) train_loss=526.08209229 time/batch=0.83s
4208/5900 (epoch 71.322) train_loss=388.90582275 time/batch=1.33s
4209/5900 (epoch 71.339) train_loss=312.58813477 time/batch=0.65s
4210/5900 (epoch 71.356) train_loss=337.32855225 time/batch=0.64s
4211/5900 (epoch 71.373) train_loss=489.90948486 time/batch=0.76s
4212/5900 (epoch 71.390) train_loss=483.20123291 time/batch=0.76s
4213/5900 (epoch 71.407) train_loss=372.30535889 time/batch=0.68s
4214/5900 (epoch 71.424) train_loss=612.84106445 time/batch=0.99s
4215/5900 (epoch 71.441) train_loss=349.49426270 time/batch=0.70s
4216/5900 (epoch 71.458) train_loss=455.78308105 time/batch=1.33s
4217/5900 (epoch 71.475) train_loss=303.81997681 time/batch=0.66s
4218/5900 (epoch 71.492) train_loss=271.31848145 time/batch=0.60s
4219/5900 (epoch 71.508) train_loss=288.29846191 time/batch=0.57s
4220/5900 (epoch 71.525) train_loss=364.78228760 time/batch=0.71s
4221/5900 (epoch 71.542) train_loss=538.87145996 time/batch=0.90s
4222/5900 (epoch 71.559) train_loss=441.83319092 time/batch=0.76s
4223/5900 (epoch 71.576) train_loss=331.09985352 time/batch=0.62s
4224/5900 (epoch 71.593) train_loss=363.47677612 time/batch=0.69s
4225/5900 (epoch 71.610) train_loss=447.74655151 time/batch=0.77s
4226/5900 (epoch 71.627) train_loss=539.97900391 time/batch=2.49s
4227/5900 (epoch 71.644) train_loss=367.31250000 time/batch=0.79s
4228/5900 (epoch 71.661) train_loss=401.68444824 time/batch=1.29s
4229/5900 (epoch 71.678) train_loss=353.61178589 time/batch=0.72s
4230/5900 (epoch 71.695) train_loss=432.54412842 time/batch=0.72s
4231/5900 (epoch 71.712) train_loss=409.57061768 time/batch=0.69s
4232/5900 (epoch 71.729) train_loss=428.03955078 time/batch=0.73s
4233/5900 (epoch 71.746) train_loss=306.40689087 time/batch=0.61s
4234/5900 (epoch 71.763) train_loss=294.36230469 time/batch=1.22s
4235/5900 (epoch 71.780) train_loss=434.02783203 time/batch=0.76s
4236/5900 (epoch 71.797) train_loss=518.57501221 time/batch=1.41s
4237/5900 (epoch 71.814) train_loss=357.91436768 time/batch=0.72s
4238/5900 (epoch 71.831) train_loss=297.66696167 time/batch=0.61s
4239/5900 (epoch 71.847) train_loss=444.24356079 time/batch=0.76s
4240/5900 (epoch 71.864) train_loss=440.83270264 time/batch=1.20s
4241/5900 (epoch 71.881) train_loss=318.59521484 time/batch=0.68s
4242/5900 (epoch 71.898) train_loss=323.56109619 time/batch=0.61s
4243/5900 (epoch 71.915) train_loss=305.79400635 time/batch=0.62s
4244/5900 (epoch 71.932) train_loss=422.97445679 time/batch=1.30s
4245/5900 (epoch 71.949) train_loss=364.42144775 time/batch=0.71s
4246/5900 (epoch 71.966) train_loss=356.40142822 time/batch=0.70s
4247/5900 (epoch 71.983) train_loss=366.06036377 time/batch=0.66s
4248/5900 (epoch 72.000) train_loss=344.74316406 time/batch=0.71s
setting learning rate to 0.0006346
4249/5900 (epoch 72.017) train_loss=573.87445068 time/batch=0.81s
4250/5900 (epoch 72.034) train_loss=620.10491943 time/batch=1.52s
4251/5900 (epoch 72.051) train_loss=698.70947266 time/batch=1.65s
4252/5900 (epoch 72.068) train_loss=312.37432861 time/batch=0.64s
4253/5900 (epoch 72.085) train_loss=490.83197021 time/batch=2.47s
4254/5900 (epoch 72.102) train_loss=278.76577759 time/batch=0.69s
4255/5900 (epoch 72.119) train_loss=620.73541260 time/batch=0.96s
4256/5900 (epoch 72.136) train_loss=387.35937500 time/batch=1.31s
4257/5900 (epoch 72.153) train_loss=655.63574219 time/batch=2.39s
4258/5900 (epoch 72.169) train_loss=314.85324097 time/batch=0.73s
4259/5900 (epoch 72.186) train_loss=654.98315430 time/batch=2.87s
4260/5900 (epoch 72.203) train_loss=526.79571533 time/batch=0.95s
4261/5900 (epoch 72.220) train_loss=649.30645752 time/batch=2.19s
4262/5900 (epoch 72.237) train_loss=436.19696045 time/batch=0.81s
4263/5900 (epoch 72.254) train_loss=373.01962280 time/batch=0.69s
4264/5900 (epoch 72.271) train_loss=326.23983765 time/batch=0.68s
4265/5900 (epoch 72.288) train_loss=341.73333740 time/batch=0.65s
4266/5900 (epoch 72.305) train_loss=514.19555664 time/batch=1.17s
4267/5900 (epoch 72.322) train_loss=453.87249756 time/batch=0.77s
4268/5900 (epoch 72.339) train_loss=458.73950195 time/batch=2.48s
4269/5900 (epoch 72.356) train_loss=467.23068237 time/batch=0.90s
4270/5900 (epoch 72.373) train_loss=428.35659790 time/batch=1.32s
4271/5900 (epoch 72.390) train_loss=477.22366333 time/batch=0.83s
4272/5900 (epoch 72.407) train_loss=418.83740234 time/batch=0.74s
4273/5900 (epoch 72.424) train_loss=318.70495605 time/batch=0.62s
4274/5900 (epoch 72.441) train_loss=292.09429932 time/batch=1.21s
4275/5900 (epoch 72.458) train_loss=355.57098389 time/batch=0.72s
4276/5900 (epoch 72.475) train_loss=451.70068359 time/batch=1.34s
4277/5900 (epoch 72.492) train_loss=449.88275146 time/batch=0.78s
4278/5900 (epoch 72.508) train_loss=373.31634521 time/batch=0.71s
4279/5900 (epoch 72.525) train_loss=398.33587646 time/batch=0.72s
4280/5900 (epoch 72.542) train_loss=430.92242432 time/batch=0.72s
4281/5900 (epoch 72.559) train_loss=359.49609375 time/batch=0.65s
4282/5900 (epoch 72.576) train_loss=351.36383057 time/batch=1.18s
4283/5900 (epoch 72.593) train_loss=428.50958252 time/batch=0.77s
4284/5900 (epoch 72.610) train_loss=431.50366211 time/batch=0.73s
4285/5900 (epoch 72.627) train_loss=357.92401123 time/batch=0.68s
4286/5900 (epoch 72.644) train_loss=411.89205933 time/batch=1.22s
4287/5900 (epoch 72.661) train_loss=377.31085205 time/batch=0.72s
4288/5900 (epoch 72.678) train_loss=329.72119141 time/batch=0.64s
4289/5900 (epoch 72.695) train_loss=290.62945557 time/batch=0.61s
4290/5900 (epoch 72.712) train_loss=490.38363647 time/batch=0.78s
4291/5900 (epoch 72.729) train_loss=429.32556152 time/batch=0.71s
4292/5900 (epoch 72.746) train_loss=346.32077026 time/batch=0.65s
4293/5900 (epoch 72.763) train_loss=352.33819580 time/batch=0.78s
4294/5900 (epoch 72.780) train_loss=315.84255981 time/batch=0.63s
4295/5900 (epoch 72.797) train_loss=320.38980103 time/batch=0.62s
4296/5900 (epoch 72.814) train_loss=355.85577393 time/batch=0.68s
4297/5900 (epoch 72.831) train_loss=346.80422974 time/batch=0.66s
4298/5900 (epoch 72.847) train_loss=465.39624023 time/batch=0.76s
4299/5900 (epoch 72.864) train_loss=348.73687744 time/batch=1.32s
4300/5900 (epoch 72.881) train_loss=411.25878906 time/batch=0.78s
4301/5900 (epoch 72.898) train_loss=367.14251709 time/batch=0.74s
4302/5900 (epoch 72.915) train_loss=330.16812134 time/batch=0.61s
4303/5900 (epoch 72.932) train_loss=508.64495850 time/batch=1.42s
4304/5900 (epoch 72.949) train_loss=299.69995117 time/batch=0.64s
4305/5900 (epoch 72.966) train_loss=358.26440430 time/batch=0.66s
4306/5900 (epoch 72.983) train_loss=321.92053223 time/batch=0.61s
4307/5900 (epoch 73.000) train_loss=299.39193726 time/batch=0.62s
setting learning rate to 0.0006155
4308/5900 (epoch 73.017) train_loss=440.52087402 time/batch=0.77s
4309/5900 (epoch 73.034) train_loss=371.81787109 time/batch=0.68s
4310/5900 (epoch 73.051) train_loss=291.41973877 time/batch=1.20s
4311/5900 (epoch 73.068) train_loss=447.45379639 time/batch=1.39s
4312/5900 (epoch 73.085) train_loss=587.23681641 time/batch=0.89s
4313/5900 (epoch 73.102) train_loss=608.50671387 time/batch=0.85s
4314/5900 (epoch 73.119) train_loss=441.95465088 time/batch=0.73s
4315/5900 (epoch 73.136) train_loss=352.07568359 time/batch=0.69s
4316/5900 (epoch 73.153) train_loss=606.90185547 time/batch=1.60s
4317/5900 (epoch 73.169) train_loss=529.24450684 time/batch=0.91s
4318/5900 (epoch 73.186) train_loss=314.11340332 time/batch=0.65s
4319/5900 (epoch 73.203) train_loss=843.35852051 time/batch=2.98s
4320/5900 (epoch 73.220) train_loss=424.01861572 time/batch=0.88s
4321/5900 (epoch 73.237) train_loss=401.51464844 time/batch=0.70s
4322/5900 (epoch 73.254) train_loss=281.21987915 time/batch=0.60s
4323/5900 (epoch 73.271) train_loss=333.34243774 time/batch=0.63s
4324/5900 (epoch 73.288) train_loss=343.13153076 time/batch=0.64s
4325/5900 (epoch 73.305) train_loss=369.40600586 time/batch=0.69s
4326/5900 (epoch 73.322) train_loss=421.41949463 time/batch=0.72s
4327/5900 (epoch 73.339) train_loss=393.33801270 time/batch=0.71s
4328/5900 (epoch 73.356) train_loss=302.58380127 time/batch=1.22s
4329/5900 (epoch 73.373) train_loss=524.44482422 time/batch=1.42s
4330/5900 (epoch 73.390) train_loss=455.60507202 time/batch=0.80s
4331/5900 (epoch 73.407) train_loss=308.12335205 time/batch=0.63s
4332/5900 (epoch 73.424) train_loss=622.85375977 time/batch=0.96s
4333/5900 (epoch 73.441) train_loss=687.57916260 time/batch=2.19s
4334/5900 (epoch 73.458) train_loss=330.05444336 time/batch=0.72s
4335/5900 (epoch 73.475) train_loss=538.59869385 time/batch=1.08s
4336/5900 (epoch 73.492) train_loss=315.25079346 time/batch=0.68s
4337/5900 (epoch 73.508) train_loss=293.89416504 time/batch=0.60s
4338/5900 (epoch 73.525) train_loss=359.42608643 time/batch=0.63s
4339/5900 (epoch 73.542) train_loss=391.21707153 time/batch=1.29s
4340/5900 (epoch 73.559) train_loss=318.53778076 time/batch=0.66s
4341/5900 (epoch 73.576) train_loss=422.20620728 time/batch=1.79s
4342/5900 (epoch 73.593) train_loss=475.69421387 time/batch=0.87s
4343/5900 (epoch 73.610) train_loss=413.23895264 time/batch=0.73s
4344/5900 (epoch 73.627) train_loss=552.44732666 time/batch=2.46s
4345/5900 (epoch 73.644) train_loss=315.54525757 time/batch=0.76s
4346/5900 (epoch 73.661) train_loss=482.09616089 time/batch=0.78s
4347/5900 (epoch 73.678) train_loss=397.90438843 time/batch=1.31s
4348/5900 (epoch 73.695) train_loss=313.83734131 time/batch=0.73s
4349/5900 (epoch 73.712) train_loss=273.04519653 time/batch=0.60s
4350/5900 (epoch 73.729) train_loss=356.73687744 time/batch=0.67s
4351/5900 (epoch 73.746) train_loss=418.49166870 time/batch=0.78s
4352/5900 (epoch 73.763) train_loss=409.31744385 time/batch=0.78s
4353/5900 (epoch 73.780) train_loss=421.67388916 time/batch=0.75s
4354/5900 (epoch 73.797) train_loss=335.81253052 time/batch=0.65s
4355/5900 (epoch 73.814) train_loss=473.37033081 time/batch=1.21s
4356/5900 (epoch 73.831) train_loss=371.69448853 time/batch=0.72s
4357/5900 (epoch 73.847) train_loss=491.41241455 time/batch=2.55s
4358/5900 (epoch 73.864) train_loss=389.18634033 time/batch=0.81s
4359/5900 (epoch 73.881) train_loss=356.71575928 time/batch=0.72s
4360/5900 (epoch 73.898) train_loss=401.22039795 time/batch=1.31s
4361/5900 (epoch 73.915) train_loss=297.25366211 time/batch=0.64s
4362/5900 (epoch 73.932) train_loss=361.24230957 time/batch=0.66s
4363/5900 (epoch 73.949) train_loss=314.11181641 time/batch=0.63s
4364/5900 (epoch 73.966) train_loss=321.05621338 time/batch=0.62s
4365/5900 (epoch 73.983) train_loss=342.83547974 time/batch=0.71s
4366/5900 (epoch 74.000) train_loss=327.56280518 time/batch=0.68s
setting learning rate to 0.0005971
4367/5900 (epoch 74.017) train_loss=469.23440552 time/batch=0.76s
4368/5900 (epoch 74.034) train_loss=286.27734375 time/batch=1.21s
4369/5900 (epoch 74.051) train_loss=403.16223145 time/batch=0.75s
4370/5900 (epoch 74.068) train_loss=450.08288574 time/batch=1.80s
4371/5900 (epoch 74.085) train_loss=524.14086914 time/batch=0.88s
4372/5900 (epoch 74.102) train_loss=330.60192871 time/batch=0.61s
4373/5900 (epoch 74.119) train_loss=334.94384766 time/batch=1.24s
4374/5900 (epoch 74.136) train_loss=586.16955566 time/batch=2.24s
4375/5900 (epoch 74.153) train_loss=311.11004639 time/batch=0.70s
4376/5900 (epoch 74.169) train_loss=419.73434448 time/batch=0.74s
4377/5900 (epoch 74.186) train_loss=375.73623657 time/batch=1.34s
4378/5900 (epoch 74.203) train_loss=558.46197510 time/batch=0.87s
4379/5900 (epoch 74.220) train_loss=461.51528931 time/batch=2.52s
4380/5900 (epoch 74.237) train_loss=644.85314941 time/batch=1.61s
4381/5900 (epoch 74.254) train_loss=594.12823486 time/batch=0.90s
4382/5900 (epoch 74.271) train_loss=420.24322510 time/batch=0.71s
4383/5900 (epoch 74.288) train_loss=389.77758789 time/batch=1.30s
4384/5900 (epoch 74.305) train_loss=470.69454956 time/batch=0.80s
4385/5900 (epoch 74.322) train_loss=354.20660400 time/batch=0.71s
4386/5900 (epoch 74.339) train_loss=636.22497559 time/batch=0.98s
4387/5900 (epoch 74.356) train_loss=355.66082764 time/batch=0.68s
4388/5900 (epoch 74.373) train_loss=412.28073120 time/batch=2.49s
4389/5900 (epoch 74.390) train_loss=508.54418945 time/batch=0.92s
4390/5900 (epoch 74.407) train_loss=296.72515869 time/batch=0.62s
4391/5900 (epoch 74.424) train_loss=313.72821045 time/batch=0.69s
4392/5900 (epoch 74.441) train_loss=303.43353271 time/batch=0.63s
4393/5900 (epoch 74.458) train_loss=744.10253906 time/batch=2.99s
4394/5900 (epoch 74.475) train_loss=352.66659546 time/batch=0.79s
4395/5900 (epoch 74.492) train_loss=381.22418213 time/batch=1.20s
4396/5900 (epoch 74.508) train_loss=411.92526245 time/batch=0.78s
4397/5900 (epoch 74.525) train_loss=409.42510986 time/batch=1.33s
4398/5900 (epoch 74.542) train_loss=317.90368652 time/batch=0.66s
4399/5900 (epoch 74.559) train_loss=285.98193359 time/batch=0.60s
4400/5900 (epoch 74.576) train_loss=524.83483887 time/batch=1.59s
4401/5900 (epoch 74.593) train_loss=459.13632202 time/batch=1.42s
4402/5900 (epoch 74.610) train_loss=534.07537842 time/batch=1.46s
4403/5900 (epoch 74.627) train_loss=483.25073242 time/batch=0.77s
4404/5900 (epoch 74.644) train_loss=352.09561157 time/batch=0.71s
4405/5900 (epoch 74.661) train_loss=376.13610840 time/batch=0.67s
4406/5900 (epoch 74.678) train_loss=313.30026245 time/batch=0.65s
4407/5900 (epoch 74.695) train_loss=462.02471924 time/batch=0.94s
4408/5900 (epoch 74.712) train_loss=414.33996582 time/batch=0.71s
4409/5900 (epoch 74.729) train_loss=324.67407227 time/batch=0.66s
4410/5900 (epoch 74.746) train_loss=410.84228516 time/batch=0.75s
4411/5900 (epoch 74.763) train_loss=353.29229736 time/batch=0.69s
4412/5900 (epoch 74.780) train_loss=306.76397705 time/batch=0.63s
4413/5900 (epoch 74.797) train_loss=411.02273560 time/batch=0.71s
4414/5900 (epoch 74.814) train_loss=367.80560303 time/batch=0.70s
4415/5900 (epoch 74.831) train_loss=357.42901611 time/batch=0.66s
4416/5900 (epoch 74.847) train_loss=317.45941162 time/batch=0.62s
4417/5900 (epoch 74.864) train_loss=293.67193604 time/batch=0.63s
4418/5900 (epoch 74.881) train_loss=331.58361816 time/batch=0.63s
4419/5900 (epoch 74.898) train_loss=503.32168579 time/batch=2.35s
4420/5900 (epoch 74.915) train_loss=282.87738037 time/batch=0.71s
4421/5900 (epoch 74.932) train_loss=344.32275391 time/batch=0.70s
4422/5900 (epoch 74.949) train_loss=288.73300171 time/batch=0.59s
4423/5900 (epoch 74.966) train_loss=405.59649658 time/batch=0.72s
4424/5900 (epoch 74.983) train_loss=346.05010986 time/batch=0.68s
4425/5900 (epoch 75.000) train_loss=313.09332275 time/batch=0.65s
setting learning rate to 0.0005792
4426/5900 (epoch 75.017) train_loss=567.30419922 time/batch=1.47s
4427/5900 (epoch 75.034) train_loss=433.87585449 time/batch=0.76s
4428/5900 (epoch 75.051) train_loss=300.08459473 time/batch=0.62s
4429/5900 (epoch 75.068) train_loss=370.06228638 time/batch=1.31s
4430/5900 (epoch 75.085) train_loss=649.12548828 time/batch=1.62s
4431/5900 (epoch 75.102) train_loss=515.28430176 time/batch=0.86s
4432/5900 (epoch 75.119) train_loss=425.23089600 time/batch=0.72s
4433/5900 (epoch 75.136) train_loss=641.64916992 time/batch=1.00s
4434/5900 (epoch 75.153) train_loss=562.28759766 time/batch=0.84s
4435/5900 (epoch 75.169) train_loss=665.97070312 time/batch=2.22s
4436/5900 (epoch 75.186) train_loss=320.84091187 time/batch=0.69s
4437/5900 (epoch 75.203) train_loss=685.89770508 time/batch=2.97s
4438/5900 (epoch 75.220) train_loss=506.50299072 time/batch=2.50s
4439/5900 (epoch 75.237) train_loss=533.34515381 time/batch=2.62s
4440/5900 (epoch 75.254) train_loss=452.31396484 time/batch=0.88s
4441/5900 (epoch 75.271) train_loss=337.93228149 time/batch=0.89s
4442/5900 (epoch 75.288) train_loss=259.20648193 time/batch=0.58s
4443/5900 (epoch 75.305) train_loss=339.29779053 time/batch=1.21s
4444/5900 (epoch 75.322) train_loss=424.46423340 time/batch=0.78s
4445/5900 (epoch 75.339) train_loss=400.50018311 time/batch=0.73s
4446/5900 (epoch 75.356) train_loss=299.88464355 time/batch=0.61s
4447/5900 (epoch 75.373) train_loss=366.44763184 time/batch=0.68s
4448/5900 (epoch 75.390) train_loss=292.61663818 time/batch=0.61s
4449/5900 (epoch 75.407) train_loss=649.52160645 time/batch=2.48s
4450/5900 (epoch 75.424) train_loss=328.09985352 time/batch=1.33s
4451/5900 (epoch 75.441) train_loss=319.00741577 time/batch=0.68s
4452/5900 (epoch 75.458) train_loss=412.17214966 time/batch=0.72s
4453/5900 (epoch 75.475) train_loss=422.33831787 time/batch=0.74s
4454/5900 (epoch 75.492) train_loss=347.07489014 time/batch=0.68s
4455/5900 (epoch 75.508) train_loss=311.26733398 time/batch=0.67s
4456/5900 (epoch 75.525) train_loss=349.93530273 time/batch=0.66s
4457/5900 (epoch 75.542) train_loss=309.55523682 time/batch=0.60s
4458/5900 (epoch 75.559) train_loss=318.57800293 time/batch=0.61s
4459/5900 (epoch 75.576) train_loss=455.44256592 time/batch=0.75s
4460/5900 (epoch 75.593) train_loss=293.15380859 time/batch=0.65s
4461/5900 (epoch 75.610) train_loss=282.29983521 time/batch=0.58s
4462/5900 (epoch 75.627) train_loss=351.48135376 time/batch=0.64s
4463/5900 (epoch 75.644) train_loss=336.06945801 time/batch=0.65s
4464/5900 (epoch 75.661) train_loss=423.02667236 time/batch=0.76s
4465/5900 (epoch 75.678) train_loss=297.58581543 time/batch=0.66s
4466/5900 (epoch 75.695) train_loss=402.82830811 time/batch=0.72s
4467/5900 (epoch 75.712) train_loss=403.59204102 time/batch=1.31s
4468/5900 (epoch 75.729) train_loss=347.64370728 time/batch=0.72s
4469/5900 (epoch 75.746) train_loss=430.51330566 time/batch=0.75s
4470/5900 (epoch 75.763) train_loss=361.59503174 time/batch=0.67s
4471/5900 (epoch 75.780) train_loss=313.95318604 time/batch=0.71s
4472/5900 (epoch 75.797) train_loss=434.97937012 time/batch=0.77s
4473/5900 (epoch 75.814) train_loss=302.97705078 time/batch=0.63s
4474/5900 (epoch 75.831) train_loss=263.48687744 time/batch=0.60s
4475/5900 (epoch 75.847) train_loss=475.76184082 time/batch=0.81s
4476/5900 (epoch 75.864) train_loss=368.46282959 time/batch=0.67s
4477/5900 (epoch 75.881) train_loss=356.82879639 time/batch=0.69s
4478/5900 (epoch 75.898) train_loss=328.53948975 time/batch=0.64s
4479/5900 (epoch 75.915) train_loss=470.84210205 time/batch=1.37s
4480/5900 (epoch 75.932) train_loss=407.78021240 time/batch=0.82s
4481/5900 (epoch 75.949) train_loss=441.99334717 time/batch=1.37s
4482/5900 (epoch 75.966) train_loss=386.77850342 time/batch=1.35s
4483/5900 (epoch 75.983) train_loss=342.04516602 time/batch=0.72s
4484/5900 (epoch 76.000) train_loss=344.71759033 time/batch=0.75s
setting learning rate to 0.0005618
4485/5900 (epoch 76.017) train_loss=339.79479980 time/batch=0.70s
4486/5900 (epoch 76.034) train_loss=334.45129395 time/batch=0.65s
4487/5900 (epoch 76.051) train_loss=663.75170898 time/batch=2.19s
4488/5900 (epoch 76.068) train_loss=456.90173340 time/batch=0.82s
4489/5900 (epoch 76.085) train_loss=432.44567871 time/batch=2.50s
4490/5900 (epoch 76.102) train_loss=427.62997437 time/batch=0.81s
4491/5900 (epoch 76.119) train_loss=286.88830566 time/batch=0.62s
4492/5900 (epoch 76.136) train_loss=391.49945068 time/batch=1.74s
4493/5900 (epoch 76.153) train_loss=400.66717529 time/batch=0.83s
4494/5900 (epoch 76.169) train_loss=458.70370483 time/batch=0.76s
4495/5900 (epoch 76.186) train_loss=295.58105469 time/batch=0.64s
4496/5900 (epoch 76.203) train_loss=388.89974976 time/batch=1.28s
4497/5900 (epoch 76.220) train_loss=551.36816406 time/batch=0.86s
4498/5900 (epoch 76.237) train_loss=294.14947510 time/batch=0.60s
4499/5900 (epoch 76.254) train_loss=408.72686768 time/batch=0.74s
4500/5900 (epoch 76.271) train_loss=519.89727783 time/batch=1.43s
4501/5900 (epoch 76.288) train_loss=406.16921997 time/batch=0.74s
4502/5900 (epoch 76.305) train_loss=464.93167114 time/batch=0.76s
4503/5900 (epoch 76.322) train_loss=778.84161377 time/batch=2.99s
4504/5900 (epoch 76.339) train_loss=307.55432129 time/batch=0.83s
4505/5900 (epoch 76.356) train_loss=612.47528076 time/batch=0.98s
4506/5900 (epoch 76.373) train_loss=542.98144531 time/batch=0.85s
4507/5900 (epoch 76.390) train_loss=284.77716064 time/batch=0.59s
4508/5900 (epoch 76.407) train_loss=530.70300293 time/batch=0.90s
4509/5900 (epoch 76.424) train_loss=420.57733154 time/batch=0.77s
4510/5900 (epoch 76.441) train_loss=588.82763672 time/batch=2.36s
4511/5900 (epoch 76.458) train_loss=326.22229004 time/batch=0.74s
4512/5900 (epoch 76.475) train_loss=314.29022217 time/batch=0.60s
4513/5900 (epoch 76.492) train_loss=301.86346436 time/batch=1.23s
4514/5900 (epoch 76.508) train_loss=278.19534302 time/batch=0.61s
4515/5900 (epoch 76.525) train_loss=476.72119141 time/batch=2.51s
4516/5900 (epoch 76.542) train_loss=412.23266602 time/batch=0.83s
4517/5900 (epoch 76.559) train_loss=299.51354980 time/batch=0.62s
4518/5900 (epoch 76.576) train_loss=333.83258057 time/batch=0.64s
4519/5900 (epoch 76.593) train_loss=285.02691650 time/batch=0.68s
4520/5900 (epoch 76.610) train_loss=342.16168213 time/batch=0.69s
4521/5900 (epoch 76.627) train_loss=337.99133301 time/batch=1.22s
4522/5900 (epoch 76.644) train_loss=385.22726440 time/batch=0.74s
4523/5900 (epoch 76.661) train_loss=393.36825562 time/batch=0.72s
4524/5900 (epoch 76.678) train_loss=411.34936523 time/batch=0.76s
4525/5900 (epoch 76.695) train_loss=355.14871216 time/batch=0.70s
4526/5900 (epoch 76.712) train_loss=393.61944580 time/batch=1.31s
4527/5900 (epoch 76.729) train_loss=304.65969849 time/batch=0.66s
4528/5900 (epoch 76.746) train_loss=303.71777344 time/batch=0.61s
4529/5900 (epoch 76.763) train_loss=534.88024902 time/batch=1.59s
4530/5900 (epoch 76.780) train_loss=307.62161255 time/batch=0.69s
4531/5900 (epoch 76.797) train_loss=360.49737549 time/batch=0.69s
4532/5900 (epoch 76.814) train_loss=305.66949463 time/batch=0.92s
4533/5900 (epoch 76.831) train_loss=385.03430176 time/batch=1.36s
4534/5900 (epoch 76.847) train_loss=468.85034180 time/batch=0.82s
4535/5900 (epoch 76.864) train_loss=386.93371582 time/batch=1.32s
4536/5900 (epoch 76.881) train_loss=425.37255859 time/batch=0.82s
4537/5900 (epoch 76.898) train_loss=454.66848755 time/batch=0.82s
4538/5900 (epoch 76.915) train_loss=330.41680908 time/batch=0.65s
4539/5900 (epoch 76.932) train_loss=360.24279785 time/batch=0.68s
4540/5900 (epoch 76.949) train_loss=321.06036377 time/batch=0.68s
4541/5900 (epoch 76.966) train_loss=310.47619629 time/batch=0.66s
4542/5900 (epoch 76.983) train_loss=347.78283691 time/batch=0.68s
4543/5900 (epoch 77.000) train_loss=432.17587280 time/batch=0.91s
setting learning rate to 0.0005449
4544/5900 (epoch 77.017) train_loss=411.34265137 time/batch=2.52s
4545/5900 (epoch 77.034) train_loss=587.19909668 time/batch=1.69s
4546/5900 (epoch 77.051) train_loss=294.99432373 time/batch=0.64s
4547/5900 (epoch 77.068) train_loss=311.17745972 time/batch=0.63s
4548/5900 (epoch 77.085) train_loss=416.24942017 time/batch=0.72s
4549/5900 (epoch 77.102) train_loss=414.18276978 time/batch=0.71s
4550/5900 (epoch 77.119) train_loss=328.26724243 time/batch=1.21s
4551/5900 (epoch 77.136) train_loss=415.68176270 time/batch=0.79s
4552/5900 (epoch 77.153) train_loss=306.91595459 time/batch=0.63s
4553/5900 (epoch 77.169) train_loss=365.53991699 time/batch=1.27s
4554/5900 (epoch 77.186) train_loss=452.04876709 time/batch=0.81s
4555/5900 (epoch 77.203) train_loss=394.37506104 time/batch=1.32s
4556/5900 (epoch 77.220) train_loss=322.55322266 time/batch=0.67s
4557/5900 (epoch 77.237) train_loss=395.55322266 time/batch=0.72s
4558/5900 (epoch 77.254) train_loss=428.24697876 time/batch=0.76s
4559/5900 (epoch 77.271) train_loss=343.48107910 time/batch=0.67s
4560/5900 (epoch 77.288) train_loss=502.45629883 time/batch=0.78s
4561/5900 (epoch 77.305) train_loss=374.77551270 time/batch=0.69s
4562/5900 (epoch 77.322) train_loss=399.37268066 time/batch=0.73s
4563/5900 (epoch 77.339) train_loss=537.38189697 time/batch=0.82s
4564/5900 (epoch 77.356) train_loss=419.10348511 time/batch=0.77s
4565/5900 (epoch 77.373) train_loss=549.39794922 time/batch=1.49s
4566/5900 (epoch 77.390) train_loss=458.64001465 time/batch=0.85s
4567/5900 (epoch 77.407) train_loss=331.30712891 time/batch=0.70s
4568/5900 (epoch 77.424) train_loss=432.12292480 time/batch=1.33s
4569/5900 (epoch 77.441) train_loss=432.24780273 time/batch=2.51s
4570/5900 (epoch 77.458) train_loss=395.06134033 time/batch=0.79s
4571/5900 (epoch 77.475) train_loss=486.44891357 time/batch=0.83s
4572/5900 (epoch 77.492) train_loss=362.41619873 time/batch=0.69s
4573/5900 (epoch 77.508) train_loss=586.33361816 time/batch=0.97s
4574/5900 (epoch 77.525) train_loss=524.98254395 time/batch=0.85s
4575/5900 (epoch 77.542) train_loss=304.01849365 time/batch=0.63s
4576/5900 (epoch 77.559) train_loss=421.35382080 time/batch=0.75s
4577/5900 (epoch 77.576) train_loss=307.68237305 time/batch=0.62s
4578/5900 (epoch 77.593) train_loss=265.64160156 time/batch=0.61s
4579/5900 (epoch 77.610) train_loss=345.57720947 time/batch=1.22s
4580/5900 (epoch 77.627) train_loss=329.62481689 time/batch=0.69s
4581/5900 (epoch 77.644) train_loss=391.95886230 time/batch=0.72s
4582/5900 (epoch 77.661) train_loss=511.75286865 time/batch=1.44s
4583/5900 (epoch 77.678) train_loss=343.13815308 time/batch=0.71s
4584/5900 (epoch 77.695) train_loss=302.50036621 time/batch=0.62s
4585/5900 (epoch 77.712) train_loss=699.29443359 time/batch=2.16s
4586/5900 (epoch 77.729) train_loss=450.09954834 time/batch=1.86s
4587/5900 (epoch 77.746) train_loss=425.00927734 time/batch=0.90s
4588/5900 (epoch 77.763) train_loss=730.96221924 time/batch=2.94s
4589/5900 (epoch 77.780) train_loss=337.77148438 time/batch=0.80s
4590/5900 (epoch 77.797) train_loss=362.13159180 time/batch=1.16s
4591/5900 (epoch 77.814) train_loss=356.39501953 time/batch=0.72s
4592/5900 (epoch 77.831) train_loss=304.71304321 time/batch=0.66s
4593/5900 (epoch 77.847) train_loss=333.95016479 time/batch=0.70s
4594/5900 (epoch 77.864) train_loss=362.60339355 time/batch=0.68s
4595/5900 (epoch 77.881) train_loss=304.77960205 time/batch=0.60s
4596/5900 (epoch 77.898) train_loss=361.94671631 time/batch=1.31s
4597/5900 (epoch 77.915) train_loss=333.55523682 time/batch=0.72s
4598/5900 (epoch 77.932) train_loss=337.47763062 time/batch=0.69s
4599/5900 (epoch 77.949) train_loss=305.25097656 time/batch=0.60s
4600/5900 (epoch 77.966) train_loss=284.60156250 time/batch=0.60s
4601/5900 (epoch 77.983) train_loss=278.06820679 time/batch=0.60s
4602/5900 (epoch 78.000) train_loss=273.13208008 time/batch=0.60s
setting learning rate to 0.0005286
4603/5900 (epoch 78.017) train_loss=622.78295898 time/batch=2.33s
4604/5900 (epoch 78.034) train_loss=551.54895020 time/batch=0.93s
4605/5900 (epoch 78.051) train_loss=357.22988892 time/batch=0.70s
4606/5900 (epoch 78.068) train_loss=414.05477905 time/batch=0.74s
4607/5900 (epoch 78.085) train_loss=324.91809082 time/batch=1.21s
4608/5900 (epoch 78.102) train_loss=432.57159424 time/batch=1.38s
4609/5900 (epoch 78.119) train_loss=375.54486084 time/batch=2.48s
4610/5900 (epoch 78.136) train_loss=505.84811401 time/batch=2.59s
4611/5900 (epoch 78.153) train_loss=535.54217529 time/batch=1.04s
4612/5900 (epoch 78.169) train_loss=723.71704102 time/batch=2.13s
4613/5900 (epoch 78.186) train_loss=377.58056641 time/batch=0.79s
4614/5900 (epoch 78.203) train_loss=341.01971436 time/batch=0.68s
4615/5900 (epoch 78.220) train_loss=335.85400391 time/batch=0.65s
4616/5900 (epoch 78.237) train_loss=451.05642700 time/batch=0.78s
4617/5900 (epoch 78.254) train_loss=295.07489014 time/batch=0.66s
4618/5900 (epoch 78.271) train_loss=401.75888062 time/batch=0.73s
4619/5900 (epoch 78.288) train_loss=300.63714600 time/batch=0.63s
4620/5900 (epoch 78.305) train_loss=438.29470825 time/batch=0.73s
4621/5900 (epoch 78.322) train_loss=367.98510742 time/batch=1.32s
4622/5900 (epoch 78.339) train_loss=581.03930664 time/batch=1.01s
4623/5900 (epoch 78.356) train_loss=295.10241699 time/batch=0.60s
4624/5900 (epoch 78.373) train_loss=674.34838867 time/batch=0.73s
4625/5900 (epoch 78.390) train_loss=712.81512451 time/batch=1.42s
4626/5900 (epoch 78.407) train_loss=540.86309814 time/batch=0.87s
4627/5900 (epoch 78.424) train_loss=408.48617554 time/batch=0.75s
4628/5900 (epoch 78.441) train_loss=355.28839111 time/batch=0.69s
4629/5900 (epoch 78.458) train_loss=436.93780518 time/batch=0.78s
4630/5900 (epoch 78.475) train_loss=622.40130615 time/batch=2.97s
4631/5900 (epoch 78.492) train_loss=542.92236328 time/batch=1.10s
4632/5900 (epoch 78.508) train_loss=288.51489258 time/batch=0.63s
4633/5900 (epoch 78.525) train_loss=305.59124756 time/batch=0.77s
4634/5900 (epoch 78.542) train_loss=333.51657104 time/batch=0.69s
4635/5900 (epoch 78.559) train_loss=462.72256470 time/batch=1.79s
4636/5900 (epoch 78.576) train_loss=383.84820557 time/batch=0.78s
4637/5900 (epoch 78.593) train_loss=356.58599854 time/batch=0.67s
4638/5900 (epoch 78.610) train_loss=347.34265137 time/batch=0.69s
4639/5900 (epoch 78.627) train_loss=416.53741455 time/batch=0.73s
4640/5900 (epoch 78.644) train_loss=404.56423950 time/batch=0.80s
4641/5900 (epoch 78.661) train_loss=303.74005127 time/batch=0.64s
4642/5900 (epoch 78.678) train_loss=387.47088623 time/batch=0.73s
4643/5900 (epoch 78.695) train_loss=313.61578369 time/batch=0.65s
4644/5900 (epoch 78.712) train_loss=375.26510620 time/batch=1.30s
4645/5900 (epoch 78.729) train_loss=449.83898926 time/batch=0.80s
4646/5900 (epoch 78.746) train_loss=376.29693604 time/batch=1.29s
4647/5900 (epoch 78.763) train_loss=382.34173584 time/batch=0.75s
4648/5900 (epoch 78.780) train_loss=290.68560791 time/batch=0.60s
4649/5900 (epoch 78.797) train_loss=287.76916504 time/batch=0.61s
4650/5900 (epoch 78.814) train_loss=302.99841309 time/batch=0.69s
4651/5900 (epoch 78.831) train_loss=290.25167847 time/batch=0.61s
4652/5900 (epoch 78.847) train_loss=372.42205811 time/batch=0.81s
4653/5900 (epoch 78.864) train_loss=300.90188599 time/batch=0.64s
4654/5900 (epoch 78.881) train_loss=338.07943726 time/batch=0.65s
4655/5900 (epoch 78.898) train_loss=264.05999756 time/batch=0.61s
4656/5900 (epoch 78.915) train_loss=330.20748901 time/batch=0.66s
4657/5900 (epoch 78.932) train_loss=340.71612549 time/batch=1.23s
4658/5900 (epoch 78.949) train_loss=321.40930176 time/batch=0.69s
4659/5900 (epoch 78.966) train_loss=376.86572266 time/batch=0.72s
4660/5900 (epoch 78.983) train_loss=294.69018555 time/batch=0.62s
4661/5900 (epoch 79.000) train_loss=281.67987061 time/batch=0.60s
setting learning rate to 0.0005127
4662/5900 (epoch 79.017) train_loss=362.34747314 time/batch=1.31s
4663/5900 (epoch 79.034) train_loss=288.13427734 time/batch=0.64s
4664/5900 (epoch 79.051) train_loss=400.13851929 time/batch=2.51s
4665/5900 (epoch 79.068) train_loss=494.73449707 time/batch=0.91s
4666/5900 (epoch 79.085) train_loss=350.34460449 time/batch=0.70s
4667/5900 (epoch 79.102) train_loss=520.83898926 time/batch=1.41s
4668/5900 (epoch 79.119) train_loss=280.01806641 time/batch=0.63s
4669/5900 (epoch 79.136) train_loss=346.08953857 time/batch=0.69s
4670/5900 (epoch 79.153) train_loss=588.83111572 time/batch=2.21s
4671/5900 (epoch 79.169) train_loss=326.39544678 time/batch=0.76s
4672/5900 (epoch 79.186) train_loss=297.10998535 time/batch=0.64s
4673/5900 (epoch 79.203) train_loss=471.52743530 time/batch=2.48s
4674/5900 (epoch 79.220) train_loss=351.33654785 time/batch=0.79s
4675/5900 (epoch 79.237) train_loss=408.98434448 time/batch=1.77s
4676/5900 (epoch 79.254) train_loss=419.01483154 time/batch=0.79s
4677/5900 (epoch 79.271) train_loss=733.84692383 time/batch=2.98s
4678/5900 (epoch 79.288) train_loss=479.04321289 time/batch=0.94s
4679/5900 (epoch 79.305) train_loss=373.72210693 time/batch=0.69s
4680/5900 (epoch 79.322) train_loss=591.33502197 time/batch=2.35s
4681/5900 (epoch 79.339) train_loss=419.07244873 time/batch=0.80s
4682/5900 (epoch 79.356) train_loss=385.18811035 time/batch=0.73s
4683/5900 (epoch 79.373) train_loss=300.10748291 time/batch=0.59s
4684/5900 (epoch 79.390) train_loss=400.20458984 time/batch=0.73s
4685/5900 (epoch 79.407) train_loss=390.82046509 time/batch=0.73s
4686/5900 (epoch 79.424) train_loss=290.55062866 time/batch=0.70s
4687/5900 (epoch 79.441) train_loss=285.69924927 time/batch=0.67s
4688/5900 (epoch 79.458) train_loss=374.16839600 time/batch=1.30s
4689/5900 (epoch 79.475) train_loss=287.80682373 time/batch=0.70s
4690/5900 (epoch 79.492) train_loss=449.82666016 time/batch=0.79s
4691/5900 (epoch 79.508) train_loss=533.77941895 time/batch=0.85s
4692/5900 (epoch 79.525) train_loss=281.36868286 time/batch=1.24s
4693/5900 (epoch 79.542) train_loss=407.17318726 time/batch=1.37s
4694/5900 (epoch 79.559) train_loss=349.76809692 time/batch=0.73s
4695/5900 (epoch 79.576) train_loss=471.10229492 time/batch=0.81s
4696/5900 (epoch 79.593) train_loss=644.00695801 time/batch=1.60s
4697/5900 (epoch 79.610) train_loss=414.11676025 time/batch=0.79s
4698/5900 (epoch 79.627) train_loss=300.53186035 time/batch=0.63s
4699/5900 (epoch 79.644) train_loss=292.94338989 time/batch=0.65s
4700/5900 (epoch 79.661) train_loss=293.76068115 time/batch=0.59s
4701/5900 (epoch 79.678) train_loss=448.79772949 time/batch=0.82s
4702/5900 (epoch 79.695) train_loss=324.65005493 time/batch=0.67s
4703/5900 (epoch 79.712) train_loss=384.08602905 time/batch=1.30s
4704/5900 (epoch 79.729) train_loss=416.36547852 time/batch=0.76s
4705/5900 (epoch 79.746) train_loss=333.89663696 time/batch=1.21s
4706/5900 (epoch 79.763) train_loss=294.82641602 time/batch=0.66s
4707/5900 (epoch 79.780) train_loss=305.47753906 time/batch=0.62s
4708/5900 (epoch 79.797) train_loss=292.65081787 time/batch=0.63s
4709/5900 (epoch 79.814) train_loss=317.11663818 time/batch=0.64s
4710/5900 (epoch 79.831) train_loss=476.95251465 time/batch=0.83s
4711/5900 (epoch 79.847) train_loss=303.40478516 time/batch=0.61s
4712/5900 (epoch 79.864) train_loss=329.48352051 time/batch=0.69s
4713/5900 (epoch 79.881) train_loss=331.92745972 time/batch=0.68s
4714/5900 (epoch 79.898) train_loss=292.82296753 time/batch=0.61s
4715/5900 (epoch 79.915) train_loss=411.99667358 time/batch=0.77s
4716/5900 (epoch 79.932) train_loss=349.65911865 time/batch=0.67s
4717/5900 (epoch 79.949) train_loss=446.45147705 time/batch=0.83s
4718/5900 (epoch 79.966) train_loss=483.91543579 time/batch=1.25s
4719/5900 (epoch 79.983) train_loss=415.60250854 time/batch=0.75s
4720/5900 (epoch 80.000) train_loss=387.41192627 time/batch=0.94s
setting learning rate to 0.0004973
  saved to metadata/config5--20190119-211157.pkl
4721/5900 (epoch 80.017) train_loss=399.79824829 time/batch=0.82s
4722/5900 (epoch 80.034) train_loss=745.40112305 time/batch=2.94s
4723/5900 (epoch 80.051) train_loss=328.98483276 time/batch=1.32s
4724/5900 (epoch 80.068) train_loss=310.39306641 time/batch=0.70s
4725/5900 (epoch 80.085) train_loss=294.17199707 time/batch=0.58s
4726/5900 (epoch 80.102) train_loss=400.16574097 time/batch=0.73s
4727/5900 (epoch 80.119) train_loss=513.03723145 time/batch=0.85s
4728/5900 (epoch 80.136) train_loss=527.22686768 time/batch=0.82s
4729/5900 (epoch 80.153) train_loss=331.71343994 time/batch=0.71s
4730/5900 (epoch 80.169) train_loss=396.87658691 time/batch=0.70s
4731/5900 (epoch 80.186) train_loss=500.42745972 time/batch=2.51s
4732/5900 (epoch 80.203) train_loss=508.33865356 time/batch=1.54s
4733/5900 (epoch 80.220) train_loss=389.76199341 time/batch=0.78s
4734/5900 (epoch 80.237) train_loss=360.47467041 time/batch=0.69s
4735/5900 (epoch 80.254) train_loss=287.31085205 time/batch=0.60s
4736/5900 (epoch 80.271) train_loss=567.86431885 time/batch=2.20s
4737/5900 (epoch 80.288) train_loss=381.46539307 time/batch=1.37s
4738/5900 (epoch 80.305) train_loss=442.19000244 time/batch=0.81s
4739/5900 (epoch 80.322) train_loss=401.81884766 time/batch=0.75s
4740/5900 (epoch 80.339) train_loss=406.94528198 time/batch=1.34s
4741/5900 (epoch 80.356) train_loss=277.97814941 time/batch=1.24s
4742/5900 (epoch 80.373) train_loss=299.94570923 time/batch=0.66s
4743/5900 (epoch 80.390) train_loss=293.34838867 time/batch=0.61s
4744/5900 (epoch 80.407) train_loss=426.59469604 time/batch=1.80s
4745/5900 (epoch 80.424) train_loss=304.25811768 time/batch=0.73s
4746/5900 (epoch 80.441) train_loss=446.79553223 time/batch=0.78s
4747/5900 (epoch 80.458) train_loss=441.77606201 time/batch=0.82s
4748/5900 (epoch 80.475) train_loss=411.32968140 time/batch=0.74s
4749/5900 (epoch 80.492) train_loss=292.62316895 time/batch=0.63s
4750/5900 (epoch 80.508) train_loss=347.02355957 time/batch=0.68s
4751/5900 (epoch 80.525) train_loss=274.81604004 time/batch=0.59s
4752/5900 (epoch 80.542) train_loss=298.19531250 time/batch=0.62s
4753/5900 (epoch 80.559) train_loss=486.81561279 time/batch=0.80s
4754/5900 (epoch 80.576) train_loss=310.60784912 time/batch=0.70s
4755/5900 (epoch 80.593) train_loss=265.17861938 time/batch=0.60s
4756/5900 (epoch 80.610) train_loss=316.65692139 time/batch=0.63s
4757/5900 (epoch 80.627) train_loss=466.12561035 time/batch=0.83s
4758/5900 (epoch 80.644) train_loss=627.07110596 time/batch=1.60s
4759/5900 (epoch 80.661) train_loss=341.55209351 time/batch=0.70s
4760/5900 (epoch 80.678) train_loss=407.28527832 time/batch=0.73s
4761/5900 (epoch 80.695) train_loss=292.33398438 time/batch=0.62s
4762/5900 (epoch 80.712) train_loss=304.07623291 time/batch=0.61s
4763/5900 (epoch 80.729) train_loss=386.14001465 time/batch=2.46s
4764/5900 (epoch 80.746) train_loss=596.39239502 time/batch=1.61s
4765/5900 (epoch 80.763) train_loss=555.04870605 time/batch=2.39s
4766/5900 (epoch 80.780) train_loss=343.18389893 time/batch=0.75s
4767/5900 (epoch 80.797) train_loss=394.26293945 time/batch=0.70s
4768/5900 (epoch 80.814) train_loss=377.63778687 time/batch=1.30s
4769/5900 (epoch 80.831) train_loss=292.06546021 time/batch=1.27s
4770/5900 (epoch 80.847) train_loss=337.80175781 time/batch=0.77s
4771/5900 (epoch 80.864) train_loss=338.93533325 time/batch=1.29s
4772/5900 (epoch 80.881) train_loss=383.37512207 time/batch=0.77s
4773/5900 (epoch 80.898) train_loss=339.75073242 time/batch=0.67s
4774/5900 (epoch 80.915) train_loss=340.94970703 time/batch=0.69s
4775/5900 (epoch 80.932) train_loss=333.27770996 time/batch=0.71s
4776/5900 (epoch 80.949) train_loss=406.25088501 time/batch=0.74s
4777/5900 (epoch 80.966) train_loss=342.66601562 time/batch=0.68s
4778/5900 (epoch 80.983) train_loss=348.03503418 time/batch=0.68s
4779/5900 (epoch 81.000) train_loss=293.83493042 time/batch=0.62s
setting learning rate to 0.0004824
4780/5900 (epoch 81.017) train_loss=419.21054077 time/batch=1.78s
4781/5900 (epoch 81.034) train_loss=309.28485107 time/batch=0.72s
4782/5900 (epoch 81.051) train_loss=372.49737549 time/batch=0.70s
4783/5900 (epoch 81.068) train_loss=687.52221680 time/batch=2.95s
4784/5900 (epoch 81.085) train_loss=469.54168701 time/batch=0.90s
4785/5900 (epoch 81.102) train_loss=425.63610840 time/batch=1.36s
4786/5900 (epoch 81.119) train_loss=402.83001709 time/batch=0.78s
4787/5900 (epoch 81.136) train_loss=316.95104980 time/batch=1.23s
4788/5900 (epoch 81.153) train_loss=357.76208496 time/batch=1.33s
4789/5900 (epoch 81.169) train_loss=333.73742676 time/batch=0.69s
4790/5900 (epoch 81.186) train_loss=301.18731689 time/batch=0.67s
4791/5900 (epoch 81.203) train_loss=397.53286743 time/batch=0.72s
4792/5900 (epoch 81.220) train_loss=395.53930664 time/batch=0.74s
4793/5900 (epoch 81.237) train_loss=344.87277222 time/batch=0.70s
4794/5900 (epoch 81.254) train_loss=544.66809082 time/batch=2.17s
4795/5900 (epoch 81.271) train_loss=543.11236572 time/batch=1.24s
4796/5900 (epoch 81.288) train_loss=295.10260010 time/batch=0.63s
4797/5900 (epoch 81.305) train_loss=299.34307861 time/batch=0.62s
4798/5900 (epoch 81.322) train_loss=297.98193359 time/batch=0.61s
4799/5900 (epoch 81.339) train_loss=517.59692383 time/batch=0.80s
4800/5900 (epoch 81.356) train_loss=331.12948608 time/batch=0.67s
4801/5900 (epoch 81.373) train_loss=483.83148193 time/batch=1.40s
4802/5900 (epoch 81.390) train_loss=294.44427490 time/batch=0.67s
4803/5900 (epoch 81.407) train_loss=506.75512695 time/batch=0.82s
4804/5900 (epoch 81.424) train_loss=497.83169556 time/batch=0.84s
4805/5900 (epoch 81.441) train_loss=359.30187988 time/batch=0.69s
4806/5900 (epoch 81.458) train_loss=281.70867920 time/batch=0.60s
4807/5900 (epoch 81.475) train_loss=276.78454590 time/batch=0.60s
4808/5900 (epoch 81.492) train_loss=566.62109375 time/batch=0.94s
4809/5900 (epoch 81.508) train_loss=397.56863403 time/batch=0.74s
4810/5900 (epoch 81.525) train_loss=493.42553711 time/batch=2.51s
4811/5900 (epoch 81.542) train_loss=276.55395508 time/batch=1.32s
4812/5900 (epoch 81.559) train_loss=291.46463013 time/batch=0.64s
4813/5900 (epoch 81.576) train_loss=395.80392456 time/batch=0.73s
4814/5900 (epoch 81.593) train_loss=325.98443604 time/batch=0.67s
4815/5900 (epoch 81.610) train_loss=261.75329590 time/batch=0.59s
4816/5900 (epoch 81.627) train_loss=488.53558350 time/batch=2.48s
4817/5900 (epoch 81.644) train_loss=312.81951904 time/batch=0.75s
4818/5900 (epoch 81.661) train_loss=389.09960938 time/batch=0.71s
4819/5900 (epoch 81.678) train_loss=381.38311768 time/batch=0.72s
4820/5900 (epoch 81.695) train_loss=282.06460571 time/batch=0.64s
4821/5900 (epoch 81.712) train_loss=266.90005493 time/batch=0.58s
4822/5900 (epoch 81.729) train_loss=295.83377075 time/batch=0.62s
4823/5900 (epoch 81.746) train_loss=298.86383057 time/batch=0.70s
4824/5900 (epoch 81.763) train_loss=416.67358398 time/batch=0.76s
4825/5900 (epoch 81.780) train_loss=334.46200562 time/batch=0.66s
4826/5900 (epoch 81.797) train_loss=467.15524292 time/batch=0.83s
4827/5900 (epoch 81.814) train_loss=340.33529663 time/batch=1.22s
4828/5900 (epoch 81.831) train_loss=409.17150879 time/batch=0.77s
4829/5900 (epoch 81.847) train_loss=407.48083496 time/batch=0.78s
4830/5900 (epoch 81.864) train_loss=487.32144165 time/batch=0.82s
4831/5900 (epoch 81.881) train_loss=429.65502930 time/batch=1.32s
4832/5900 (epoch 81.898) train_loss=369.24508667 time/batch=0.77s
4833/5900 (epoch 81.915) train_loss=339.53179932 time/batch=0.91s
4834/5900 (epoch 81.932) train_loss=465.16033936 time/batch=1.53s
4835/5900 (epoch 81.949) train_loss=348.37591553 time/batch=0.75s
4836/5900 (epoch 81.966) train_loss=338.92868042 time/batch=0.70s
4837/5900 (epoch 81.983) train_loss=424.63989258 time/batch=0.87s
4838/5900 (epoch 82.000) train_loss=339.34457397 time/batch=0.69s
setting learning rate to 0.0004679
4839/5900 (epoch 82.017) train_loss=622.27447510 time/batch=2.20s
4840/5900 (epoch 82.034) train_loss=292.99719238 time/batch=0.69s
4841/5900 (epoch 82.051) train_loss=456.78097534 time/batch=2.48s
4842/5900 (epoch 82.068) train_loss=273.04302979 time/batch=0.69s
4843/5900 (epoch 82.085) train_loss=397.70513916 time/batch=1.78s
4844/5900 (epoch 82.102) train_loss=412.57296753 time/batch=0.81s
4845/5900 (epoch 82.119) train_loss=276.75549316 time/batch=0.60s
4846/5900 (epoch 82.136) train_loss=375.23385620 time/batch=0.70s
4847/5900 (epoch 82.153) train_loss=506.71160889 time/batch=0.80s
4848/5900 (epoch 82.169) train_loss=506.01791382 time/batch=1.43s
4849/5900 (epoch 82.186) train_loss=610.52252197 time/batch=1.04s
4850/5900 (epoch 82.203) train_loss=412.68914795 time/batch=0.75s
4851/5900 (epoch 82.220) train_loss=283.87060547 time/batch=0.69s
4852/5900 (epoch 82.237) train_loss=414.70764160 time/batch=0.72s
4853/5900 (epoch 82.254) train_loss=286.17544556 time/batch=0.61s
4854/5900 (epoch 82.271) train_loss=408.60546875 time/batch=0.75s
4855/5900 (epoch 82.288) train_loss=372.64843750 time/batch=0.75s
4856/5900 (epoch 82.305) train_loss=305.70828247 time/batch=1.21s
4857/5900 (epoch 82.322) train_loss=385.44805908 time/batch=0.73s
4858/5900 (epoch 82.339) train_loss=609.86016846 time/batch=1.59s
4859/5900 (epoch 82.356) train_loss=390.70611572 time/batch=0.79s
4860/5900 (epoch 82.373) train_loss=407.08850098 time/batch=1.35s
4861/5900 (epoch 82.390) train_loss=422.59020996 time/batch=0.80s
4862/5900 (epoch 82.407) train_loss=473.29272461 time/batch=0.81s
4863/5900 (epoch 82.424) train_loss=400.05999756 time/batch=0.71s
4864/5900 (epoch 82.441) train_loss=447.06405640 time/batch=0.82s
4865/5900 (epoch 82.458) train_loss=309.22625732 time/batch=0.70s
4866/5900 (epoch 82.475) train_loss=303.54956055 time/batch=0.65s
4867/5900 (epoch 82.492) train_loss=313.57232666 time/batch=0.64s
4868/5900 (epoch 82.508) train_loss=361.93511963 time/batch=0.69s
4869/5900 (epoch 82.525) train_loss=751.78234863 time/batch=2.94s
4870/5900 (epoch 82.542) train_loss=304.80062866 time/batch=0.76s
4871/5900 (epoch 82.559) train_loss=397.43551636 time/batch=2.51s
4872/5900 (epoch 82.576) train_loss=297.75836182 time/batch=0.74s
4873/5900 (epoch 82.593) train_loss=389.43658447 time/batch=1.02s
4874/5900 (epoch 82.610) train_loss=275.45507812 time/batch=0.62s
4875/5900 (epoch 82.627) train_loss=520.05273438 time/batch=0.84s
4876/5900 (epoch 82.644) train_loss=288.04095459 time/batch=0.65s
4877/5900 (epoch 82.661) train_loss=365.08294678 time/batch=0.71s
4878/5900 (epoch 82.678) train_loss=439.50146484 time/batch=0.80s
4879/5900 (epoch 82.695) train_loss=482.82855225 time/batch=0.89s
4880/5900 (epoch 82.712) train_loss=287.99520874 time/batch=0.68s
4881/5900 (epoch 82.729) train_loss=361.43905640 time/batch=0.77s
4882/5900 (epoch 82.746) train_loss=333.90878296 time/batch=0.65s
4883/5900 (epoch 82.763) train_loss=291.27606201 time/batch=0.61s
4884/5900 (epoch 82.780) train_loss=303.69323730 time/batch=0.65s
4885/5900 (epoch 82.797) train_loss=370.63973999 time/batch=1.30s
4886/5900 (epoch 82.814) train_loss=293.68576050 time/batch=0.65s
4887/5900 (epoch 82.831) train_loss=350.29272461 time/batch=1.32s
4888/5900 (epoch 82.847) train_loss=305.94442749 time/batch=1.26s
4889/5900 (epoch 82.864) train_loss=307.95153809 time/batch=0.69s
4890/5900 (epoch 82.881) train_loss=303.65982056 time/batch=0.66s
4891/5900 (epoch 82.898) train_loss=329.41857910 time/batch=0.67s
4892/5900 (epoch 82.915) train_loss=385.88455200 time/batch=1.31s
4893/5900 (epoch 82.932) train_loss=343.49789429 time/batch=0.70s
4894/5900 (epoch 82.949) train_loss=357.80068970 time/batch=0.69s
4895/5900 (epoch 82.966) train_loss=326.00280762 time/batch=0.69s
4896/5900 (epoch 82.983) train_loss=322.58801270 time/batch=0.71s
4897/5900 (epoch 83.000) train_loss=354.74981689 time/batch=0.71s
setting learning rate to 0.0004539
4898/5900 (epoch 83.017) train_loss=397.10626221 time/batch=0.72s
4899/5900 (epoch 83.034) train_loss=412.76351929 time/batch=0.76s
4900/5900 (epoch 83.051) train_loss=405.68572998 time/batch=0.73s
4901/5900 (epoch 83.068) train_loss=489.97286987 time/batch=1.42s
4902/5900 (epoch 83.085) train_loss=319.99652100 time/batch=0.73s
4903/5900 (epoch 83.102) train_loss=326.66217041 time/batch=0.67s
4904/5900 (epoch 83.119) train_loss=453.29138184 time/batch=2.46s
4905/5900 (epoch 83.136) train_loss=289.75329590 time/batch=0.75s
4906/5900 (epoch 83.153) train_loss=434.73635864 time/batch=0.77s
4907/5900 (epoch 83.169) train_loss=305.76068115 time/batch=1.21s
4908/5900 (epoch 83.186) train_loss=610.06091309 time/batch=1.63s
4909/5900 (epoch 83.203) train_loss=663.88110352 time/batch=2.18s
4910/5900 (epoch 83.220) train_loss=312.78015137 time/batch=0.72s
4911/5900 (epoch 83.237) train_loss=374.54797363 time/batch=1.29s
4912/5900 (epoch 83.254) train_loss=383.48220825 time/batch=1.83s
4913/5900 (epoch 83.271) train_loss=752.31445312 time/batch=3.03s
4914/5900 (epoch 83.288) train_loss=329.98178101 time/batch=0.81s
4915/5900 (epoch 83.305) train_loss=318.99179077 time/batch=0.66s
4916/5900 (epoch 83.322) train_loss=251.32295227 time/batch=0.58s
4917/5900 (epoch 83.339) train_loss=539.54406738 time/batch=2.45s
4918/5900 (epoch 83.356) train_loss=494.48718262 time/batch=0.96s
4919/5900 (epoch 83.373) train_loss=433.80938721 time/batch=0.80s
4920/5900 (epoch 83.390) train_loss=314.53323364 time/batch=0.64s
4921/5900 (epoch 83.407) train_loss=413.37698364 time/batch=1.31s
4922/5900 (epoch 83.424) train_loss=464.36495972 time/batch=1.03s
4923/5900 (epoch 83.441) train_loss=404.53445435 time/batch=0.78s
4924/5900 (epoch 83.458) train_loss=391.35168457 time/batch=0.93s
4925/5900 (epoch 83.475) train_loss=400.26269531 time/batch=0.76s
4926/5900 (epoch 83.492) train_loss=334.79162598 time/batch=0.66s
4927/5900 (epoch 83.508) train_loss=295.49407959 time/batch=0.60s
4928/5900 (epoch 83.525) train_loss=284.24353027 time/batch=0.63s
4929/5900 (epoch 83.542) train_loss=303.09790039 time/batch=1.19s
4930/5900 (epoch 83.559) train_loss=281.14056396 time/batch=0.68s
4931/5900 (epoch 83.576) train_loss=334.33178711 time/batch=0.69s
4932/5900 (epoch 83.593) train_loss=434.51843262 time/batch=0.78s
4933/5900 (epoch 83.610) train_loss=394.97692871 time/batch=0.79s
4934/5900 (epoch 83.627) train_loss=297.95513916 time/batch=0.68s
4935/5900 (epoch 83.644) train_loss=380.21533203 time/batch=0.71s
4936/5900 (epoch 83.661) train_loss=343.63922119 time/batch=0.68s
4937/5900 (epoch 83.678) train_loss=332.48571777 time/batch=1.31s
4938/5900 (epoch 83.695) train_loss=282.67269897 time/batch=0.64s
4939/5900 (epoch 83.712) train_loss=334.63360596 time/batch=0.68s
4940/5900 (epoch 83.729) train_loss=516.33880615 time/batch=0.81s
4941/5900 (epoch 83.746) train_loss=387.11322021 time/batch=0.75s
4942/5900 (epoch 83.763) train_loss=340.09643555 time/batch=0.67s
4943/5900 (epoch 83.780) train_loss=301.84188843 time/batch=0.61s
4944/5900 (epoch 83.797) train_loss=254.10624695 time/batch=0.58s
4945/5900 (epoch 83.814) train_loss=349.29772949 time/batch=1.29s
4946/5900 (epoch 83.831) train_loss=473.51684570 time/batch=0.84s
4947/5900 (epoch 83.847) train_loss=282.27844238 time/batch=0.62s
4948/5900 (epoch 83.864) train_loss=266.42523193 time/batch=0.61s
4949/5900 (epoch 83.881) train_loss=365.49591064 time/batch=0.70s
4950/5900 (epoch 83.898) train_loss=372.87780762 time/batch=0.68s
4951/5900 (epoch 83.915) train_loss=342.69250488 time/batch=0.69s
4952/5900 (epoch 83.932) train_loss=325.06518555 time/batch=0.81s
4953/5900 (epoch 83.949) train_loss=305.06994629 time/batch=0.70s
4954/5900 (epoch 83.966) train_loss=284.30670166 time/batch=0.62s
4955/5900 (epoch 83.983) train_loss=327.21386719 time/batch=0.69s
4956/5900 (epoch 84.000) train_loss=437.47198486 time/batch=0.81s
setting learning rate to 0.0004403
4957/5900 (epoch 84.017) train_loss=272.53118896 time/batch=0.58s
4958/5900 (epoch 84.034) train_loss=467.89141846 time/batch=0.81s
4959/5900 (epoch 84.051) train_loss=593.35260010 time/batch=1.00s
4960/5900 (epoch 84.068) train_loss=559.90930176 time/batch=1.57s
4961/5900 (epoch 84.085) train_loss=437.35327148 time/batch=0.85s
4962/5900 (epoch 84.102) train_loss=382.41918945 time/batch=0.73s
4963/5900 (epoch 84.119) train_loss=348.66098022 time/batch=1.18s
4964/5900 (epoch 84.136) train_loss=392.27014160 time/batch=0.74s
4965/5900 (epoch 84.153) train_loss=754.78344727 time/batch=2.95s
4966/5900 (epoch 84.169) train_loss=255.97927856 time/batch=0.72s
4967/5900 (epoch 84.186) train_loss=513.57849121 time/batch=0.82s
4968/5900 (epoch 84.203) train_loss=514.20593262 time/batch=0.85s
4969/5900 (epoch 84.220) train_loss=296.22058105 time/batch=0.63s
4970/5900 (epoch 84.237) train_loss=369.13006592 time/batch=0.72s
4971/5900 (epoch 84.254) train_loss=291.03048706 time/batch=0.64s
4972/5900 (epoch 84.271) train_loss=340.58312988 time/batch=1.27s
4973/5900 (epoch 84.288) train_loss=486.75631714 time/batch=1.43s
4974/5900 (epoch 84.305) train_loss=262.52151489 time/batch=0.63s
4975/5900 (epoch 84.322) train_loss=301.21154785 time/batch=0.65s
4976/5900 (epoch 84.339) train_loss=369.92962646 time/batch=1.31s
4977/5900 (epoch 84.356) train_loss=396.80404663 time/batch=1.83s
4978/5900 (epoch 84.373) train_loss=515.32885742 time/batch=2.53s
4979/5900 (epoch 84.390) train_loss=648.68762207 time/batch=2.27s
4980/5900 (epoch 84.407) train_loss=276.83486938 time/batch=1.28s
4981/5900 (epoch 84.424) train_loss=321.78253174 time/batch=0.68s
4982/5900 (epoch 84.441) train_loss=327.81375122 time/batch=0.66s
4983/5900 (epoch 84.458) train_loss=333.08734131 time/batch=0.68s
4984/5900 (epoch 84.475) train_loss=276.58850098 time/batch=0.62s
4985/5900 (epoch 84.492) train_loss=288.80352783 time/batch=0.62s
4986/5900 (epoch 84.508) train_loss=336.90850830 time/batch=0.69s
4987/5900 (epoch 84.525) train_loss=425.16610718 time/batch=0.76s
4988/5900 (epoch 84.542) train_loss=328.25735474 time/batch=0.67s
4989/5900 (epoch 84.559) train_loss=291.09469604 time/batch=0.64s
4990/5900 (epoch 84.576) train_loss=404.18597412 time/batch=0.76s
4991/5900 (epoch 84.593) train_loss=367.13403320 time/batch=1.30s
4992/5900 (epoch 84.610) train_loss=270.31927490 time/batch=0.64s
4993/5900 (epoch 84.627) train_loss=341.79052734 time/batch=1.18s
4994/5900 (epoch 84.644) train_loss=395.52359009 time/batch=0.78s
4995/5900 (epoch 84.661) train_loss=294.06964111 time/batch=0.62s
4996/5900 (epoch 84.678) train_loss=371.13824463 time/batch=0.74s
4997/5900 (epoch 84.695) train_loss=273.65927124 time/batch=0.59s
4998/5900 (epoch 84.712) train_loss=329.20022583 time/batch=0.68s
4999/5900 (epoch 84.729) train_loss=337.91003418 time/batch=0.66s
Validating
    loss:	326.753774

5000/5900 (epoch 84.746) train_loss=393.58782959 time/batch=1.61s
5001/5900 (epoch 84.763) train_loss=283.81579590 time/batch=0.65s
5002/5900 (epoch 84.780) train_loss=376.82711792 time/batch=0.70s
5003/5900 (epoch 84.797) train_loss=318.17822266 time/batch=0.69s
5004/5900 (epoch 84.814) train_loss=299.22003174 time/batch=0.63s
5005/5900 (epoch 84.831) train_loss=401.95953369 time/batch=1.35s
5006/5900 (epoch 84.847) train_loss=452.14465332 time/batch=0.81s
5007/5900 (epoch 84.864) train_loss=353.87716675 time/batch=0.72s
5008/5900 (epoch 84.881) train_loss=403.29858398 time/batch=0.74s
5009/5900 (epoch 84.898) train_loss=315.93072510 time/batch=0.64s
5010/5900 (epoch 84.915) train_loss=407.64825439 time/batch=0.82s
5011/5900 (epoch 84.932) train_loss=353.25799561 time/batch=1.24s
5012/5900 (epoch 84.949) train_loss=339.77545166 time/batch=0.75s
5013/5900 (epoch 84.966) train_loss=355.96231079 time/batch=0.74s
5014/5900 (epoch 84.983) train_loss=391.85574341 time/batch=0.72s
5015/5900 (epoch 85.000) train_loss=319.99661255 time/batch=0.69s
setting learning rate to 0.0004271
5016/5900 (epoch 85.017) train_loss=492.77893066 time/batch=2.33s
5017/5900 (epoch 85.034) train_loss=479.48818970 time/batch=0.92s
5018/5900 (epoch 85.051) train_loss=413.04217529 time/batch=0.75s
5019/5900 (epoch 85.068) train_loss=411.64828491 time/batch=2.50s
5020/5900 (epoch 85.085) train_loss=283.43170166 time/batch=0.75s
5021/5900 (epoch 85.102) train_loss=366.52566528 time/batch=0.70s
5022/5900 (epoch 85.119) train_loss=555.70800781 time/batch=2.19s
5023/5900 (epoch 85.136) train_loss=340.37921143 time/batch=0.74s
5024/5900 (epoch 85.153) train_loss=390.99685669 time/batch=0.76s
5025/5900 (epoch 85.169) train_loss=362.17123413 time/batch=0.71s
5026/5900 (epoch 85.186) train_loss=453.26177979 time/batch=2.47s
5027/5900 (epoch 85.203) train_loss=365.85595703 time/batch=1.40s
5028/5900 (epoch 85.220) train_loss=337.19134521 time/batch=0.71s
5029/5900 (epoch 85.237) train_loss=258.30078125 time/batch=0.60s
5030/5900 (epoch 85.254) train_loss=713.12500000 time/batch=2.92s
5031/5900 (epoch 85.271) train_loss=340.15850830 time/batch=0.83s
5032/5900 (epoch 85.288) train_loss=281.79309082 time/batch=0.61s
5033/5900 (epoch 85.305) train_loss=391.41696167 time/batch=0.71s
5034/5900 (epoch 85.322) train_loss=368.54791260 time/batch=0.72s
5035/5900 (epoch 85.339) train_loss=357.65774536 time/batch=1.21s
5036/5900 (epoch 85.356) train_loss=250.41036987 time/batch=0.62s
5037/5900 (epoch 85.373) train_loss=407.59887695 time/batch=0.72s
5038/5900 (epoch 85.390) train_loss=271.22827148 time/batch=0.60s
5039/5900 (epoch 85.407) train_loss=255.96040344 time/batch=1.23s
5040/5900 (epoch 85.424) train_loss=587.90783691 time/batch=1.60s
5041/5900 (epoch 85.441) train_loss=293.96304321 time/batch=0.74s
5042/5900 (epoch 85.458) train_loss=378.51214600 time/batch=0.72s
5043/5900 (epoch 85.475) train_loss=313.73657227 time/batch=0.66s
5044/5900 (epoch 85.492) train_loss=293.82873535 time/batch=0.66s
5045/5900 (epoch 85.508) train_loss=511.74395752 time/batch=0.82s
5046/5900 (epoch 85.525) train_loss=570.87194824 time/batch=1.52s
5047/5900 (epoch 85.542) train_loss=420.43695068 time/batch=0.82s
5048/5900 (epoch 85.559) train_loss=486.04333496 time/batch=1.38s
5049/5900 (epoch 85.576) train_loss=305.44967651 time/batch=1.23s
5050/5900 (epoch 85.593) train_loss=386.26156616 time/batch=0.82s
5051/5900 (epoch 85.610) train_loss=443.43402100 time/batch=0.99s
5052/5900 (epoch 85.627) train_loss=428.68481445 time/batch=0.77s
5053/5900 (epoch 85.644) train_loss=290.59103394 time/batch=0.61s
5054/5900 (epoch 85.661) train_loss=428.08959961 time/batch=0.76s
5055/5900 (epoch 85.678) train_loss=326.00634766 time/batch=0.84s
5056/5900 (epoch 85.695) train_loss=480.19073486 time/batch=0.84s
5057/5900 (epoch 85.712) train_loss=316.15612793 time/batch=0.70s
5058/5900 (epoch 85.729) train_loss=286.24322510 time/batch=0.64s
5059/5900 (epoch 85.746) train_loss=304.24230957 time/batch=0.62s
5060/5900 (epoch 85.763) train_loss=339.84020996 time/batch=1.31s
5061/5900 (epoch 85.780) train_loss=335.58737183 time/batch=0.70s
5062/5900 (epoch 85.797) train_loss=371.16717529 time/batch=1.32s
5063/5900 (epoch 85.814) train_loss=364.48837280 time/batch=0.72s
5064/5900 (epoch 85.831) train_loss=280.48126221 time/batch=0.62s
5065/5900 (epoch 85.847) train_loss=387.30865479 time/batch=1.35s
5066/5900 (epoch 85.864) train_loss=447.75415039 time/batch=0.87s
5067/5900 (epoch 85.881) train_loss=292.22857666 time/batch=0.62s
5068/5900 (epoch 85.898) train_loss=327.48791504 time/batch=0.69s
5069/5900 (epoch 85.915) train_loss=297.43817139 time/batch=0.63s
5070/5900 (epoch 85.932) train_loss=268.74053955 time/batch=0.62s
5071/5900 (epoch 85.949) train_loss=318.61990356 time/batch=0.68s
5072/5900 (epoch 85.966) train_loss=322.95126343 time/batch=0.82s
5073/5900 (epoch 85.983) train_loss=318.93676758 time/batch=0.69s
5074/5900 (epoch 86.000) train_loss=364.45401001 time/batch=0.71s
setting learning rate to 0.0004143
5075/5900 (epoch 86.017) train_loss=416.55633545 time/batch=2.50s
5076/5900 (epoch 86.034) train_loss=428.08621216 time/batch=0.91s
5077/5900 (epoch 86.051) train_loss=577.31628418 time/batch=1.60s
5078/5900 (epoch 86.068) train_loss=348.48016357 time/batch=0.74s
5079/5900 (epoch 86.085) train_loss=439.07580566 time/batch=0.81s
5080/5900 (epoch 86.102) train_loss=526.70690918 time/batch=1.52s
5081/5900 (epoch 86.119) train_loss=340.97866821 time/batch=0.71s
5082/5900 (epoch 86.136) train_loss=471.33389282 time/batch=0.80s
5083/5900 (epoch 86.153) train_loss=500.70581055 time/batch=0.81s
5084/5900 (epoch 86.169) train_loss=339.09082031 time/batch=0.70s
5085/5900 (epoch 86.186) train_loss=396.25427246 time/batch=0.75s
5086/5900 (epoch 86.203) train_loss=393.11309814 time/batch=0.70s
5087/5900 (epoch 86.220) train_loss=280.28228760 time/batch=0.61s
5088/5900 (epoch 86.237) train_loss=565.54736328 time/batch=2.17s
5089/5900 (epoch 86.254) train_loss=709.93811035 time/batch=3.03s
5090/5900 (epoch 86.271) train_loss=304.37652588 time/batch=0.79s
5091/5900 (epoch 86.288) train_loss=554.02740479 time/batch=2.35s
5092/5900 (epoch 86.305) train_loss=411.11306763 time/batch=1.42s
5093/5900 (epoch 86.322) train_loss=486.53182983 time/batch=0.85s
5094/5900 (epoch 86.339) train_loss=251.83702087 time/batch=0.62s
5095/5900 (epoch 86.356) train_loss=277.89254761 time/batch=0.60s
5096/5900 (epoch 86.373) train_loss=485.80715942 time/batch=1.44s
5097/5900 (epoch 86.390) train_loss=412.03222656 time/batch=0.77s
5098/5900 (epoch 86.407) train_loss=356.95108032 time/batch=2.47s
5099/5900 (epoch 86.424) train_loss=443.92749023 time/batch=0.98s
5100/5900 (epoch 86.441) train_loss=292.05548096 time/batch=0.72s
5101/5900 (epoch 86.458) train_loss=353.94903564 time/batch=0.72s
5102/5900 (epoch 86.475) train_loss=386.06369019 time/batch=0.75s
5103/5900 (epoch 86.492) train_loss=320.94137573 time/batch=0.65s
5104/5900 (epoch 86.508) train_loss=401.66070557 time/batch=0.94s
5105/5900 (epoch 86.525) train_loss=382.68572998 time/batch=0.75s
5106/5900 (epoch 86.542) train_loss=279.37384033 time/batch=0.59s
5107/5900 (epoch 86.559) train_loss=303.03515625 time/batch=0.70s
5108/5900 (epoch 86.576) train_loss=262.54260254 time/batch=0.59s
5109/5900 (epoch 86.593) train_loss=397.79257202 time/batch=1.19s
5110/5900 (epoch 86.610) train_loss=286.23895264 time/batch=0.68s
5111/5900 (epoch 86.627) train_loss=247.92980957 time/batch=0.58s
5112/5900 (epoch 86.644) train_loss=364.85244751 time/batch=1.30s
5113/5900 (epoch 86.661) train_loss=292.56307983 time/batch=0.66s
5114/5900 (epoch 86.678) train_loss=302.40386963 time/batch=1.19s
5115/5900 (epoch 86.695) train_loss=320.45751953 time/batch=0.72s
5116/5900 (epoch 86.712) train_loss=340.51831055 time/batch=0.72s
5117/5900 (epoch 86.729) train_loss=385.61126709 time/batch=1.12s
5118/5900 (epoch 86.746) train_loss=344.68991089 time/batch=1.33s
5119/5900 (epoch 86.763) train_loss=285.06317139 time/batch=0.68s
5120/5900 (epoch 86.780) train_loss=346.06744385 time/batch=1.28s
5121/5900 (epoch 86.797) train_loss=303.20657349 time/batch=0.65s
5122/5900 (epoch 86.814) train_loss=263.98309326 time/batch=0.61s
5123/5900 (epoch 86.831) train_loss=356.49737549 time/batch=0.72s
5124/5900 (epoch 86.847) train_loss=296.29010010 time/batch=0.63s
5125/5900 (epoch 86.864) train_loss=288.50531006 time/batch=0.62s
5126/5900 (epoch 86.881) train_loss=326.72253418 time/batch=0.67s
5127/5900 (epoch 86.898) train_loss=337.17810059 time/batch=1.81s
5128/5900 (epoch 86.915) train_loss=307.96322632 time/batch=0.71s
5129/5900 (epoch 86.932) train_loss=368.37158203 time/batch=0.71s
5130/5900 (epoch 86.949) train_loss=350.16677856 time/batch=0.73s
5131/5900 (epoch 86.966) train_loss=309.43103027 time/batch=0.69s
5132/5900 (epoch 86.983) train_loss=392.85189819 time/batch=0.75s
5133/5900 (epoch 87.000) train_loss=343.43420410 time/batch=0.72s
setting learning rate to 0.0004018
5134/5900 (epoch 87.017) train_loss=427.97961426 time/batch=0.79s
5135/5900 (epoch 87.034) train_loss=426.55499268 time/batch=0.80s
5136/5900 (epoch 87.051) train_loss=389.96844482 time/batch=1.82s
5137/5900 (epoch 87.068) train_loss=606.23187256 time/batch=2.27s
5138/5900 (epoch 87.085) train_loss=425.69647217 time/batch=0.83s
5139/5900 (epoch 87.102) train_loss=493.47521973 time/batch=0.94s
5140/5900 (epoch 87.119) train_loss=439.70883179 time/batch=2.49s
5141/5900 (epoch 87.136) train_loss=359.95196533 time/batch=1.40s
5142/5900 (epoch 87.153) train_loss=301.68444824 time/batch=0.66s
5143/5900 (epoch 87.169) train_loss=396.09133911 time/batch=0.75s
5144/5900 (epoch 87.186) train_loss=261.89770508 time/batch=1.21s
5145/5900 (epoch 87.203) train_loss=340.03564453 time/batch=1.35s
5146/5900 (epoch 87.220) train_loss=325.17285156 time/batch=0.70s
5147/5900 (epoch 87.237) train_loss=282.44384766 time/batch=0.64s
5148/5900 (epoch 87.254) train_loss=330.62722778 time/batch=0.67s
5149/5900 (epoch 87.271) train_loss=373.86816406 time/batch=2.49s
5150/5900 (epoch 87.288) train_loss=270.98910522 time/batch=0.71s
5151/5900 (epoch 87.305) train_loss=259.41436768 time/batch=0.58s
5152/5900 (epoch 87.322) train_loss=305.58541870 time/batch=0.64s
5153/5900 (epoch 87.339) train_loss=540.52062988 time/batch=0.98s
5154/5900 (epoch 87.356) train_loss=393.20556641 time/batch=0.74s
5155/5900 (epoch 87.373) train_loss=371.35290527 time/batch=0.70s
5156/5900 (epoch 87.390) train_loss=282.42181396 time/batch=0.70s
5157/5900 (epoch 87.407) train_loss=498.99340820 time/batch=0.84s
5158/5900 (epoch 87.424) train_loss=257.35144043 time/batch=0.59s
5159/5900 (epoch 87.441) train_loss=416.35684204 time/batch=0.74s
5160/5900 (epoch 87.458) train_loss=362.37713623 time/batch=0.74s
5161/5900 (epoch 87.475) train_loss=404.13937378 time/batch=1.34s
5162/5900 (epoch 87.492) train_loss=308.91424561 time/batch=1.26s
5163/5900 (epoch 87.508) train_loss=368.86303711 time/batch=0.77s
5164/5900 (epoch 87.525) train_loss=494.17926025 time/batch=0.85s
5165/5900 (epoch 87.542) train_loss=475.25195312 time/batch=0.83s
5166/5900 (epoch 87.559) train_loss=303.92559814 time/batch=0.67s
5167/5900 (epoch 87.576) train_loss=467.00244141 time/batch=2.33s
5168/5900 (epoch 87.593) train_loss=286.84951782 time/batch=0.72s
5169/5900 (epoch 87.610) train_loss=323.83374023 time/batch=0.69s
5170/5900 (epoch 87.627) train_loss=373.65188599 time/batch=0.71s
5171/5900 (epoch 87.644) train_loss=408.18893433 time/batch=0.78s
5172/5900 (epoch 87.661) train_loss=285.38546753 time/batch=0.62s
5173/5900 (epoch 87.678) train_loss=286.71353149 time/batch=0.62s
5174/5900 (epoch 87.695) train_loss=600.85070801 time/batch=1.55s
5175/5900 (epoch 87.712) train_loss=335.38250732 time/batch=0.74s
5176/5900 (epoch 87.729) train_loss=372.41464233 time/batch=0.70s
5177/5900 (epoch 87.746) train_loss=563.14575195 time/batch=2.98s
5178/5900 (epoch 87.763) train_loss=393.23535156 time/batch=0.84s
5179/5900 (epoch 87.780) train_loss=282.96316528 time/batch=0.63s
5180/5900 (epoch 87.797) train_loss=431.94692993 time/batch=1.43s
5181/5900 (epoch 87.814) train_loss=338.07977295 time/batch=0.71s
5182/5900 (epoch 87.831) train_loss=352.37066650 time/batch=1.32s
5183/5900 (epoch 87.847) train_loss=304.88909912 time/batch=0.71s
5184/5900 (epoch 87.864) train_loss=287.24246216 time/batch=0.66s
5185/5900 (epoch 87.881) train_loss=316.65246582 time/batch=0.68s
5186/5900 (epoch 87.898) train_loss=424.26977539 time/batch=1.70s
5187/5900 (epoch 87.915) train_loss=293.50885010 time/batch=0.71s
5188/5900 (epoch 87.932) train_loss=318.09613037 time/batch=0.69s
5189/5900 (epoch 87.949) train_loss=279.25793457 time/batch=0.60s
5190/5900 (epoch 87.966) train_loss=296.63247681 time/batch=0.66s
5191/5900 (epoch 87.983) train_loss=349.79479980 time/batch=0.79s
5192/5900 (epoch 88.000) train_loss=272.62094116 time/batch=0.59s
setting learning rate to 0.0003898
5193/5900 (epoch 88.017) train_loss=324.26089478 time/batch=0.68s
5194/5900 (epoch 88.034) train_loss=487.88854980 time/batch=0.82s
5195/5900 (epoch 88.051) train_loss=480.68023682 time/batch=1.44s
5196/5900 (epoch 88.068) train_loss=462.52297974 time/batch=2.53s
5197/5900 (epoch 88.085) train_loss=514.24920654 time/batch=0.96s
5198/5900 (epoch 88.102) train_loss=347.27136230 time/batch=1.31s
5199/5900 (epoch 88.119) train_loss=282.82803345 time/batch=0.65s
5200/5900 (epoch 88.136) train_loss=382.51959229 time/batch=0.75s
5201/5900 (epoch 88.153) train_loss=322.73611450 time/batch=0.66s
5202/5900 (epoch 88.169) train_loss=328.14779663 time/batch=0.68s
5203/5900 (epoch 88.186) train_loss=468.27203369 time/batch=0.87s
5204/5900 (epoch 88.203) train_loss=386.31347656 time/batch=0.73s
5205/5900 (epoch 88.220) train_loss=304.44763184 time/batch=0.66s
5206/5900 (epoch 88.237) train_loss=306.65722656 time/batch=0.67s
5207/5900 (epoch 88.254) train_loss=373.59295654 time/batch=0.72s
5208/5900 (epoch 88.271) train_loss=266.74429321 time/batch=0.63s
5209/5900 (epoch 88.288) train_loss=513.06085205 time/batch=1.00s
5210/5900 (epoch 88.305) train_loss=478.34729004 time/batch=0.95s
5211/5900 (epoch 88.322) train_loss=423.90194702 time/batch=0.81s
5212/5900 (epoch 88.339) train_loss=295.33807373 time/batch=1.12s
5213/5900 (epoch 88.356) train_loss=262.98858643 time/batch=1.24s
5214/5900 (epoch 88.373) train_loss=385.60418701 time/batch=0.74s
5215/5900 (epoch 88.390) train_loss=401.72552490 time/batch=1.35s
5216/5900 (epoch 88.407) train_loss=427.76727295 time/batch=0.81s
5217/5900 (epoch 88.424) train_loss=273.58349609 time/batch=0.64s
5218/5900 (epoch 88.441) train_loss=297.36889648 time/batch=1.21s
5219/5900 (epoch 88.458) train_loss=406.70446777 time/batch=2.50s
5220/5900 (epoch 88.475) train_loss=323.56973267 time/batch=0.77s
5221/5900 (epoch 88.492) train_loss=731.94970703 time/batch=2.97s
5222/5900 (epoch 88.508) train_loss=456.93334961 time/batch=0.91s
5223/5900 (epoch 88.525) train_loss=634.84924316 time/batch=2.19s
5224/5900 (epoch 88.542) train_loss=332.14080811 time/batch=0.77s
5225/5900 (epoch 88.559) train_loss=396.70156860 time/batch=0.77s
5226/5900 (epoch 88.576) train_loss=430.69128418 time/batch=0.85s
5227/5900 (epoch 88.593) train_loss=279.63150024 time/batch=0.68s
5228/5900 (epoch 88.610) train_loss=289.56796265 time/batch=0.64s
5229/5900 (epoch 88.627) train_loss=269.46679688 time/batch=0.59s
5230/5900 (epoch 88.644) train_loss=281.68008423 time/batch=0.61s
5231/5900 (epoch 88.661) train_loss=278.78152466 time/batch=0.62s
5232/5900 (epoch 88.678) train_loss=393.41598511 time/batch=0.76s
5233/5900 (epoch 88.695) train_loss=418.17303467 time/batch=1.20s
5234/5900 (epoch 88.712) train_loss=353.59240723 time/batch=1.32s
5235/5900 (epoch 88.729) train_loss=293.59075928 time/batch=0.66s
5236/5900 (epoch 88.746) train_loss=321.80233765 time/batch=0.69s
5237/5900 (epoch 88.763) train_loss=300.52020264 time/batch=0.66s
5238/5900 (epoch 88.780) train_loss=264.28454590 time/batch=0.57s
5239/5900 (epoch 88.797) train_loss=289.48944092 time/batch=0.63s
5240/5900 (epoch 88.814) train_loss=373.82595825 time/batch=0.73s
5241/5900 (epoch 88.831) train_loss=461.50360107 time/batch=1.50s
5242/5900 (epoch 88.847) train_loss=285.95391846 time/batch=0.67s
5243/5900 (epoch 88.864) train_loss=303.09197998 time/batch=0.66s
5244/5900 (epoch 88.881) train_loss=309.41241455 time/batch=0.94s
5245/5900 (epoch 88.898) train_loss=359.45581055 time/batch=0.75s
5246/5900 (epoch 88.915) train_loss=282.21234131 time/batch=0.60s
5247/5900 (epoch 88.932) train_loss=383.73233032 time/batch=0.72s
5248/5900 (epoch 88.949) train_loss=363.93725586 time/batch=1.32s
5249/5900 (epoch 88.966) train_loss=331.62860107 time/batch=0.72s
5250/5900 (epoch 88.983) train_loss=269.47271729 time/batch=0.69s
5251/5900 (epoch 89.000) train_loss=323.81561279 time/batch=0.71s
setting learning rate to 0.0003781
5252/5900 (epoch 89.017) train_loss=330.89312744 time/batch=0.70s
5253/5900 (epoch 89.034) train_loss=356.66058350 time/batch=0.73s
5254/5900 (epoch 89.051) train_loss=490.07205200 time/batch=0.83s
5255/5900 (epoch 89.068) train_loss=401.16082764 time/batch=1.33s
5256/5900 (epoch 89.085) train_loss=302.62005615 time/batch=1.26s
5257/5900 (epoch 89.102) train_loss=682.19659424 time/batch=2.97s
5258/5900 (epoch 89.119) train_loss=422.33166504 time/batch=0.89s
5259/5900 (epoch 89.136) train_loss=255.07788086 time/batch=0.58s
5260/5900 (epoch 89.153) train_loss=468.49560547 time/batch=2.49s
5261/5900 (epoch 89.169) train_loss=249.24481201 time/batch=0.70s
5262/5900 (epoch 89.186) train_loss=338.27310181 time/batch=1.28s
5263/5900 (epoch 89.203) train_loss=470.65438843 time/batch=0.89s
5264/5900 (epoch 89.220) train_loss=313.64660645 time/batch=0.68s
5265/5900 (epoch 89.237) train_loss=373.87158203 time/batch=0.74s
5266/5900 (epoch 89.254) train_loss=530.47662354 time/batch=1.55s
5267/5900 (epoch 89.271) train_loss=332.81198120 time/batch=0.75s
5268/5900 (epoch 89.288) train_loss=533.05908203 time/batch=1.50s
5269/5900 (epoch 89.305) train_loss=392.81698608 time/batch=0.80s
5270/5900 (epoch 89.322) train_loss=288.51367188 time/batch=0.70s
5271/5900 (epoch 89.339) train_loss=276.35705566 time/batch=0.96s
5272/5900 (epoch 89.356) train_loss=450.06036377 time/batch=1.43s
5273/5900 (epoch 89.373) train_loss=554.27856445 time/batch=2.23s
5274/5900 (epoch 89.390) train_loss=498.24066162 time/batch=2.43s
5275/5900 (epoch 89.407) train_loss=313.05004883 time/batch=0.77s
5276/5900 (epoch 89.424) train_loss=438.03521729 time/batch=1.80s
5277/5900 (epoch 89.441) train_loss=249.26307678 time/batch=0.73s
5278/5900 (epoch 89.458) train_loss=308.16455078 time/batch=0.65s
5279/5900 (epoch 89.475) train_loss=270.80657959 time/batch=0.66s
5280/5900 (epoch 89.492) train_loss=274.32620239 time/batch=0.62s
5281/5900 (epoch 89.508) train_loss=375.02972412 time/batch=2.46s
5282/5900 (epoch 89.525) train_loss=285.35174561 time/batch=0.72s
5283/5900 (epoch 89.542) train_loss=412.50836182 time/batch=0.79s
5284/5900 (epoch 89.559) train_loss=284.69995117 time/batch=0.64s
5285/5900 (epoch 89.576) train_loss=411.32067871 time/batch=0.76s
5286/5900 (epoch 89.593) train_loss=273.20233154 time/batch=0.63s
5287/5900 (epoch 89.610) train_loss=283.77023315 time/batch=0.61s
5288/5900 (epoch 89.627) train_loss=364.71026611 time/batch=0.73s
5289/5900 (epoch 89.644) train_loss=286.86209106 time/batch=0.68s
5290/5900 (epoch 89.661) train_loss=382.20568848 time/batch=0.73s
5291/5900 (epoch 89.678) train_loss=279.41781616 time/batch=0.62s
5292/5900 (epoch 89.695) train_loss=276.49755859 time/batch=0.63s
5293/5900 (epoch 89.712) train_loss=378.34796143 time/batch=0.70s
5294/5900 (epoch 89.729) train_loss=510.57077026 time/batch=1.18s
5295/5900 (epoch 89.746) train_loss=393.20788574 time/batch=0.77s
5296/5900 (epoch 89.763) train_loss=423.84188843 time/batch=0.78s
5297/5900 (epoch 89.780) train_loss=294.85662842 time/batch=0.71s
5298/5900 (epoch 89.797) train_loss=264.00390625 time/batch=0.61s
5299/5900 (epoch 89.814) train_loss=300.16387939 time/batch=0.63s
5300/5900 (epoch 89.831) train_loss=295.72039795 time/batch=0.65s
5301/5900 (epoch 89.847) train_loss=289.05047607 time/batch=1.15s
5302/5900 (epoch 89.864) train_loss=327.28515625 time/batch=0.73s
5303/5900 (epoch 89.881) train_loss=431.70550537 time/batch=1.30s
5304/5900 (epoch 89.898) train_loss=329.53274536 time/batch=0.72s
5305/5900 (epoch 89.915) train_loss=347.75982666 time/batch=0.70s
5306/5900 (epoch 89.932) train_loss=395.49542236 time/batch=0.78s
5307/5900 (epoch 89.949) train_loss=374.18460083 time/batch=0.74s
5308/5900 (epoch 89.966) train_loss=374.05053711 time/batch=1.29s
5309/5900 (epoch 89.983) train_loss=324.88366699 time/batch=0.72s
5310/5900 (epoch 90.000) train_loss=325.78552246 time/batch=0.69s
setting learning rate to 0.0003668
  saved to metadata/config5--20190119-211157.pkl
5311/5900 (epoch 90.017) train_loss=524.02618408 time/batch=1.05s
5312/5900 (epoch 90.034) train_loss=362.69543457 time/batch=0.72s
5313/5900 (epoch 90.051) train_loss=459.28924561 time/batch=0.79s
5314/5900 (epoch 90.068) train_loss=517.19793701 time/batch=1.00s
5315/5900 (epoch 90.085) train_loss=278.28137207 time/batch=0.64s
5316/5900 (epoch 90.102) train_loss=458.98712158 time/batch=2.50s
5317/5900 (epoch 90.119) train_loss=323.90991211 time/batch=0.77s
5318/5900 (epoch 90.136) train_loss=356.74172974 time/batch=1.78s
5319/5900 (epoch 90.153) train_loss=367.94586182 time/batch=0.77s
5320/5900 (epoch 90.169) train_loss=260.01950073 time/batch=0.63s
5321/5900 (epoch 90.186) train_loss=730.78204346 time/batch=2.96s
5322/5900 (epoch 90.203) train_loss=280.06445312 time/batch=0.77s
5323/5900 (epoch 90.220) train_loss=300.23376465 time/batch=0.64s
5324/5900 (epoch 90.237) train_loss=287.53967285 time/batch=1.20s
5325/5900 (epoch 90.254) train_loss=391.63528442 time/batch=0.78s
5326/5900 (epoch 90.271) train_loss=261.83218384 time/batch=0.57s
5327/5900 (epoch 90.288) train_loss=323.36120605 time/batch=0.66s
5328/5900 (epoch 90.305) train_loss=493.97763062 time/batch=0.82s
5329/5900 (epoch 90.322) train_loss=549.29486084 time/batch=2.20s
5330/5900 (epoch 90.339) train_loss=497.20654297 time/batch=1.50s
5331/5900 (epoch 90.356) train_loss=387.97830200 time/batch=0.80s
5332/5900 (epoch 90.373) train_loss=376.24456787 time/batch=0.73s
5333/5900 (epoch 90.390) train_loss=318.17294312 time/batch=0.70s
5334/5900 (epoch 90.407) train_loss=265.45886230 time/batch=0.62s
5335/5900 (epoch 90.424) train_loss=474.64602661 time/batch=0.83s
5336/5900 (epoch 90.441) train_loss=538.16839600 time/batch=1.51s
5337/5900 (epoch 90.458) train_loss=337.92614746 time/batch=2.52s
5338/5900 (epoch 90.475) train_loss=504.25888062 time/batch=1.68s
5339/5900 (epoch 90.492) train_loss=333.83459473 time/batch=1.32s
5340/5900 (epoch 90.508) train_loss=296.60220337 time/batch=1.28s
5341/5900 (epoch 90.525) train_loss=395.20755005 time/batch=0.79s
5342/5900 (epoch 90.542) train_loss=326.34942627 time/batch=0.69s
5343/5900 (epoch 90.559) train_loss=340.39953613 time/batch=1.30s
5344/5900 (epoch 90.576) train_loss=286.40994263 time/batch=0.64s
5345/5900 (epoch 90.593) train_loss=393.67370605 time/batch=0.75s
5346/5900 (epoch 90.610) train_loss=280.86874390 time/batch=0.64s
5347/5900 (epoch 90.627) train_loss=368.10589600 time/batch=0.74s
5348/5900 (epoch 90.644) train_loss=351.36709595 time/batch=1.30s
5349/5900 (epoch 90.661) train_loss=306.73895264 time/batch=0.73s
5350/5900 (epoch 90.678) train_loss=284.03594971 time/batch=0.61s
5351/5900 (epoch 90.695) train_loss=387.39208984 time/batch=0.76s
5352/5900 (epoch 90.712) train_loss=364.62020874 time/batch=0.71s
5353/5900 (epoch 90.729) train_loss=335.47814941 time/batch=0.69s
5354/5900 (epoch 90.746) train_loss=392.61541748 time/batch=0.78s
5355/5900 (epoch 90.763) train_loss=382.04113770 time/batch=0.78s
5356/5900 (epoch 90.780) train_loss=277.97155762 time/batch=0.69s
5357/5900 (epoch 90.797) train_loss=285.29751587 time/batch=0.64s
5358/5900 (epoch 90.814) train_loss=251.99304199 time/batch=0.58s
5359/5900 (epoch 90.831) train_loss=371.54681396 time/batch=0.74s
5360/5900 (epoch 90.847) train_loss=252.13436890 time/batch=0.60s
5361/5900 (epoch 90.864) train_loss=315.22473145 time/batch=0.67s
5362/5900 (epoch 90.881) train_loss=317.49316406 time/batch=0.68s
5363/5900 (epoch 90.898) train_loss=361.58331299 time/batch=0.70s
5364/5900 (epoch 90.915) train_loss=302.74002075 time/batch=0.68s
5365/5900 (epoch 90.932) train_loss=278.07089233 time/batch=0.64s
5366/5900 (epoch 90.949) train_loss=293.69940186 time/batch=0.65s
5367/5900 (epoch 90.966) train_loss=389.83462524 time/batch=1.33s
5368/5900 (epoch 90.983) train_loss=270.11846924 time/batch=0.67s
5369/5900 (epoch 91.000) train_loss=334.05645752 time/batch=0.68s
setting learning rate to 0.0003557
5370/5900 (epoch 91.017) train_loss=399.50360107 time/batch=1.81s
5371/5900 (epoch 91.034) train_loss=301.80575562 time/batch=0.75s
5372/5900 (epoch 91.051) train_loss=352.64294434 time/batch=1.29s
5373/5900 (epoch 91.068) train_loss=274.89535522 time/batch=1.27s
5374/5900 (epoch 91.085) train_loss=364.70809937 time/batch=0.79s
5375/5900 (epoch 91.102) train_loss=409.38287354 time/batch=0.77s
5376/5900 (epoch 91.119) train_loss=554.77178955 time/batch=2.33s
5377/5900 (epoch 91.136) train_loss=454.41656494 time/batch=0.91s
5378/5900 (epoch 91.153) train_loss=267.93292236 time/batch=0.61s
5379/5900 (epoch 91.169) train_loss=379.09411621 time/batch=0.73s
5380/5900 (epoch 91.186) train_loss=451.81829834 time/batch=0.80s
5381/5900 (epoch 91.203) train_loss=248.13221741 time/batch=0.60s
5382/5900 (epoch 91.220) train_loss=525.67712402 time/batch=0.97s
5383/5900 (epoch 91.237) train_loss=272.53323364 time/batch=0.71s
5384/5900 (epoch 91.254) train_loss=406.66421509 time/batch=0.76s
5385/5900 (epoch 91.271) train_loss=266.47558594 time/batch=0.60s
5386/5900 (epoch 91.288) train_loss=370.70376587 time/batch=0.72s
5387/5900 (epoch 91.305) train_loss=333.36715698 time/batch=1.31s
5388/5900 (epoch 91.322) train_loss=476.68194580 time/batch=0.96s
5389/5900 (epoch 91.339) train_loss=506.98632812 time/batch=1.52s
5390/5900 (epoch 91.356) train_loss=423.90402222 time/batch=0.87s
5391/5900 (epoch 91.373) train_loss=289.70581055 time/batch=0.63s
5392/5900 (epoch 91.390) train_loss=355.55770874 time/batch=0.70s
5393/5900 (epoch 91.407) train_loss=328.47805786 time/batch=0.70s
5394/5900 (epoch 91.424) train_loss=298.68835449 time/batch=0.66s
5395/5900 (epoch 91.441) train_loss=273.62152100 time/batch=0.66s
5396/5900 (epoch 91.458) train_loss=402.01855469 time/batch=0.73s
5397/5900 (epoch 91.475) train_loss=472.04376221 time/batch=0.81s
5398/5900 (epoch 91.492) train_loss=288.08724976 time/batch=0.62s
5399/5900 (epoch 91.508) train_loss=265.63763428 time/batch=0.60s
5400/5900 (epoch 91.525) train_loss=642.76544189 time/batch=2.13s
5401/5900 (epoch 91.542) train_loss=340.62371826 time/batch=0.78s
5402/5900 (epoch 91.559) train_loss=321.69711304 time/batch=0.68s
5403/5900 (epoch 91.576) train_loss=380.61267090 time/batch=1.36s
5404/5900 (epoch 91.593) train_loss=316.19738770 time/batch=0.70s
5405/5900 (epoch 91.610) train_loss=295.60446167 time/batch=1.19s
5406/5900 (epoch 91.627) train_loss=281.51019287 time/batch=0.67s
5407/5900 (epoch 91.644) train_loss=383.52215576 time/batch=0.71s
5408/5900 (epoch 91.661) train_loss=344.17272949 time/batch=0.70s
5409/5900 (epoch 91.678) train_loss=439.78015137 time/batch=2.96s
5410/5900 (epoch 91.695) train_loss=372.86419678 time/batch=0.87s
5411/5900 (epoch 91.712) train_loss=500.43969727 time/batch=1.39s
5412/5900 (epoch 91.729) train_loss=278.62902832 time/batch=0.66s
5413/5900 (epoch 91.746) train_loss=516.41015625 time/batch=1.01s
5414/5900 (epoch 91.763) train_loss=383.13360596 time/batch=0.77s
5415/5900 (epoch 91.780) train_loss=278.16400146 time/batch=0.64s
5416/5900 (epoch 91.797) train_loss=317.91015625 time/batch=0.68s
5417/5900 (epoch 91.814) train_loss=320.29406738 time/batch=0.70s
5418/5900 (epoch 91.831) train_loss=309.27728271 time/batch=0.68s
5419/5900 (epoch 91.847) train_loss=271.68133545 time/batch=0.63s
5420/5900 (epoch 91.864) train_loss=276.02713013 time/batch=0.62s
5421/5900 (epoch 91.881) train_loss=281.69622803 time/batch=0.62s
5422/5900 (epoch 91.898) train_loss=323.19140625 time/batch=0.73s
5423/5900 (epoch 91.915) train_loss=336.95269775 time/batch=1.30s
5424/5900 (epoch 91.932) train_loss=301.60052490 time/batch=0.72s
5425/5900 (epoch 91.949) train_loss=491.39434814 time/batch=2.51s
5426/5900 (epoch 91.966) train_loss=364.42144775 time/batch=0.83s
5427/5900 (epoch 91.983) train_loss=273.83020020 time/batch=0.66s
5428/5900 (epoch 92.000) train_loss=281.58825684 time/batch=0.76s
setting learning rate to 0.0003451
5429/5900 (epoch 92.017) train_loss=336.00128174 time/batch=1.21s
5430/5900 (epoch 92.034) train_loss=338.81454468 time/batch=1.31s
5431/5900 (epoch 92.051) train_loss=379.07574463 time/batch=0.78s
5432/5900 (epoch 92.068) train_loss=479.34329224 time/batch=2.48s
5433/5900 (epoch 92.085) train_loss=371.84027100 time/batch=1.87s
5434/5900 (epoch 92.102) train_loss=323.87194824 time/batch=0.72s
5435/5900 (epoch 92.119) train_loss=268.86614990 time/batch=0.60s
5436/5900 (epoch 92.136) train_loss=373.34710693 time/batch=0.71s
5437/5900 (epoch 92.153) train_loss=284.83453369 time/batch=0.69s
5438/5900 (epoch 92.169) train_loss=319.41464233 time/batch=0.68s
5439/5900 (epoch 92.186) train_loss=290.88275146 time/batch=0.63s
5440/5900 (epoch 92.203) train_loss=350.68347168 time/batch=0.72s
5441/5900 (epoch 92.220) train_loss=401.34994507 time/batch=0.76s
5442/5900 (epoch 92.237) train_loss=488.09661865 time/batch=0.84s
5443/5900 (epoch 92.254) train_loss=274.73889160 time/batch=0.63s
5444/5900 (epoch 92.271) train_loss=486.40753174 time/batch=0.92s
5445/5900 (epoch 92.288) train_loss=478.11999512 time/batch=2.38s
5446/5900 (epoch 92.305) train_loss=459.30758667 time/batch=0.91s
5447/5900 (epoch 92.322) train_loss=267.52337646 time/batch=0.61s
5448/5900 (epoch 92.339) train_loss=474.86700439 time/batch=0.83s
5449/5900 (epoch 92.356) train_loss=584.06457520 time/batch=3.00s
5450/5900 (epoch 92.373) train_loss=465.79077148 time/batch=1.52s
5451/5900 (epoch 92.390) train_loss=418.97613525 time/batch=0.82s
5452/5900 (epoch 92.407) train_loss=354.92852783 time/batch=1.71s
5453/5900 (epoch 92.424) train_loss=388.21353149 time/batch=1.03s
5454/5900 (epoch 92.441) train_loss=383.90136719 time/batch=0.80s
5455/5900 (epoch 92.458) train_loss=445.79504395 time/batch=1.23s
5456/5900 (epoch 92.475) train_loss=378.11495972 time/batch=0.75s
5457/5900 (epoch 92.492) train_loss=278.96954346 time/batch=0.63s
5458/5900 (epoch 92.508) train_loss=267.41552734 time/batch=0.67s
5459/5900 (epoch 92.525) train_loss=274.74401855 time/batch=0.63s
5460/5900 (epoch 92.542) train_loss=633.26977539 time/batch=2.18s
5461/5900 (epoch 92.559) train_loss=266.54022217 time/batch=0.74s
5462/5900 (epoch 92.576) train_loss=285.71728516 time/batch=0.64s
5463/5900 (epoch 92.593) train_loss=315.03973389 time/batch=0.66s
5464/5900 (epoch 92.610) train_loss=272.87896729 time/batch=0.60s
5465/5900 (epoch 92.627) train_loss=273.85226440 time/batch=0.61s
5466/5900 (epoch 92.644) train_loss=414.99066162 time/batch=0.77s
5467/5900 (epoch 92.661) train_loss=255.05665588 time/batch=0.60s
5468/5900 (epoch 92.678) train_loss=379.51998901 time/batch=1.30s
5469/5900 (epoch 92.695) train_loss=320.05136108 time/batch=0.73s
5470/5900 (epoch 92.712) train_loss=303.03637695 time/batch=0.67s
5471/5900 (epoch 92.729) train_loss=306.61273193 time/batch=0.85s
5472/5900 (epoch 92.746) train_loss=356.99664307 time/batch=1.33s
5473/5900 (epoch 92.763) train_loss=275.71997070 time/batch=0.64s
5474/5900 (epoch 92.780) train_loss=349.98284912 time/batch=0.73s
5475/5900 (epoch 92.797) train_loss=299.78704834 time/batch=0.66s
5476/5900 (epoch 92.814) train_loss=328.94201660 time/batch=0.68s
5477/5900 (epoch 92.831) train_loss=265.09387207 time/batch=0.62s
5478/5900 (epoch 92.847) train_loss=342.27972412 time/batch=0.84s
5479/5900 (epoch 92.864) train_loss=318.09854126 time/batch=0.70s
5480/5900 (epoch 92.881) train_loss=384.11825562 time/batch=0.74s
5481/5900 (epoch 92.898) train_loss=357.72012329 time/batch=0.73s
5482/5900 (epoch 92.915) train_loss=330.86114502 time/batch=0.69s
5483/5900 (epoch 92.932) train_loss=331.03109741 time/batch=0.84s
5484/5900 (epoch 92.949) train_loss=380.34118652 time/batch=0.74s
5485/5900 (epoch 92.966) train_loss=369.18963623 time/batch=0.73s
5486/5900 (epoch 92.983) train_loss=304.40777588 time/batch=0.70s
5487/5900 (epoch 93.000) train_loss=353.89312744 time/batch=0.80s
setting learning rate to 0.0003347
5488/5900 (epoch 93.017) train_loss=246.62048340 time/batch=0.59s
5489/5900 (epoch 93.034) train_loss=422.20019531 time/batch=0.80s
5490/5900 (epoch 93.051) train_loss=263.94400024 time/batch=0.64s
5491/5900 (epoch 93.068) train_loss=340.52359009 time/batch=1.31s
5492/5900 (epoch 93.085) train_loss=445.09783936 time/batch=2.51s
5493/5900 (epoch 93.102) train_loss=720.86145020 time/batch=3.04s
5494/5900 (epoch 93.119) train_loss=242.03390503 time/batch=0.71s
5495/5900 (epoch 93.136) train_loss=352.53460693 time/batch=0.71s
5496/5900 (epoch 93.153) train_loss=477.83511353 time/batch=0.85s
5497/5900 (epoch 93.169) train_loss=299.07122803 time/batch=0.71s
5498/5900 (epoch 93.186) train_loss=509.65710449 time/batch=1.58s
5499/5900 (epoch 93.203) train_loss=266.02520752 time/batch=0.73s
5500/5900 (epoch 93.220) train_loss=478.98132324 time/batch=0.81s
5501/5900 (epoch 93.237) train_loss=271.45617676 time/batch=0.62s
5502/5900 (epoch 93.254) train_loss=365.83041382 time/batch=2.45s
5503/5900 (epoch 93.271) train_loss=387.92419434 time/batch=1.45s
5504/5900 (epoch 93.288) train_loss=272.79040527 time/batch=0.67s
5505/5900 (epoch 93.305) train_loss=318.82733154 time/batch=0.68s
5506/5900 (epoch 93.322) train_loss=444.78411865 time/batch=0.81s
5507/5900 (epoch 93.339) train_loss=520.30181885 time/batch=0.99s
5508/5900 (epoch 93.356) train_loss=300.29187012 time/batch=0.68s
5509/5900 (epoch 93.373) train_loss=274.62695312 time/batch=0.59s
5510/5900 (epoch 93.390) train_loss=595.77868652 time/batch=2.16s
5511/5900 (epoch 93.407) train_loss=301.02954102 time/batch=0.78s
5512/5900 (epoch 93.424) train_loss=315.04391479 time/batch=0.68s
5513/5900 (epoch 93.441) train_loss=462.98727417 time/batch=1.42s
5514/5900 (epoch 93.458) train_loss=338.89776611 time/batch=0.74s
5515/5900 (epoch 93.475) train_loss=311.54699707 time/batch=1.19s
5516/5900 (epoch 93.492) train_loss=306.82986450 time/batch=0.69s
5517/5900 (epoch 93.508) train_loss=335.03988647 time/batch=0.70s
5518/5900 (epoch 93.525) train_loss=325.94262695 time/batch=1.32s
5519/5900 (epoch 93.542) train_loss=309.59341431 time/batch=0.67s
5520/5900 (epoch 93.559) train_loss=406.03961182 time/batch=0.76s
5521/5900 (epoch 93.576) train_loss=273.27465820 time/batch=0.62s
5522/5900 (epoch 93.593) train_loss=307.88769531 time/batch=0.70s
5523/5900 (epoch 93.610) train_loss=256.62655640 time/batch=1.18s
5524/5900 (epoch 93.627) train_loss=368.24536133 time/batch=0.77s
5525/5900 (epoch 93.644) train_loss=356.75067139 time/batch=1.11s
5526/5900 (epoch 93.661) train_loss=404.14343262 time/batch=0.78s
5527/5900 (epoch 93.678) train_loss=306.87536621 time/batch=0.65s
5528/5900 (epoch 93.695) train_loss=249.35363770 time/batch=0.59s
5529/5900 (epoch 93.712) train_loss=271.77755737 time/batch=0.61s
5530/5900 (epoch 93.729) train_loss=372.27908325 time/batch=0.77s
5531/5900 (epoch 93.746) train_loss=462.81741333 time/batch=1.80s
5532/5900 (epoch 93.763) train_loss=300.62329102 time/batch=1.21s
5533/5900 (epoch 93.780) train_loss=374.84234619 time/batch=0.76s
5534/5900 (epoch 93.797) train_loss=326.40289307 time/batch=0.70s
5535/5900 (epoch 93.814) train_loss=376.79391479 time/batch=0.71s
5536/5900 (epoch 93.831) train_loss=331.48635864 time/batch=1.32s
5537/5900 (epoch 93.847) train_loss=359.70794678 time/batch=0.77s
5538/5900 (epoch 93.864) train_loss=329.76593018 time/batch=0.70s
5539/5900 (epoch 93.881) train_loss=363.58288574 time/batch=0.75s
5540/5900 (epoch 93.898) train_loss=381.59936523 time/batch=0.82s
5541/5900 (epoch 93.915) train_loss=338.57708740 time/batch=0.74s
5542/5900 (epoch 93.932) train_loss=332.88146973 time/batch=0.78s
5543/5900 (epoch 93.949) train_loss=284.44409180 time/batch=0.63s
5544/5900 (epoch 93.966) train_loss=336.14993286 time/batch=0.74s
5545/5900 (epoch 93.983) train_loss=293.98492432 time/batch=0.68s
5546/5900 (epoch 94.000) train_loss=285.14599609 time/batch=0.73s
setting learning rate to 0.0003247
5547/5900 (epoch 94.017) train_loss=551.51367188 time/batch=1.60s
5548/5900 (epoch 94.034) train_loss=242.05895996 time/batch=0.65s
5549/5900 (epoch 94.051) train_loss=360.49322510 time/batch=0.71s
5550/5900 (epoch 94.068) train_loss=273.59756470 time/batch=0.63s
5551/5900 (epoch 94.085) train_loss=360.19476318 time/batch=0.69s
5552/5900 (epoch 94.102) train_loss=382.65051270 time/batch=1.33s
5553/5900 (epoch 94.119) train_loss=292.99581909 time/batch=0.71s
5554/5900 (epoch 94.136) train_loss=465.19937134 time/batch=0.96s
5555/5900 (epoch 94.153) train_loss=300.87451172 time/batch=0.71s
5556/5900 (epoch 94.169) train_loss=383.57913208 time/batch=0.74s
5557/5900 (epoch 94.186) train_loss=232.47770691 time/batch=0.58s
5558/5900 (epoch 94.203) train_loss=316.54696655 time/batch=0.69s
5559/5900 (epoch 94.220) train_loss=399.88098145 time/batch=0.79s
5560/5900 (epoch 94.237) train_loss=353.78979492 time/batch=0.74s
5561/5900 (epoch 94.254) train_loss=432.01333618 time/batch=2.48s
5562/5900 (epoch 94.271) train_loss=401.71136475 time/batch=1.90s
5563/5900 (epoch 94.288) train_loss=338.16424561 time/batch=1.35s
5564/5900 (epoch 94.305) train_loss=383.92541504 time/batch=0.77s
5565/5900 (epoch 94.322) train_loss=270.45367432 time/batch=0.66s
5566/5900 (epoch 94.339) train_loss=472.28698730 time/batch=0.83s
5567/5900 (epoch 94.356) train_loss=327.52972412 time/batch=1.24s
5568/5900 (epoch 94.373) train_loss=328.81567383 time/batch=0.73s
5569/5900 (epoch 94.390) train_loss=668.14392090 time/batch=2.97s
5570/5900 (epoch 94.407) train_loss=451.01828003 time/batch=0.95s
5571/5900 (epoch 94.424) train_loss=458.09753418 time/batch=1.43s
5572/5900 (epoch 94.441) train_loss=288.91482544 time/batch=0.67s
5573/5900 (epoch 94.458) train_loss=553.27929688 time/batch=2.17s
5574/5900 (epoch 94.475) train_loss=374.85098267 time/batch=0.83s
5575/5900 (epoch 94.492) train_loss=364.57797241 time/batch=2.47s
5576/5900 (epoch 94.508) train_loss=274.36917114 time/batch=0.72s
5577/5900 (epoch 94.525) train_loss=286.08447266 time/batch=0.68s
5578/5900 (epoch 94.542) train_loss=297.81704712 time/batch=0.70s
5579/5900 (epoch 94.559) train_loss=389.77136230 time/batch=0.77s
5580/5900 (epoch 94.576) train_loss=263.69055176 time/batch=0.60s
5581/5900 (epoch 94.593) train_loss=479.45330811 time/batch=0.83s
5582/5900 (epoch 94.610) train_loss=298.73999023 time/batch=0.63s
5583/5900 (epoch 94.627) train_loss=275.19317627 time/batch=0.63s
5584/5900 (epoch 94.644) train_loss=356.89544678 time/batch=0.71s
5585/5900 (epoch 94.661) train_loss=253.27613831 time/batch=0.61s
5586/5900 (epoch 94.678) train_loss=317.58511353 time/batch=0.69s
5587/5900 (epoch 94.695) train_loss=384.11752319 time/batch=1.32s
5588/5900 (epoch 94.712) train_loss=364.09948730 time/batch=0.78s
5589/5900 (epoch 94.729) train_loss=283.25448608 time/batch=0.66s
5590/5900 (epoch 94.746) train_loss=488.86441040 time/batch=1.50s
5591/5900 (epoch 94.763) train_loss=450.69241333 time/batch=2.42s
5592/5900 (epoch 94.780) train_loss=304.47467041 time/batch=0.77s
5593/5900 (epoch 94.797) train_loss=308.18765259 time/batch=0.66s
5594/5900 (epoch 94.814) train_loss=345.90289307 time/batch=0.69s
5595/5900 (epoch 94.831) train_loss=280.66662598 time/batch=0.66s
5596/5900 (epoch 94.847) train_loss=356.36843872 time/batch=0.70s
5597/5900 (epoch 94.864) train_loss=295.56973267 time/batch=0.67s
5598/5900 (epoch 94.881) train_loss=319.53637695 time/batch=0.68s
5599/5900 (epoch 94.898) train_loss=258.47946167 time/batch=0.62s
5600/5900 (epoch 94.915) train_loss=392.18103027 time/batch=0.78s
5601/5900 (epoch 94.932) train_loss=272.26376343 time/batch=0.63s
5602/5900 (epoch 94.949) train_loss=321.20233154 time/batch=0.69s
5603/5900 (epoch 94.966) train_loss=266.62594604 time/batch=0.64s
5604/5900 (epoch 94.983) train_loss=266.94702148 time/batch=0.62s
5605/5900 (epoch 95.000) train_loss=255.73205566 time/batch=0.61s
setting learning rate to 0.0003149
5606/5900 (epoch 95.017) train_loss=388.82434082 time/batch=1.77s
5607/5900 (epoch 95.034) train_loss=275.61041260 time/batch=0.71s
5608/5900 (epoch 95.051) train_loss=444.45513916 time/batch=0.79s
5609/5900 (epoch 95.068) train_loss=482.26266479 time/batch=0.83s
5610/5900 (epoch 95.085) train_loss=275.96331787 time/batch=0.65s
5611/5900 (epoch 95.102) train_loss=343.15765381 time/batch=1.29s
5612/5900 (epoch 95.119) train_loss=259.82012939 time/batch=0.64s
5613/5900 (epoch 95.136) train_loss=285.57864380 time/batch=0.62s
5614/5900 (epoch 95.153) train_loss=459.17358398 time/batch=0.95s
5615/5900 (epoch 95.169) train_loss=352.01312256 time/batch=0.75s
5616/5900 (epoch 95.186) train_loss=562.00054932 time/batch=2.20s
5617/5900 (epoch 95.203) train_loss=283.24267578 time/batch=0.72s
5618/5900 (epoch 95.220) train_loss=394.81320190 time/batch=0.76s
5619/5900 (epoch 95.237) train_loss=390.74789429 time/batch=1.32s
5620/5900 (epoch 95.254) train_loss=544.72314453 time/batch=1.63s
5621/5900 (epoch 95.271) train_loss=449.39636230 time/batch=2.52s
5622/5900 (epoch 95.288) train_loss=388.27282715 time/batch=0.84s
5623/5900 (epoch 95.305) train_loss=346.26184082 time/batch=0.71s
5624/5900 (epoch 95.322) train_loss=358.05480957 time/batch=0.75s
5625/5900 (epoch 95.339) train_loss=276.91314697 time/batch=0.70s
5626/5900 (epoch 95.356) train_loss=368.96572876 time/batch=0.72s
5627/5900 (epoch 95.373) train_loss=235.52203369 time/batch=0.57s
5628/5900 (epoch 95.390) train_loss=268.05700684 time/batch=0.63s
5629/5900 (epoch 95.407) train_loss=256.58352661 time/batch=0.61s
5630/5900 (epoch 95.424) train_loss=288.79757690 time/batch=0.70s
5631/5900 (epoch 95.441) train_loss=345.14978027 time/batch=1.30s
5632/5900 (epoch 95.458) train_loss=373.19488525 time/batch=0.76s
5633/5900 (epoch 95.475) train_loss=322.21716309 time/batch=1.30s
5634/5900 (epoch 95.492) train_loss=266.52099609 time/batch=0.66s
5635/5900 (epoch 95.508) train_loss=344.86230469 time/batch=0.73s
5636/5900 (epoch 95.525) train_loss=379.81781006 time/batch=0.77s
5637/5900 (epoch 95.542) train_loss=255.42881775 time/batch=0.59s
5638/5900 (epoch 95.559) train_loss=279.55157471 time/batch=1.21s
5639/5900 (epoch 95.576) train_loss=300.02008057 time/batch=0.69s
5640/5900 (epoch 95.593) train_loss=401.30920410 time/batch=0.78s
5641/5900 (epoch 95.610) train_loss=455.21777344 time/batch=1.41s
5642/5900 (epoch 95.627) train_loss=354.58850098 time/batch=0.79s
5643/5900 (epoch 95.644) train_loss=264.49200439 time/batch=0.62s
5644/5900 (epoch 95.661) train_loss=322.63354492 time/batch=2.46s
5645/5900 (epoch 95.678) train_loss=272.77679443 time/batch=0.74s
5646/5900 (epoch 95.695) train_loss=319.84799194 time/batch=0.68s
5647/5900 (epoch 95.712) train_loss=309.38098145 time/batch=0.66s
5648/5900 (epoch 95.729) train_loss=469.20281982 time/batch=0.99s
5649/5900 (epoch 95.746) train_loss=551.04345703 time/batch=1.01s
5650/5900 (epoch 95.763) train_loss=302.94415283 time/batch=0.67s
5651/5900 (epoch 95.780) train_loss=405.42694092 time/batch=0.78s
5652/5900 (epoch 95.797) train_loss=293.36770630 time/batch=0.66s
5653/5900 (epoch 95.814) train_loss=270.07238770 time/batch=0.61s
5654/5900 (epoch 95.831) train_loss=253.80348206 time/batch=0.58s
5655/5900 (epoch 95.847) train_loss=607.89233398 time/batch=2.97s
5656/5900 (epoch 95.864) train_loss=335.16964722 time/batch=0.83s
5657/5900 (epoch 95.881) train_loss=495.44201660 time/batch=2.33s
5658/5900 (epoch 95.898) train_loss=317.30322266 time/batch=0.77s
5659/5900 (epoch 95.915) train_loss=318.27871704 time/batch=0.70s
5660/5900 (epoch 95.932) train_loss=326.33880615 time/batch=0.69s
5661/5900 (epoch 95.949) train_loss=363.92633057 time/batch=1.24s
5662/5900 (epoch 95.966) train_loss=318.38565063 time/batch=0.74s
5663/5900 (epoch 95.983) train_loss=268.12530518 time/batch=0.69s
5664/5900 (epoch 96.000) train_loss=285.54183960 time/batch=0.66s
setting learning rate to 0.0003055
5665/5900 (epoch 96.017) train_loss=345.33374023 time/batch=0.72s
5666/5900 (epoch 96.034) train_loss=274.53341675 time/batch=0.71s
5667/5900 (epoch 96.051) train_loss=524.01696777 time/batch=1.01s
5668/5900 (epoch 96.068) train_loss=645.38122559 time/batch=2.99s
5669/5900 (epoch 96.085) train_loss=314.40435791 time/batch=0.82s
5670/5900 (epoch 96.102) train_loss=448.10803223 time/batch=2.49s
5671/5900 (epoch 96.119) train_loss=265.85702515 time/batch=0.76s
5672/5900 (epoch 96.136) train_loss=347.71728516 time/batch=0.72s
5673/5900 (epoch 96.153) train_loss=435.66027832 time/batch=0.83s
5674/5900 (epoch 96.169) train_loss=368.71520996 time/batch=0.75s
5675/5900 (epoch 96.186) train_loss=377.96817017 time/batch=0.74s
5676/5900 (epoch 96.203) train_loss=525.44299316 time/batch=1.58s
5677/5900 (epoch 96.220) train_loss=380.27923584 time/batch=0.79s
5678/5900 (epoch 96.237) train_loss=276.03070068 time/batch=0.62s
5679/5900 (epoch 96.254) train_loss=266.29061890 time/batch=0.60s
5680/5900 (epoch 96.271) train_loss=424.54840088 time/batch=1.11s
5681/5900 (epoch 96.288) train_loss=314.95135498 time/batch=1.33s
5682/5900 (epoch 96.305) train_loss=273.53329468 time/batch=1.26s
5683/5900 (epoch 96.322) train_loss=499.38488770 time/batch=2.18s
5684/5900 (epoch 96.339) train_loss=309.19244385 time/batch=0.75s
5685/5900 (epoch 96.356) train_loss=332.81823730 time/batch=0.70s
5686/5900 (epoch 96.373) train_loss=382.33468628 time/batch=1.32s
5687/5900 (epoch 96.390) train_loss=363.65402222 time/batch=0.76s
5688/5900 (epoch 96.407) train_loss=466.90301514 time/batch=0.80s
5689/5900 (epoch 96.424) train_loss=288.34442139 time/batch=1.23s
5690/5900 (epoch 96.441) train_loss=258.94647217 time/batch=0.71s
5691/5900 (epoch 96.458) train_loss=328.82116699 time/batch=1.29s
5692/5900 (epoch 96.475) train_loss=280.11419678 time/batch=0.68s
5693/5900 (epoch 96.492) train_loss=266.36132812 time/batch=0.63s
5694/5900 (epoch 96.508) train_loss=292.38302612 time/batch=0.64s
5695/5900 (epoch 96.525) train_loss=253.51356506 time/batch=0.58s
5696/5900 (epoch 96.542) train_loss=249.67918396 time/batch=1.19s
5697/5900 (epoch 96.559) train_loss=400.04071045 time/batch=0.82s
5698/5900 (epoch 96.576) train_loss=354.32968140 time/batch=1.33s
5699/5900 (epoch 96.593) train_loss=362.89086914 time/batch=2.54s
5700/5900 (epoch 96.610) train_loss=278.87847900 time/batch=0.72s
5701/5900 (epoch 96.627) train_loss=352.05261230 time/batch=0.71s
5702/5900 (epoch 96.644) train_loss=320.27636719 time/batch=0.66s
5703/5900 (epoch 96.661) train_loss=383.98867798 time/batch=0.78s
5704/5900 (epoch 96.678) train_loss=316.18359375 time/batch=0.66s
5705/5900 (epoch 96.695) train_loss=250.90542603 time/batch=0.59s
5706/5900 (epoch 96.712) train_loss=382.83099365 time/batch=0.74s
5707/5900 (epoch 96.729) train_loss=439.86914062 time/batch=0.83s
5708/5900 (epoch 96.746) train_loss=307.00387573 time/batch=0.65s
5709/5900 (epoch 96.763) train_loss=390.69271851 time/batch=1.79s
5710/5900 (epoch 96.780) train_loss=264.54815674 time/batch=0.71s
5711/5900 (epoch 96.797) train_loss=295.73764038 time/batch=0.84s
5712/5900 (epoch 96.814) train_loss=463.39788818 time/batch=0.85s
5713/5900 (epoch 96.831) train_loss=304.22216797 time/batch=0.71s
5714/5900 (epoch 96.847) train_loss=277.23803711 time/batch=0.62s
5715/5900 (epoch 96.864) train_loss=264.99194336 time/batch=0.63s
5716/5900 (epoch 96.881) train_loss=315.06097412 time/batch=0.69s
5717/5900 (epoch 96.898) train_loss=306.22537231 time/batch=0.68s
5718/5900 (epoch 96.915) train_loss=298.25653076 time/batch=0.69s
5719/5900 (epoch 96.932) train_loss=397.94808960 time/batch=0.78s
5720/5900 (epoch 96.949) train_loss=467.99243164 time/batch=1.41s
5721/5900 (epoch 96.966) train_loss=324.04986572 time/batch=0.74s
5722/5900 (epoch 96.983) train_loss=354.63226318 time/batch=0.74s
5723/5900 (epoch 97.000) train_loss=279.67871094 time/batch=0.78s
setting learning rate to 0.0002963
5724/5900 (epoch 97.017) train_loss=328.30404663 time/batch=1.21s
5725/5900 (epoch 97.034) train_loss=631.45947266 time/batch=3.01s
5726/5900 (epoch 97.051) train_loss=569.76281738 time/batch=2.30s
5727/5900 (epoch 97.068) train_loss=284.50592041 time/batch=0.70s
5728/5900 (epoch 97.085) train_loss=351.77331543 time/batch=0.72s
5729/5900 (epoch 97.102) train_loss=523.14331055 time/batch=1.00s
5730/5900 (epoch 97.119) train_loss=314.98870850 time/batch=0.69s
5731/5900 (epoch 97.136) train_loss=286.30148315 time/batch=1.24s
5732/5900 (epoch 97.153) train_loss=331.58035278 time/batch=0.74s
5733/5900 (epoch 97.169) train_loss=523.89355469 time/batch=1.55s
5734/5900 (epoch 97.186) train_loss=289.22668457 time/batch=0.74s
5735/5900 (epoch 97.203) train_loss=435.14248657 time/batch=1.12s
5736/5900 (epoch 97.220) train_loss=393.52294922 time/batch=1.82s
5737/5900 (epoch 97.237) train_loss=444.45944214 time/batch=1.49s
5738/5900 (epoch 97.254) train_loss=462.39398193 time/batch=0.89s
5739/5900 (epoch 97.271) train_loss=395.37298584 time/batch=0.77s
5740/5900 (epoch 97.288) train_loss=301.54849243 time/batch=0.70s
5741/5900 (epoch 97.305) train_loss=265.93322754 time/batch=0.68s
5742/5900 (epoch 97.322) train_loss=434.34826660 time/batch=0.81s
5743/5900 (epoch 97.339) train_loss=306.88858032 time/batch=0.68s
5744/5900 (epoch 97.356) train_loss=394.89495850 time/batch=0.78s
5745/5900 (epoch 97.373) train_loss=335.47033691 time/batch=1.30s
5746/5900 (epoch 97.390) train_loss=274.23693848 time/batch=0.74s
5747/5900 (epoch 97.407) train_loss=410.77648926 time/batch=0.81s
5748/5900 (epoch 97.424) train_loss=251.09605408 time/batch=1.20s
5749/5900 (epoch 97.441) train_loss=256.50085449 time/batch=0.63s
5750/5900 (epoch 97.458) train_loss=384.62774658 time/batch=2.51s
5751/5900 (epoch 97.475) train_loss=287.66415405 time/batch=0.75s
5752/5900 (epoch 97.492) train_loss=460.12762451 time/batch=0.83s
5753/5900 (epoch 97.508) train_loss=360.74890137 time/batch=0.73s
5754/5900 (epoch 97.525) train_loss=366.24703979 time/batch=0.73s
5755/5900 (epoch 97.542) train_loss=392.23260498 time/batch=0.74s
5756/5900 (epoch 97.559) train_loss=241.18705750 time/batch=0.60s
5757/5900 (epoch 97.576) train_loss=275.29882812 time/batch=0.65s
5758/5900 (epoch 97.593) train_loss=339.77630615 time/batch=1.30s
5759/5900 (epoch 97.610) train_loss=367.17181396 time/batch=0.74s
5760/5900 (epoch 97.627) train_loss=264.24667358 time/batch=0.62s
5761/5900 (epoch 97.644) train_loss=265.04309082 time/batch=0.63s
5762/5900 (epoch 97.661) train_loss=258.89044189 time/batch=0.62s
5763/5900 (epoch 97.678) train_loss=314.63476562 time/batch=0.66s
5764/5900 (epoch 97.695) train_loss=313.01422119 time/batch=0.65s
5765/5900 (epoch 97.712) train_loss=258.27416992 time/batch=0.62s
5766/5900 (epoch 97.729) train_loss=342.00451660 time/batch=0.72s
5767/5900 (epoch 97.746) train_loss=255.76655579 time/batch=0.60s
5768/5900 (epoch 97.763) train_loss=303.26275635 time/batch=0.71s
5769/5900 (epoch 97.780) train_loss=369.51165771 time/batch=0.77s
5770/5900 (epoch 97.797) train_loss=354.45501709 time/batch=0.80s
5771/5900 (epoch 97.814) train_loss=268.72070312 time/batch=0.65s
5772/5900 (epoch 97.831) train_loss=268.37194824 time/batch=0.61s
5773/5900 (epoch 97.847) train_loss=288.53033447 time/batch=0.65s
5774/5900 (epoch 97.864) train_loss=376.78662109 time/batch=1.35s
5775/5900 (epoch 97.881) train_loss=364.31710815 time/batch=2.48s
5776/5900 (epoch 97.898) train_loss=327.85574341 time/batch=1.40s
5777/5900 (epoch 97.915) train_loss=380.23376465 time/batch=0.87s
5778/5900 (epoch 97.932) train_loss=322.68524170 time/batch=0.70s
5779/5900 (epoch 97.949) train_loss=320.17321777 time/batch=0.68s
5780/5900 (epoch 97.966) train_loss=354.33493042 time/batch=0.71s
5781/5900 (epoch 97.983) train_loss=316.97082520 time/batch=0.75s
5782/5900 (epoch 98.000) train_loss=277.48004150 time/batch=0.62s
setting learning rate to 0.0002874
5783/5900 (epoch 98.017) train_loss=267.52563477 time/batch=0.62s
5784/5900 (epoch 98.034) train_loss=559.77349854 time/batch=3.00s
5785/5900 (epoch 98.051) train_loss=388.86730957 time/batch=1.92s
5786/5900 (epoch 98.068) train_loss=253.23889160 time/batch=0.68s
5787/5900 (epoch 98.085) train_loss=384.63211060 time/batch=0.73s
5788/5900 (epoch 98.102) train_loss=248.14479065 time/batch=0.61s
5789/5900 (epoch 98.119) train_loss=344.45446777 time/batch=0.74s
5790/5900 (epoch 98.136) train_loss=361.43579102 time/batch=0.73s
5791/5900 (epoch 98.153) train_loss=280.20898438 time/batch=0.64s
5792/5900 (epoch 98.169) train_loss=443.58218384 time/batch=1.41s
5793/5900 (epoch 98.186) train_loss=328.88342285 time/batch=1.34s
5794/5900 (epoch 98.203) train_loss=444.65835571 time/batch=0.91s
5795/5900 (epoch 98.220) train_loss=327.06909180 time/batch=2.47s
5796/5900 (epoch 98.237) train_loss=363.50985718 time/batch=0.81s
5797/5900 (epoch 98.254) train_loss=467.38848877 time/batch=0.84s
5798/5900 (epoch 98.271) train_loss=392.74600220 time/batch=0.78s
5799/5900 (epoch 98.288) train_loss=352.86633301 time/batch=0.73s
5800/5900 (epoch 98.305) train_loss=294.68975830 time/batch=0.65s
5801/5900 (epoch 98.322) train_loss=328.64831543 time/batch=0.73s
5802/5900 (epoch 98.339) train_loss=312.77767944 time/batch=0.68s
5803/5900 (epoch 98.356) train_loss=254.91186523 time/batch=0.59s
5804/5900 (epoch 98.373) train_loss=302.42517090 time/batch=0.68s
5805/5900 (epoch 98.390) train_loss=228.10552979 time/batch=0.57s
5806/5900 (epoch 98.407) train_loss=313.88742065 time/batch=0.68s
5807/5900 (epoch 98.424) train_loss=397.25628662 time/batch=0.79s
5808/5900 (epoch 98.441) train_loss=339.85580444 time/batch=0.76s
5809/5900 (epoch 98.458) train_loss=265.16915894 time/batch=0.64s
5810/5900 (epoch 98.475) train_loss=339.05108643 time/batch=1.28s
5811/5900 (epoch 98.492) train_loss=307.80523682 time/batch=0.73s
5812/5900 (epoch 98.508) train_loss=268.42242432 time/batch=0.62s
5813/5900 (epoch 98.525) train_loss=274.79776001 time/batch=0.60s
5814/5900 (epoch 98.542) train_loss=562.33251953 time/batch=1.68s
5815/5900 (epoch 98.559) train_loss=359.55358887 time/batch=0.79s
5816/5900 (epoch 98.576) train_loss=421.64245605 time/batch=0.83s
5817/5900 (epoch 98.593) train_loss=514.89074707 time/batch=2.36s
5818/5900 (epoch 98.610) train_loss=459.74963379 time/batch=1.03s
5819/5900 (epoch 98.627) train_loss=248.74609375 time/batch=0.60s
5820/5900 (epoch 98.644) train_loss=272.46035767 time/batch=0.63s
5821/5900 (epoch 98.661) train_loss=317.68203735 time/batch=1.30s
5822/5900 (epoch 98.678) train_loss=277.90985107 time/batch=0.68s
5823/5900 (epoch 98.695) train_loss=314.91427612 time/batch=0.69s
5824/5900 (epoch 98.712) train_loss=565.14904785 time/batch=2.17s
5825/5900 (epoch 98.729) train_loss=283.14178467 time/batch=0.77s
5826/5900 (epoch 98.746) train_loss=494.46936035 time/batch=1.48s
5827/5900 (epoch 98.763) train_loss=263.83288574 time/batch=0.73s
5828/5900 (epoch 98.780) train_loss=285.43103027 time/batch=0.64s
5829/5900 (epoch 98.797) train_loss=253.87231445 time/batch=0.59s
5830/5900 (epoch 98.814) train_loss=456.56103516 time/batch=2.50s
5831/5900 (epoch 98.831) train_loss=297.16860962 time/batch=0.80s
5832/5900 (epoch 98.847) train_loss=322.45223999 time/batch=1.23s
5833/5900 (epoch 98.864) train_loss=374.83666992 time/batch=0.79s
5834/5900 (epoch 98.881) train_loss=368.34899902 time/batch=0.75s
5835/5900 (epoch 98.898) train_loss=349.23931885 time/batch=0.70s
5836/5900 (epoch 98.915) train_loss=261.94198608 time/batch=0.62s
5837/5900 (epoch 98.932) train_loss=285.03802490 time/batch=0.65s
5838/5900 (epoch 98.949) train_loss=373.01708984 time/batch=0.76s
5839/5900 (epoch 98.966) train_loss=270.14215088 time/batch=0.64s
5840/5900 (epoch 98.983) train_loss=299.24755859 time/batch=0.75s
5841/5900 (epoch 99.000) train_loss=349.24295044 time/batch=1.32s
setting learning rate to 0.0002788
5842/5900 (epoch 99.017) train_loss=412.72277832 time/batch=2.53s
5843/5900 (epoch 99.034) train_loss=353.16162109 time/batch=0.84s
5844/5900 (epoch 99.051) train_loss=448.03012085 time/batch=1.43s
5845/5900 (epoch 99.068) train_loss=439.87377930 time/batch=2.56s
5846/5900 (epoch 99.085) train_loss=463.84759521 time/batch=0.93s
5847/5900 (epoch 99.102) train_loss=262.47692871 time/batch=0.65s
5848/5900 (epoch 99.119) train_loss=350.99731445 time/batch=0.71s
5849/5900 (epoch 99.136) train_loss=388.73345947 time/batch=0.81s
5850/5900 (epoch 99.153) train_loss=279.18774414 time/batch=0.64s
5851/5900 (epoch 99.169) train_loss=356.79138184 time/batch=0.76s
5852/5900 (epoch 99.186) train_loss=298.06506348 time/batch=0.68s
5853/5900 (epoch 99.203) train_loss=443.99124146 time/batch=0.85s
5854/5900 (epoch 99.220) train_loss=284.32232666 time/batch=1.24s
5855/5900 (epoch 99.237) train_loss=312.75097656 time/batch=0.72s
5856/5900 (epoch 99.254) train_loss=312.07034302 time/batch=1.32s
5857/5900 (epoch 99.271) train_loss=565.35009766 time/batch=2.17s
5858/5900 (epoch 99.288) train_loss=459.20922852 time/batch=0.99s
5859/5900 (epoch 99.305) train_loss=501.45629883 time/batch=1.62s
5860/5900 (epoch 99.322) train_loss=471.07601929 time/batch=1.01s
5861/5900 (epoch 99.339) train_loss=382.33966064 time/batch=0.78s
5862/5900 (epoch 99.356) train_loss=281.15338135 time/batch=0.64s
5863/5900 (epoch 99.373) train_loss=225.10760498 time/batch=0.57s
5864/5900 (epoch 99.390) train_loss=365.96636963 time/batch=0.71s
5865/5900 (epoch 99.407) train_loss=301.94607544 time/batch=0.65s
5866/5900 (epoch 99.424) train_loss=373.14999390 time/batch=0.75s
5867/5900 (epoch 99.441) train_loss=316.51510620 time/batch=0.70s
5868/5900 (epoch 99.458) train_loss=263.11697388 time/batch=0.60s
5869/5900 (epoch 99.475) train_loss=263.74774170 time/batch=1.20s
5870/5900 (epoch 99.492) train_loss=641.52746582 time/batch=2.99s
5871/5900 (epoch 99.508) train_loss=301.67208862 time/batch=0.79s
5872/5900 (epoch 99.525) train_loss=570.79943848 time/batch=2.35s
5873/5900 (epoch 99.542) train_loss=380.60693359 time/batch=1.45s
5874/5900 (epoch 99.559) train_loss=365.17050171 time/batch=0.76s
5875/5900 (epoch 99.576) train_loss=336.35266113 time/batch=0.76s
5876/5900 (epoch 99.593) train_loss=266.73135376 time/batch=0.60s
5877/5900 (epoch 99.610) train_loss=337.35076904 time/batch=0.69s
5878/5900 (epoch 99.627) train_loss=244.81347656 time/batch=0.58s
5879/5900 (epoch 99.644) train_loss=346.01531982 time/batch=0.72s
5880/5900 (epoch 99.661) train_loss=258.07550049 time/batch=0.64s
5881/5900 (epoch 99.678) train_loss=259.80075073 time/batch=0.62s
5882/5900 (epoch 99.695) train_loss=311.91082764 time/batch=0.68s
5883/5900 (epoch 99.712) train_loss=292.72061157 time/batch=0.66s
5884/5900 (epoch 99.729) train_loss=370.92614746 time/batch=0.76s
5885/5900 (epoch 99.746) train_loss=313.92596436 time/batch=0.68s
5886/5900 (epoch 99.763) train_loss=274.54263306 time/batch=0.70s
5887/5900 (epoch 99.780) train_loss=271.97344971 time/batch=1.18s
5888/5900 (epoch 99.797) train_loss=269.42864990 time/batch=0.67s
5889/5900 (epoch 99.814) train_loss=354.88073730 time/batch=1.27s
5890/5900 (epoch 99.831) train_loss=333.69775391 time/batch=1.34s
5891/5900 (epoch 99.847) train_loss=369.46017456 time/batch=0.83s
5892/5900 (epoch 99.864) train_loss=270.35787964 time/batch=0.62s
5893/5900 (epoch 99.881) train_loss=270.29699707 time/batch=0.65s
5894/5900 (epoch 99.898) train_loss=300.42218018 time/batch=0.68s
5895/5900 (epoch 99.915) train_loss=266.10333252 time/batch=0.63s
5896/5900 (epoch 99.932) train_loss=257.14489746 time/batch=0.65s
5897/5900 (epoch 99.949) train_loss=408.80560303 time/batch=0.80s
5898/5900 (epoch 99.966) train_loss=270.93041992 time/batch=0.64s
5899/5900 (epoch 99.983) train_loss=284.35388184 time/batch=0.70s
5900/5900 (epoch 100.000) train_loss=284.78826904 time/batch=1.15s
setting learning rate to 0.0002705
  saved to metadata/config5--20190119-211157.pkl
