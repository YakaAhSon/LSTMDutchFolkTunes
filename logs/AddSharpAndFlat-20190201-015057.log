set(['1/4=76\n', '[I:setbarnb 80]', 'G2>', 'G2<', '1/2=56\n', '1/2=60\n', '[I:setbarnb 61]', '[K:F]', '[I:setbarnb 91]', '[I:setbarnb 41]', 'G7', 'G6', 'G4', 'G3', 'G2', '[I:setbarnb 48]', 'G>', 'G<', '[I:setbarnb 56]', 'G8', '1/2=100\n', 'G/', 'G,', 'g7', 'g6', 'g4', 'g3', 'g2', 'g>', 'g<', 'F2', 'g8', "g'", '_A4', 'F4>', '1/4=152\n', 'g/', '16/2\n', "^c'", '_A2', '^A2', 'B2>', 'B2<', '^A6', 'G,4<', '^A4', 'G,4>', 'F clef=treble\n', '^A>', '8/4\n', '^A<', 'c4<', '_e2>', '[I:setbarnb 58]', '_e2<', '_A>', '3/8=60\n', 'e/8', 'e/>', '3/4=60\n', 'e/<', '1/4=100\n', 'b2>', 'b2<', '^a6', '^c>', '^a4', 'A,2>', 'A2<', 'e4<', 'n', 'd4', 'M:', '1/4=84\n', '^E/', 'g2>', '^c4', 'g2<', 'E,2>', 'Db clef=treble\n', 'F2>', '3/8=144\n', '[I:setbarnb 34]', '[K:G]', 'Z4', 'Z5', 'A clef=treble\n', '3/8=132\n', 'Z2', 'Z3', '_B>', 'z/', '[K:F#]', '3/4=63\n', '^d6', 'G,/', '^c7', '[I:setbarnb 5]', 'z<', '1/2=88\n', 'z>', 'Eb clef=treble\n', 'z8', '[I:setbarnb 24]', 'G,>', 'z4', '1/2=54\n', 'G,2', 'G,3', 'G,4', 'z2', 'z3', 'A,/', '_G/', 'F7', 'g4<', 'E clef=treble\n', '[I:setbarnb 66]', 'A,>', '[M:3/4]', '6/8\n', 'A,8', 'A,6', 'A,4', 'A,2', 'A,3', '3/2\n', '_G2', "d'2<", "d'2>", "d'4>", '12/2\n', 'A4>', 'B,>', '1/4=96\n', "e'2>", 'G/<', 'e7', '3/8=184\n', '_g2', "c'2<", '6/2\n', '_d4', 'D clef=bass\n', 'C,2>', 'C,2<', 'F/<', "c'/>", '[I:setbarnb 40]', '_A2<', '5/8\n', 'F', 'E2<', '^e2', 'E2>', '^e3', '_A8', 'B,3', '[M:4/8]', 'F,2<', 'F,2>', 'F3', 'F4', 'F6', 'f', 'F8', 'c4>', '1/8=152\n', 'F<', '^E3', 'F>', 'F clef=bass\n', '[I:setbarnb 11]', '^G,2>', '3/8=126\n', 'F,', '1/4=168\n', 'F/', '^e>', 'B,<', 'f2', 'f3', 'f4', '[M:10/4]', 'f6', 'f7', 'f8', 'B,4', '^e4', 'B,6', 'f<', 'F4<', 'f>', 'B,2', '^e/', 'B,/', '^d<', "f'", '^D,4', '[I:setbarnb 78]', 'f/', '[I:setbarnb 30]', '[I:setbarnb 65]', '^B/', '^B,', 'x/>', 'z2>', 'z2<', '^C,2>', '1/4=88\n', '[M:6/2]', '^B3', '^B2', '^E4', '^B4', 'A', '[I:setbarnb 93]', 'w', '[M:8/4]', '_b2', 'G,<', '[I:setbarnb 44]', '^G2>', '^D,2', 'D4<', 'L:', 'a', '3/8=108\n', 'e2<', 'e2>', '[I:setbarnb 23]', '[M:5/8]', '[K:Bb]', '^C4', '^E2', '[I:setbarnb 9]', '[I:setbarnb 71]', '_a2', '_G', '_E', '_D', '_B', '_A', '[I:setbarnb 68]', '^c4<', '^c4>', 'D,<', 'f4<', '[M:7/4]', 'f4>', '[I:setbarnb 116]', '3/8=80\n', '_g', 'A/>', '_e', '_d', '_c', '_b', '_a', 'A/8', '^G,4', '^A3', '1/2=63\n', 'D clef=treble\n', '3/8=96\n', '2/4\n', 'D/>', 'a/>', '[I:setbarnb 134]', 'a/<', "e'>", 'A,4>', "e'3", "e'2", '_E,', 'l', '1/8=120\n', '[M:2/2]', 'A,4<', "e'/", 'd4>', 'd4<', "^c'4", '|', 'C,/', 'b<', '[I:setbarnb 4]', '^A,>', '[M:1/4]', '1/8=168\n', '[I:setbarnb 57]', 'C,8', 'C,4', '[K:Ab]', 'C,6', 'G4<', 'C,2', '1/4=92\n', 'G clef=treble\n', '^F6', 'E/', '^F4', '^F3', '^F2', 'p', '5/2\n', '^F>', '^F<', '_A,/>', '^F8', 'E<', 'E>', '3/8=168\n', 'E8', '3/8=63\n', '^F/', 'E4', 'E7', 'E6', '3/8=152\n', 'E3', 'E2', '^f6', 'e/', '^f4', '^f3', '^f2', 'G', '^f>', "e'", '^f<', "^f'", 'e<', 'e>', 'e8', 'x', '^f/', 'e4', 'A4<', 'e6', 'e3', 'e2', '_B,4', '1/2=120\n', '_B,2', 'g', 'G clef=bass\n', '^A/', 'G,2>', 'd/8', 'G,2<', 'd/>', '^A,', 'd/<', '[I:setbarnb 20]', '_B,/', '^D3', 'D4>', '1/4=126\n', '^a2', '^F,', '4/4\n', '^G2<', 'D,2>', 'D,2<', '1/2=152\n', '[I:setbarnb 26]', 'G/>', 'G/8', 'K:', "e'4", '[M:13/8]', 'A,2<', '^b', '[I:setbarnb 12]', '[M:2/1]', '1/2=48\n', '7/8\n', 'g4>', '^C,3', 'B', '^D/', '^C,6', '3/8=84\n', '[M:12/8]', '^C,>', 'x8', 'x>', '^e', 'x2', 'x3', 'x6', 'x7', 'x4', 'b', '[I:setbarnb 19]', "e'6", '3/4=69\n', '[I:setbarnb 29]', 'r', 'G,/>', 'a4>', 'a4<', '[I:setbarnb 35]', 'B/8', '^G,3', '^G,2', '1/4=176\n', 'Q:', 'D,/', '[K:D]', 'D,2', '^C,2', 'D,6', '1/4=160\n', 'D,4', 'D,8', 'D,>', 'x/', 'B/>', '[I:setbarnb 54]', '^d>', '^a/', 'g/<', 'g/>', 'g/8', '[I:setbarnb 8]', '[K:C]', "f'4", 'Bb clef=bass\n', '1/4\n', "f'3", '9/8\n', "f'/", '^A', '^B', '^C', ']', '^E', '^F', '^G', 'D/', 'D,', '[K:clef=bass]', '^C/', '^C,', 'B4<', 'B4>', 'm', 'D>', 'D<', '^C>', 'E,2<', 'D6', 'D7', '^C2', '^c', 'D2', '[I:setbarnb 18]', '^f', '^g', 'd/', '^c/', "d'", '3/8=240\n', 'd>', '3/8=69\n', 'd<', '^C2<', '^c<', 'd8', 'C<', 'd6', 'd7', '^c2', '^c3', 'd2', 'd3', '^c6', 'F2<', '[I:setbarnb 16]', '_B<', 'Z', '^C2>', '_B8', '_B6', '_B4', '_B2', '_B3', '_f/', '7/4\n', '_B/', '[I:setbarnb 36]', 'x2>', '^a', '[I:setbarnb 99]', '_b>', '_b<', '1/2=52\n', '[I:setbarnb 3]', '_b6', '_b4', 'C2>', '_b3', 'C2<', '_b/', '[I:setbarnb 22]', '^e/>', '[I:setbarnb 38]', '3/8=88\n', 'Z6', 'Z7', '_E/', '[I:setbarnb 31]', '[I:setbarnb 76]', '_E>', '_E3', '_E2', '_E6', '_E4', '_e/', '_E,>', "_e'", '_e8', '_e>', '_e<', '_e3', '_e2', '_e6', '_e4', '[M:10/8]', '_E,3', '[I:setbarnb 46]', '1/8=160\n', '^g2<', '^c2>', '^c2<', '^F,3', 'f2>', 'z/>', 'f2<', '^A/>', 'C', '2/2\n', 'E4>', '^F/>', '3/8=160\n', "d'/", 'E4<', 'C/>', "d'2", "d'3", "d'6", "d'4", "d'8", '[M:2/16]', "d'>", "d'<", '^G4', 'G,8', 'c', '^G2', '^G3', '^G>', 'c2>', 'c2<', "c'2>", '3/8=100\n', '_d2<', '[I:setbarnb 125]', '^F,2>', '^G,', '[M:2/4]', '^G/', '_a2<', '^g4', '1/2=80\n', '^g6', '^d/>', '^g2', '^g3', '^g>', '^g8', ',', 'G,6', '1/4=138\n', '[M:9/4]', '^g/', 'z6', '[I:setbarnb 73]', 'z7', 'C/', 'C,', '_B/>', '[I:setbarnb 28]', 'C8', 'C>', '^c/>', '8/8\n', 'C3', 'C2', 'C6', '[I:setbarnb 32]', 'C4', '^G,>', 'c/', '1/2=76\n', '[I:setbarnb 69]', '^F2>', '^F2<', "c'", '^G6', 'c8', 'c>', '[I:setbarnb 50]', 'c<', 'c3', 'c2', 'c7', 'c6', 'c4', 'D,3', '[M:1/2]', 'A/<', '_A3', '9/4\n', '_a2>', 'c/8', '[I:setbarnb 21]', '^f/>', 'e4>', 'c/<', 'A2>', 'c/>', '[I:setbarnb 7]', '1/4=120\n', '1/2=96\n', '_A/', '_A,', '[I:setbarnb 59]', '_a4', '_a3', '[I:setbarnb 43]', '_A2>', '_a>', 'F/>', 'a2<', 'a2>', '_A,/', '_e4>', '1/2=66\n', '[I:setbarnb 27]', 'A,<', 'D4', '[I:setbarnb 110]', '[I:setbarnb 53]', '[M:22/8]', 'A,/>', '3/8=176\n', '[M:3/16]', '3/8=112\n', '_G7', '1/16\n', '^f2>', '^f2<', 'B,/>', 'B clef=treble\n', '[I:setbarnb 13]', '^e2<', '^F,/', '3/8=116\n', '_E,/', '3/4=66\n', '[I:setbarnb 2]', '_A,4', '^F,>', '[M:9/8]', '[I:setbarnb 25]', '^F,4', '^F,6', '1/4=72\n', '^F,2', '[I:setbarnb 39]', 'Eb clef=bass\n', '[M:8/8]', '[I:setbarnb 67]', 'f/<', 'f/>', 'f/8', '[I:setbarnb 77]', '[M:6/4]', '_A,3', '[M:19/16]', '[I:setbarnb 49]', '_B,', 'D', '3/8=138\n', 'A6', '^g2>', '1/2=44\n', '[I:setbarnb 42]', 'E,8', '^e2>', 'F,/', '1/2=72\n', '_A,2', '3/8=72\n', '[M:3/2]', '14/2\n', 'd', 'B,', 'B/', 'B4', '1/4=132\n', 'B6', 'B7', 't', 'B2', 'B3', 'B<', 'B>', 'B8', 'E,/', '1/2=92\n', 'b/', '3/4\n', '4/2\n', 'b4', 'b6', 'E,>', '_b2<', 'b2', 'b3', 'E,2', 'E,3', 'b>', '12/8\n', 'E,6', 'E,4', '_D,', 'F,>', '1/8=144\n', '_a/', '[I:setbarnb 122]', '[I:setbarnb 10]', '1/8=176\n', '_D4', '[I:setbarnb 138]', '_B2<', '1/8=240\n', '_d/', '_B2>', 'F,4<', "f'2", '_d>', '_d2', '[M:5/4]', '1/4=69\n', '1/4=56\n', '[I:setbarnb 17]', 'B,8', '1/8\n', '_B,2>', 'o', '[I:setbarnb 15]', '[I:setbarnb 37]', '^A2>', '^C,4', '_A<', 'a4', '2/1\n', '[M:4/4]', '^c8', '3/8=120\n', '[M:7/8]', "^c'/", "^c'2", '1/4=60\n', '[I:setbarnb 51]', '[I:setbarnb 92]', '1/4=80\n', '[K:Eb]', '[M:6/8]', '5/4\n', '3/8=66\n', 'i', '^D>', '^D', '1/2=104\n', '^D2', '^D4', 'E/>', '[K:clef=treble]', '[I:setbarnb 6]', '2/8\n', '[M:4/2]', '^D2<', '^D2>', 'C clef=bass\n', 'B/<', 'D2<', "c'/", 'D2>', '[I:setbarnb 85]', '1/2=84\n', '^d3', '^d2', '^d4', '[K:A]', '1/4=144\n', "c'8", "c'<", '^d/', "c'>", 'b/<', "c'3", "c'2", 'C clef=treble\n', "c'4", "c'6", "^d'2", '3/8=92\n', '[I:setbarnb 45]', 'C,>', '1/4=112\n', '1/4=104\n', '3/8=76\n', 'z', "^d'/", '3/8\n', '[I:setbarnb 105]', 'E,<', 'Bb clef=treble\n', '_b2>', '1/8=112\n', '1/4=108\n', 'F/8', '1/4=192\n', 'B,2<', '[M:2/8]', 'B,2>', 'b8', "g'2", 'A,', 'A/', '10/2\n', '1/4=46\n', 'A3', 'A2', 'A4', 'A7', '6/4\n', 'A8', 'C,3', 'A<', '[I:setbarnb 14]', 'A>', '8/16\n', '[I:setbarnb 1]', 'E', 'D8', '[M:3/8]', 'E,', 'F,3', 'F,2', 'F,4', 'a/', 'F,6', 'a3', 'a2', '_E2>', '1/2=69\n', '_E2<', 'a6', 'a8', 'E/8', 'a<', 'G4>', 'a>', '^d2>', '^C3', 'e', 'd2<', 'b/>', 'd2>', '^d', '4/8\n', 'D3', '^G4>', 'u', "_e'2", 'Ab clef=treble\n', '[I:setbarnb 33]'])
vocabulary size: 895
n tunes: 18107
n train tunes: 17195
n validation tunes: 912
min, max length 15 1884
Building the model
  number of parameters: 8345216
  layer output shapes:               #params:   output shape:
    InputLayer                       0          (16, None)
    EmbeddingLayer                   801025     (16, None, 895)
    InputLayer                       0          (16, None)
    LSTMLayer                        2884608    (16, None, 512)
    DropoutLayer                     0          (16, None, 512)
    LSTMLayer                        2100224    (16, None, 512)
    DropoutLayer                     0          (16, None, 512)
    LSTMLayer                        2100224    (16, None, 512)
    DropoutLayer                     0          (16, None, 512)
    ReshapeLayer                     0          (None, 512)
    DenseLayer                       459135     (None, 895)
Train model
1/107400 (epoch 0.001) train_loss=1915.89428711 time/batch=1.17s
2/107400 (epoch 0.002) train_loss=2444.61499023 time/batch=0.56s
3/107400 (epoch 0.003) train_loss=1166.86596680 time/batch=0.41s
4/107400 (epoch 0.004) train_loss=1218.12426758 time/batch=0.42s
5/107400 (epoch 0.005) train_loss=976.73132324 time/batch=0.32s
6/107400 (epoch 0.006) train_loss=1116.24804688 time/batch=0.39s
7/107400 (epoch 0.007) train_loss=3492.70849609 time/batch=1.26s
8/107400 (epoch 0.007) train_loss=506.27679443 time/batch=0.24s
9/107400 (epoch 0.008) train_loss=1104.75988770 time/batch=0.35s
10/107400 (epoch 0.009) train_loss=770.58410645 time/batch=0.28s
11/107400 (epoch 0.010) train_loss=936.72668457 time/batch=0.34s
12/107400 (epoch 0.011) train_loss=220.48257446 time/batch=0.10s
13/107400 (epoch 0.012) train_loss=2378.60278320 time/batch=0.82s
14/107400 (epoch 0.013) train_loss=167.42578125 time/batch=0.12s
15/107400 (epoch 0.014) train_loss=681.45300293 time/batch=0.24s
16/107400 (epoch 0.015) train_loss=1181.57836914 time/batch=0.42s
17/107400 (epoch 0.016) train_loss=563.56640625 time/batch=0.22s
18/107400 (epoch 0.017) train_loss=785.18933105 time/batch=0.28s
19/107400 (epoch 0.018) train_loss=339.49200439 time/batch=0.13s
20/107400 (epoch 0.019) train_loss=1400.48974609 time/batch=0.47s
21/107400 (epoch 0.020) train_loss=565.71960449 time/batch=0.23s
22/107400 (epoch 0.020) train_loss=1515.49230957 time/batch=0.54s
23/107400 (epoch 0.021) train_loss=440.41589355 time/batch=0.18s
24/107400 (epoch 0.022) train_loss=127.79241943 time/batch=0.06s
25/107400 (epoch 0.023) train_loss=1312.37792969 time/batch=0.43s
26/107400 (epoch 0.024) train_loss=433.95312500 time/batch=0.18s
27/107400 (epoch 0.025) train_loss=861.23596191 time/batch=0.30s
28/107400 (epoch 0.026) train_loss=1149.67224121 time/batch=0.44s
29/107400 (epoch 0.027) train_loss=205.45440674 time/batch=0.09s
30/107400 (epoch 0.028) train_loss=1647.03955078 time/batch=0.59s
31/107400 (epoch 0.029) train_loss=3432.83056641 time/batch=1.87s
32/107400 (epoch 0.030) train_loss=777.25085449 time/batch=0.41s
33/107400 (epoch 0.031) train_loss=771.90588379 time/batch=0.27s
34/107400 (epoch 0.032) train_loss=1206.93078613 time/batch=0.44s
35/107400 (epoch 0.033) train_loss=692.63671875 time/batch=0.28s
36/107400 (epoch 0.034) train_loss=1457.64733887 time/batch=0.53s
37/107400 (epoch 0.034) train_loss=3964.28613281 time/batch=2.60s
38/107400 (epoch 0.035) train_loss=444.21670532 time/batch=0.34s
39/107400 (epoch 0.036) train_loss=835.45654297 time/batch=0.31s
40/107400 (epoch 0.037) train_loss=678.67785645 time/batch=0.26s
41/107400 (epoch 0.038) train_loss=1800.15625000 time/batch=0.69s
42/107400 (epoch 0.039) train_loss=173.34201050 time/batch=0.11s
43/107400 (epoch 0.040) train_loss=1246.79064941 time/batch=0.44s
44/107400 (epoch 0.041) train_loss=556.76574707 time/batch=0.24s
45/107400 (epoch 0.042) train_loss=736.77478027 time/batch=0.27s
46/107400 (epoch 0.043) train_loss=1926.95043945 time/batch=0.70s
47/107400 (epoch 0.044) train_loss=655.54150391 time/batch=0.28s
48/107400 (epoch 0.045) train_loss=369.64459229 time/batch=0.15s
49/107400 (epoch 0.046) train_loss=982.27239990 time/batch=0.36s
50/107400 (epoch 0.047) train_loss=309.65164185 time/batch=0.14s
51/107400 (epoch 0.047) train_loss=1319.50097656 time/batch=0.49s
52/107400 (epoch 0.048) train_loss=1125.28784180 time/batch=0.46s
53/107400 (epoch 0.049) train_loss=962.47662354 time/batch=0.36s
54/107400 (epoch 0.050) train_loss=263.55084229 time/batch=0.12s
55/107400 (epoch 0.051) train_loss=727.87408447 time/batch=0.28s
56/107400 (epoch 0.052) train_loss=1802.34741211 time/batch=0.74s
57/107400 (epoch 0.053) train_loss=440.94924927 time/batch=0.20s
58/107400 (epoch 0.054) train_loss=236.79995728 time/batch=0.10s
59/107400 (epoch 0.055) train_loss=681.83251953 time/batch=0.25s
60/107400 (epoch 0.056) train_loss=854.85046387 time/batch=0.32s
61/107400 (epoch 0.057) train_loss=406.99487305 time/batch=0.18s
62/107400 (epoch 0.058) train_loss=549.97741699 time/batch=0.21s
63/107400 (epoch 0.059) train_loss=556.84136963 time/batch=0.22s
64/107400 (epoch 0.060) train_loss=276.63537598 time/batch=0.12s
65/107400 (epoch 0.061) train_loss=461.34008789 time/batch=0.18s
66/107400 (epoch 0.061) train_loss=771.28356934 time/batch=0.30s
67/107400 (epoch 0.062) train_loss=902.44042969 time/batch=0.33s
68/107400 (epoch 0.063) train_loss=467.61416626 time/batch=0.19s
69/107400 (epoch 0.064) train_loss=503.24694824 time/batch=0.20s
70/107400 (epoch 0.065) train_loss=394.88507080 time/batch=0.18s
71/107400 (epoch 0.066) train_loss=615.43725586 time/batch=0.24s
72/107400 (epoch 0.067) train_loss=479.87530518 time/batch=0.20s
73/107400 (epoch 0.068) train_loss=707.27954102 time/batch=0.27s
74/107400 (epoch 0.069) train_loss=262.72805786 time/batch=0.12s
75/107400 (epoch 0.070) train_loss=61.59366608 time/batch=0.04s
76/107400 (epoch 0.071) train_loss=341.75280762 time/batch=0.13s
77/107400 (epoch 0.072) train_loss=686.83264160 time/batch=0.26s
78/107400 (epoch 0.073) train_loss=452.73461914 time/batch=0.17s
79/107400 (epoch 0.074) train_loss=202.32824707 time/batch=0.09s
80/107400 (epoch 0.074) train_loss=330.58459473 time/batch=0.14s
81/107400 (epoch 0.075) train_loss=809.19012451 time/batch=0.30s
82/107400 (epoch 0.076) train_loss=951.68725586 time/batch=0.35s
83/107400 (epoch 0.077) train_loss=512.43933105 time/batch=0.21s
84/107400 (epoch 0.078) train_loss=1234.40075684 time/batch=0.44s
85/107400 (epoch 0.079) train_loss=523.80950928 time/batch=0.23s
86/107400 (epoch 0.080) train_loss=574.63525391 time/batch=0.21s
87/107400 (epoch 0.081) train_loss=843.91418457 time/batch=0.31s
88/107400 (epoch 0.082) train_loss=813.85815430 time/batch=0.33s
89/107400 (epoch 0.083) train_loss=584.89990234 time/batch=0.24s
90/107400 (epoch 0.084) train_loss=764.46148682 time/batch=0.28s
91/107400 (epoch 0.085) train_loss=618.05187988 time/batch=0.25s
92/107400 (epoch 0.086) train_loss=492.77310181 time/batch=0.20s
93/107400 (epoch 0.087) train_loss=863.68957520 time/batch=0.32s
94/107400 (epoch 0.088) train_loss=933.25000000 time/batch=0.35s
95/107400 (epoch 0.088) train_loss=408.95776367 time/batch=0.18s
96/107400 (epoch 0.089) train_loss=684.11041260 time/batch=0.26s
97/107400 (epoch 0.090) train_loss=897.60534668 time/batch=0.34s
98/107400 (epoch 0.091) train_loss=540.83843994 time/batch=0.23s
99/107400 (epoch 0.092) train_loss=348.85565186 time/batch=0.15s
100/107400 (epoch 0.093) train_loss=1115.58251953 time/batch=0.38s
101/107400 (epoch 0.094) train_loss=408.11071777 time/batch=0.18s
102/107400 (epoch 0.095) train_loss=319.16317749 time/batch=0.13s
103/107400 (epoch 0.096) train_loss=689.46240234 time/batch=0.25s
104/107400 (epoch 0.097) train_loss=885.14587402 time/batch=0.34s
105/107400 (epoch 0.098) train_loss=110.18453217 time/batch=0.09s
106/107400 (epoch 0.099) train_loss=1415.98376465 time/batch=0.71s
107/107400 (epoch 0.100) train_loss=116.82040405 time/batch=0.11s
108/107400 (epoch 0.101) train_loss=111.19333649 time/batch=0.06s
109/107400 (epoch 0.101) train_loss=791.03295898 time/batch=0.29s
110/107400 (epoch 0.102) train_loss=716.09472656 time/batch=0.28s
111/107400 (epoch 0.103) train_loss=699.95660400 time/batch=0.28s
112/107400 (epoch 0.104) train_loss=418.75433350 time/batch=0.18s
113/107400 (epoch 0.105) train_loss=777.73071289 time/batch=0.30s
114/107400 (epoch 0.106) train_loss=938.00402832 time/batch=0.36s
115/107400 (epoch 0.107) train_loss=672.68359375 time/batch=0.27s
116/107400 (epoch 0.108) train_loss=446.90539551 time/batch=0.18s
117/107400 (epoch 0.109) train_loss=1014.30389404 time/batch=0.36s
118/107400 (epoch 0.110) train_loss=504.07684326 time/batch=0.22s
119/107400 (epoch 0.111) train_loss=369.29394531 time/batch=0.15s
120/107400 (epoch 0.112) train_loss=456.18029785 time/batch=0.20s
121/107400 (epoch 0.113) train_loss=371.34338379 time/batch=0.15s
122/107400 (epoch 0.114) train_loss=781.04443359 time/batch=0.30s
123/107400 (epoch 0.115) train_loss=682.29882812 time/batch=0.26s
124/107400 (epoch 0.115) train_loss=322.68307495 time/batch=0.15s
125/107400 (epoch 0.116) train_loss=1113.06921387 time/batch=0.45s
126/107400 (epoch 0.117) train_loss=642.34277344 time/batch=0.27s
127/107400 (epoch 0.118) train_loss=684.76818848 time/batch=0.27s
128/107400 (epoch 0.119) train_loss=796.86572266 time/batch=0.32s
129/107400 (epoch 0.120) train_loss=581.01080322 time/batch=0.23s
130/107400 (epoch 0.121) train_loss=636.18359375 time/batch=0.25s
131/107400 (epoch 0.122) train_loss=246.35546875 time/batch=0.11s
132/107400 (epoch 0.123) train_loss=269.71929932 time/batch=0.11s
133/107400 (epoch 0.124) train_loss=982.13385010 time/batch=0.36s
134/107400 (epoch 0.125) train_loss=591.89324951 time/batch=0.24s
135/107400 (epoch 0.126) train_loss=534.52178955 time/batch=0.22s
136/107400 (epoch 0.127) train_loss=461.11221313 time/batch=0.18s
137/107400 (epoch 0.128) train_loss=1149.88269043 time/batch=0.46s
138/107400 (epoch 0.128) train_loss=82.97846985 time/batch=0.09s
139/107400 (epoch 0.129) train_loss=503.78414917 time/batch=0.17s
140/107400 (epoch 0.130) train_loss=429.91137695 time/batch=0.17s
141/107400 (epoch 0.131) train_loss=1035.26904297 time/batch=0.37s
142/107400 (epoch 0.132) train_loss=542.23352051 time/batch=0.22s
143/107400 (epoch 0.133) train_loss=736.79797363 time/batch=0.28s
144/107400 (epoch 0.134) train_loss=746.88977051 time/batch=0.30s
145/107400 (epoch 0.135) train_loss=627.89404297 time/batch=0.24s
146/107400 (epoch 0.136) train_loss=843.06274414 time/batch=0.30s
147/107400 (epoch 0.137) train_loss=259.45062256 time/batch=0.13s
148/107400 (epoch 0.138) train_loss=720.45654297 time/batch=0.27s
149/107400 (epoch 0.139) train_loss=863.18713379 time/batch=0.32s
150/107400 (epoch 0.140) train_loss=368.29248047 time/batch=0.16s
151/107400 (epoch 0.141) train_loss=206.70645142 time/batch=0.11s
152/107400 (epoch 0.142) train_loss=482.73693848 time/batch=0.18s
153/107400 (epoch 0.142) train_loss=604.05200195 time/batch=0.24s
154/107400 (epoch 0.143) train_loss=248.18092346 time/batch=0.11s
155/107400 (epoch 0.144) train_loss=219.38195801 time/batch=0.11s
156/107400 (epoch 0.145) train_loss=557.23132324 time/batch=0.20s
157/107400 (epoch 0.146) train_loss=244.73522949 time/batch=0.11s
158/107400 (epoch 0.147) train_loss=470.76303101 time/batch=0.18s
159/107400 (epoch 0.148) train_loss=846.18591309 time/batch=0.31s
160/107400 (epoch 0.149) train_loss=618.33129883 time/batch=0.25s
161/107400 (epoch 0.150) train_loss=896.32977295 time/batch=0.33s
162/107400 (epoch 0.151) train_loss=416.73791504 time/batch=0.18s
163/107400 (epoch 0.152) train_loss=110.84222412 time/batch=0.07s
164/107400 (epoch 0.153) train_loss=551.79455566 time/batch=0.20s
165/107400 (epoch 0.154) train_loss=363.24642944 time/batch=0.15s
166/107400 (epoch 0.155) train_loss=535.50604248 time/batch=0.21s
167/107400 (epoch 0.155) train_loss=253.93615723 time/batch=0.12s
168/107400 (epoch 0.156) train_loss=178.72860718 time/batch=0.09s
169/107400 (epoch 0.157) train_loss=394.46374512 time/batch=0.15s
170/107400 (epoch 0.158) train_loss=516.60119629 time/batch=0.20s
171/107400 (epoch 0.159) train_loss=660.07861328 time/batch=0.26s
172/107400 (epoch 0.160) train_loss=282.95996094 time/batch=0.14s
173/107400 (epoch 0.161) train_loss=332.31951904 time/batch=0.13s
174/107400 (epoch 0.162) train_loss=929.52978516 time/batch=0.34s
175/107400 (epoch 0.163) train_loss=472.71435547 time/batch=0.20s
176/107400 (epoch 0.164) train_loss=205.27352905 time/batch=0.11s
177/107400 (epoch 0.165) train_loss=730.71801758 time/batch=0.27s
178/107400 (epoch 0.166) train_loss=779.97583008 time/batch=0.31s
179/107400 (epoch 0.167) train_loss=224.80703735 time/batch=0.11s
180/107400 (epoch 0.168) train_loss=787.20269775 time/batch=0.28s
181/107400 (epoch 0.169) train_loss=364.34948730 time/batch=0.16s
182/107400 (epoch 0.169) train_loss=566.59777832 time/batch=0.21s
183/107400 (epoch 0.170) train_loss=313.40637207 time/batch=0.14s
184/107400 (epoch 0.171) train_loss=547.50170898 time/batch=0.21s
185/107400 (epoch 0.172) train_loss=698.41607666 time/batch=0.26s
186/107400 (epoch 0.173) train_loss=955.19451904 time/batch=0.38s
187/107400 (epoch 0.174) train_loss=650.10772705 time/batch=0.26s
188/107400 (epoch 0.175) train_loss=623.38763428 time/batch=0.25s
189/107400 (epoch 0.176) train_loss=437.54122925 time/batch=0.17s
190/107400 (epoch 0.177) train_loss=270.26672363 time/batch=0.12s
191/107400 (epoch 0.178) train_loss=583.50097656 time/batch=0.23s
192/107400 (epoch 0.179) train_loss=444.65594482 time/batch=0.19s
193/107400 (epoch 0.180) train_loss=544.52526855 time/batch=0.21s
194/107400 (epoch 0.181) train_loss=874.78143311 time/batch=0.37s
195/107400 (epoch 0.182) train_loss=348.74301147 time/batch=0.16s
196/107400 (epoch 0.182) train_loss=509.84906006 time/batch=0.20s
197/107400 (epoch 0.183) train_loss=431.86737061 time/batch=0.16s
198/107400 (epoch 0.184) train_loss=256.45300293 time/batch=0.12s
199/107400 (epoch 0.185) train_loss=640.55090332 time/batch=0.24s
200/107400 (epoch 0.186) train_loss=173.23225403 time/batch=0.09s
201/107400 (epoch 0.187) train_loss=561.96423340 time/batch=0.22s
202/107400 (epoch 0.188) train_loss=579.08312988 time/batch=0.24s
203/107400 (epoch 0.189) train_loss=207.53157043 time/batch=0.09s
204/107400 (epoch 0.190) train_loss=104.24211884 time/batch=0.07s
205/107400 (epoch 0.191) train_loss=462.13854980 time/batch=0.18s
206/107400 (epoch 0.192) train_loss=737.57922363 time/batch=0.27s
207/107400 (epoch 0.193) train_loss=555.44677734 time/batch=0.23s
208/107400 (epoch 0.194) train_loss=324.28088379 time/batch=0.14s
209/107400 (epoch 0.195) train_loss=286.35919189 time/batch=0.12s
210/107400 (epoch 0.196) train_loss=293.36193848 time/batch=0.12s
211/107400 (epoch 0.196) train_loss=153.87074280 time/batch=0.08s
212/107400 (epoch 0.197) train_loss=139.50987244 time/batch=0.07s
213/107400 (epoch 0.198) train_loss=316.12203979 time/batch=0.13s
214/107400 (epoch 0.199) train_loss=633.45782471 time/batch=0.22s
215/107400 (epoch 0.200) train_loss=450.56869507 time/batch=0.17s
216/107400 (epoch 0.201) train_loss=709.44689941 time/batch=0.27s
217/107400 (epoch 0.202) train_loss=213.37429810 time/batch=0.11s
218/107400 (epoch 0.203) train_loss=673.67724609 time/batch=0.25s
219/107400 (epoch 0.204) train_loss=259.38989258 time/batch=0.12s
220/107400 (epoch 0.205) train_loss=511.36248779 time/batch=0.19s
221/107400 (epoch 0.206) train_loss=202.57324219 time/batch=0.09s
222/107400 (epoch 0.207) train_loss=178.57188416 time/batch=0.10s
223/107400 (epoch 0.208) train_loss=727.76629639 time/batch=0.27s
224/107400 (epoch 0.209) train_loss=646.21575928 time/batch=0.25s
225/107400 (epoch 0.209) train_loss=308.44558716 time/batch=0.14s
226/107400 (epoch 0.210) train_loss=413.53576660 time/batch=0.17s
227/107400 (epoch 0.211) train_loss=240.52395630 time/batch=0.12s
228/107400 (epoch 0.212) train_loss=339.42080688 time/batch=0.15s
229/107400 (epoch 0.213) train_loss=626.26147461 time/batch=0.23s
230/107400 (epoch 0.214) train_loss=440.82366943 time/batch=0.20s
231/107400 (epoch 0.215) train_loss=273.94445801 time/batch=0.12s
232/107400 (epoch 0.216) train_loss=107.78313446 time/batch=0.06s
233/107400 (epoch 0.217) train_loss=311.70874023 time/batch=0.13s
234/107400 (epoch 0.218) train_loss=499.83459473 time/batch=0.19s
235/107400 (epoch 0.219) train_loss=254.24073792 time/batch=0.12s
236/107400 (epoch 0.220) train_loss=134.69189453 time/batch=0.08s
237/107400 (epoch 0.221) train_loss=814.71374512 time/batch=0.28s
238/107400 (epoch 0.222) train_loss=286.99536133 time/batch=0.13s
239/107400 (epoch 0.223) train_loss=385.01724243 time/batch=0.16s
240/107400 (epoch 0.223) train_loss=616.24462891 time/batch=0.23s
241/107400 (epoch 0.224) train_loss=388.91821289 time/batch=0.17s
242/107400 (epoch 0.225) train_loss=720.50665283 time/batch=0.25s
243/107400 (epoch 0.226) train_loss=299.68319702 time/batch=0.14s
244/107400 (epoch 0.227) train_loss=593.56536865 time/batch=0.24s
245/107400 (epoch 0.228) train_loss=574.79632568 time/batch=0.22s
246/107400 (epoch 0.229) train_loss=418.40359497 time/batch=0.17s
247/107400 (epoch 0.230) train_loss=132.46041870 time/batch=0.07s
248/107400 (epoch 0.231) train_loss=194.49496460 time/batch=0.08s
249/107400 (epoch 0.232) train_loss=744.57946777 time/batch=0.28s
250/107400 (epoch 0.233) train_loss=445.35491943 time/batch=0.20s
251/107400 (epoch 0.234) train_loss=491.31643677 time/batch=0.19s
252/107400 (epoch 0.235) train_loss=360.16754150 time/batch=0.15s
253/107400 (epoch 0.236) train_loss=529.32269287 time/batch=0.21s
254/107400 (epoch 0.236) train_loss=448.27682495 time/batch=0.18s
255/107400 (epoch 0.237) train_loss=345.86489868 time/batch=0.14s
256/107400 (epoch 0.238) train_loss=214.64166260 time/batch=0.09s
257/107400 (epoch 0.239) train_loss=375.48410034 time/batch=0.16s
258/107400 (epoch 0.240) train_loss=159.42840576 time/batch=0.07s
259/107400 (epoch 0.241) train_loss=366.69256592 time/batch=0.15s
260/107400 (epoch 0.242) train_loss=132.32897949 time/batch=0.07s
261/107400 (epoch 0.243) train_loss=617.80419922 time/batch=0.23s
262/107400 (epoch 0.244) train_loss=611.19519043 time/batch=0.24s
263/107400 (epoch 0.245) train_loss=710.64447021 time/batch=0.28s
264/107400 (epoch 0.246) train_loss=281.92279053 time/batch=0.13s
265/107400 (epoch 0.247) train_loss=353.37405396 time/batch=0.15s
266/107400 (epoch 0.248) train_loss=366.04714966 time/batch=0.16s
267/107400 (epoch 0.249) train_loss=673.61090088 time/batch=0.26s
268/107400 (epoch 0.250) train_loss=543.37030029 time/batch=0.21s
269/107400 (epoch 0.250) train_loss=718.63195801 time/batch=0.27s
270/107400 (epoch 0.251) train_loss=731.75122070 time/batch=0.28s
271/107400 (epoch 0.252) train_loss=629.08306885 time/batch=0.25s
272/107400 (epoch 0.253) train_loss=513.43426514 time/batch=0.20s
273/107400 (epoch 0.254) train_loss=357.95178223 time/batch=0.15s
274/107400 (epoch 0.255) train_loss=366.96096802 time/batch=0.16s
275/107400 (epoch 0.256) train_loss=175.27508545 time/batch=0.09s
276/107400 (epoch 0.257) train_loss=396.05847168 time/batch=0.16s
277/107400 (epoch 0.258) train_loss=380.45370483 time/batch=0.16s
278/107400 (epoch 0.259) train_loss=541.81817627 time/batch=0.22s
279/107400 (epoch 0.260) train_loss=202.97409058 time/batch=0.10s
280/107400 (epoch 0.261) train_loss=666.39587402 time/batch=0.25s
281/107400 (epoch 0.262) train_loss=543.79803467 time/batch=0.22s
282/107400 (epoch 0.263) train_loss=216.04254150 time/batch=0.11s
283/107400 (epoch 0.264) train_loss=154.25378418 time/batch=0.07s
284/107400 (epoch 0.264) train_loss=217.30317688 time/batch=0.09s
285/107400 (epoch 0.265) train_loss=291.02868652 time/batch=0.13s
286/107400 (epoch 0.266) train_loss=434.56399536 time/batch=0.18s
287/107400 (epoch 0.267) train_loss=151.94732666 time/batch=0.08s
288/107400 (epoch 0.268) train_loss=586.50616455 time/batch=0.21s
289/107400 (epoch 0.269) train_loss=237.15188599 time/batch=0.11s
290/107400 (epoch 0.270) train_loss=706.34564209 time/batch=0.26s
291/107400 (epoch 0.271) train_loss=657.69116211 time/batch=0.25s
292/107400 (epoch 0.272) train_loss=156.86932373 time/batch=0.09s
293/107400 (epoch 0.273) train_loss=283.36993408 time/batch=0.12s
294/107400 (epoch 0.274) train_loss=342.78793335 time/batch=0.15s
295/107400 (epoch 0.275) train_loss=168.40577698 time/batch=0.08s
296/107400 (epoch 0.276) train_loss=170.95632935 time/batch=0.08s
297/107400 (epoch 0.277) train_loss=696.37701416 time/batch=0.25s
298/107400 (epoch 0.277) train_loss=272.02862549 time/batch=0.12s
299/107400 (epoch 0.278) train_loss=245.48725891 time/batch=0.11s
300/107400 (epoch 0.279) train_loss=508.91708374 time/batch=0.20s
301/107400 (epoch 0.280) train_loss=334.93679810 time/batch=0.14s
302/107400 (epoch 0.281) train_loss=377.07855225 time/batch=0.14s
303/107400 (epoch 0.282) train_loss=615.00067139 time/batch=0.23s
304/107400 (epoch 0.283) train_loss=279.06030273 time/batch=0.13s
305/107400 (epoch 0.284) train_loss=536.74810791 time/batch=0.21s
306/107400 (epoch 0.285) train_loss=324.69970703 time/batch=0.15s
307/107400 (epoch 0.286) train_loss=403.13610840 time/batch=0.16s
308/107400 (epoch 0.287) train_loss=622.10668945 time/batch=0.24s
309/107400 (epoch 0.288) train_loss=325.95892334 time/batch=0.15s
310/107400 (epoch 0.289) train_loss=665.87957764 time/batch=0.25s
311/107400 (epoch 0.290) train_loss=701.67797852 time/batch=0.27s
312/107400 (epoch 0.291) train_loss=561.44897461 time/batch=0.23s
313/107400 (epoch 0.291) train_loss=351.66278076 time/batch=0.15s
314/107400 (epoch 0.292) train_loss=257.43823242 time/batch=0.11s
315/107400 (epoch 0.293) train_loss=299.98953247 time/batch=0.12s
316/107400 (epoch 0.294) train_loss=375.33013916 time/batch=0.16s
317/107400 (epoch 0.295) train_loss=190.51095581 time/batch=0.09s
318/107400 (epoch 0.296) train_loss=652.62640381 time/batch=0.24s
319/107400 (epoch 0.297) train_loss=231.59085083 time/batch=0.12s
320/107400 (epoch 0.298) train_loss=473.40997314 time/batch=0.17s
321/107400 (epoch 0.299) train_loss=239.33813477 time/batch=0.11s
322/107400 (epoch 0.300) train_loss=596.01153564 time/batch=0.23s
323/107400 (epoch 0.301) train_loss=741.42382812 time/batch=0.29s
324/107400 (epoch 0.302) train_loss=815.06927490 time/batch=0.37s
325/107400 (epoch 0.303) train_loss=194.84341431 time/batch=0.10s
326/107400 (epoch 0.304) train_loss=418.89300537 time/batch=0.16s
327/107400 (epoch 0.304) train_loss=122.17138672 time/batch=0.07s
328/107400 (epoch 0.305) train_loss=396.36148071 time/batch=0.16s
329/107400 (epoch 0.306) train_loss=625.33178711 time/batch=0.25s
330/107400 (epoch 0.307) train_loss=284.78048706 time/batch=0.13s
331/107400 (epoch 0.308) train_loss=472.46517944 time/batch=0.20s
332/107400 (epoch 0.309) train_loss=130.97352600 time/batch=0.07s
333/107400 (epoch 0.310) train_loss=516.33020020 time/batch=0.20s
334/107400 (epoch 0.311) train_loss=405.45135498 time/batch=0.17s
335/107400 (epoch 0.312) train_loss=431.68865967 time/batch=0.18s
336/107400 (epoch 0.313) train_loss=736.07043457 time/batch=0.29s
337/107400 (epoch 0.314) train_loss=328.60253906 time/batch=0.14s
338/107400 (epoch 0.315) train_loss=572.94360352 time/batch=0.22s
339/107400 (epoch 0.316) train_loss=539.13049316 time/batch=0.22s
340/107400 (epoch 0.317) train_loss=241.88497925 time/batch=0.11s
341/107400 (epoch 0.318) train_loss=133.24743652 time/batch=0.07s
342/107400 (epoch 0.318) train_loss=215.17835999 time/batch=0.10s
343/107400 (epoch 0.319) train_loss=334.09722900 time/batch=0.14s
344/107400 (epoch 0.320) train_loss=119.97216797 time/batch=0.07s
345/107400 (epoch 0.321) train_loss=312.88836670 time/batch=0.12s
