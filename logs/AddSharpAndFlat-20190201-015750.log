set(['1/4=76\n', '[I:setbarnb 80]', 'G2>', 'G2<', '1/2=56\n', '1/2=60\n', '[I:setbarnb 61]', '[K:F]', '[I:setbarnb 91]', '[I:setbarnb 41]', 'G7', 'G6', 'G4', 'G3', 'G2', '[I:setbarnb 48]', 'G>', 'G<', '[I:setbarnb 56]', 'G8', '1/2=100\n', 'G/', 'G,', 'g7', 'g6', 'g4', 'g3', 'g2', 'g>', 'g<', 'F2', 'g8', "g'", '_A4', 'F4>', '1/4=152\n', 'g/', '16/2\n', "^c'", '_A2', '^A2', 'B2>', 'B2<', '^A6', 'G,4<', '^A4', 'G,4>', 'F clef=treble\n', '^A>', '8/4\n', '^A<', 'c4<', '_e2>', '[I:setbarnb 58]', '_e2<', '_A>', '3/8=60\n', 'e/8', 'e/>', '3/4=60\n', 'e/<', '1/4=100\n', 'b2>', 'b2<', '^a6', '^c>', '^a4', 'A,2>', 'A2<', 'e4<', 'n', 'd4', 'M:', '1/4=84\n', '^E/', 'g2>', '^c4', 'g2<', 'E,2>', 'Db clef=treble\n', 'F2>', '3/8=144\n', '[I:setbarnb 34]', '[K:G]', 'Z4', 'Z5', 'A clef=treble\n', '3/8=132\n', 'Z2', 'Z3', '_B>', 'z/', '[K:F#]', '3/4=63\n', '^d6', 'G,/', '^c7', '[I:setbarnb 5]', 'z<', '1/2=88\n', 'z>', 'Eb clef=treble\n', 'z8', '[I:setbarnb 24]', 'G,>', 'z4', '1/2=54\n', 'G,2', 'G,3', 'G,4', 'z2', 'z3', 'A,/', '_G/', 'F7', 'g4<', 'E clef=treble\n', '[I:setbarnb 66]', 'A,>', '[M:3/4]', '6/8\n', 'A,8', 'A,6', 'A,4', 'A,2', 'A,3', '3/2\n', '_G2', "d'2<", "d'2>", "d'4>", '12/2\n', 'A4>', 'B,>', '1/4=96\n', "e'2>", 'G/<', 'e7', '3/8=184\n', '_g2', "c'2<", '6/2\n', '_d4', 'D clef=bass\n', 'C,2>', 'C,2<', 'F/<', "c'/>", '[I:setbarnb 40]', '_A2<', '5/8\n', 'F', 'E2<', '^e2', 'E2>', '^e3', '_A8', 'B,3', '[M:4/8]', 'F,2<', 'F,2>', 'F3', 'F4', 'F6', 'f', 'F8', 'c4>', '1/8=152\n', 'F<', '^E3', 'F>', 'F clef=bass\n', '[I:setbarnb 11]', '^G,2>', '3/8=126\n', 'F,', '1/4=168\n', 'F/', '^e>', 'B,<', 'f2', 'f3', 'f4', '[M:10/4]', 'f6', 'f7', 'f8', 'B,4', '^e4', 'B,6', 'f<', 'F4<', 'f>', 'B,2', '^e/', 'B,/', '^d<', "f'", '^D,4', '[I:setbarnb 78]', 'f/', '[I:setbarnb 30]', '[I:setbarnb 65]', '^B/', '^B,', 'x/>', 'z2>', 'z2<', '^C,2>', '1/4=88\n', '[M:6/2]', '^B3', '^B2', '^E4', '^B4', 'A', '[I:setbarnb 93]', 'w', '[M:8/4]', '_b2', 'G,<', '[I:setbarnb 44]', '^G2>', '^D,2', 'D4<', 'L:', 'a', '3/8=108\n', 'e2<', 'e2>', '[I:setbarnb 23]', '[M:5/8]', '[K:Bb]', '^C4', '^E2', '[I:setbarnb 9]', '[I:setbarnb 71]', '_a2', '_G', '_E', '_D', '_B', '_A', '[I:setbarnb 68]', '^c4<', '^c4>', 'D,<', 'f4<', '[M:7/4]', 'f4>', '[I:setbarnb 116]', '3/8=80\n', '_g', 'A/>', '_e', '_d', '_c', '_b', '_a', 'A/8', '^G,4', '^A3', '1/2=63\n', 'D clef=treble\n', '3/8=96\n', '2/4\n', 'D/>', 'a/>', '[I:setbarnb 134]', 'a/<', "e'>", 'A,4>', "e'3", "e'2", '_E,', 'l', '1/8=120\n', '[M:2/2]', 'A,4<', "e'/", 'd4>', 'd4<', "^c'4", '|', 'C,/', 'b<', '[I:setbarnb 4]', '^A,>', '[M:1/4]', '1/8=168\n', '[I:setbarnb 57]', 'C,8', 'C,4', '[K:Ab]', 'C,6', 'G4<', 'C,2', '1/4=92\n', 'G clef=treble\n', '^F6', 'E/', '^F4', '^F3', '^F2', 'p', '5/2\n', '^F>', '^F<', '_A,/>', '^F8', 'E<', 'E>', '3/8=168\n', 'E8', '3/8=63\n', '^F/', 'E4', 'E7', 'E6', '3/8=152\n', 'E3', 'E2', '^f6', 'e/', '^f4', '^f3', '^f2', 'G', '^f>', "e'", '^f<', "^f'", 'e<', 'e>', 'e8', 'x', '^f/', 'e4', 'A4<', 'e6', 'e3', 'e2', '_B,4', '1/2=120\n', '_B,2', 'g', 'G clef=bass\n', '^A/', 'G,2>', 'd/8', 'G,2<', 'd/>', '^A,', 'd/<', '[I:setbarnb 20]', '_B,/', '^D3', 'D4>', '1/4=126\n', '^a2', '^F,', '4/4\n', '^G2<', 'D,2>', 'D,2<', '1/2=152\n', '[I:setbarnb 26]', 'G/>', 'G/8', 'K:', "e'4", '[M:13/8]', 'A,2<', '^b', '[I:setbarnb 12]', '[M:2/1]', '1/2=48\n', '7/8\n', 'g4>', '^C,3', 'B', '^D/', '^C,6', '3/8=84\n', '[M:12/8]', '^C,>', 'x8', 'x>', '^e', 'x2', 'x3', 'x6', 'x7', 'x4', 'b', '[I:setbarnb 19]', "e'6", '3/4=69\n', '[I:setbarnb 29]', 'r', 'G,/>', 'a4>', 'a4<', '[I:setbarnb 35]', 'B/8', '^G,3', '^G,2', '1/4=176\n', 'Q:', 'D,/', '[K:D]', 'D,2', '^C,2', 'D,6', '1/4=160\n', 'D,4', 'D,8', 'D,>', 'x/', 'B/>', '[I:setbarnb 54]', '^d>', '^a/', 'g/<', 'g/>', 'g/8', '[I:setbarnb 8]', '[K:C]', "f'4", 'Bb clef=bass\n', '1/4\n', "f'3", '9/8\n', "f'/", '^A', '^B', '^C', ']', '^E', '^F', '^G', 'D/', 'D,', '[K:clef=bass]', '^C/', '^C,', 'B4<', 'B4>', 'm', 'D>', 'D<', '^C>', 'E,2<', 'D6', 'D7', '^C2', '^c', 'D2', '[I:setbarnb 18]', '^f', '^g', 'd/', '^c/', "d'", '3/8=240\n', 'd>', '3/8=69\n', 'd<', '^C2<', '^c<', 'd8', 'C<', 'd6', 'd7', '^c2', '^c3', 'd2', 'd3', '^c6', 'F2<', '[I:setbarnb 16]', '_B<', 'Z', '^C2>', '_B8', '_B6', '_B4', '_B2', '_B3', '_f/', '7/4\n', '_B/', '[I:setbarnb 36]', 'x2>', '^a', '[I:setbarnb 99]', '_b>', '_b<', '1/2=52\n', '[I:setbarnb 3]', '_b6', '_b4', 'C2>', '_b3', 'C2<', '_b/', '[I:setbarnb 22]', '^e/>', '[I:setbarnb 38]', '3/8=88\n', 'Z6', 'Z7', '_E/', '[I:setbarnb 31]', '[I:setbarnb 76]', '_E>', '_E3', '_E2', '_E6', '_E4', '_e/', '_E,>', "_e'", '_e8', '_e>', '_e<', '_e3', '_e2', '_e6', '_e4', '[M:10/8]', '_E,3', '[I:setbarnb 46]', '1/8=160\n', '^g2<', '^c2>', '^c2<', '^F,3', 'f2>', 'z/>', 'f2<', '^A/>', 'C', '2/2\n', 'E4>', '^F/>', '3/8=160\n', "d'/", 'E4<', 'C/>', "d'2", "d'3", "d'6", "d'4", "d'8", '[M:2/16]', "d'>", "d'<", '^G4', 'G,8', 'c', '^G2', '^G3', '^G>', 'c2>', 'c2<', "c'2>", '3/8=100\n', '_d2<', '[I:setbarnb 125]', '^F,2>', '^G,', '[M:2/4]', '^G/', '_a2<', '^g4', '1/2=80\n', '^g6', '^d/>', '^g2', '^g3', '^g>', '^g8', ',', 'G,6', '1/4=138\n', '[M:9/4]', '^g/', 'z6', '[I:setbarnb 73]', 'z7', 'C/', 'C,', '_B/>', '[I:setbarnb 28]', 'C8', 'C>', '^c/>', '8/8\n', 'C3', 'C2', 'C6', '[I:setbarnb 32]', 'C4', '^G,>', 'c/', '1/2=76\n', '[I:setbarnb 69]', '^F2>', '^F2<', "c'", '^G6', 'c8', 'c>', '[I:setbarnb 50]', 'c<', 'c3', 'c2', 'c7', 'c6', 'c4', 'D,3', '[M:1/2]', 'A/<', '_A3', '9/4\n', '_a2>', 'c/8', '[I:setbarnb 21]', '^f/>', 'e4>', 'c/<', 'A2>', 'c/>', '[I:setbarnb 7]', '1/4=120\n', '1/2=96\n', '_A/', '_A,', '[I:setbarnb 59]', '_a4', '_a3', '[I:setbarnb 43]', '_A2>', '_a>', 'F/>', 'a2<', 'a2>', '_A,/', '_e4>', '1/2=66\n', '[I:setbarnb 27]', 'A,<', 'D4', '[I:setbarnb 110]', '[I:setbarnb 53]', '[M:22/8]', 'A,/>', '3/8=176\n', '[M:3/16]', '3/8=112\n', '_G7', '1/16\n', '^f2>', '^f2<', 'B,/>', 'B clef=treble\n', '[I:setbarnb 13]', '^e2<', '^F,/', '3/8=116\n', '_E,/', '3/4=66\n', '[I:setbarnb 2]', '_A,4', '^F,>', '[M:9/8]', '[I:setbarnb 25]', '^F,4', '^F,6', '1/4=72\n', '^F,2', '[I:setbarnb 39]', 'Eb clef=bass\n', '[M:8/8]', '[I:setbarnb 67]', 'f/<', 'f/>', 'f/8', '[I:setbarnb 77]', '[M:6/4]', '_A,3', '[M:19/16]', '[I:setbarnb 49]', '_B,', 'D', '3/8=138\n', 'A6', '^g2>', '1/2=44\n', '[I:setbarnb 42]', 'E,8', '^e2>', 'F,/', '1/2=72\n', '_A,2', '3/8=72\n', '[M:3/2]', '14/2\n', 'd', 'B,', 'B/', 'B4', '1/4=132\n', 'B6', 'B7', 't', 'B2', 'B3', 'B<', 'B>', 'B8', 'E,/', '1/2=92\n', 'b/', '3/4\n', '4/2\n', 'b4', 'b6', 'E,>', '_b2<', 'b2', 'b3', 'E,2', 'E,3', 'b>', '12/8\n', 'E,6', 'E,4', '_D,', 'F,>', '1/8=144\n', '_a/', '[I:setbarnb 122]', '[I:setbarnb 10]', '1/8=176\n', '_D4', '[I:setbarnb 138]', '_B2<', '1/8=240\n', '_d/', '_B2>', 'F,4<', "f'2", '_d>', '_d2', '[M:5/4]', '1/4=69\n', '1/4=56\n', '[I:setbarnb 17]', 'B,8', '1/8\n', '_B,2>', 'o', '[I:setbarnb 15]', '[I:setbarnb 37]', '^A2>', '^C,4', '_A<', 'a4', '2/1\n', '[M:4/4]', '^c8', '3/8=120\n', '[M:7/8]', "^c'/", "^c'2", '1/4=60\n', '[I:setbarnb 51]', '[I:setbarnb 92]', '1/4=80\n', '[K:Eb]', '[M:6/8]', '5/4\n', '3/8=66\n', 'i', '^D>', '^D', '1/2=104\n', '^D2', '^D4', 'E/>', '[K:clef=treble]', '[I:setbarnb 6]', '2/8\n', '[M:4/2]', '^D2<', '^D2>', 'C clef=bass\n', 'B/<', 'D2<', "c'/", 'D2>', '[I:setbarnb 85]', '1/2=84\n', '^d3', '^d2', '^d4', '[K:A]', '1/4=144\n', "c'8", "c'<", '^d/', "c'>", 'b/<', "c'3", "c'2", 'C clef=treble\n', "c'4", "c'6", "^d'2", '3/8=92\n', '[I:setbarnb 45]', 'C,>', '1/4=112\n', '1/4=104\n', '3/8=76\n', 'z', "^d'/", '3/8\n', '[I:setbarnb 105]', 'E,<', 'Bb clef=treble\n', '_b2>', '1/8=112\n', '1/4=108\n', 'F/8', '1/4=192\n', 'B,2<', '[M:2/8]', 'B,2>', 'b8', "g'2", 'A,', 'A/', '10/2\n', '1/4=46\n', 'A3', 'A2', 'A4', 'A7', '6/4\n', 'A8', 'C,3', 'A<', '[I:setbarnb 14]', 'A>', '8/16\n', '[I:setbarnb 1]', 'E', 'D8', '[M:3/8]', 'E,', 'F,3', 'F,2', 'F,4', 'a/', 'F,6', 'a3', 'a2', '_E2>', '1/2=69\n', '_E2<', 'a6', 'a8', 'E/8', 'a<', 'G4>', 'a>', '^d2>', '^C3', 'e', 'd2<', 'b/>', 'd2>', '^d', '4/8\n', 'D3', '^G4>', 'u', "_e'2", 'Ab clef=treble\n', '[I:setbarnb 33]'])
vocabulary size: 895
n tunes: 18107
n train tunes: 17211
n validation tunes: 896
min, max length 15 1884
Building the model
  number of parameters: 8345216
  layer output shapes:               #params:   output shape:
    InputLayer                       0          (32, None)
    EmbeddingLayer                   801025     (32, None, 895)
    InputLayer                       0          (32, None)
    LSTMLayer                        2884608    (32, None, 512)
    DropoutLayer                     0          (32, None, 512)
    LSTMLayer                        2100224    (32, None, 512)
    DropoutLayer                     0          (32, None, 512)
    LSTMLayer                        2100224    (32, None, 512)
    DropoutLayer                     0          (32, None, 512)
    ReshapeLayer                     0          (None, 512)
    DenseLayer                       459135     (None, 895)
Train model
1/53700 (epoch 0.002) train_loss=3950.28222656 time/batch=1.75s
2/53700 (epoch 0.004) train_loss=2913.81958008 time/batch=0.84s
3/53700 (epoch 0.006) train_loss=219.11042786 time/batch=0.17s
4/53700 (epoch 0.007) train_loss=1266.28247070 time/batch=0.43s
5/53700 (epoch 0.009) train_loss=1409.28027344 time/batch=0.54s
6/53700 (epoch 0.011) train_loss=1530.09375000 time/batch=0.58s
7/53700 (epoch 0.013) train_loss=1058.91247559 time/batch=0.45s
8/53700 (epoch 0.015) train_loss=1114.79016113 time/batch=0.46s
9/53700 (epoch 0.017) train_loss=964.57202148 time/batch=0.42s
10/53700 (epoch 0.019) train_loss=284.71551514 time/batch=0.15s
11/53700 (epoch 0.020) train_loss=2155.56738281 time/batch=1.08s
12/53700 (epoch 0.022) train_loss=473.96026611 time/batch=0.31s
13/53700 (epoch 0.024) train_loss=582.26928711 time/batch=0.23s
14/53700 (epoch 0.026) train_loss=593.46136475 time/batch=0.25s
15/53700 (epoch 0.028) train_loss=307.05145264 time/batch=0.13s
16/53700 (epoch 0.030) train_loss=487.45904541 time/batch=0.20s
17/53700 (epoch 0.032) train_loss=802.66125488 time/batch=0.33s
18/53700 (epoch 0.034) train_loss=133.90390015 time/batch=0.09s
19/53700 (epoch 0.035) train_loss=1596.09960938 time/batch=0.60s
20/53700 (epoch 0.037) train_loss=770.85748291 time/batch=0.34s
21/53700 (epoch 0.039) train_loss=229.12796021 time/batch=0.12s
22/53700 (epoch 0.041) train_loss=353.25152588 time/batch=0.14s
23/53700 (epoch 0.043) train_loss=840.01184082 time/batch=0.33s
24/53700 (epoch 0.045) train_loss=955.37561035 time/batch=0.40s
25/53700 (epoch 0.047) train_loss=510.56225586 time/batch=0.24s
26/53700 (epoch 0.048) train_loss=1107.65966797 time/batch=0.47s
27/53700 (epoch 0.050) train_loss=534.30181885 time/batch=0.27s
28/53700 (epoch 0.052) train_loss=452.14947510 time/batch=0.20s
29/53700 (epoch 0.054) train_loss=178.13502502 time/batch=0.10s
30/53700 (epoch 0.056) train_loss=592.85876465 time/batch=0.24s
31/53700 (epoch 0.058) train_loss=772.83142090 time/batch=0.33s
32/53700 (epoch 0.060) train_loss=864.67407227 time/batch=0.37s
33/53700 (epoch 0.061) train_loss=706.90313721 time/batch=0.31s
34/53700 (epoch 0.063) train_loss=430.29437256 time/batch=0.19s
35/53700 (epoch 0.065) train_loss=1297.18701172 time/batch=0.50s
36/53700 (epoch 0.067) train_loss=1433.46411133 time/batch=0.61s
37/53700 (epoch 0.069) train_loss=93.72823334 time/batch=0.12s
38/53700 (epoch 0.071) train_loss=578.86682129 time/batch=0.23s
39/53700 (epoch 0.073) train_loss=909.99267578 time/batch=0.37s
40/53700 (epoch 0.074) train_loss=919.14196777 time/batch=0.39s
41/53700 (epoch 0.076) train_loss=1622.13244629 time/batch=1.26s
42/53700 (epoch 0.078) train_loss=552.92889404 time/batch=0.37s
43/53700 (epoch 0.080) train_loss=796.07928467 time/batch=0.34s
44/53700 (epoch 0.082) train_loss=658.36193848 time/batch=0.30s
45/53700 (epoch 0.084) train_loss=259.67004395 time/batch=0.14s
46/53700 (epoch 0.086) train_loss=261.96276855 time/batch=0.11s
47/53700 (epoch 0.088) train_loss=917.55541992 time/batch=0.38s
Traceback (most recent call last):
  File "train_rnn.py", line 204, in <module>
    train_loss = train(x_batch, mask_batch)
  File "D:\Anaconda\lib\site-packages\theano\compile\function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "D:\Anaconda\lib\site-packages\theano\gof\link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "D:\Anaconda\lib\site-packages\theano\compile\function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "D:\Anaconda\lib\site-packages\theano\scan_module\scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "D:\Anaconda\lib\site-packages\theano\scan_module\scan_op.py", line 952, in p
    self, node)
  File "scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform
  File "D:\Anaconda\lib\site-packages\theano\gpuarray\type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu\gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu\gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu\gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu\gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory
Apply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(Elemwise{minimum,no_inplace}.0, InplaceGpuDimShuffle{0,2,1}.0, InplaceGpuDimShuffle{0,2,1}.0, GpuAlloc<None>{memset_0=True}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc<None>{memset_0=True}.0, GpuSubtensor{::int64}.0, GpuAlloc<None>{memset_0=True}.0, Elemwise{minimum,no_inplace}.0, Elemwise{minimum,no_inplace}.0, GpuJoin.0, GpuJoin.0, InplaceGpuDimShuffle{x,0}.0, InplaceGpuDimShuffle{1,0}.0, InplaceGpuDimShuffle{1,0}.0)
Toposort index: 840
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (False, False, True)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (False, False, True)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, matrix), TensorType(int64, scalar), TensorType(int64, scalar), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix)]
Inputs shapes: [(), (1883, 512, 32), (1883, 512, 32), (1883, 32, 1), (1883, 32, 512), (1883, 32, 1), (1883, 32, 512), (1883, 32, 512), (1884, 32, 512), (1884, 32, 512), (2, 2048), (), (), (512, 2048), (512, 2048), (1, 2048), (2048, 512), (2048, 512)]
Inputs strides: [(), (-65536, 4, 2048), (-65536, 4, 2048), (128, 4, 4), (-65536, 2048, 4), (-4, 7532, 241024), (-65536, 2048, 4), (-65536, 2048, 4), (65536, 2048, 4), (-65536, 2048, 4), (8192, 4), (), (), (8192, 4), (8192, 4), (8192, 4), (4, 8192), (4, 8192)]
Inputs values: [array(1883, dtype=int64), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(1883, dtype=int64), array(1883, dtype=int64), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})], [GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.1, ScalarFromTensor.0, ScalarFromTensor.0, Constant{-1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.2, ScalarFromTensor.0)], [GpuSubtensor{::int64}(forall_inplace,gpu,grad_of_scan_fn}.3, Constant{-1})], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.4, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
