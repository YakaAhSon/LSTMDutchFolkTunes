set(['1/4=76\n', '[I:setbarnb 80]', 'G2>', 'G2<', '1/2=56\n', '1/2=60\n', '[I:setbarnb 61]', '[K:F]', '[I:setbarnb 91]', '[I:setbarnb 41]', 'G7', 'G6', 'G4', 'G3', 'G2', '[I:setbarnb 48]', 'G>', 'G<', '[I:setbarnb 56]', 'G8', '1/2=100\n', 'G/', 'G,', 'g7', 'g6', 'g4', 'g3', 'g2', 'g>', 'g<', 'F2', 'g8', "g'", '_A4', 'F4>', '1/4=152\n', 'g/', '16/2\n', "^c'", '_A2', '^A2', 'B2>', 'B2<', '^A6', 'G,4<', '^A4', 'G,4>', 'F clef=treble\n', '^A>', '8/4\n', '^A<', 'c4<', '_e2>', '[I:setbarnb 58]', '_e2<', '_A>', '3/8=60\n', 'e/8', 'e/>', '3/4=60\n', 'e/<', '1/4=100\n', 'b2>', 'b2<', '^a6', '^c>', '^a4', 'A,2>', 'A2<', 'e4<', 'n', 'd4', 'M:', '1/4=84\n', '^E/', 'g2>', '^c4', 'g2<', 'E,2>', 'Db clef=treble\n', 'F2>', '3/8=144\n', '[I:setbarnb 34]', '[K:G]', 'Z4', 'Z5', 'A clef=treble\n', '3/8=132\n', 'Z2', 'Z3', '_B>', 'z/', '[K:F#]', '3/4=63\n', '^d6', 'G,/', '^c7', '[I:setbarnb 5]', 'z<', '1/2=88\n', 'z>', 'Eb clef=treble\n', 'z8', '[I:setbarnb 24]', 'G,>', 'z4', '1/2=54\n', 'G,2', 'G,3', 'G,4', 'z2', 'z3', 'A,/', '_G/', 'F7', 'g4<', 'E clef=treble\n', '[I:setbarnb 66]', 'A,>', '[M:3/4]', '6/8\n', 'A,8', 'A,6', 'A,4', 'A,2', 'A,3', '3/2\n', '_G2', "d'2<", "d'2>", "d'4>", '12/2\n', 'A4>', 'B,>', '1/4=96\n', "e'2>", 'G/<', 'e7', '3/8=184\n', '_g2', "c'2<", '6/2\n', '_d4', 'D clef=bass\n', 'C,2>', 'C,2<', 'F/<', "c'/>", '[I:setbarnb 40]', '_A2<', '5/8\n', 'F', 'E2<', '^e2', 'E2>', '^e3', '_A8', 'B,3', '[M:4/8]', 'F,2<', 'F,2>', 'F3', 'F4', 'F6', 'f', 'F8', 'c4>', '1/8=152\n', 'F<', '^E3', 'F>', 'F clef=bass\n', '[I:setbarnb 11]', '^G,2>', '3/8=126\n', 'F,', '1/4=168\n', 'F/', '^e>', 'B,<', 'f2', 'f3', 'f4', '[M:10/4]', 'f6', 'f7', 'f8', 'B,4', '^e4', 'B,6', 'f<', 'F4<', 'f>', 'B,2', '^e/', 'B,/', '^d<', "f'", '^D,4', '[I:setbarnb 78]', 'f/', '[I:setbarnb 30]', '[I:setbarnb 65]', '^B/', '^B,', 'x/>', 'z2>', 'z2<', '^C,2>', '1/4=88\n', '[M:6/2]', '^B3', '^B2', '^E4', '^B4', 'A', '[I:setbarnb 93]', 'w', '[M:8/4]', '_b2', 'G,<', '[I:setbarnb 44]', '^G2>', '^D,2', 'D4<', 'L:', 'a', '3/8=108\n', 'e2<', 'e2>', '[I:setbarnb 23]', '[M:5/8]', '[K:Bb]', '^C4', '^E2', '[I:setbarnb 9]', '[I:setbarnb 71]', '_a2', '_G', '_E', '_D', '_B', '_A', '[I:setbarnb 68]', '^c4<', '^c4>', 'D,<', 'f4<', '[M:7/4]', 'f4>', '[I:setbarnb 116]', '3/8=80\n', '_g', 'A/>', '_e', '_d', '_c', '_b', '_a', 'A/8', '^G,4', '^A3', '1/2=63\n', 'D clef=treble\n', '3/8=96\n', '2/4\n', 'D/>', 'a/>', '[I:setbarnb 134]', 'a/<', "e'>", 'A,4>', "e'3", "e'2", '_E,', 'l', '1/8=120\n', '[M:2/2]', 'A,4<', "e'/", 'd4>', 'd4<', "^c'4", '|', 'C,/', 'b<', '[I:setbarnb 4]', '^A,>', '[M:1/4]', '1/8=168\n', '[I:setbarnb 57]', 'C,8', 'C,4', '[K:Ab]', 'C,6', 'G4<', 'C,2', '1/4=92\n', 'G clef=treble\n', '^F6', 'E/', '^F4', '^F3', '^F2', 'p', '5/2\n', '^F>', '^F<', '_A,/>', '^F8', 'E<', 'E>', '3/8=168\n', 'E8', '3/8=63\n', '^F/', 'E4', 'E7', 'E6', '3/8=152\n', 'E3', 'E2', '^f6', 'e/', '^f4', '^f3', '^f2', 'G', '^f>', "e'", '^f<', "^f'", 'e<', 'e>', 'e8', 'x', '^f/', 'e4', 'A4<', 'e6', 'e3', 'e2', '_B,4', '1/2=120\n', '_B,2', 'g', 'G clef=bass\n', '^A/', 'G,2>', 'd/8', 'G,2<', 'd/>', '^A,', 'd/<', '[I:setbarnb 20]', '_B,/', '^D3', 'D4>', '1/4=126\n', '^a2', '^F,', '4/4\n', '^G2<', 'D,2>', 'D,2<', '1/2=152\n', '[I:setbarnb 26]', 'G/>', 'G/8', 'K:', "e'4", '[M:13/8]', 'A,2<', '^b', '[I:setbarnb 12]', '[M:2/1]', '1/2=48\n', '7/8\n', 'g4>', '^C,3', 'B', '^D/', '^C,6', '3/8=84\n', '[M:12/8]', '^C,>', 'x8', 'x>', '^e', 'x2', 'x3', 'x6', 'x7', 'x4', 'b', '[I:setbarnb 19]', "e'6", '3/4=69\n', '[I:setbarnb 29]', 'r', 'G,/>', 'a4>', 'a4<', '[I:setbarnb 35]', 'B/8', '^G,3', '^G,2', '1/4=176\n', 'Q:', 'D,/', '[K:D]', 'D,2', '^C,2', 'D,6', '1/4=160\n', 'D,4', 'D,8', 'D,>', 'x/', 'B/>', '[I:setbarnb 54]', '^d>', '^a/', 'g/<', 'g/>', 'g/8', '[I:setbarnb 8]', '[K:C]', "f'4", 'Bb clef=bass\n', '1/4\n', "f'3", '9/8\n', "f'/", '^A', '^B', '^C', ']', '^E', '^F', '^G', 'D/', 'D,', '[K:clef=bass]', '^C/', '^C,', 'B4<', 'B4>', 'm', 'D>', 'D<', '^C>', 'E,2<', 'D6', 'D7', '^C2', '^c', 'D2', '[I:setbarnb 18]', '^f', '^g', 'd/', '^c/', "d'", '3/8=240\n', 'd>', '3/8=69\n', 'd<', '^C2<', '^c<', 'd8', 'C<', 'd6', 'd7', '^c2', '^c3', 'd2', 'd3', '^c6', 'F2<', '[I:setbarnb 16]', '_B<', 'Z', '^C2>', '_B8', '_B6', '_B4', '_B2', '_B3', '_f/', '7/4\n', '_B/', '[I:setbarnb 36]', 'x2>', '^a', '[I:setbarnb 99]', '_b>', '_b<', '1/2=52\n', '[I:setbarnb 3]', '_b6', '_b4', 'C2>', '_b3', 'C2<', '_b/', '[I:setbarnb 22]', '^e/>', '[I:setbarnb 38]', '3/8=88\n', 'Z6', 'Z7', '_E/', '[I:setbarnb 31]', '[I:setbarnb 76]', '_E>', '_E3', '_E2', '_E6', '_E4', '_e/', '_E,>', "_e'", '_e8', '_e>', '_e<', '_e3', '_e2', '_e6', '_e4', '[M:10/8]', '_E,3', '[I:setbarnb 46]', '1/8=160\n', '^g2<', '^c2>', '^c2<', '^F,3', 'f2>', 'z/>', 'f2<', '^A/>', 'C', '2/2\n', 'E4>', '^F/>', '3/8=160\n', "d'/", 'E4<', 'C/>', "d'2", "d'3", "d'6", "d'4", "d'8", '[M:2/16]', "d'>", "d'<", '^G4', 'G,8', 'c', '^G2', '^G3', '^G>', 'c2>', 'c2<', "c'2>", '3/8=100\n', '_d2<', '[I:setbarnb 125]', '^F,2>', '^G,', '[M:2/4]', '^G/', '_a2<', '^g4', '1/2=80\n', '^g6', '^d/>', '^g2', '^g3', '^g>', '^g8', ',', 'G,6', '1/4=138\n', '[M:9/4]', '^g/', 'z6', '[I:setbarnb 73]', 'z7', 'C/', 'C,', '_B/>', '[I:setbarnb 28]', 'C8', 'C>', '^c/>', '8/8\n', 'C3', 'C2', 'C6', '[I:setbarnb 32]', 'C4', '^G,>', 'c/', '1/2=76\n', '[I:setbarnb 69]', '^F2>', '^F2<', "c'", '^G6', 'c8', 'c>', '[I:setbarnb 50]', 'c<', 'c3', 'c2', 'c7', 'c6', 'c4', 'D,3', '[M:1/2]', 'A/<', '_A3', '9/4\n', '_a2>', 'c/8', '[I:setbarnb 21]', '^f/>', 'e4>', 'c/<', 'A2>', 'c/>', '[I:setbarnb 7]', '1/4=120\n', '1/2=96\n', '_A/', '_A,', '[I:setbarnb 59]', '_a4', '_a3', '[I:setbarnb 43]', '_A2>', '_a>', 'F/>', 'a2<', 'a2>', '_A,/', '_e4>', '1/2=66\n', '[I:setbarnb 27]', 'A,<', 'D4', '[I:setbarnb 110]', '[I:setbarnb 53]', '[M:22/8]', 'A,/>', '3/8=176\n', '[M:3/16]', '3/8=112\n', '_G7', '1/16\n', '^f2>', '^f2<', 'B,/>', 'B clef=treble\n', '[I:setbarnb 13]', '^e2<', '^F,/', '3/8=116\n', '_E,/', '3/4=66\n', '[I:setbarnb 2]', '_A,4', '^F,>', '[M:9/8]', '[I:setbarnb 25]', '^F,4', '^F,6', '1/4=72\n', '^F,2', '[I:setbarnb 39]', 'Eb clef=bass\n', '[M:8/8]', '[I:setbarnb 67]', 'f/<', 'f/>', 'f/8', '[I:setbarnb 77]', '[M:6/4]', '_A,3', '[M:19/16]', '[I:setbarnb 49]', '_B,', 'D', '3/8=138\n', 'A6', '^g2>', '1/2=44\n', '[I:setbarnb 42]', 'E,8', '^e2>', 'F,/', '1/2=72\n', '_A,2', '3/8=72\n', '[M:3/2]', '14/2\n', 'd', 'B,', 'B/', 'B4', '1/4=132\n', 'B6', 'B7', 't', 'B2', 'B3', 'B<', 'B>', 'B8', 'E,/', '1/2=92\n', 'b/', '3/4\n', '4/2\n', 'b4', 'b6', 'E,>', '_b2<', 'b2', 'b3', 'E,2', 'E,3', 'b>', '12/8\n', 'E,6', 'E,4', '_D,', 'F,>', '1/8=144\n', '_a/', '[I:setbarnb 122]', '[I:setbarnb 10]', '1/8=176\n', '_D4', '[I:setbarnb 138]', '_B2<', '1/8=240\n', '_d/', '_B2>', 'F,4<', "f'2", '_d>', '_d2', '[M:5/4]', '1/4=69\n', '1/4=56\n', '[I:setbarnb 17]', 'B,8', '1/8\n', '_B,2>', 'o', '[I:setbarnb 15]', '[I:setbarnb 37]', '^A2>', '^C,4', '_A<', 'a4', '2/1\n', '[M:4/4]', '^c8', '3/8=120\n', '[M:7/8]', "^c'/", "^c'2", '1/4=60\n', '[I:setbarnb 51]', '[I:setbarnb 92]', '1/4=80\n', '[K:Eb]', '[M:6/8]', '5/4\n', '3/8=66\n', 'i', '^D>', '^D', '1/2=104\n', '^D2', '^D4', 'E/>', '[K:clef=treble]', '[I:setbarnb 6]', '2/8\n', '[M:4/2]', '^D2<', '^D2>', 'C clef=bass\n', 'B/<', 'D2<', "c'/", 'D2>', '[I:setbarnb 85]', '1/2=84\n', '^d3', '^d2', '^d4', '[K:A]', '1/4=144\n', "c'8", "c'<", '^d/', "c'>", 'b/<', "c'3", "c'2", 'C clef=treble\n', "c'4", "c'6", "^d'2", '3/8=92\n', '[I:setbarnb 45]', 'C,>', '1/4=112\n', '1/4=104\n', '3/8=76\n', 'z', "^d'/", '3/8\n', '[I:setbarnb 105]', 'E,<', 'Bb clef=treble\n', '_b2>', '1/8=112\n', '1/4=108\n', 'F/8', '1/4=192\n', 'B,2<', '[M:2/8]', 'B,2>', 'b8', "g'2", 'A,', 'A/', '10/2\n', '1/4=46\n', 'A3', 'A2', 'A4', 'A7', '6/4\n', 'A8', 'C,3', 'A<', '[I:setbarnb 14]', 'A>', '8/16\n', '[I:setbarnb 1]', 'E', 'D8', '[M:3/8]', 'E,', 'F,3', 'F,2', 'F,4', 'a/', 'F,6', 'a3', 'a2', '_E2>', '1/2=69\n', '_E2<', 'a6', 'a8', 'E/8', 'a<', 'G4>', 'a>', '^d2>', '^C3', 'e', 'd2<', 'b/>', 'd2>', '^d', '4/8\n', 'D3', '^G4>', 'u', "_e'2", 'Ab clef=treble\n', '[I:setbarnb 33]'])
vocabulary size: 895
n tunes: 18107
n train tunes: 17211
n validation tunes: 896
min, max length 15 1884
Building the model
  number of parameters: 3262848
  layer output shapes:               #params:   output shape:
    InputLayer                       0          (32, None)
    EmbeddingLayer                   801025     (32, None, 895)
    InputLayer                       0          (32, None)
    LSTMLayer                        1180160    (32, None, 256)
    DropoutLayer                     0          (32, None, 256)
    LSTMLayer                        525824     (32, None, 256)
    DropoutLayer                     0          (32, None, 256)
    LSTMLayer                        525824     (32, None, 256)
    DropoutLayer                     0          (32, None, 256)
    ReshapeLayer                     0          (None, 256)
    DenseLayer                       230015     (None, 895)
Train model
1/537 (epoch 0.002) train_loss=3902.42431641 time/batch=1.45s
2/537 (epoch 0.004) train_loss=3039.94433594 time/batch=0.55s
3/537 (epoch 0.006) train_loss=263.18481445 time/batch=0.08s
4/537 (epoch 0.007) train_loss=1602.75085449 time/batch=0.29s
5/537 (epoch 0.009) train_loss=1460.29516602 time/batch=0.34s
6/537 (epoch 0.011) train_loss=1415.07971191 time/batch=0.38s
7/537 (epoch 0.013) train_loss=1017.29785156 time/batch=0.29s
8/537 (epoch 0.015) train_loss=1104.57421875 time/batch=0.30s
9/537 (epoch 0.017) train_loss=964.99963379 time/batch=0.26s
10/537 (epoch 0.019) train_loss=288.25866699 time/batch=0.09s
11/537 (epoch 0.020) train_loss=2154.88720703 time/batch=0.72s
12/537 (epoch 0.022) train_loss=467.03393555 time/batch=0.19s
13/537 (epoch 0.024) train_loss=584.24011230 time/batch=0.15s
14/537 (epoch 0.026) train_loss=598.91003418 time/batch=0.16s
15/537 (epoch 0.028) train_loss=312.82406616 time/batch=0.08s
16/537 (epoch 0.030) train_loss=495.87759399 time/batch=0.12s
17/537 (epoch 0.032) train_loss=808.36169434 time/batch=0.23s
18/537 (epoch 0.034) train_loss=141.52035522 time/batch=0.05s
19/537 (epoch 0.035) train_loss=1597.90844727 time/batch=0.41s
20/537 (epoch 0.037) train_loss=756.69201660 time/batch=0.22s
21/537 (epoch 0.039) train_loss=234.71258545 time/batch=0.07s
22/537 (epoch 0.041) train_loss=357.66833496 time/batch=0.10s
23/537 (epoch 0.043) train_loss=839.87274170 time/batch=0.22s
24/537 (epoch 0.045) train_loss=961.02368164 time/batch=0.26s
25/537 (epoch 0.047) train_loss=515.52593994 time/batch=0.15s
26/537 (epoch 0.048) train_loss=1109.59350586 time/batch=0.31s
27/537 (epoch 0.050) train_loss=534.20916748 time/batch=0.16s
28/537 (epoch 0.052) train_loss=456.89355469 time/batch=0.12s
29/537 (epoch 0.054) train_loss=184.17048645 time/batch=0.05s
30/537 (epoch 0.056) train_loss=597.81115723 time/batch=0.15s
31/537 (epoch 0.058) train_loss=774.48632812 time/batch=0.22s
32/537 (epoch 0.060) train_loss=865.84045410 time/batch=0.24s
33/537 (epoch 0.061) train_loss=705.50988770 time/batch=0.20s
34/537 (epoch 0.063) train_loss=438.40530396 time/batch=0.12s
35/537 (epoch 0.065) train_loss=1291.01562500 time/batch=0.33s
36/537 (epoch 0.067) train_loss=1428.48803711 time/batch=0.40s
37/537 (epoch 0.069) train_loss=99.11600494 time/batch=0.06s
38/537 (epoch 0.071) train_loss=586.06622314 time/batch=0.15s
39/537 (epoch 0.073) train_loss=909.70703125 time/batch=0.25s
40/537 (epoch 0.074) train_loss=922.86505127 time/batch=0.26s
41/537 (epoch 0.076) train_loss=1621.50573730 time/batch=0.83s
42/537 (epoch 0.078) train_loss=554.02960205 time/batch=0.20s
43/537 (epoch 0.080) train_loss=800.23095703 time/batch=0.21s
44/537 (epoch 0.082) train_loss=663.16339111 time/batch=0.20s
45/537 (epoch 0.084) train_loss=257.99774170 time/batch=0.08s
46/537 (epoch 0.086) train_loss=268.28515625 time/batch=0.08s
47/537 (epoch 0.088) train_loss=917.84240723 time/batch=0.26s
48/537 (epoch 0.089) train_loss=3454.43432617 time/batch=1.91s
49/537 (epoch 0.091) train_loss=128.27246094 time/batch=0.22s
50/537 (epoch 0.093) train_loss=539.88964844 time/batch=0.14s
51/537 (epoch 0.095) train_loss=1051.47558594 time/batch=0.30s
52/537 (epoch 0.097) train_loss=278.56335449 time/batch=0.10s
53/537 (epoch 0.099) train_loss=725.08081055 time/batch=0.19s
54/537 (epoch 0.101) train_loss=843.44750977 time/batch=0.24s
55/537 (epoch 0.102) train_loss=171.14328003 time/batch=0.06s
56/537 (epoch 0.104) train_loss=390.92306519 time/batch=0.11s
57/537 (epoch 0.106) train_loss=229.38610840 time/batch=0.07s
58/537 (epoch 0.108) train_loss=505.57321167 time/batch=0.13s
59/537 (epoch 0.110) train_loss=1055.11791992 time/batch=0.29s
60/537 (epoch 0.112) train_loss=504.47204590 time/batch=0.16s
61/537 (epoch 0.114) train_loss=795.67779541 time/batch=0.22s
62/537 (epoch 0.115) train_loss=622.35418701 time/batch=0.19s
63/537 (epoch 0.117) train_loss=734.81323242 time/batch=0.21s
64/537 (epoch 0.119) train_loss=436.12606812 time/batch=0.14s
65/537 (epoch 0.121) train_loss=127.22836304 time/batch=0.04s
66/537 (epoch 0.123) train_loss=396.27270508 time/batch=0.11s
67/537 (epoch 0.125) train_loss=571.51141357 time/batch=0.16s
68/537 (epoch 0.127) train_loss=288.14630127 time/batch=0.08s
69/537 (epoch 0.128) train_loss=199.33372498 time/batch=0.07s
70/537 (epoch 0.130) train_loss=401.09735107 time/batch=0.11s
71/537 (epoch 0.132) train_loss=527.68597412 time/batch=0.14s
72/537 (epoch 0.134) train_loss=678.05944824 time/batch=0.20s
73/537 (epoch 0.136) train_loss=310.59570312 time/batch=0.09s
74/537 (epoch 0.138) train_loss=340.53735352 time/batch=0.11s
75/537 (epoch 0.140) train_loss=967.58593750 time/batch=0.26s
76/537 (epoch 0.142) train_loss=842.04650879 time/batch=0.24s
77/537 (epoch 0.143) train_loss=813.85009766 time/batch=0.23s
78/537 (epoch 0.145) train_loss=584.60882568 time/batch=0.17s
79/537 (epoch 0.147) train_loss=331.73599243 time/batch=0.10s
80/537 (epoch 0.149) train_loss=567.39257812 time/batch=0.15s
81/537 (epoch 0.151) train_loss=697.07263184 time/batch=0.21s
82/537 (epoch 0.153) train_loss=176.98243713 time/batch=0.07s
83/537 (epoch 0.155) train_loss=128.60910034 time/batch=0.04s
84/537 (epoch 0.156) train_loss=609.74694824 time/batch=0.16s
85/537 (epoch 0.158) train_loss=663.22039795 time/batch=0.20s
86/537 (epoch 0.160) train_loss=655.72827148 time/batch=0.19s
87/537 (epoch 0.162) train_loss=449.53738403 time/batch=0.13s
88/537 (epoch 0.164) train_loss=305.00415039 time/batch=0.09s
89/537 (epoch 0.166) train_loss=621.07458496 time/batch=0.17s
90/537 (epoch 0.168) train_loss=481.75207520 time/batch=0.14s
91/537 (epoch 0.169) train_loss=603.76409912 time/batch=0.16s
92/537 (epoch 0.171) train_loss=173.53936768 time/batch=0.06s
93/537 (epoch 0.173) train_loss=749.15002441 time/batch=0.20s
94/537 (epoch 0.175) train_loss=570.27612305 time/batch=0.19s
95/537 (epoch 0.177) train_loss=482.94052124 time/batch=0.13s
96/537 (epoch 0.179) train_loss=367.12664795 time/batch=0.12s
97/537 (epoch 0.181) train_loss=514.62432861 time/batch=0.15s
98/537 (epoch 0.182) train_loss=429.09454346 time/batch=0.12s
99/537 (epoch 0.184) train_loss=432.41210938 time/batch=0.11s
100/537 (epoch 0.186) train_loss=284.16366577 time/batch=0.08s
101/537 (epoch 0.188) train_loss=668.35253906 time/batch=0.19s
102/537 (epoch 0.190) train_loss=618.26696777 time/batch=0.19s
103/537 (epoch 0.192) train_loss=219.95562744 time/batch=0.07s
104/537 (epoch 0.194) train_loss=117.05141449 time/batch=0.04s
105/537 (epoch 0.196) train_loss=496.26446533 time/batch=0.14s
106/537 (epoch 0.197) train_loss=1052.10546875 time/batch=0.30s
107/537 (epoch 0.199) train_loss=310.26007080 time/batch=0.11s
108/537 (epoch 0.201) train_loss=169.11955261 time/batch=0.05s
109/537 (epoch 0.203) train_loss=145.88302612 time/batch=0.05s
110/537 (epoch 0.205) train_loss=319.23040771 time/batch=0.10s
111/537 (epoch 0.207) train_loss=602.60473633 time/batch=0.17s
112/537 (epoch 0.209) train_loss=451.98968506 time/batch=0.12s
113/537 (epoch 0.210) train_loss=744.40740967 time/batch=0.21s
114/537 (epoch 0.212) train_loss=225.42127991 time/batch=0.08s
115/537 (epoch 0.214) train_loss=720.34722900 time/batch=0.19s
116/537 (epoch 0.216) train_loss=192.17631531 time/batch=0.08s
117/537 (epoch 0.218) train_loss=260.94305420 time/batch=0.07s
118/537 (epoch 0.220) train_loss=501.76385498 time/batch=0.15s
119/537 (epoch 0.222) train_loss=216.50003052 time/batch=0.07s
120/537 (epoch 0.223) train_loss=203.25639343 time/batch=0.06s
121/537 (epoch 0.225) train_loss=761.49536133 time/batch=0.20s
122/537 (epoch 0.227) train_loss=707.52246094 time/batch=0.20s
123/537 (epoch 0.229) train_loss=336.01818848 time/batch=0.11s
124/537 (epoch 0.231) train_loss=433.21441650 time/batch=0.12s
125/537 (epoch 0.233) train_loss=266.83013916 time/batch=0.08s
126/537 (epoch 0.235) train_loss=382.80682373 time/batch=0.11s
127/537 (epoch 0.236) train_loss=635.80401611 time/batch=0.19s
128/537 (epoch 0.238) train_loss=446.46899414 time/batch=0.12s
129/537 (epoch 0.240) train_loss=293.26184082 time/batch=0.09s
130/537 (epoch 0.242) train_loss=120.55007935 time/batch=0.05s
131/537 (epoch 0.244) train_loss=334.89898682 time/batch=0.10s
132/537 (epoch 0.246) train_loss=513.43298340 time/batch=0.15s
133/537 (epoch 0.248) train_loss=280.46875000 time/batch=0.10s
134/537 (epoch 0.250) train_loss=161.14393616 time/batch=0.05s
135/537 (epoch 0.251) train_loss=622.07879639 time/batch=0.17s
136/537 (epoch 0.253) train_loss=318.88488770 time/batch=0.11s
137/537 (epoch 0.255) train_loss=418.19012451 time/batch=0.13s
138/537 (epoch 0.257) train_loss=596.22485352 time/batch=0.17s
139/537 (epoch 0.259) train_loss=400.96514893 time/batch=0.13s
140/537 (epoch 0.261) train_loss=722.78027344 time/batch=0.19s
141/537 (epoch 0.263) train_loss=320.62649536 time/batch=0.11s
142/537 (epoch 0.264) train_loss=626.92761230 time/batch=0.17s
143/537 (epoch 0.266) train_loss=590.56188965 time/batch=0.17s
144/537 (epoch 0.268) train_loss=153.87405396 time/batch=0.07s
145/537 (epoch 0.270) train_loss=221.84405518 time/batch=0.07s
146/537 (epoch 0.272) train_loss=530.32647705 time/batch=0.15s
147/537 (epoch 0.274) train_loss=529.41088867 time/batch=0.14s
148/537 (epoch 0.276) train_loss=370.39459229 time/batch=0.12s
149/537 (epoch 0.277) train_loss=561.35717773 time/batch=0.16s
150/537 (epoch 0.279) train_loss=466.68032837 time/batch=0.14s
151/537 (epoch 0.281) train_loss=337.19775391 time/batch=0.10s
152/537 (epoch 0.283) train_loss=217.68167114 time/batch=0.07s
153/537 (epoch 0.285) train_loss=389.25335693 time/batch=0.11s
154/537 (epoch 0.287) train_loss=160.83065796 time/batch=0.06s
155/537 (epoch 0.289) train_loss=378.14093018 time/batch=0.11s
156/537 (epoch 0.291) train_loss=156.67343140 time/batch=0.06s
157/537 (epoch 0.292) train_loss=633.09765625 time/batch=0.19s
158/537 (epoch 0.294) train_loss=680.03466797 time/batch=0.19s
159/537 (epoch 0.296) train_loss=845.71850586 time/batch=0.31s
160/537 (epoch 0.298) train_loss=320.64428711 time/batch=0.11s
161/537 (epoch 0.300) train_loss=399.09588623 time/batch=0.12s
162/537 (epoch 0.302) train_loss=379.50042725 time/batch=0.12s
163/537 (epoch 0.304) train_loss=794.60211182 time/batch=0.22s
164/537 (epoch 0.305) train_loss=464.98834229 time/batch=0.14s
165/537 (epoch 0.307) train_loss=342.91540527 time/batch=0.11s
166/537 (epoch 0.309) train_loss=735.54785156 time/batch=0.20s
167/537 (epoch 0.311) train_loss=389.54406738 time/batch=0.13s
168/537 (epoch 0.313) train_loss=478.49331665 time/batch=0.15s
169/537 (epoch 0.315) train_loss=389.68466187 time/batch=0.11s
170/537 (epoch 0.317) train_loss=407.82305908 time/batch=0.12s
171/537 (epoch 0.318) train_loss=197.63949585 time/batch=0.07s
172/537 (epoch 0.320) train_loss=412.66906738 time/batch=0.11s
173/537 (epoch 0.322) train_loss=400.47912598 time/batch=0.12s
174/537 (epoch 0.324) train_loss=612.94897461 time/batch=0.16s
175/537 (epoch 0.326) train_loss=201.09205627 time/batch=0.08s
176/537 (epoch 0.328) train_loss=158.69720459 time/batch=0.05s
177/537 (epoch 0.330) train_loss=588.43310547 time/batch=0.16s
178/537 (epoch 0.331) train_loss=233.73168945 time/batch=0.08s
179/537 (epoch 0.333) train_loss=161.42448425 time/batch=0.06s
180/537 (epoch 0.335) train_loss=224.69931030 time/batch=0.07s
181/537 (epoch 0.337) train_loss=321.36477661 time/batch=0.11s
182/537 (epoch 0.339) train_loss=462.74890137 time/batch=0.12s
183/537 (epoch 0.341) train_loss=164.02697754 time/batch=0.07s
184/537 (epoch 0.343) train_loss=605.41339111 time/batch=0.16s
185/537 (epoch 0.345) train_loss=254.07722473 time/batch=0.09s
186/537 (epoch 0.346) train_loss=178.68295288 time/batch=0.06s
187/537 (epoch 0.348) train_loss=302.70245361 time/batch=0.10s
188/537 (epoch 0.350) train_loss=369.73074341 time/batch=0.11s
189/537 (epoch 0.352) train_loss=176.68518066 time/batch=0.07s
190/537 (epoch 0.354) train_loss=187.07113647 time/batch=0.06s
191/537 (epoch 0.356) train_loss=279.66439819 time/batch=0.08s
192/537 (epoch 0.358) train_loss=266.20721436 time/batch=0.09s
193/537 (epoch 0.359) train_loss=558.13940430 time/batch=0.15s
194/537 (epoch 0.361) train_loss=339.57815552 time/batch=0.12s
195/537 (epoch 0.363) train_loss=367.00463867 time/batch=0.11s
196/537 (epoch 0.365) train_loss=623.11602783 time/batch=0.18s
197/537 (epoch 0.367) train_loss=302.89929199 time/batch=0.10s
198/537 (epoch 0.369) train_loss=544.03161621 time/batch=0.15s
199/537 (epoch 0.371) train_loss=362.79376221 time/batch=0.11s
200/537 (epoch 0.372) train_loss=420.75164795 time/batch=0.12s
201/537 (epoch 0.374) train_loss=715.91931152 time/batch=0.20s
202/537 (epoch 0.376) train_loss=336.35720825 time/batch=0.12s
203/537 (epoch 0.378) train_loss=127.43663788 time/batch=0.04s
204/537 (epoch 0.380) train_loss=167.75434875 time/batch=0.05s
205/537 (epoch 0.382) train_loss=720.44458008 time/batch=0.19s
206/537 (epoch 0.384) train_loss=143.74072266 time/batch=0.06s
207/537 (epoch 0.385) train_loss=457.51303101 time/batch=0.13s
208/537 (epoch 0.387) train_loss=348.41912842 time/batch=0.11s
209/537 (epoch 0.389) train_loss=375.02099609 time/batch=0.11s
210/537 (epoch 0.391) train_loss=288.64727783 time/batch=0.08s
211/537 (epoch 0.393) train_loss=317.87481689 time/batch=0.11s
212/537 (epoch 0.395) train_loss=398.14685059 time/batch=0.10s
213/537 (epoch 0.397) train_loss=202.76727295 time/batch=0.08s
214/537 (epoch 0.399) train_loss=122.75144958 time/batch=0.04s
215/537 (epoch 0.400) train_loss=242.65431213 time/batch=0.08s
216/537 (epoch 0.402) train_loss=475.70471191 time/batch=0.13s
217/537 (epoch 0.404) train_loss=259.76193237 time/batch=0.08s
218/537 (epoch 0.406) train_loss=648.52270508 time/batch=0.19s
219/537 (epoch 0.408) train_loss=282.26550293 time/batch=0.09s
220/537 (epoch 0.410) train_loss=230.11560059 time/batch=0.07s
221/537 (epoch 0.412) train_loss=154.97257996 time/batch=0.05s
222/537 (epoch 0.413) train_loss=404.06884766 time/batch=0.12s
223/537 (epoch 0.415) train_loss=362.73837280 time/batch=0.11s
224/537 (epoch 0.417) train_loss=152.14053345 time/batch=0.06s
225/537 (epoch 0.419) train_loss=629.81646729 time/batch=0.17s
226/537 (epoch 0.421) train_loss=148.92605591 time/batch=0.06s
227/537 (epoch 0.423) train_loss=429.41726685 time/batch=0.12s
228/537 (epoch 0.425) train_loss=385.62567139 time/batch=0.12s
229/537 (epoch 0.426) train_loss=272.46417236 time/batch=0.08s
230/537 (epoch 0.428) train_loss=255.69999695 time/batch=0.08s
231/537 (epoch 0.430) train_loss=274.52947998 time/batch=0.09s
232/537 (epoch 0.432) train_loss=310.67175293 time/batch=0.10s
233/537 (epoch 0.434) train_loss=502.78063965 time/batch=0.14s
234/537 (epoch 0.436) train_loss=591.32910156 time/batch=0.16s
235/537 (epoch 0.438) train_loss=306.92831421 time/batch=0.11s
236/537 (epoch 0.439) train_loss=527.68884277 time/batch=0.15s
237/537 (epoch 0.441) train_loss=170.50418091 time/batch=0.07s
238/537 (epoch 0.443) train_loss=251.54229736 time/batch=0.07s
239/537 (epoch 0.445) train_loss=591.17980957 time/batch=0.16s
240/537 (epoch 0.447) train_loss=500.34851074 time/batch=0.15s
241/537 (epoch 0.449) train_loss=677.43920898 time/batch=0.20s
242/537 (epoch 0.451) train_loss=186.08372498 time/batch=0.08s
243/537 (epoch 0.453) train_loss=400.89169312 time/batch=0.11s
244/537 (epoch 0.454) train_loss=542.64215088 time/batch=0.15s
245/537 (epoch 0.456) train_loss=265.76049805 time/batch=0.09s
246/537 (epoch 0.458) train_loss=172.69163513 time/batch=0.06s
247/537 (epoch 0.460) train_loss=267.66098022 time/batch=0.08s
248/537 (epoch 0.462) train_loss=377.72097778 time/batch=0.11s
249/537 (epoch 0.464) train_loss=131.02421570 time/batch=0.05s
250/537 (epoch 0.466) train_loss=388.23599243 time/batch=0.11s
251/537 (epoch 0.467) train_loss=429.46539307 time/batch=0.12s
252/537 (epoch 0.469) train_loss=197.57745361 time/batch=0.07s
253/537 (epoch 0.471) train_loss=392.89932251 time/batch=0.11s
254/537 (epoch 0.473) train_loss=340.50900269 time/batch=0.12s
255/537 (epoch 0.475) train_loss=349.88073730 time/batch=0.11s
256/537 (epoch 0.477) train_loss=500.81005859 time/batch=0.15s
257/537 (epoch 0.479) train_loss=145.10659790 time/batch=0.07s
258/537 (epoch 0.480) train_loss=546.16333008 time/batch=0.15s
259/537 (epoch 0.482) train_loss=297.17230225 time/batch=0.10s
260/537 (epoch 0.484) train_loss=403.34075928 time/batch=0.12s
261/537 (epoch 0.486) train_loss=470.92745972 time/batch=0.14s
262/537 (epoch 0.488) train_loss=425.24871826 time/batch=0.12s
263/537 (epoch 0.490) train_loss=482.44250488 time/batch=0.15s
264/537 (epoch 0.492) train_loss=417.20129395 time/batch=0.12s
265/537 (epoch 0.493) train_loss=400.37481689 time/batch=0.12s
266/537 (epoch 0.495) train_loss=396.65585327 time/batch=0.12s
267/537 (epoch 0.497) train_loss=421.37152100 time/batch=0.12s
268/537 (epoch 0.499) train_loss=224.91497803 time/batch=0.07s
269/537 (epoch 0.501) train_loss=181.74031067 time/batch=0.07s
270/537 (epoch 0.503) train_loss=395.99868774 time/batch=0.11s
271/537 (epoch 0.505) train_loss=303.89221191 time/batch=0.10s
272/537 (epoch 0.507) train_loss=475.72463989 time/batch=0.14s
273/537 (epoch 0.508) train_loss=515.95928955 time/batch=0.14s
274/537 (epoch 0.510) train_loss=400.47708130 time/batch=0.12s
275/537 (epoch 0.512) train_loss=322.69323730 time/batch=0.11s
276/537 (epoch 0.514) train_loss=210.87521362 time/batch=0.07s
277/537 (epoch 0.516) train_loss=576.30322266 time/batch=0.15s
278/537 (epoch 0.518) train_loss=513.68432617 time/batch=0.16s
279/537 (epoch 0.520) train_loss=354.74353027 time/batch=0.12s
280/537 (epoch 0.521) train_loss=516.71838379 time/batch=0.15s
281/537 (epoch 0.523) train_loss=600.42590332 time/batch=0.19s
282/537 (epoch 0.525) train_loss=396.22717285 time/batch=0.12s
283/537 (epoch 0.527) train_loss=417.69854736 time/batch=0.13s
284/537 (epoch 0.529) train_loss=448.92742920 time/batch=0.14s
285/537 (epoch 0.531) train_loss=456.01644897 time/batch=0.12s
286/537 (epoch 0.533) train_loss=192.97164917 time/batch=0.07s
287/537 (epoch 0.534) train_loss=217.63568115 time/batch=0.07s
288/537 (epoch 0.536) train_loss=214.39651489 time/batch=0.07s
289/537 (epoch 0.538) train_loss=248.63911438 time/batch=0.08s
290/537 (epoch 0.540) train_loss=162.31478882 time/batch=0.06s
291/537 (epoch 0.542) train_loss=281.09863281 time/batch=0.08s
292/537 (epoch 0.544) train_loss=375.96282959 time/batch=0.12s
293/537 (epoch 0.546) train_loss=177.82040405 time/batch=0.06s
294/537 (epoch 0.547) train_loss=154.62145996 time/batch=0.06s
295/537 (epoch 0.549) train_loss=314.27923584 time/batch=0.09s
296/537 (epoch 0.551) train_loss=155.25373840 time/batch=0.06s
297/537 (epoch 0.553) train_loss=432.05822754 time/batch=0.12s
298/537 (epoch 0.555) train_loss=387.62994385 time/batch=0.11s
299/537 (epoch 0.557) train_loss=417.01565552 time/batch=0.13s
300/537 (epoch 0.559) train_loss=415.06695557 time/batch=0.13s
301/537 (epoch 0.561) train_loss=244.28405762 time/batch=0.08s
302/537 (epoch 0.562) train_loss=278.98202515 time/batch=0.08s
303/537 (epoch 0.564) train_loss=292.43005371 time/batch=0.09s
304/537 (epoch 0.566) train_loss=359.42446899 time/batch=0.11s
305/537 (epoch 0.568) train_loss=245.08871460 time/batch=0.08s
306/537 (epoch 0.570) train_loss=388.70263672 time/batch=0.11s
307/537 (epoch 0.572) train_loss=166.19561768 time/batch=0.06s
308/537 (epoch 0.574) train_loss=676.85595703 time/batch=0.18s
309/537 (epoch 0.575) train_loss=374.89367676 time/batch=0.12s
310/537 (epoch 0.577) train_loss=347.35028076 time/batch=0.11s
311/537 (epoch 0.579) train_loss=200.02732849 time/batch=0.07s
312/537 (epoch 0.581) train_loss=507.19476318 time/batch=0.15s
313/537 (epoch 0.583) train_loss=495.38967896 time/batch=0.14s
314/537 (epoch 0.585) train_loss=366.86657715 time/batch=0.11s
315/537 (epoch 0.587) train_loss=494.29617310 time/batch=0.13s
316/537 (epoch 0.588) train_loss=429.92742920 time/batch=0.13s
317/537 (epoch 0.590) train_loss=199.66516113 time/batch=0.08s
318/537 (epoch 0.592) train_loss=240.29103088 time/batch=0.07s
319/537 (epoch 0.594) train_loss=339.30908203 time/batch=0.11s
320/537 (epoch 0.596) train_loss=446.73297119 time/batch=0.12s
321/537 (epoch 0.598) train_loss=370.05596924 time/batch=0.12s
322/537 (epoch 0.600) train_loss=463.45599365 time/batch=0.14s
323/537 (epoch 0.601) train_loss=239.63586426 time/batch=0.08s
324/537 (epoch 0.603) train_loss=257.64477539 time/batch=0.09s
325/537 (epoch 0.605) train_loss=192.52284241 time/batch=0.07s
326/537 (epoch 0.607) train_loss=242.29893494 time/batch=0.07s
327/537 (epoch 0.609) train_loss=430.48120117 time/batch=0.12s
328/537 (epoch 0.611) train_loss=195.62728882 time/batch=0.07s
329/537 (epoch 0.613) train_loss=218.93496704 time/batch=0.07s
330/537 (epoch 0.615) train_loss=288.22747803 time/batch=0.09s
331/537 (epoch 0.616) train_loss=465.09191895 time/batch=0.15s
332/537 (epoch 0.618) train_loss=492.39138794 time/batch=0.15s
333/537 (epoch 0.620) train_loss=359.52069092 time/batch=0.12s
334/537 (epoch 0.622) train_loss=170.25230408 time/batch=0.06s
335/537 (epoch 0.624) train_loss=307.38565063 time/batch=0.09s
336/537 (epoch 0.626) train_loss=324.74313354 time/batch=0.09s
337/537 (epoch 0.628) train_loss=188.25416565 time/batch=0.07s
338/537 (epoch 0.629) train_loss=544.09484863 time/batch=0.15s
339/537 (epoch 0.631) train_loss=288.54666138 time/batch=0.10s
340/537 (epoch 0.633) train_loss=561.41430664 time/batch=0.15s
341/537 (epoch 0.635) train_loss=500.08352661 time/batch=0.14s
342/537 (epoch 0.637) train_loss=242.29356384 time/batch=0.08s
343/537 (epoch 0.639) train_loss=243.51988220 time/batch=0.08s
344/537 (epoch 0.641) train_loss=244.87231445 time/batch=0.07s
345/537 (epoch 0.642) train_loss=253.66059875 time/batch=0.08s
346/537 (epoch 0.644) train_loss=555.95172119 time/batch=0.17s
347/537 (epoch 0.646) train_loss=505.18484497 time/batch=0.16s
348/537 (epoch 0.648) train_loss=373.72750854 time/batch=0.11s
349/537 (epoch 0.650) train_loss=293.20080566 time/batch=0.11s
350/537 (epoch 0.652) train_loss=240.85205078 time/batch=0.07s
351/537 (epoch 0.654) train_loss=379.86947632 time/batch=0.11s
352/537 (epoch 0.655) train_loss=357.88311768 time/batch=0.12s
353/537 (epoch 0.657) train_loss=284.85107422 time/batch=0.09s
354/537 (epoch 0.659) train_loss=478.73333740 time/batch=0.13s
355/537 (epoch 0.661) train_loss=339.50958252 time/batch=0.11s
356/537 (epoch 0.663) train_loss=505.22457886 time/batch=0.13s
357/537 (epoch 0.665) train_loss=415.84863281 time/batch=0.12s
358/537 (epoch 0.667) train_loss=201.05091858 time/batch=0.07s
359/537 (epoch 0.669) train_loss=259.28356934 time/batch=0.07s
360/537 (epoch 0.670) train_loss=208.31649780 time/batch=0.07s
361/537 (epoch 0.672) train_loss=260.67443848 time/batch=0.09s
362/537 (epoch 0.674) train_loss=362.48229980 time/batch=0.10s
363/537 (epoch 0.676) train_loss=302.56622314 time/batch=0.09s
364/537 (epoch 0.678) train_loss=229.55175781 time/batch=0.08s
365/537 (epoch 0.680) train_loss=192.47761536 time/batch=0.06s
366/537 (epoch 0.682) train_loss=483.38104248 time/batch=0.14s
367/537 (epoch 0.683) train_loss=421.95336914 time/batch=0.14s
368/537 (epoch 0.685) train_loss=188.98953247 time/batch=0.06s
369/537 (epoch 0.687) train_loss=280.19683838 time/batch=0.08s
370/537 (epoch 0.689) train_loss=270.71752930 time/batch=0.09s
371/537 (epoch 0.691) train_loss=203.77838135 time/batch=0.07s
372/537 (epoch 0.693) train_loss=256.96673584 time/batch=0.07s
373/537 (epoch 0.695) train_loss=166.54171753 time/batch=0.07s
374/537 (epoch 0.696) train_loss=258.92956543 time/batch=0.07s
375/537 (epoch 0.698) train_loss=509.55187988 time/batch=0.15s
376/537 (epoch 0.700) train_loss=459.06896973 time/batch=0.14s
377/537 (epoch 0.702) train_loss=242.23913574 time/batch=0.08s
378/537 (epoch 0.704) train_loss=415.51989746 time/batch=0.12s
379/537 (epoch 0.706) train_loss=402.45828247 time/batch=0.12s
380/537 (epoch 0.708) train_loss=416.71075439 time/batch=0.12s
381/537 (epoch 0.709) train_loss=196.46203613 time/batch=0.07s
382/537 (epoch 0.711) train_loss=160.57934570 time/batch=0.06s
383/537 (epoch 0.713) train_loss=465.21636963 time/batch=0.12s
384/537 (epoch 0.715) train_loss=331.57318115 time/batch=0.11s
385/537 (epoch 0.717) train_loss=254.84155273 time/batch=0.08s
386/537 (epoch 0.719) train_loss=294.48638916 time/batch=0.09s
387/537 (epoch 0.721) train_loss=265.27249146 time/batch=0.08s
388/537 (epoch 0.723) train_loss=462.77120972 time/batch=0.14s
389/537 (epoch 0.724) train_loss=453.27355957 time/batch=0.13s
390/537 (epoch 0.726) train_loss=305.68173218 time/batch=0.10s
391/537 (epoch 0.728) train_loss=295.82757568 time/batch=0.10s
392/537 (epoch 0.730) train_loss=461.10083008 time/batch=0.12s
393/537 (epoch 0.732) train_loss=327.61459351 time/batch=0.11s
394/537 (epoch 0.734) train_loss=340.50561523 time/batch=0.09s
395/537 (epoch 0.736) train_loss=222.81021118 time/batch=0.07s
396/537 (epoch 0.737) train_loss=208.60446167 time/batch=0.07s
397/537 (epoch 0.739) train_loss=379.81924438 time/batch=0.11s
398/537 (epoch 0.741) train_loss=413.14132690 time/batch=0.13s
399/537 (epoch 0.743) train_loss=313.47155762 time/batch=0.11s
400/537 (epoch 0.745) train_loss=260.11718750 time/batch=0.08s
401/537 (epoch 0.747) train_loss=411.94778442 time/batch=0.12s
402/537 (epoch 0.749) train_loss=343.23291016 time/batch=0.11s
403/537 (epoch 0.750) train_loss=315.67260742 time/batch=0.10s
404/537 (epoch 0.752) train_loss=199.96461487 time/batch=0.07s
405/537 (epoch 0.754) train_loss=295.75494385 time/batch=0.09s
406/537 (epoch 0.756) train_loss=407.21218872 time/batch=0.12s
407/537 (epoch 0.758) train_loss=172.34991455 time/batch=0.06s
408/537 (epoch 0.760) train_loss=253.59790039 time/batch=0.08s
409/537 (epoch 0.762) train_loss=327.82394409 time/batch=0.11s
410/537 (epoch 0.764) train_loss=302.14166260 time/batch=0.09s
411/537 (epoch 0.765) train_loss=219.43673706 time/batch=0.07s
412/537 (epoch 0.767) train_loss=336.94018555 time/batch=0.10s
413/537 (epoch 0.769) train_loss=207.15142822 time/batch=0.07s
414/537 (epoch 0.771) train_loss=273.13214111 time/batch=0.08s
415/537 (epoch 0.773) train_loss=298.11676025 time/batch=0.10s
416/537 (epoch 0.775) train_loss=217.74966431 time/batch=0.07s
417/537 (epoch 0.777) train_loss=332.73669434 time/batch=0.11s
418/537 (epoch 0.778) train_loss=254.14773560 time/batch=0.08s
419/537 (epoch 0.780) train_loss=503.17974854 time/batch=0.15s
420/537 (epoch 0.782) train_loss=209.74205017 time/batch=0.08s
421/537 (epoch 0.784) train_loss=196.91992188 time/batch=0.06s
422/537 (epoch 0.786) train_loss=223.86616516 time/batch=0.08s
423/537 (epoch 0.788) train_loss=341.18774414 time/batch=0.10s
424/537 (epoch 0.790) train_loss=281.47192383 time/batch=0.09s
425/537 (epoch 0.791) train_loss=329.86224365 time/batch=0.10s
426/537 (epoch 0.793) train_loss=342.95172119 time/batch=0.11s
427/537 (epoch 0.795) train_loss=361.10687256 time/batch=0.11s
428/537 (epoch 0.797) train_loss=285.24966431 time/batch=0.09s
429/537 (epoch 0.799) train_loss=262.59414673 time/batch=0.09s
430/537 (epoch 0.801) train_loss=189.83236694 time/batch=0.07s
431/537 (epoch 0.803) train_loss=319.48678589 time/batch=0.11s
432/537 (epoch 0.804) train_loss=267.29089355 time/batch=0.08s
433/537 (epoch 0.806) train_loss=192.21185303 time/batch=0.07s
434/537 (epoch 0.808) train_loss=424.09411621 time/batch=0.12s
435/537 (epoch 0.810) train_loss=403.67095947 time/batch=0.13s
436/537 (epoch 0.812) train_loss=475.84121704 time/batch=0.15s
437/537 (epoch 0.814) train_loss=335.45983887 time/batch=0.11s
438/537 (epoch 0.816) train_loss=187.93121338 time/batch=0.06s
439/537 (epoch 0.818) train_loss=305.02648926 time/batch=0.09s
440/537 (epoch 0.819) train_loss=263.44879150 time/batch=0.09s
441/537 (epoch 0.821) train_loss=431.83666992 time/batch=0.13s
442/537 (epoch 0.823) train_loss=312.37969971 time/batch=0.11s
443/537 (epoch 0.825) train_loss=369.71145630 time/batch=0.10s
444/537 (epoch 0.827) train_loss=231.71903992 time/batch=0.08s
445/537 (epoch 0.829) train_loss=188.23474121 time/batch=0.07s
446/537 (epoch 0.831) train_loss=172.79858398 time/batch=0.06s
447/537 (epoch 0.832) train_loss=291.42880249 time/batch=0.09s
448/537 (epoch 0.834) train_loss=161.76223755 time/batch=0.06s
449/537 (epoch 0.836) train_loss=162.11355591 time/batch=0.07s
450/537 (epoch 0.838) train_loss=308.42971802 time/batch=0.10s
451/537 (epoch 0.840) train_loss=272.58349609 time/batch=0.09s
452/537 (epoch 0.842) train_loss=216.87326050 time/batch=0.07s
453/537 (epoch 0.844) train_loss=179.83697510 time/batch=0.07s
454/537 (epoch 0.845) train_loss=289.83074951 time/batch=0.09s
455/537 (epoch 0.847) train_loss=444.52832031 time/batch=0.13s
456/537 (epoch 0.849) train_loss=296.87496948 time/batch=0.10s
457/537 (epoch 0.851) train_loss=231.62554932 time/batch=0.07s
458/537 (epoch 0.853) train_loss=237.36096191 time/batch=0.08s
459/537 (epoch 0.855) train_loss=433.43066406 time/batch=0.12s
460/537 (epoch 0.857) train_loss=220.54742432 time/batch=0.08s
461/537 (epoch 0.858) train_loss=225.08679199 time/batch=0.07s
462/537 (epoch 0.860) train_loss=417.14950562 time/batch=0.12s
463/537 (epoch 0.862) train_loss=206.35896301 time/batch=0.08s
464/537 (epoch 0.864) train_loss=241.32745361 time/batch=0.08s
465/537 (epoch 0.866) train_loss=331.15985107 time/batch=0.11s
466/537 (epoch 0.868) train_loss=262.47708130 time/batch=0.09s
467/537 (epoch 0.870) train_loss=195.31619263 time/batch=0.08s
468/537 (epoch 0.872) train_loss=462.73928833 time/batch=0.13s
469/537 (epoch 0.873) train_loss=267.58908081 time/batch=0.09s
470/537 (epoch 0.875) train_loss=285.82266235 time/batch=0.10s
471/537 (epoch 0.877) train_loss=217.31207275 time/batch=0.08s
472/537 (epoch 0.879) train_loss=283.62622070 time/batch=0.09s
473/537 (epoch 0.881) train_loss=218.03094482 time/batch=0.07s
474/537 (epoch 0.883) train_loss=251.83145142 time/batch=0.08s
475/537 (epoch 0.885) train_loss=300.31872559 time/batch=0.10s
476/537 (epoch 0.886) train_loss=251.08685303 time/batch=0.08s
477/537 (epoch 0.888) train_loss=258.11712646 time/batch=0.09s
478/537 (epoch 0.890) train_loss=458.27825928 time/batch=0.13s
479/537 (epoch 0.892) train_loss=273.87097168 time/batch=0.09s
480/537 (epoch 0.894) train_loss=301.49197388 time/batch=0.10s
481/537 (epoch 0.896) train_loss=299.41381836 time/batch=0.10s
482/537 (epoch 0.898) train_loss=368.06875610 time/batch=0.11s
483/537 (epoch 0.899) train_loss=348.26983643 time/batch=0.11s
484/537 (epoch 0.901) train_loss=369.90756226 time/batch=0.12s
485/537 (epoch 0.903) train_loss=266.20056152 time/batch=0.08s
486/537 (epoch 0.905) train_loss=216.29251099 time/batch=0.07s
487/537 (epoch 0.907) train_loss=332.19421387 time/batch=0.11s
488/537 (epoch 0.909) train_loss=346.76873779 time/batch=0.11s
489/537 (epoch 0.911) train_loss=377.48089600 time/batch=0.11s
490/537 (epoch 0.912) train_loss=367.48574829 time/batch=0.11s
491/537 (epoch 0.914) train_loss=230.30670166 time/batch=0.08s
492/537 (epoch 0.916) train_loss=209.73500061 time/batch=0.07s
493/537 (epoch 0.918) train_loss=231.22592163 time/batch=0.07s
494/537 (epoch 0.920) train_loss=223.22991943 time/batch=0.07s
495/537 (epoch 0.922) train_loss=354.99926758 time/batch=0.11s
496/537 (epoch 0.924) train_loss=315.32525635 time/batch=0.10s
497/537 (epoch 0.926) train_loss=341.59552002 time/batch=0.12s
498/537 (epoch 0.927) train_loss=259.60729980 time/batch=0.08s
499/537 (epoch 0.929) train_loss=320.11514282 time/batch=0.10s
500/537 (epoch 0.931) train_loss=319.01589966 time/batch=0.11s
501/537 (epoch 0.933) train_loss=306.21008301 time/batch=0.10s
502/537 (epoch 0.935) train_loss=324.48022461 time/batch=0.10s
503/537 (epoch 0.937) train_loss=307.19906616 time/batch=0.10s
504/537 (epoch 0.939) train_loss=366.93182373 time/batch=0.13s
505/537 (epoch 0.940) train_loss=259.85534668 time/batch=0.09s
506/537 (epoch 0.942) train_loss=211.84446716 time/batch=0.07s
507/537 (epoch 0.944) train_loss=273.89257812 time/batch=0.09s
508/537 (epoch 0.946) train_loss=267.29840088 time/batch=0.08s
509/537 (epoch 0.948) train_loss=263.20382690 time/batch=0.09s
510/537 (epoch 0.950) train_loss=253.87142944 time/batch=0.09s
511/537 (epoch 0.952) train_loss=234.04547119 time/batch=0.08s
512/537 (epoch 0.953) train_loss=318.90734863 time/batch=0.10s
513/537 (epoch 0.955) train_loss=231.42167664 time/batch=0.07s
514/537 (epoch 0.957) train_loss=277.49349976 time/batch=0.08s
515/537 (epoch 0.959) train_loss=206.63301086 time/batch=0.07s
516/537 (epoch 0.961) train_loss=272.60632324 time/batch=0.10s
517/537 (epoch 0.963) train_loss=338.77496338 time/batch=0.10s
518/537 (epoch 0.965) train_loss=207.82276917 time/batch=0.07s
519/537 (epoch 0.966) train_loss=350.38854980 time/batch=0.11s
520/537 (epoch 0.968) train_loss=287.17364502 time/batch=0.09s
521/537 (epoch 0.970) train_loss=270.64636230 time/batch=0.09s
522/537 (epoch 0.972) train_loss=227.68566895 time/batch=0.08s
523/537 (epoch 0.974) train_loss=230.10827637 time/batch=0.08s
524/537 (epoch 0.976) train_loss=296.04974365 time/batch=0.09s
525/537 (epoch 0.978) train_loss=221.36349487 time/batch=0.07s
526/537 (epoch 0.980) train_loss=265.17282104 time/batch=0.09s
527/537 (epoch 0.981) train_loss=206.30303955 time/batch=0.08s
528/537 (epoch 0.983) train_loss=231.81381226 time/batch=0.07s
529/537 (epoch 0.985) train_loss=226.82791138 time/batch=0.08s
530/537 (epoch 0.987) train_loss=368.91375732 time/batch=0.12s
531/537 (epoch 0.989) train_loss=273.49847412 time/batch=0.08s
532/537 (epoch 0.991) train_loss=306.45440674 time/batch=0.11s
533/537 (epoch 0.993) train_loss=268.41510010 time/batch=0.08s
534/537 (epoch 0.994) train_loss=333.22845459 time/batch=0.12s
535/537 (epoch 0.996) train_loss=307.46502686 time/batch=0.10s
536/537 (epoch 0.998) train_loss=305.85363770 time/batch=0.11s
537/537 (epoch 1.000) train_loss=260.62371826 time/batch=0.09s
  saved to metadata/AddSharpAndFlat-20190201-022312
