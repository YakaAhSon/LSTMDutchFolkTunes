set(['1/4=76\n', '[I:setbarnb 80]', 'G2>', 'G2<', '1/2=56\n', '1/2=60\n', '[I:setbarnb 61]', '[K:F]', '[I:setbarnb 91]', '[I:setbarnb 41]', 'G7', 'G6', 'G4', 'G3', 'G2', '[I:setbarnb 48]', 'G>', 'G<', '[I:setbarnb 56]', 'G8', '1/2=100\n', 'G/', 'G,', 'g7', 'g6', 'g4', 'g3', 'g2', 'g>', 'g<', 'F2', 'g8', "g'", '_A4', 'F4>', '1/4=152\n', 'g/', '16/2\n', "^c'", '_A2', '^A2', 'B2>', 'B2<', '^A6', 'G,4<', '^A4', 'G,4>', 'F clef=treble\n', '^A>', '8/4\n', '^A<', 'c4<', '_e2>', '[I:setbarnb 58]', '_e2<', '_A>', '3/8=60\n', 'e/8', 'e/>', '3/4=60\n', 'e/<', '1/4=100\n', 'b2>', 'b2<', '^a6', '^c>', '^a4', 'A,2>', 'A2<', 'e4<', 'n', 'd4', 'M:', '1/4=84\n', '^E/', 'g2>', '^c4', 'g2<', 'E,2>', 'Db clef=treble\n', 'F2>', '3/8=144\n', '[I:setbarnb 34]', '[K:G]', 'Z4', 'Z5', 'A clef=treble\n', '3/8=132\n', 'Z2', 'Z3', '_B>', 'z/', '[K:F#]', '3/4=63\n', '^d6', 'G,/', '^c7', '[I:setbarnb 5]', 'z<', '1/2=88\n', 'z>', 'Eb clef=treble\n', 'z8', '[I:setbarnb 24]', 'G,>', 'z4', '1/2=54\n', 'G,2', 'G,3', 'G,4', 'z2', 'z3', 'A,/', '_G/', 'F7', 'g4<', 'E clef=treble\n', '[I:setbarnb 66]', 'A,>', '[M:3/4]', '6/8\n', 'A,8', 'A,6', 'A,4', 'A,2', 'A,3', '3/2\n', '_G2', "d'2<", "d'2>", "d'4>", '12/2\n', 'A4>', 'B,>', '1/4=96\n', "e'2>", 'G/<', 'e7', '3/8=184\n', '_g2', "c'2<", '6/2\n', '_d4', 'D clef=bass\n', 'C,2>', 'C,2<', 'F/<', "c'/>", '[I:setbarnb 40]', '_A2<', '5/8\n', 'F', 'E2<', '^e2', 'E2>', '^e3', '_A8', 'B,3', '[M:4/8]', 'F,2<', 'F,2>', 'F3', 'F4', 'F6', 'f', 'F8', 'c4>', '1/8=152\n', 'F<', '^E3', 'F>', 'F clef=bass\n', '[I:setbarnb 11]', '^G,2>', '3/8=126\n', 'F,', '1/4=168\n', 'F/', '^e>', 'B,<', 'f2', 'f3', 'f4', '[M:10/4]', 'f6', 'f7', 'f8', 'B,4', '^e4', 'B,6', 'f<', 'F4<', 'f>', 'B,2', '^e/', 'B,/', '^d<', "f'", '^D,4', '[I:setbarnb 78]', 'f/', '[I:setbarnb 30]', '[I:setbarnb 65]', '^B/', '^B,', 'x/>', 'z2>', 'z2<', '^C,2>', '1/4=88\n', '[M:6/2]', '^B3', '^B2', '^E4', '^B4', 'A', '[I:setbarnb 93]', 'w', '[M:8/4]', '_b2', 'G,<', '[I:setbarnb 44]', '^G2>', '^D,2', 'D4<', 'L:', 'a', '3/8=108\n', 'e2<', 'e2>', '[I:setbarnb 23]', '[M:5/8]', '[K:Bb]', '^C4', '^E2', '[I:setbarnb 9]', '[I:setbarnb 71]', '_a2', '_G', '_E', '_D', '_B', '_A', '[I:setbarnb 68]', '^c4<', '^c4>', 'D,<', 'f4<', '[M:7/4]', 'f4>', '[I:setbarnb 116]', '3/8=80\n', '_g', 'A/>', '_e', '_d', '_c', '_b', '_a', 'A/8', '^G,4', '^A3', '1/2=63\n', 'D clef=treble\n', '3/8=96\n', '2/4\n', 'D/>', 'a/>', '[I:setbarnb 134]', 'a/<', "e'>", 'A,4>', "e'3", "e'2", '_E,', 'l', '1/8=120\n', '[M:2/2]', 'A,4<', "e'/", 'd4>', 'd4<', "^c'4", '|', 'C,/', 'b<', '[I:setbarnb 4]', '^A,>', '[M:1/4]', '1/8=168\n', '[I:setbarnb 57]', 'C,8', 'C,4', '[K:Ab]', 'C,6', 'G4<', 'C,2', '1/4=92\n', 'G clef=treble\n', '^F6', 'E/', '^F4', '^F3', '^F2', 'p', '5/2\n', '^F>', '^F<', '_A,/>', '^F8', 'E<', 'E>', '3/8=168\n', 'E8', '3/8=63\n', '^F/', 'E4', 'E7', 'E6', '3/8=152\n', 'E3', 'E2', '^f6', 'e/', '^f4', '^f3', '^f2', 'G', '^f>', "e'", '^f<', "^f'", 'e<', 'e>', 'e8', 'x', '^f/', 'e4', 'A4<', 'e6', 'e3', 'e2', '_B,4', '1/2=120\n', '_B,2', 'g', 'G clef=bass\n', '^A/', 'G,2>', 'd/8', 'G,2<', 'd/>', '^A,', 'd/<', '[I:setbarnb 20]', '_B,/', '^D3', 'D4>', '1/4=126\n', '^a2', '^F,', '4/4\n', '^G2<', 'D,2>', 'D,2<', '1/2=152\n', '[I:setbarnb 26]', 'G/>', 'G/8', 'K:', "e'4", '[M:13/8]', 'A,2<', '^b', '[I:setbarnb 12]', '[M:2/1]', '1/2=48\n', '7/8\n', 'g4>', '^C,3', 'B', '^D/', '^C,6', '3/8=84\n', '[M:12/8]', '^C,>', 'x8', 'x>', '^e', 'x2', 'x3', 'x6', 'x7', 'x4', 'b', '[I:setbarnb 19]', "e'6", '3/4=69\n', '[I:setbarnb 29]', 'r', 'G,/>', 'a4>', 'a4<', '[I:setbarnb 35]', 'B/8', '^G,3', '^G,2', '1/4=176\n', 'Q:', 'D,/', '[K:D]', 'D,2', '^C,2', 'D,6', '1/4=160\n', 'D,4', 'D,8', 'D,>', 'x/', 'B/>', '[I:setbarnb 54]', '^d>', '^a/', 'g/<', 'g/>', 'g/8', '[I:setbarnb 8]', '[K:C]', "f'4", 'Bb clef=bass\n', '1/4\n', "f'3", '9/8\n', "f'/", '^A', '^B', '^C', ']', '^E', '^F', '^G', 'D/', 'D,', '[K:clef=bass]', '^C/', '^C,', 'B4<', 'B4>', 'm', 'D>', 'D<', '^C>', 'E,2<', 'D6', 'D7', '^C2', '^c', 'D2', '[I:setbarnb 18]', '^f', '^g', 'd/', '^c/', "d'", '3/8=240\n', 'd>', '3/8=69\n', 'd<', '^C2<', '^c<', 'd8', 'C<', 'd6', 'd7', '^c2', '^c3', 'd2', 'd3', '^c6', 'F2<', '[I:setbarnb 16]', '_B<', 'Z', '^C2>', '_B8', '_B6', '_B4', '_B2', '_B3', '_f/', '7/4\n', '_B/', '[I:setbarnb 36]', 'x2>', '^a', '[I:setbarnb 99]', '_b>', '_b<', '1/2=52\n', '[I:setbarnb 3]', '_b6', '_b4', 'C2>', '_b3', 'C2<', '_b/', '[I:setbarnb 22]', '^e/>', '[I:setbarnb 38]', '3/8=88\n', 'Z6', 'Z7', '_E/', '[I:setbarnb 31]', '[I:setbarnb 76]', '_E>', '_E3', '_E2', '_E6', '_E4', '_e/', '_E,>', "_e'", '_e8', '_e>', '_e<', '_e3', '_e2', '_e6', '_e4', '[M:10/8]', '_E,3', '[I:setbarnb 46]', '1/8=160\n', '^g2<', '^c2>', '^c2<', '^F,3', 'f2>', 'z/>', 'f2<', '^A/>', 'C', '2/2\n', 'E4>', '^F/>', '3/8=160\n', "d'/", 'E4<', 'C/>', "d'2", "d'3", "d'6", "d'4", "d'8", '[M:2/16]', "d'>", "d'<", '^G4', 'G,8', 'c', '^G2', '^G3', '^G>', 'c2>', 'c2<', "c'2>", '3/8=100\n', '_d2<', '[I:setbarnb 125]', '^F,2>', '^G,', '[M:2/4]', '^G/', '_a2<', '^g4', '1/2=80\n', '^g6', '^d/>', '^g2', '^g3', '^g>', '^g8', ',', 'G,6', '1/4=138\n', '[M:9/4]', '^g/', 'z6', '[I:setbarnb 73]', 'z7', 'C/', 'C,', '_B/>', '[I:setbarnb 28]', 'C8', 'C>', '^c/>', '8/8\n', 'C3', 'C2', 'C6', '[I:setbarnb 32]', 'C4', '^G,>', 'c/', '1/2=76\n', '[I:setbarnb 69]', '^F2>', '^F2<', "c'", '^G6', 'c8', 'c>', '[I:setbarnb 50]', 'c<', 'c3', 'c2', 'c7', 'c6', 'c4', 'D,3', '[M:1/2]', 'A/<', '_A3', '9/4\n', '_a2>', 'c/8', '[I:setbarnb 21]', '^f/>', 'e4>', 'c/<', 'A2>', 'c/>', '[I:setbarnb 7]', '1/4=120\n', '1/2=96\n', '_A/', '_A,', '[I:setbarnb 59]', '_a4', '_a3', '[I:setbarnb 43]', '_A2>', '_a>', 'F/>', 'a2<', 'a2>', '_A,/', '_e4>', '1/2=66\n', '[I:setbarnb 27]', 'A,<', 'D4', '[I:setbarnb 110]', '[I:setbarnb 53]', '[M:22/8]', 'A,/>', '3/8=176\n', '[M:3/16]', '3/8=112\n', '_G7', '1/16\n', '^f2>', '^f2<', 'B,/>', 'B clef=treble\n', '[I:setbarnb 13]', '^e2<', '^F,/', '3/8=116\n', '_E,/', '3/4=66\n', '[I:setbarnb 2]', '_A,4', '^F,>', '[M:9/8]', '[I:setbarnb 25]', '^F,4', '^F,6', '1/4=72\n', '^F,2', '[I:setbarnb 39]', 'Eb clef=bass\n', '[M:8/8]', '[I:setbarnb 67]', 'f/<', 'f/>', 'f/8', '[I:setbarnb 77]', '[M:6/4]', '_A,3', '[M:19/16]', '[I:setbarnb 49]', '_B,', 'D', '3/8=138\n', 'A6', '^g2>', '1/2=44\n', '[I:setbarnb 42]', 'E,8', '^e2>', 'F,/', '1/2=72\n', '_A,2', '3/8=72\n', '[M:3/2]', '14/2\n', 'd', 'B,', 'B/', 'B4', '1/4=132\n', 'B6', 'B7', 't', 'B2', 'B3', 'B<', 'B>', 'B8', 'E,/', '1/2=92\n', 'b/', '3/4\n', '4/2\n', 'b4', 'b6', 'E,>', '_b2<', 'b2', 'b3', 'E,2', 'E,3', 'b>', '12/8\n', 'E,6', 'E,4', '_D,', 'F,>', '1/8=144\n', '_a/', '[I:setbarnb 122]', '[I:setbarnb 10]', '1/8=176\n', '_D4', '[I:setbarnb 138]', '_B2<', '1/8=240\n', '_d/', '_B2>', 'F,4<', "f'2", '_d>', '_d2', '[M:5/4]', '1/4=69\n', '1/4=56\n', '[I:setbarnb 17]', 'B,8', '1/8\n', '_B,2>', 'o', '[I:setbarnb 15]', '[I:setbarnb 37]', '^A2>', '^C,4', '_A<', 'a4', '2/1\n', '[M:4/4]', '^c8', '3/8=120\n', '[M:7/8]', "^c'/", "^c'2", '1/4=60\n', '[I:setbarnb 51]', '[I:setbarnb 92]', '1/4=80\n', '[K:Eb]', '[M:6/8]', '5/4\n', '3/8=66\n', 'i', '^D>', '^D', '1/2=104\n', '^D2', '^D4', 'E/>', '[K:clef=treble]', '[I:setbarnb 6]', '2/8\n', '[M:4/2]', '^D2<', '^D2>', 'C clef=bass\n', 'B/<', 'D2<', "c'/", 'D2>', '[I:setbarnb 85]', '1/2=84\n', '^d3', '^d2', '^d4', '[K:A]', '1/4=144\n', "c'8", "c'<", '^d/', "c'>", 'b/<', "c'3", "c'2", 'C clef=treble\n', "c'4", "c'6", "^d'2", '3/8=92\n', '[I:setbarnb 45]', 'C,>', '1/4=112\n', '1/4=104\n', '3/8=76\n', 'z', "^d'/", '3/8\n', '[I:setbarnb 105]', 'E,<', 'Bb clef=treble\n', '_b2>', '1/8=112\n', '1/4=108\n', 'F/8', '1/4=192\n', 'B,2<', '[M:2/8]', 'B,2>', 'b8', "g'2", 'A,', 'A/', '10/2\n', '1/4=46\n', 'A3', 'A2', 'A4', 'A7', '6/4\n', 'A8', 'C,3', 'A<', '[I:setbarnb 14]', 'A>', '8/16\n', '[I:setbarnb 1]', 'E', 'D8', '[M:3/8]', 'E,', 'F,3', 'F,2', 'F,4', 'a/', 'F,6', 'a3', 'a2', '_E2>', '1/2=69\n', '_E2<', 'a6', 'a8', 'E/8', 'a<', 'G4>', 'a>', '^d2>', '^C3', 'e', 'd2<', 'b/>', 'd2>', '^d', '4/8\n', 'D3', '^G4>', 'u', "_e'2", 'Ab clef=treble\n', '[I:setbarnb 33]'])
vocabulary size: 895
n tunes: 18107
n train tunes: 17211
n validation tunes: 896
min, max length 15 1884
Building the model
  number of parameters: 3262848
  layer output shapes:               #params:   output shape:
    InputLayer                       0          (32, None)
    EmbeddingLayer                   801025     (32, None, 895)
    InputLayer                       0          (32, None)
    LSTMLayer                        1180160    (32, None, 256)
    DropoutLayer                     0          (32, None, 256)
    LSTMLayer                        525824     (32, None, 256)
    DropoutLayer                     0          (32, None, 256)
    LSTMLayer                        525824     (32, None, 256)
    DropoutLayer                     0          (32, None, 256)
    ReshapeLayer                     0          (None, 256)
    DenseLayer                       230015     (None, 895)
Train model
1/537 (epoch 0.002) train_loss=3921.37963867 time/batch=1.45s
2/537 (epoch 0.004) train_loss=2909.95581055 time/batch=0.52s
3/537 (epoch 0.006) train_loss=223.28984070 time/batch=0.08s
4/537 (epoch 0.007) train_loss=1362.57177734 time/batch=0.29s
5/537 (epoch 0.009) train_loss=1365.88281250 time/batch=0.34s
6/537 (epoch 0.011) train_loss=1402.28491211 time/batch=0.38s
7/537 (epoch 0.013) train_loss=1013.41528320 time/batch=0.27s
8/537 (epoch 0.015) train_loss=1103.00024414 time/batch=0.30s
9/537 (epoch 0.017) train_loss=964.51666260 time/batch=0.26s
10/537 (epoch 0.019) train_loss=289.35934448 time/batch=0.09s
11/537 (epoch 0.020) train_loss=2156.86181641 time/batch=0.67s
12/537 (epoch 0.022) train_loss=472.79833984 time/batch=0.18s
13/537 (epoch 0.024) train_loss=588.05249023 time/batch=0.14s
14/537 (epoch 0.026) train_loss=599.73815918 time/batch=0.15s
15/537 (epoch 0.028) train_loss=314.81118774 time/batch=0.08s
16/537 (epoch 0.030) train_loss=497.36755371 time/batch=0.12s
17/537 (epoch 0.032) train_loss=809.31439209 time/batch=0.21s
18/537 (epoch 0.034) train_loss=143.11633301 time/batch=0.05s
19/537 (epoch 0.035) train_loss=1603.16601562 time/batch=0.39s
20/537 (epoch 0.037) train_loss=754.86950684 time/batch=0.20s
21/537 (epoch 0.039) train_loss=235.81683350 time/batch=0.07s
22/537 (epoch 0.041) train_loss=359.47537231 time/batch=0.08s
23/537 (epoch 0.043) train_loss=842.12872314 time/batch=0.22s
24/537 (epoch 0.045) train_loss=961.63854980 time/batch=0.26s
25/537 (epoch 0.047) train_loss=514.74255371 time/batch=0.15s
26/537 (epoch 0.048) train_loss=1110.80334473 time/batch=0.29s
27/537 (epoch 0.050) train_loss=535.06243896 time/batch=0.17s
28/537 (epoch 0.052) train_loss=459.28509521 time/batch=0.13s
29/537 (epoch 0.054) train_loss=186.30284119 time/batch=0.05s
30/537 (epoch 0.056) train_loss=603.97961426 time/batch=0.15s
31/537 (epoch 0.058) train_loss=776.30651855 time/batch=0.21s
32/537 (epoch 0.060) train_loss=866.98156738 time/batch=0.23s
33/537 (epoch 0.061) train_loss=706.52313232 time/batch=0.20s
34/537 (epoch 0.063) train_loss=437.06198120 time/batch=0.12s
35/537 (epoch 0.065) train_loss=1289.78784180 time/batch=0.33s
36/537 (epoch 0.067) train_loss=1425.35510254 time/batch=0.41s
37/537 (epoch 0.069) train_loss=99.51779175 time/batch=0.06s
38/537 (epoch 0.071) train_loss=582.80303955 time/batch=0.15s
39/537 (epoch 0.073) train_loss=907.47851562 time/batch=0.24s
40/537 (epoch 0.074) train_loss=919.80218506 time/batch=0.25s
41/537 (epoch 0.076) train_loss=1621.86132812 time/batch=0.81s
42/537 (epoch 0.078) train_loss=554.86584473 time/batch=0.22s
43/537 (epoch 0.080) train_loss=799.97534180 time/batch=0.22s
44/537 (epoch 0.082) train_loss=664.61987305 time/batch=0.19s
45/537 (epoch 0.084) train_loss=257.69882202 time/batch=0.09s
46/537 (epoch 0.086) train_loss=266.57934570 time/batch=0.07s
47/537 (epoch 0.088) train_loss=916.69958496 time/batch=0.24s
48/537 (epoch 0.089) train_loss=3458.96826172 time/batch=1.90s
49/537 (epoch 0.091) train_loss=129.53147888 time/batch=0.21s
50/537 (epoch 0.093) train_loss=539.34545898 time/batch=0.14s
51/537 (epoch 0.095) train_loss=1047.17968750 time/batch=0.30s
52/537 (epoch 0.097) train_loss=271.68338013 time/batch=0.09s
53/537 (epoch 0.099) train_loss=726.71606445 time/batch=0.20s
54/537 (epoch 0.101) train_loss=846.31359863 time/batch=0.23s
55/537 (epoch 0.102) train_loss=169.15609741 time/batch=0.06s
56/537 (epoch 0.104) train_loss=387.38919067 time/batch=0.10s
57/537 (epoch 0.106) train_loss=227.88131714 time/batch=0.08s
58/537 (epoch 0.108) train_loss=500.69036865 time/batch=0.14s
59/537 (epoch 0.110) train_loss=1050.75927734 time/batch=0.30s
60/537 (epoch 0.112) train_loss=499.60327148 time/batch=0.15s
61/537 (epoch 0.114) train_loss=798.76037598 time/batch=0.22s
62/537 (epoch 0.115) train_loss=634.19055176 time/batch=0.17s
63/537 (epoch 0.117) train_loss=733.11596680 time/batch=0.20s
64/537 (epoch 0.119) train_loss=432.89959717 time/batch=0.13s
65/537 (epoch 0.121) train_loss=124.69596863 time/batch=0.05s
66/537 (epoch 0.123) train_loss=389.15911865 time/batch=0.10s
67/537 (epoch 0.125) train_loss=570.67169189 time/batch=0.15s
68/537 (epoch 0.127) train_loss=288.60528564 time/batch=0.09s
69/537 (epoch 0.128) train_loss=198.37533569 time/batch=0.06s
70/537 (epoch 0.130) train_loss=396.47109985 time/batch=0.11s
71/537 (epoch 0.132) train_loss=527.95349121 time/batch=0.14s
72/537 (epoch 0.134) train_loss=678.09594727 time/batch=0.19s
73/537 (epoch 0.136) train_loss=307.89910889 time/batch=0.09s
74/537 (epoch 0.138) train_loss=335.55899048 time/batch=0.10s
75/537 (epoch 0.140) train_loss=968.06274414 time/batch=0.26s
76/537 (epoch 0.142) train_loss=843.55957031 time/batch=0.25s
77/537 (epoch 0.143) train_loss=813.13244629 time/batch=0.24s
78/537 (epoch 0.145) train_loss=578.82543945 time/batch=0.17s
79/537 (epoch 0.147) train_loss=329.32363892 time/batch=0.11s
80/537 (epoch 0.149) train_loss=565.89526367 time/batch=0.15s
81/537 (epoch 0.151) train_loss=694.78649902 time/batch=0.20s
82/537 (epoch 0.153) train_loss=176.78742981 time/batch=0.07s
83/537 (epoch 0.155) train_loss=127.18889618 time/batch=0.04s
84/537 (epoch 0.156) train_loss=605.26422119 time/batch=0.16s
85/537 (epoch 0.158) train_loss=662.94964600 time/batch=0.19s
86/537 (epoch 0.160) train_loss=654.12365723 time/batch=0.19s
87/537 (epoch 0.162) train_loss=448.15631104 time/batch=0.13s
88/537 (epoch 0.164) train_loss=303.23126221 time/batch=0.10s
89/537 (epoch 0.166) train_loss=617.17443848 time/batch=0.16s
90/537 (epoch 0.168) train_loss=475.67736816 time/batch=0.13s
91/537 (epoch 0.169) train_loss=605.10107422 time/batch=0.16s
92/537 (epoch 0.171) train_loss=177.28152466 time/batch=0.07s
93/537 (epoch 0.173) train_loss=748.36480713 time/batch=0.19s
94/537 (epoch 0.175) train_loss=568.69982910 time/batch=0.17s
95/537 (epoch 0.177) train_loss=481.61560059 time/batch=0.14s
96/537 (epoch 0.179) train_loss=363.21725464 time/batch=0.10s
97/537 (epoch 0.181) train_loss=510.96990967 time/batch=0.15s
98/537 (epoch 0.182) train_loss=424.58496094 time/batch=0.12s
99/537 (epoch 0.184) train_loss=432.70275879 time/batch=0.12s
100/537 (epoch 0.186) train_loss=285.95220947 time/batch=0.08s
101/537 (epoch 0.188) train_loss=666.98022461 time/batch=0.18s
102/537 (epoch 0.190) train_loss=619.65527344 time/batch=0.18s
103/537 (epoch 0.192) train_loss=219.31349182 time/batch=0.08s
104/537 (epoch 0.194) train_loss=116.39906311 time/batch=0.04s
105/537 (epoch 0.196) train_loss=489.97149658 time/batch=0.14s
106/537 (epoch 0.197) train_loss=1040.90136719 time/batch=0.31s
107/537 (epoch 0.199) train_loss=312.70458984 time/batch=0.11s
108/537 (epoch 0.201) train_loss=168.41604614 time/batch=0.05s
109/537 (epoch 0.203) train_loss=145.66401672 time/batch=0.05s
110/537 (epoch 0.205) train_loss=322.17980957 time/batch=0.09s
111/537 (epoch 0.207) train_loss=602.89123535 time/batch=0.16s
112/537 (epoch 0.209) train_loss=448.53240967 time/batch=0.13s
113/537 (epoch 0.210) train_loss=741.90679932 time/batch=0.20s
114/537 (epoch 0.212) train_loss=222.18962097 time/batch=0.09s
115/537 (epoch 0.214) train_loss=717.59020996 time/batch=0.18s
116/537 (epoch 0.216) train_loss=189.28265381 time/batch=0.08s
117/537 (epoch 0.218) train_loss=258.30728149 time/batch=0.08s
118/537 (epoch 0.220) train_loss=499.99157715 time/batch=0.14s
119/537 (epoch 0.222) train_loss=214.95492554 time/batch=0.07s
120/537 (epoch 0.223) train_loss=202.73786926 time/batch=0.06s
121/537 (epoch 0.225) train_loss=760.44409180 time/batch=0.20s
122/537 (epoch 0.227) train_loss=706.32263184 time/batch=0.21s
123/537 (epoch 0.229) train_loss=331.39111328 time/batch=0.11s
124/537 (epoch 0.231) train_loss=429.17065430 time/batch=0.12s
125/537 (epoch 0.233) train_loss=265.64166260 time/batch=0.09s
126/537 (epoch 0.235) train_loss=381.16107178 time/batch=0.11s
127/537 (epoch 0.236) train_loss=635.05780029 time/batch=0.18s
128/537 (epoch 0.238) train_loss=443.87908936 time/batch=0.13s
129/537 (epoch 0.240) train_loss=292.69949341 time/batch=0.09s
130/537 (epoch 0.242) train_loss=120.39506531 time/batch=0.04s
131/537 (epoch 0.244) train_loss=335.70761108 time/batch=0.10s
132/537 (epoch 0.246) train_loss=516.19238281 time/batch=0.14s
133/537 (epoch 0.248) train_loss=280.33306885 time/batch=0.08s
134/537 (epoch 0.250) train_loss=158.51184082 time/batch=0.06s
135/537 (epoch 0.251) train_loss=618.15393066 time/batch=0.17s
136/537 (epoch 0.253) train_loss=315.25811768 time/batch=0.10s
137/537 (epoch 0.255) train_loss=416.33673096 time/batch=0.12s
138/537 (epoch 0.257) train_loss=595.48889160 time/batch=0.17s
139/537 (epoch 0.259) train_loss=400.11776733 time/batch=0.12s
140/537 (epoch 0.261) train_loss=723.65582275 time/batch=0.21s
141/537 (epoch 0.263) train_loss=320.62960815 time/batch=0.10s
142/537 (epoch 0.264) train_loss=627.67272949 time/batch=0.17s
143/537 (epoch 0.266) train_loss=591.49145508 time/batch=0.18s
144/537 (epoch 0.268) train_loss=153.52536011 time/batch=0.06s
145/537 (epoch 0.270) train_loss=219.46783447 time/batch=0.06s
146/537 (epoch 0.272) train_loss=525.66406250 time/batch=0.15s
147/537 (epoch 0.274) train_loss=524.90893555 time/batch=0.14s
148/537 (epoch 0.276) train_loss=364.89456177 time/batch=0.12s
149/537 (epoch 0.277) train_loss=558.68518066 time/batch=0.15s
150/537 (epoch 0.279) train_loss=465.45135498 time/batch=0.13s
151/537 (epoch 0.281) train_loss=336.30590820 time/batch=0.11s
152/537 (epoch 0.283) train_loss=216.23297119 time/batch=0.08s
153/537 (epoch 0.285) train_loss=389.34545898 time/batch=0.11s
154/537 (epoch 0.287) train_loss=159.07478333 time/batch=0.06s
155/537 (epoch 0.289) train_loss=376.58853149 time/batch=0.11s
156/537 (epoch 0.291) train_loss=154.35110474 time/batch=0.06s
157/537 (epoch 0.292) train_loss=629.42089844 time/batch=0.17s
158/537 (epoch 0.294) train_loss=675.35870361 time/batch=0.19s
159/537 (epoch 0.296) train_loss=842.79675293 time/batch=0.31s
160/537 (epoch 0.298) train_loss=318.11944580 time/batch=0.11s
161/537 (epoch 0.300) train_loss=398.54095459 time/batch=0.11s
162/537 (epoch 0.302) train_loss=379.04556274 time/batch=0.12s
163/537 (epoch 0.304) train_loss=795.55847168 time/batch=0.21s
164/537 (epoch 0.305) train_loss=462.39587402 time/batch=0.13s
165/537 (epoch 0.307) train_loss=351.97875977 time/batch=0.11s
166/537 (epoch 0.309) train_loss=743.06646729 time/batch=0.22s
167/537 (epoch 0.311) train_loss=392.65496826 time/batch=0.13s
168/537 (epoch 0.313) train_loss=479.30960083 time/batch=0.13s
169/537 (epoch 0.315) train_loss=388.59936523 time/batch=0.12s
170/537 (epoch 0.317) train_loss=407.18139648 time/batch=0.11s
171/537 (epoch 0.318) train_loss=196.74258423 time/batch=0.07s
172/537 (epoch 0.320) train_loss=410.74505615 time/batch=0.11s
173/537 (epoch 0.322) train_loss=394.83914185 time/batch=0.11s
174/537 (epoch 0.324) train_loss=606.85705566 time/batch=0.18s
175/537 (epoch 0.326) train_loss=199.50274658 time/batch=0.08s
176/537 (epoch 0.328) train_loss=157.54882812 time/batch=0.06s
177/537 (epoch 0.330) train_loss=587.99310303 time/batch=0.15s
178/537 (epoch 0.331) train_loss=233.52323914 time/batch=0.08s
179/537 (epoch 0.333) train_loss=160.49888611 time/batch=0.06s
180/537 (epoch 0.335) train_loss=224.57073975 time/batch=0.07s
181/537 (epoch 0.337) train_loss=321.44915771 time/batch=0.09s
182/537 (epoch 0.339) train_loss=463.11853027 time/batch=0.13s
183/537 (epoch 0.341) train_loss=164.92318726 time/batch=0.06s
184/537 (epoch 0.343) train_loss=605.51446533 time/batch=0.15s
185/537 (epoch 0.345) train_loss=252.80130005 time/batch=0.09s
186/537 (epoch 0.346) train_loss=178.81407166 time/batch=0.06s
187/537 (epoch 0.348) train_loss=302.10104370 time/batch=0.09s
188/537 (epoch 0.350) train_loss=367.89944458 time/batch=0.11s
189/537 (epoch 0.352) train_loss=175.49775696 time/batch=0.07s
190/537 (epoch 0.354) train_loss=185.61907959 time/batch=0.07s
191/537 (epoch 0.356) train_loss=278.77697754 time/batch=0.09s
192/537 (epoch 0.358) train_loss=264.75131226 time/batch=0.08s
193/537 (epoch 0.359) train_loss=559.49890137 time/batch=0.15s
194/537 (epoch 0.361) train_loss=339.31658936 time/batch=0.12s
195/537 (epoch 0.363) train_loss=366.75317383 time/batch=0.10s
196/537 (epoch 0.365) train_loss=624.83392334 time/batch=0.18s
197/537 (epoch 0.367) train_loss=302.81262207 time/batch=0.10s
198/537 (epoch 0.369) train_loss=542.80456543 time/batch=0.16s
199/537 (epoch 0.371) train_loss=360.60351562 time/batch=0.12s
200/537 (epoch 0.372) train_loss=419.86114502 time/batch=0.11s
201/537 (epoch 0.374) train_loss=715.75927734 time/batch=0.20s
202/537 (epoch 0.376) train_loss=336.28305054 time/batch=0.12s
203/537 (epoch 0.378) train_loss=127.29173279 time/batch=0.04s
204/537 (epoch 0.380) train_loss=167.42984009 time/batch=0.07s
205/537 (epoch 0.382) train_loss=721.81469727 time/batch=0.18s
206/537 (epoch 0.384) train_loss=142.85841370 time/batch=0.06s
207/537 (epoch 0.385) train_loss=459.06945801 time/batch=0.14s
208/537 (epoch 0.387) train_loss=345.65405273 time/batch=0.11s
209/537 (epoch 0.389) train_loss=357.45996094 time/batch=0.11s
210/537 (epoch 0.391) train_loss=285.92681885 time/batch=0.08s
211/537 (epoch 0.393) train_loss=315.12191772 time/batch=0.10s
212/537 (epoch 0.395) train_loss=395.23522949 time/batch=0.11s
213/537 (epoch 0.397) train_loss=202.20965576 time/batch=0.08s
214/537 (epoch 0.399) train_loss=121.80678558 time/batch=0.04s
215/537 (epoch 0.400) train_loss=241.54544067 time/batch=0.08s
216/537 (epoch 0.402) train_loss=474.90075684 time/batch=0.13s
217/537 (epoch 0.404) train_loss=259.29577637 time/batch=0.09s
218/537 (epoch 0.406) train_loss=648.85144043 time/batch=0.20s
219/537 (epoch 0.408) train_loss=282.63568115 time/batch=0.10s
220/537 (epoch 0.410) train_loss=228.98152161 time/batch=0.08s
221/537 (epoch 0.412) train_loss=153.72410583 time/batch=0.05s
222/537 (epoch 0.413) train_loss=402.08990479 time/batch=0.12s
223/537 (epoch 0.415) train_loss=362.66757202 time/batch=0.11s
224/537 (epoch 0.417) train_loss=152.81851196 time/batch=0.06s
225/537 (epoch 0.419) train_loss=629.46423340 time/batch=0.17s
226/537 (epoch 0.421) train_loss=148.72549438 time/batch=0.06s
227/537 (epoch 0.423) train_loss=428.20989990 time/batch=0.13s
228/537 (epoch 0.425) train_loss=384.78829956 time/batch=0.11s
229/537 (epoch 0.426) train_loss=272.41992188 time/batch=0.10s
230/537 (epoch 0.428) train_loss=255.20425415 time/batch=0.08s
231/537 (epoch 0.430) train_loss=274.26214600 time/batch=0.10s
232/537 (epoch 0.432) train_loss=310.25094604 time/batch=0.10s
233/537 (epoch 0.434) train_loss=504.03433228 time/batch=0.14s
234/537 (epoch 0.436) train_loss=591.80303955 time/batch=0.17s
235/537 (epoch 0.438) train_loss=307.15002441 time/batch=0.10s
236/537 (epoch 0.439) train_loss=527.99194336 time/batch=0.15s
237/537 (epoch 0.441) train_loss=170.10675049 time/batch=0.07s
238/537 (epoch 0.443) train_loss=251.08644104 time/batch=0.07s
239/537 (epoch 0.445) train_loss=592.11254883 time/batch=0.16s
240/537 (epoch 0.447) train_loss=500.55017090 time/batch=0.15s
241/537 (epoch 0.449) train_loss=675.96496582 time/batch=0.20s
242/537 (epoch 0.451) train_loss=185.00718689 time/batch=0.07s
243/537 (epoch 0.453) train_loss=400.77514648 time/batch=0.11s
244/537 (epoch 0.454) train_loss=543.09448242 time/batch=0.16s
245/537 (epoch 0.456) train_loss=264.92767334 time/batch=0.09s
246/537 (epoch 0.458) train_loss=172.79269409 time/batch=0.06s
247/537 (epoch 0.460) train_loss=267.42669678 time/batch=0.08s
248/537 (epoch 0.462) train_loss=376.33837891 time/batch=0.12s
249/537 (epoch 0.464) train_loss=131.26681519 time/batch=0.05s
250/537 (epoch 0.466) train_loss=388.35470581 time/batch=0.11s
251/537 (epoch 0.467) train_loss=430.23602295 time/batch=0.13s
252/537 (epoch 0.469) train_loss=197.78182983 time/batch=0.07s
253/537 (epoch 0.471) train_loss=391.85806274 time/batch=0.11s
254/537 (epoch 0.473) train_loss=340.69558716 time/batch=0.10s
255/537 (epoch 0.475) train_loss=349.73681641 time/batch=0.11s
256/537 (epoch 0.477) train_loss=500.20324707 time/batch=0.15s
257/537 (epoch 0.479) train_loss=150.96292114 time/batch=0.05s
258/537 (epoch 0.480) train_loss=539.79418945 time/batch=0.16s
259/537 (epoch 0.482) train_loss=297.41665649 time/batch=0.10s
260/537 (epoch 0.484) train_loss=403.14584351 time/batch=0.12s
261/537 (epoch 0.486) train_loss=470.56604004 time/batch=0.14s
262/537 (epoch 0.488) train_loss=423.94116211 time/batch=0.13s
263/537 (epoch 0.490) train_loss=482.36959839 time/batch=0.14s
264/537 (epoch 0.492) train_loss=416.55700684 time/batch=0.13s
265/537 (epoch 0.493) train_loss=400.02258301 time/batch=0.12s
266/537 (epoch 0.495) train_loss=397.02728271 time/batch=0.12s
267/537 (epoch 0.497) train_loss=420.36767578 time/batch=0.13s
268/537 (epoch 0.499) train_loss=225.21614075 time/batch=0.07s
269/537 (epoch 0.501) train_loss=181.51382446 time/batch=0.07s
270/537 (epoch 0.503) train_loss=396.31115723 time/batch=0.11s
271/537 (epoch 0.505) train_loss=304.19610596 time/batch=0.09s
272/537 (epoch 0.507) train_loss=475.79904175 time/batch=0.14s
273/537 (epoch 0.508) train_loss=515.58697510 time/batch=0.15s
274/537 (epoch 0.510) train_loss=401.27679443 time/batch=0.11s
275/537 (epoch 0.512) train_loss=322.04986572 time/batch=0.10s
276/537 (epoch 0.514) train_loss=211.25811768 time/batch=0.07s
277/537 (epoch 0.516) train_loss=576.27111816 time/batch=0.15s
278/537 (epoch 0.518) train_loss=513.82495117 time/batch=0.16s
279/537 (epoch 0.520) train_loss=354.22802734 time/batch=0.11s
280/537 (epoch 0.521) train_loss=515.52728271 time/batch=0.16s
281/537 (epoch 0.523) train_loss=599.72869873 time/batch=0.18s
282/537 (epoch 0.525) train_loss=395.68316650 time/batch=0.12s
283/537 (epoch 0.527) train_loss=417.35137939 time/batch=0.13s
284/537 (epoch 0.529) train_loss=449.83300781 time/batch=0.13s
285/537 (epoch 0.531) train_loss=456.58349609 time/batch=0.14s
286/537 (epoch 0.533) train_loss=191.97348022 time/batch=0.06s
287/537 (epoch 0.534) train_loss=216.88562012 time/batch=0.07s
288/537 (epoch 0.536) train_loss=212.66928101 time/batch=0.07s
289/537 (epoch 0.538) train_loss=247.04492188 time/batch=0.08s
290/537 (epoch 0.540) train_loss=163.35629272 time/batch=0.07s
291/537 (epoch 0.542) train_loss=279.16265869 time/batch=0.08s
292/537 (epoch 0.544) train_loss=375.00149536 time/batch=0.12s
293/537 (epoch 0.546) train_loss=178.44146729 time/batch=0.06s
294/537 (epoch 0.547) train_loss=154.61842346 time/batch=0.06s
295/537 (epoch 0.549) train_loss=313.55175781 time/batch=0.08s
296/537 (epoch 0.551) train_loss=155.41360474 time/batch=0.07s
297/537 (epoch 0.553) train_loss=430.94055176 time/batch=0.11s
298/537 (epoch 0.555) train_loss=389.23022461 time/batch=0.12s
299/537 (epoch 0.557) train_loss=415.99273682 time/batch=0.13s
300/537 (epoch 0.559) train_loss=414.47839355 time/batch=0.12s
301/537 (epoch 0.561) train_loss=244.69111633 time/batch=0.08s
302/537 (epoch 0.562) train_loss=278.51657104 time/batch=0.09s
303/537 (epoch 0.564) train_loss=292.79269409 time/batch=0.09s
304/537 (epoch 0.566) train_loss=357.95684814 time/batch=0.11s
305/537 (epoch 0.568) train_loss=244.48391724 time/batch=0.07s
306/537 (epoch 0.570) train_loss=390.57397461 time/batch=0.11s
307/537 (epoch 0.572) train_loss=166.23898315 time/batch=0.07s
308/537 (epoch 0.574) train_loss=673.48974609 time/batch=0.19s
309/537 (epoch 0.575) train_loss=376.95373535 time/batch=0.13s
310/537 (epoch 0.577) train_loss=348.45114136 time/batch=0.09s
311/537 (epoch 0.579) train_loss=199.96101379 time/batch=0.07s
312/537 (epoch 0.581) train_loss=507.35659790 time/batch=0.14s
313/537 (epoch 0.583) train_loss=495.59939575 time/batch=0.14s
314/537 (epoch 0.585) train_loss=366.31274414 time/batch=0.12s
315/537 (epoch 0.587) train_loss=493.09722900 time/batch=0.14s
316/537 (epoch 0.588) train_loss=429.23922729 time/batch=0.13s
317/537 (epoch 0.590) train_loss=199.52148438 time/batch=0.06s
318/537 (epoch 0.592) train_loss=240.29685974 time/batch=0.08s
319/537 (epoch 0.594) train_loss=338.81860352 time/batch=0.10s
320/537 (epoch 0.596) train_loss=446.58789062 time/batch=0.12s
321/537 (epoch 0.598) train_loss=369.15151978 time/batch=0.12s
322/537 (epoch 0.600) train_loss=462.62112427 time/batch=0.14s
323/537 (epoch 0.601) train_loss=238.57347107 time/batch=0.08s
324/537 (epoch 0.603) train_loss=257.85354614 time/batch=0.08s
325/537 (epoch 0.605) train_loss=190.68063354 time/batch=0.06s
326/537 (epoch 0.607) train_loss=242.33114624 time/batch=0.08s
327/537 (epoch 0.609) train_loss=430.99649048 time/batch=0.12s
328/537 (epoch 0.611) train_loss=194.80862427 time/batch=0.07s
329/537 (epoch 0.613) train_loss=218.27120972 time/batch=0.07s
330/537 (epoch 0.615) train_loss=287.57946777 time/batch=0.10s
331/537 (epoch 0.616) train_loss=465.44769287 time/batch=0.14s
332/537 (epoch 0.618) train_loss=490.59948730 time/batch=0.14s
333/537 (epoch 0.620) train_loss=359.32910156 time/batch=0.11s
334/537 (epoch 0.622) train_loss=170.05920410 time/batch=0.06s
335/537 (epoch 0.624) train_loss=307.25674438 time/batch=0.10s
336/537 (epoch 0.626) train_loss=337.26702881 time/batch=0.11s
337/537 (epoch 0.628) train_loss=197.35372925 time/batch=0.07s
338/537 (epoch 0.629) train_loss=544.76135254 time/batch=0.15s
339/537 (epoch 0.631) train_loss=289.11184692 time/batch=0.09s
340/537 (epoch 0.633) train_loss=557.64758301 time/batch=0.16s
341/537 (epoch 0.635) train_loss=495.76428223 time/batch=0.14s
342/537 (epoch 0.637) train_loss=239.07904053 time/batch=0.09s
343/537 (epoch 0.639) train_loss=242.27243042 time/batch=0.08s
344/537 (epoch 0.641) train_loss=244.16604614 time/batch=0.08s
345/537 (epoch 0.642) train_loss=253.38034058 time/batch=0.08s
346/537 (epoch 0.644) train_loss=555.64874268 time/batch=0.18s
347/537 (epoch 0.646) train_loss=505.62030029 time/batch=0.14s
348/537 (epoch 0.648) train_loss=373.44635010 time/batch=0.12s
349/537 (epoch 0.650) train_loss=292.51275635 time/batch=0.10s
350/537 (epoch 0.652) train_loss=240.08245850 time/batch=0.08s
351/537 (epoch 0.654) train_loss=380.69863892 time/batch=0.11s
352/537 (epoch 0.655) train_loss=357.37847900 time/batch=0.11s
353/537 (epoch 0.657) train_loss=284.23745728 time/batch=0.08s
354/537 (epoch 0.659) train_loss=477.73376465 time/batch=0.12s
355/537 (epoch 0.661) train_loss=338.77914429 time/batch=0.11s
356/537 (epoch 0.663) train_loss=506.54757690 time/batch=0.13s
357/537 (epoch 0.665) train_loss=416.79244995 time/batch=0.12s
358/537 (epoch 0.667) train_loss=201.41432190 time/batch=0.08s
359/537 (epoch 0.669) train_loss=258.86718750 time/batch=0.08s
360/537 (epoch 0.670) train_loss=208.28845215 time/batch=0.07s
361/537 (epoch 0.672) train_loss=260.47006226 time/batch=0.09s
362/537 (epoch 0.674) train_loss=361.34298706 time/batch=0.11s
363/537 (epoch 0.676) train_loss=302.16006470 time/batch=0.10s
364/537 (epoch 0.678) train_loss=229.58403015 time/batch=0.08s
365/537 (epoch 0.680) train_loss=192.85379028 time/batch=0.06s
366/537 (epoch 0.682) train_loss=480.44927979 time/batch=0.13s
367/537 (epoch 0.683) train_loss=421.67510986 time/batch=0.12s
368/537 (epoch 0.685) train_loss=188.44305420 time/batch=0.07s
369/537 (epoch 0.687) train_loss=281.19577026 time/batch=0.08s
370/537 (epoch 0.689) train_loss=270.22296143 time/batch=0.08s
371/537 (epoch 0.691) train_loss=203.65835571 time/batch=0.07s
372/537 (epoch 0.693) train_loss=256.02606201 time/batch=0.07s
373/537 (epoch 0.695) train_loss=164.61054993 time/batch=0.07s
374/537 (epoch 0.696) train_loss=258.10852051 time/batch=0.08s
375/537 (epoch 0.698) train_loss=506.78219604 time/batch=0.13s
376/537 (epoch 0.700) train_loss=458.95233154 time/batch=0.14s
377/537 (epoch 0.702) train_loss=243.29971313 time/batch=0.09s
378/537 (epoch 0.704) train_loss=412.88970947 time/batch=0.12s
379/537 (epoch 0.706) train_loss=398.92922974 time/batch=0.11s
380/537 (epoch 0.708) train_loss=416.15701294 time/batch=0.13s
381/537 (epoch 0.709) train_loss=197.61560059 time/batch=0.06s
382/537 (epoch 0.711) train_loss=160.64422607 time/batch=0.06s
383/537 (epoch 0.713) train_loss=463.71865845 time/batch=0.12s
384/537 (epoch 0.715) train_loss=330.98999023 time/batch=0.11s
385/537 (epoch 0.717) train_loss=253.88626099 time/batch=0.07s
386/537 (epoch 0.719) train_loss=292.23348999 time/batch=0.10s
387/537 (epoch 0.721) train_loss=264.43560791 time/batch=0.08s
388/537 (epoch 0.723) train_loss=460.54589844 time/batch=0.15s
389/537 (epoch 0.724) train_loss=455.82763672 time/batch=0.13s
390/537 (epoch 0.726) train_loss=309.24780273 time/batch=0.10s
391/537 (epoch 0.728) train_loss=294.44439697 time/batch=0.10s
392/537 (epoch 0.730) train_loss=460.27993774 time/batch=0.12s
393/537 (epoch 0.732) train_loss=325.74444580 time/batch=0.10s
394/537 (epoch 0.734) train_loss=338.65197754 time/batch=0.11s
395/537 (epoch 0.736) train_loss=221.94946289 time/batch=0.07s
396/537 (epoch 0.737) train_loss=206.21943665 time/batch=0.07s
397/537 (epoch 0.739) train_loss=378.22717285 time/batch=0.11s
398/537 (epoch 0.741) train_loss=412.41528320 time/batch=0.13s
399/537 (epoch 0.743) train_loss=312.67639160 time/batch=0.10s
400/537 (epoch 0.745) train_loss=260.09423828 time/batch=0.07s
401/537 (epoch 0.747) train_loss=407.13790894 time/batch=0.12s
402/537 (epoch 0.749) train_loss=341.08929443 time/batch=0.12s
403/537 (epoch 0.750) train_loss=314.11578369 time/batch=0.10s
404/537 (epoch 0.752) train_loss=199.29888916 time/batch=0.06s
405/537 (epoch 0.754) train_loss=293.08172607 time/batch=0.10s
406/537 (epoch 0.756) train_loss=402.82891846 time/batch=0.11s
407/537 (epoch 0.758) train_loss=173.77488708 time/batch=0.07s
408/537 (epoch 0.760) train_loss=252.54258728 time/batch=0.07s
409/537 (epoch 0.762) train_loss=325.69812012 time/batch=0.10s
410/537 (epoch 0.764) train_loss=300.28698730 time/batch=0.09s
411/537 (epoch 0.765) train_loss=216.95996094 time/batch=0.07s
412/537 (epoch 0.767) train_loss=329.61566162 time/batch=0.11s
413/537 (epoch 0.769) train_loss=204.13865662 time/batch=0.06s
414/537 (epoch 0.771) train_loss=271.81610107 time/batch=0.08s
415/537 (epoch 0.773) train_loss=297.79534912 time/batch=0.09s
416/537 (epoch 0.775) train_loss=215.74874878 time/batch=0.08s
417/537 (epoch 0.777) train_loss=327.94714355 time/batch=0.10s
418/537 (epoch 0.778) train_loss=251.14515686 time/batch=0.08s
419/537 (epoch 0.780) train_loss=498.59216309 time/batch=0.14s
420/537 (epoch 0.782) train_loss=206.26412964 time/batch=0.08s
421/537 (epoch 0.784) train_loss=192.40182495 time/batch=0.06s
422/537 (epoch 0.786) train_loss=218.06127930 time/batch=0.07s
423/537 (epoch 0.788) train_loss=336.19964600 time/batch=0.09s
424/537 (epoch 0.790) train_loss=281.24575806 time/batch=0.09s
425/537 (epoch 0.791) train_loss=330.27243042 time/batch=0.10s
426/537 (epoch 0.793) train_loss=340.17486572 time/batch=0.10s
427/537 (epoch 0.795) train_loss=354.63983154 time/batch=0.12s
428/537 (epoch 0.797) train_loss=279.76846313 time/batch=0.09s
429/537 (epoch 0.799) train_loss=259.19677734 time/batch=0.09s
430/537 (epoch 0.801) train_loss=187.82318115 time/batch=0.07s
431/537 (epoch 0.803) train_loss=305.61163330 time/batch=0.10s
432/537 (epoch 0.804) train_loss=269.26571655 time/batch=0.08s
433/537 (epoch 0.806) train_loss=188.14620972 time/batch=0.06s
434/537 (epoch 0.808) train_loss=418.90563965 time/batch=0.12s
435/537 (epoch 0.810) train_loss=398.88732910 time/batch=0.12s
436/537 (epoch 0.812) train_loss=470.93652344 time/batch=0.15s
437/537 (epoch 0.814) train_loss=339.05859375 time/batch=0.11s
438/537 (epoch 0.816) train_loss=184.70642090 time/batch=0.06s
439/537 (epoch 0.818) train_loss=300.60021973 time/batch=0.10s
440/537 (epoch 0.819) train_loss=259.17199707 time/batch=0.08s
441/537 (epoch 0.821) train_loss=424.19818115 time/batch=0.12s
442/537 (epoch 0.823) train_loss=309.80242920 time/batch=0.11s
443/537 (epoch 0.825) train_loss=361.29284668 time/batch=0.11s
444/537 (epoch 0.827) train_loss=220.80934143 time/batch=0.07s
445/537 (epoch 0.829) train_loss=181.11425781 time/batch=0.07s
446/537 (epoch 0.831) train_loss=167.41152954 time/batch=0.06s
447/537 (epoch 0.832) train_loss=282.67742920 time/batch=0.09s
448/537 (epoch 0.834) train_loss=157.03001404 time/batch=0.06s
449/537 (epoch 0.836) train_loss=155.86102295 time/batch=0.06s
450/537 (epoch 0.838) train_loss=298.65985107 time/batch=0.09s
451/537 (epoch 0.840) train_loss=268.57101440 time/batch=0.09s
452/537 (epoch 0.842) train_loss=206.36730957 time/batch=0.07s
453/537 (epoch 0.844) train_loss=175.26144409 time/batch=0.07s
454/537 (epoch 0.845) train_loss=284.15814209 time/batch=0.09s
455/537 (epoch 0.847) train_loss=432.48135376 time/batch=0.12s
456/537 (epoch 0.849) train_loss=292.69567871 time/batch=0.10s
457/537 (epoch 0.851) train_loss=224.42617798 time/batch=0.07s
458/537 (epoch 0.853) train_loss=230.03585815 time/batch=0.07s
459/537 (epoch 0.855) train_loss=422.96572876 time/batch=0.12s
460/537 (epoch 0.857) train_loss=212.04772949 time/batch=0.07s
461/537 (epoch 0.858) train_loss=218.30987549 time/batch=0.08s
462/537 (epoch 0.860) train_loss=406.02038574 time/batch=0.12s
463/537 (epoch 0.862) train_loss=203.86163330 time/batch=0.08s
464/537 (epoch 0.864) train_loss=235.14297485 time/batch=0.08s
465/537 (epoch 0.866) train_loss=322.87799072 time/batch=0.10s
466/537 (epoch 0.868) train_loss=257.66027832 time/batch=0.09s
467/537 (epoch 0.870) train_loss=189.90713501 time/batch=0.08s
468/537 (epoch 0.872) train_loss=449.05114746 time/batch=0.13s
469/537 (epoch 0.873) train_loss=258.36859131 time/batch=0.10s
470/537 (epoch 0.875) train_loss=269.04034424 time/batch=0.09s
471/537 (epoch 0.877) train_loss=206.52307129 time/batch=0.07s
472/537 (epoch 0.879) train_loss=274.37878418 time/batch=0.09s
473/537 (epoch 0.881) train_loss=211.12519836 time/batch=0.08s
474/537 (epoch 0.883) train_loss=242.13262939 time/batch=0.09s
475/537 (epoch 0.885) train_loss=293.78985596 time/batch=0.08s
476/537 (epoch 0.886) train_loss=239.66267395 time/batch=0.09s
477/537 (epoch 0.888) train_loss=248.27296448 time/batch=0.08s
478/537 (epoch 0.890) train_loss=444.25363159 time/batch=0.13s
479/537 (epoch 0.892) train_loss=259.09368896 time/batch=0.09s
480/537 (epoch 0.894) train_loss=289.58093262 time/batch=0.10s
481/537 (epoch 0.896) train_loss=291.63082886 time/batch=0.09s
482/537 (epoch 0.898) train_loss=358.72296143 time/batch=0.11s
483/537 (epoch 0.899) train_loss=334.08697510 time/batch=0.11s
484/537 (epoch 0.901) train_loss=359.67047119 time/batch=0.12s
485/537 (epoch 0.903) train_loss=257.00585938 time/batch=0.08s
486/537 (epoch 0.905) train_loss=207.74331665 time/batch=0.08s
487/537 (epoch 0.907) train_loss=323.11938477 time/batch=0.11s
488/537 (epoch 0.909) train_loss=337.13244629 time/batch=0.10s
489/537 (epoch 0.911) train_loss=367.12054443 time/batch=0.11s
490/537 (epoch 0.912) train_loss=368.37564087 time/batch=0.10s
491/537 (epoch 0.914) train_loss=219.53475952 time/batch=0.07s
492/537 (epoch 0.916) train_loss=200.89968872 time/batch=0.08s
493/537 (epoch 0.918) train_loss=222.42358398 time/batch=0.08s
494/537 (epoch 0.920) train_loss=215.83372498 time/batch=0.07s
495/537 (epoch 0.922) train_loss=338.75549316 time/batch=0.11s
496/537 (epoch 0.924) train_loss=304.70562744 time/batch=0.09s
497/537 (epoch 0.926) train_loss=328.51455688 time/batch=0.11s
498/537 (epoch 0.927) train_loss=253.25662231 time/batch=0.09s
499/537 (epoch 0.929) train_loss=306.81274414 time/batch=0.11s
500/537 (epoch 0.931) train_loss=306.99890137 time/batch=0.10s
501/537 (epoch 0.933) train_loss=295.02954102 time/batch=0.09s
502/537 (epoch 0.935) train_loss=294.87231445 time/batch=0.11s
503/537 (epoch 0.937) train_loss=293.13229370 time/batch=0.10s
504/537 (epoch 0.939) train_loss=354.72753906 time/batch=0.12s
505/537 (epoch 0.940) train_loss=253.54440308 time/batch=0.10s
506/537 (epoch 0.942) train_loss=203.31056213 time/batch=0.07s
507/537 (epoch 0.944) train_loss=262.73132324 time/batch=0.09s
508/537 (epoch 0.946) train_loss=256.72058105 time/batch=0.09s
509/537 (epoch 0.948) train_loss=255.32067871 time/batch=0.08s
510/537 (epoch 0.950) train_loss=254.54144287 time/batch=0.08s
511/537 (epoch 0.952) train_loss=226.60946655 time/batch=0.08s
512/537 (epoch 0.953) train_loss=308.37789917 time/batch=0.10s
513/537 (epoch 0.955) train_loss=216.19348145 time/batch=0.07s
514/537 (epoch 0.957) train_loss=258.81860352 time/batch=0.09s
515/537 (epoch 0.959) train_loss=196.74134827 time/batch=0.07s
516/537 (epoch 0.961) train_loss=262.16403198 time/batch=0.09s
517/537 (epoch 0.963) train_loss=327.54357910 time/batch=0.11s
518/537 (epoch 0.965) train_loss=195.32489014 time/batch=0.06s
519/537 (epoch 0.966) train_loss=339.22326660 time/batch=0.11s
520/537 (epoch 0.968) train_loss=277.03610229 time/batch=0.10s
521/537 (epoch 0.970) train_loss=260.38073730 time/batch=0.09s
522/537 (epoch 0.972) train_loss=214.16833496 time/batch=0.08s
523/537 (epoch 0.974) train_loss=222.74981689 time/batch=0.08s
524/537 (epoch 0.976) train_loss=282.00961304 time/batch=0.09s
525/537 (epoch 0.978) train_loss=219.60540771 time/batch=0.07s
526/537 (epoch 0.980) train_loss=260.71691895 time/batch=0.08s
527/537 (epoch 0.981) train_loss=201.67068481 time/batch=0.07s
528/537 (epoch 0.983) train_loss=225.08460999 time/batch=0.09s
529/537 (epoch 0.985) train_loss=217.15093994 time/batch=0.08s
530/537 (epoch 0.987) train_loss=345.95074463 time/batch=0.10s
531/537 (epoch 0.989) train_loss=257.86480713 time/batch=0.08s
532/537 (epoch 0.991) train_loss=293.26654053 time/batch=0.10s
533/537 (epoch 0.993) train_loss=260.74478149 time/batch=0.10s
534/537 (epoch 0.994) train_loss=316.87405396 time/batch=0.11s
535/537 (epoch 0.996) train_loss=292.16467285 time/batch=0.10s
536/537 (epoch 0.998) train_loss=291.39450073 time/batch=0.10s
537/537 (epoch 1.000) train_loss=252.06269836 time/batch=0.11s
  saved to metadata/AddSharpAndFlat-20190201-021958
Traceback (most recent call last):
  File "train_rnn.py", line 253, in <module>
    json.dump(training_loss_list,open(metadata_target_path+".json","w"))
  File "D:\Anaconda\lib\json\__init__.py", line 189, in dump
    for chunk in iterable:
  File "D:\Anaconda\lib\json\encoder.py", line 431, in _iterencode
    for chunk in _iterencode_list(o, _current_indent_level):
  File "D:\Anaconda\lib\json\encoder.py", line 332, in _iterencode_list
    for chunk in chunks:
  File "D:\Anaconda\lib\json\encoder.py", line 442, in _iterencode
    o = _default(o)
  File "D:\Anaconda\lib\json\encoder.py", line 184, in default
    raise TypeError(repr(o) + " is not JSON serializable")
TypeError: array(3921.3796, dtype=float32) is not JSON serializable
